{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "455f4fc9-2d60-4de0-9177-dcb2abd5972a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "    \n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d4dd3fc6-aa5e-4f09-aa99-97ac24689e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Hello, world. This, is a test.\"\n",
    "result = re.split(r'(\\s)', text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ffe44724-a00a-40b9-8464-103b50028fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world. Is this-- a test?\"\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0a18a4f6-18fc-4b4d-a7af-8e11ada501ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world. Is this-- a test?\"\n",
    "\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "71d3ce45-de9e-4d08-a6fb-c6c2aeb81a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(preprocessed[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4f752954-2f17-4579-9831-c98279849190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n"
     ]
    }
   ],
   "source": [
    "print(len(preprocessed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "17033ba2-0879-486d-89b8-9265d7ad460b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "79dfa5a9-6f1f-4675-b738-7d4809b4a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4fc82880-3d69-4998-bb53-7632bf0e737a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n",
      "('Burlington', 21)\n",
      "('But', 22)\n",
      "('By', 23)\n",
      "('Carlo', 24)\n",
      "('Chicago', 25)\n",
      "('Claude', 26)\n",
      "('Come', 27)\n",
      "('Croft', 28)\n",
      "('Destroyed', 29)\n",
      "('Devonshire', 30)\n",
      "('Don', 31)\n",
      "('Dubarry', 32)\n",
      "('Emperors', 33)\n",
      "('Florence', 34)\n",
      "('For', 35)\n",
      "('Gallery', 36)\n",
      "('Gideon', 37)\n",
      "('Gisburn', 38)\n",
      "('Gisburns', 39)\n",
      "('Grafton', 40)\n",
      "('Greek', 41)\n",
      "('Grindle', 42)\n",
      "('Grindles', 43)\n",
      "('HAD', 44)\n",
      "('Had', 45)\n",
      "('Hang', 46)\n",
      "('Has', 47)\n",
      "('He', 48)\n",
      "('Her', 49)\n",
      "('Hermia', 50)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3285139f-4ba8-4e27-8179-43e1ab402196",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "                                \n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0a3ec2c6-d634-42f2-a80a-f01820c1e3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cea09167-d1e5-4265-a335-5af29216b84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "89360933-faea-4e75-a2a7-1d03cf5e5d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.ci.artifacts.walmart.com/artifactory/api/pypi/external-pypi/simple\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x103334ee0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /artifactory/api/pypi/external-pypi/simple/tiktoken/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x1033351e0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /artifactory/api/pypi/external-pypi/simple/tiktoken/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x103335390>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /artifactory/api/pypi/external-pypi/simple/tiktoken/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x103335540>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /artifactory/api/pypi/external-pypi/simple/tiktoken/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x1033356f0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /artifactory/api/pypi/external-pypi/simple/tiktoken/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement tiktoken (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tiktoken\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip3 install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "55e90a6f-88a3-4a18-b376-f0872135e219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2e3089bd-32ac-455a-8629-88b45c473d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c2ead28b-b969-456b-bc84-ca711d8ede42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\"\n",
    ")\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e0cf7abf-899b-4d1c-897d-ba50a97a092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "70bec81c-8ad7-4a29-a010-a7bbbceca855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33901, 86, 343, 86, 220, 959]\n",
      "Akwirw ier\n"
     ]
    }
   ],
   "source": [
    "integers = tokenizer.encode(\"Akwirw ier\")\n",
    "print(integers)\n",
    "\n",
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "60d11b24-cd90-4d45-922d-0f4bcd3c41b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary size for GPT2 is: 50257\n",
      "The vocabulary size for GPT3 is: 50281\n",
      "The vocabulary size for GPT4 is: 100277\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Initialize the encodings for GPT-2, GPT-3, and GPT-4\n",
    "encodings = {\n",
    "    \"gpt2\": tiktoken.get_encoding(\"gpt2\"),\n",
    "    \"gpt3\": tiktoken.get_encoding(\"p50k_base\"),  # Commonly associated with GPT-3 models\n",
    "    \"gpt4\": tiktoken.get_encoding(\"cl100k_base\")  # Used for GPT-4 and later versions\n",
    "}\n",
    "\n",
    "# Get the vocabulary size for each encoding\n",
    "vocab_sizes = {model: encoding.n_vocab for model, encoding in encodings.items()}\n",
    "\n",
    "# Print the vocabulary sizes\n",
    "for model, size in vocab_sizes.items():\n",
    "    print(f\"The vocabulary size for {model.upper()} is: {size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "12598d43-06a3-4bff-af21-a620b903f098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "06498df8-899b-4807-98c8-5d8c0278f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ad5dea71-62a8-4866-ad7f-29f5e85ee06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:      [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4 #length of the input\n",
    "#The context_size of 4 means that the model is trained to look at a sequence of 4 words (or tokens) \n",
    "#to predict the next word in the sequence. \n",
    "#The input x is the first 4 tokens [1, 2, 3, 4], and the target y is the next 4 tokens [2, 3, 4, 5]\n",
    "\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f8593076-f669-482d-9942-8efc2bd0a69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----> 4920\n",
      "[290, 4920] ----> 2241\n",
      "[290, 4920, 2241] ----> 287\n",
      "[290, 4920, 2241, 287] ----> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    print(context, \"---->\", desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "27a99457-bba4-4741-b603-c51822c7bfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8ffed6f2-3cb2-4b67-957c-c1a4cd4ef27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "38fdc702-cc43-410c-b529-4d919163115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f506b28b-c1c0-41b0-96d5-b0443a9267ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "829f808e-f331-4c12-b2f1-36ce0b5af30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.0\n",
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7b8d0e52-b760-4865-9bd3-088353a41042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "895b5de7-c8d1-4027-9f8f-47e535ad9e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3a753bb9-d149-4313-9e54-6742f9b776d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d616a3ab-a3f3-4917-932c-0873645676a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "42324830-28eb-479a-8c9a-cd205e2df583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cd2be17e-e7f6-44a0-95fe-fd1d5f21bb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9b618885-d5a6-4205-9c01-53416bbea75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7344af0d-59ca-41b3-9e01-fc16a213409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0994e480-a622-41ff-82e8-85ca53d4609e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9bf14fe0-50b2-474e-a99b-6f061dd1feea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3a742716-f8f6-4a81-a7d4-77f96bab4076",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8ad3368f-5bd1-42d5-83e5-4c0624773acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1a6428aa-dd3e-4f54-89de-0f80a545147c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4a9226f5-39bf-46c3-8012-590f7a67e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simplified Attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0a85ccdb-cfdb-46bf-b4a3-66a86b50a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c587fb31-c58b-4d8e-a348-8aaa1c88efd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]  # 2nd input token is the query\n",
    "\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query) # dot product (transpose not necessary here since they are 1-dim vectors)\n",
    "\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8676fa79-e8e9-4578-b63e-1d9f21448354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum: tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
    "\n",
    "print(\"Attention weights:\", attn_weights_2_tmp)\n",
    "print(\"Sum:\", attn_weights_2_tmp.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fa516e3a-b940-43fe-ac9a-d83b5068f45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "print(\"Attention weights:\", attn_weights_2)\n",
    "print(\"Sum:\", attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3c303afb-dc97-409e-a702-bb47dfe181a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1] # 2nd input token is the query\n",
    "\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i,x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i]*x_i\n",
    "\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "697de719-3ccc-495c-9e1d-4988542f5ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = torch.empty(6, 6)\n",
    "\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        attn_scores[i, j] = torch.dot(x_i, x_j)\n",
    "\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f4f32b04-7af3-47a4-886c-f7e2315f0a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = inputs @ inputs.T\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "549e5142-2673-4190-be76-33dce165accb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "95167c1b-a017-48be-972d-3815e0672d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2 sum: 1.0\n",
      "All row sums: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "row_2_sum = sum([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
    "print(\"Row 2 sum:\", row_2_sum)\n",
    "print(\"All row sums:\", attn_weights.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "902ac242-93b9-40e2-916f-5e4a63e96223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "all_context_vecs = attn_weights @ inputs\n",
    "print(all_context_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a0073902-c665-468c-8c6f-190db4226956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous 2nd context vector: tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "print(\"Previous 2nd context vector:\", context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e87a3ad2-817b-4475-bc27-a965759d7568",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPLEMENTING SELF ATTENTION WITH TRAINABLE WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "09e1aedc-5654-4086-8ba0-587ce67467eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "242bba3a-8531-4bb5-9951-a99330c00836",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1] #A\n",
    "d_in = inputs.shape[1] #B\n",
    "d_out = 2 #C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "de771f4f-e75b-4395-a3bf-0b7e69825aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1e76d163-7b3b-4813-bfe1-40988cdadcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.2961, 0.5166],\n",
      "        [0.2517, 0.6886],\n",
      "        [0.0740, 0.8665]])\n"
     ]
    }
   ],
   "source": [
    "print(W_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5308b19c-c1b8-45fa-8f89-ca45d7c84404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n"
     ]
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "print(query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "116101f1-9d23-4ff4-8d75-d73c400c2871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n",
      "queries.shape: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "queries = inputs @ W_query\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "\n",
    "print(\"values.shape:\", values.shape)\n",
    "\n",
    "print(\"queries.shape:\", queries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "72f1c255-3848-4ec3-8a00-3e9235f47292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8524)\n"
     ]
    }
   ],
   "source": [
    "keys_2 = keys[1] #A\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "print(attn_score_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3484e3f3-e8f3-454c-a233-74199e574d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "attn_scores_2 = query_2 @ keys.T # All attention scores for given query\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "33e5ab3c-7a6e-468a-9cb6-b624602df889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9231, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],\n",
      "        [1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],\n",
      "        [1.2544, 1.8284, 1.7877, 1.0654, 0.5508, 1.5238],\n",
      "        [0.6973, 1.0167, 0.9941, 0.5925, 0.3061, 0.8475],\n",
      "        [0.6114, 0.8819, 0.8626, 0.5121, 0.2707, 0.7307],\n",
      "        [0.8995, 1.3165, 1.2871, 0.7682, 0.3937, 1.0996]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = queries @ keys.T # omega\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2b438c01-314e-4165-8241-f0cbd5558659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "d_k = keys.shape[-1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
    "print(attn_weights_2)\n",
    "print(d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7a5560b8-982c-410e-adcd-5018f2143268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax without scaling: tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n",
      "Softmax after scaling (tensor * 8): tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the tensor\n",
    "tensor = torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])\n",
    "\n",
    "# Apply softmax without scaling\n",
    "softmax_result = torch.softmax(tensor, dim=-1)\n",
    "print(\"Softmax without scaling:\", softmax_result)\n",
    "\n",
    "# Multiply the tensor by 8 and then apply softmax\n",
    "scaled_tensor = tensor * 8\n",
    "softmax_scaled_result = torch.softmax(scaled_tensor, dim=-1)\n",
    "print(\"Softmax after scaling (tensor * 8):\", softmax_scaled_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8699a11b-9bb0-4971-be06-4a160903bc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "context_vec_2 = attn_weights_2 @ values\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b1879007-6766-4c22-9272-d1c07ab96b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "        \n",
    "        attn_scores = queries @ keys.T # omega\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ac7161cd-ec89-46a9-9271-f7165a8b3898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ae19b0f1-2816-4a04-9dec-f99b7607d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "2edf8866-92fb-4d05-ac7e-b200c6aac49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b7f32bda-2095-4967-9a42-10c371b360dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "735432ec-3909-49c0-bad2-057e43d32943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
      "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
      "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs) #A\n",
    "keys = sa_v2.W_key(inputs)\n",
    "attn_scores = queries @ keys.T\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "218c04df-269b-464c-a695-4e8cca09144c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(context_length, context_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "75dc406b-f098-4c22-8ce3-a3d5de1ceffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "context_length = attn_scores.shape[0]\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "print(mask_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7036af03-800e-45bf-93bf-144b69fbe340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "masked_simple = attn_weights*mask_simple\n",
    "print(masked_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1686eca1-f118-4431-9f9a-272ae3f39455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "row_sums = masked_simple.sum(dim=1, keepdim=True)\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "print(masked_simple_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "cef94b69-d95d-42bc-96ad-b5e518ab08c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2899,  0.0716,  0.0760, -0.0138,  0.1344, -0.0511],\n",
      "        [ 0.4656,  0.1723,  0.1751,  0.0259,  0.1771,  0.0085],\n",
      "        [ 0.4594,  0.1703,  0.1731,  0.0259,  0.1745,  0.0090],\n",
      "        [ 0.2642,  0.1024,  0.1036,  0.0186,  0.0973,  0.0122],\n",
      "        [ 0.2183,  0.0874,  0.0882,  0.0177,  0.0786,  0.0144],\n",
      "        [ 0.3408,  0.1270,  0.1290,  0.0198,  0.1290,  0.0078]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e1018d0f-99e8-41ed-ad18-86ac7cfb255c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(torch.ones(context_length, context_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "46d5fb44-1a75-48fd-ba42-8f1eaeb4ef9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d2bbe754-10c4-49b0-a808-717d46c6d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c7a81c16-978d-458e-b1dd-bedce20e9fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b5e0c011-de43-4ecb-82bd-7f2655a47bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##IMPLEMENTING A COMPACT CAUSAL ATTENTION CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "5fe24f71-b560-427a-ae2c-e969a675f98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a5a84a26-230d-415d-a17d-0689f4cdf5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length,\n",
    "                 dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout) # New\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1)) # New\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape # New batch dimension b\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1, 2) # Changed transpose\n",
    "        attn_scores.masked_fill_(  # New, _ ops are in-place\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)  # `:num_tokens` to account for cases where the number of tokens in the batch is smaller than the supported context_size\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        attn_weights = self.dropout(attn_weights) # New\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e06a3e56-fe44-43ac-ae5d-8ece6bbf1c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(d_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6bbebc3c-5e2d-4ee0-a5de-7f4e2c0c5370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(d_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "08eb6f6a-ee0e-46af-b0d5-d08c8e1ae409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "context_vecs = ca(batch)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c053e057-5c33-43ba-a3be-6ad762955b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]],\n",
      "\n",
      "        [[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(context_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7fed428a-eef2-42e8-bb2c-2d4bbe27e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias) \n",
    "             for _ in range(num_heads)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e0b240f8-f9a8-4893-ac9c-552015a3a29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7c9cf250-2bd6-475d-a9e9-bdb7360302d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1] # This is the number of tokens = 6\n",
    "d_in, d_out = 3, 2\n",
    "mha = MultiHeadAttentionWrapper(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b38cc8e9-3571-4d83-8d6c-d873a5e7babc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPLEMENTING MULTI-HEAD ATTENTION WITH WEIGHT SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "af61955a-0510-4a2a-b936-111e3b2f2aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "36be8b34-a9fb-4644-b336-93ad922d5c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 6])\n",
      "tensor([[[ 0.1569, -0.0873,  0.0210,  0.0215, -0.3243, -0.2518],\n",
      "         [ 0.1117, -0.0547,  0.0406, -0.0213, -0.3251, -0.2993],\n",
      "         [ 0.1196, -0.0491,  0.0318, -0.0635, -0.2788, -0.2578]],\n",
      "\n",
      "        [[ 0.1569, -0.0873,  0.0210,  0.0215, -0.3243, -0.2518],\n",
      "         [ 0.1117, -0.0547,  0.0406, -0.0213, -0.3251, -0.2993],\n",
      "         [ 0.1196, -0.0491,  0.0318, -0.0635, -0.2788, -0.2578]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# Define the tensor with 3 rows and 6 columns\n",
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89, 0.55, 0.87, 0.66],  # Row 1\n",
    "     [0.57, 0.85, 0.64, 0.22, 0.58, 0.33],  # Row 2\n",
    "     [0.77, 0.25, 0.10, 0.05, 0.80, 0.55]]  # Row 3\n",
    ")\n",
    "\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape) \n",
    "\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 6\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "060dd86e-63f5-48e6-871e-87a16cc907ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPLEMENTING A GPT MODEL FROM SCRATCH TO GENERATE TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "2b674653-584d-4c97-86d1-91a87b133cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "322b91ca-f080-4711-8b89-4ed798fb2c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        # Use a placeholder for TransformerBlock\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        # Use a placeholder for LayerNorm\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # A simple placeholder\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This block does nothing and just returns its input.\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # The parameters here are just to mimic the LayerNorm interface.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This layer does nothing and just returns its input.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e3e1f09d-c64b-4fbd-96d9-1816f2a9a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 1: TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c1a2be70-ccbe-4d4b-b8f2-ec04efaeb124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "3987d648-e766-4e28-8eed-e9a398c8e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 2: CREATE AN INSTANCE OF DUMMYGPTMODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1b48023c-3f85-487a-81a6-9c9e61b88f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6755, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "41816846-bbbc-47f1-bad7-8617c1a2bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "##GPT ARCHITECTURE PART 2: LAYER NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "753a6503-70fc-4f93-a25f-cc7f368dfdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5) #A\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "4c8c8060-fa18-4af4-8880-0c6f2a705d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "90a665be-d3c1-49cc-8803-72ea22e0e7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "3ea90ebc-ffdb-4208-ac60-4182fd780300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e734ae00-eec9-4fa4-a44a-aaa0225b3457",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ed542caf-1b24-47e9-bdd2-13d4f4eb70cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "305d884d-76d9-4c85-8d22-3a43f0809acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPT ARCHITECTURE PART 3: FEEDFORWARD NEURAL NETWORK WITH GELU ACTIVATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "1c489637-6f74-45b1-8a2a-0eec4b14305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "af1b98f7-1681-4a0b-953d-9ef969c7a87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAEiCAYAAABkykQ1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABrLUlEQVR4nO3deVhUZfsH8O8wwLDIIjsomxvuiqCJuaQmJlpqm1supf7ErTfRVLQybdHUt6zcy/RV0twyK9GgErTUBMQlcV9AERREdhhmOb8/iMkRUIbtzAzfz3XNVXPmnDP3zeA83Oc8i0QQBAFEREREREQ1YCJ2AEREREREZPhYWBARERERUY2xsCAiIiIiohpjYUFERERERDXGwoKIiIiIiGqMhQUREREREdUYCwsiIiIiIqoxFhZERERERFRjLCyIiIiIiKjGWFg0QGfPnsXEiRPRvHlzWFpawtLSEi1btsSUKVMQHx+vte/7778PiURS6ePmzZuafSUSCWbMmFHp+z7zzDNo3759ha9lZmZCIpHg/fffr40Uq2zt2rXYsmVLue03b96ERCKp8LXakpSUhPfff1/rZ1hmwoQJ8PHxqbP3fpybN29i8ODBcHBwgEQiwVtvvSVKHABQWFiI999/HzExMeVe27JlS7nfQSKqvrJ/U2UPU1NTuLu7Y+TIkbhy5Uq1zhkTEwOJRII9e/ZUus/j2o49e/ZAIpFU+B1QV8T+3omMjKy0LfTx8cGECRPq7L0f57fffkNgYCCsra0hkUjwww8/iBIHoL/tJwGmYgdA9WvDhg2YMWMG/Pz88J///Aft2rWDRCLBhQsXsGPHDnTt2hVXr15F8+bNtY47dOgQ7Ozsyp3P3d29vkKvE2vXroWTk1O5L2p3d3ccP3683M+hNiUlJWHx4sV45plnyn0Jvvvuu/jPf/5TZ+/9OLNmzcJff/2Fb775Bm5ubqJ+xoWFhVi8eDGA0sL0YYMHD8bx48cN/neQSN9s3rwZrVu3RnFxMf7880989NFHOHz4MC5evIjGjRuLHV6dE/t7JzIyEmvWrKmwuNi3bx9sbW3r7L0rIwgCXn31VbRq1Qo//vgjrK2t4efnV+9xlNHX9pNYWDQof/75J6ZNm4bBgwdjz549MDc317zWr18/TJ8+Hbt374alpWW5YwMCAuDk5FSf4YpKJpOhe/fuor1/XRY0T/L333+jW7duGDZsmGgxVIWzszOcnZ3FDoPI6LRv3x6BgYEASv+wVqlUWLRoEX744Qe8/vrrIkcnLrG/d/z9/UV53zt37iArKwvDhw9H//79RYmhqsRsP4ldoRqUjz/+GFKpFBs2bNAqKh72yiuvwMPDo54jq7ri4mLMnj0bnTt3hp2dHRwcHBAUFIT9+/eX21etVuPLL79E586dYWlpCXt7e3Tv3h0//vgjgNJbyufPn0dsbKzm1n/ZlY9Hu0L98MMPkEgk+O2338q9z7p16yCRSHD27FkAQHx8PEaOHAkfHx9YWlrCx8cHo0aNQnJysuaYLVu24JVXXgEA9O3bV/P+Ze9X0a3c4uJihIeHw9fXF+bm5mjSpAmmT5+O7Oxsrf18fHwwZMgQHDp0CF26dIGlpSVat26Nb7755rE/27IuC1evXsXBgwe1urtVdvu/7JiHuwyUdXmLi4tDr169YGVlhWbNmmHZsmVQq9Vax2dnZ2P27Nlo1qwZZDIZXFxcEBISgosXL+LmzZuaBnzx4sWaeMruLlUW0zfffINOnTrBwsICDg4OGD58OC5cuKC1z4QJE9CoUSNcvXoVISEhaNSoETw9PTF79mzI5fLH/pyIGpqyIuPu3bta2+Pj4/HCCy/AwcEBFhYW8Pf3x65du8QIEVevXsXrr7+Oli1bwsrKCk2aNMHzzz+Pc+fOldu3Nr933nrrLVhbWyM3N7fc+4wYMQKurq5QKBQAgJ07dyI4OBju7u6wtLREmzZtMH/+fBQUFGiOmTBhAtasWQMAFXY7rqgrVEpKCl577TW4uLhAJpOhTZs2+O9//6v1fVvWpq1cuRKffvopfH190ahRIwQFBeHEiROP/dm+//77aNq0KQBg3rx5Wm1lZd2OyrpRP6ysy9u2bdvQpk0bWFlZoVOnTvj555/LHX/x4kWMGjUKrq6ukMlk8PLywrhx4yCXy/Wy/aR/8Y5FA6FSqXD48GEEBgZW6xauSqWCUqnU2iaRSCCVSmsrxCqRy+XIysrCnDlz0KRJE5SUlODXX3/Fiy++iM2bN2PcuHGafSdMmICIiAhMnDgRS5Ysgbm5OU6dOqX5gt63bx9efvll2NnZYe3atQBK71RUZMiQIXBxccHmzZvLXa3ZsmULunTpgo4dOwIo/QL38/PDyJEj4eDggLS0NKxbtw5du3ZFUlISnJycMHjwYHz88cdYsGAB1qxZgy5dugCo/EqLIAgYNmwYfvvtN4SHh6NXr144e/YsFi1ahOPHj+P48eNasZ85cwazZ8/G/Pnz4erqiq+//hoTJ05EixYt0Lt37wrfo0uXLjh+/DiGDx+O5s2bY+XKlQCq190tPT0dY8aMwezZs7Fo0SLs27cP4eHh8PDw0HxGeXl56NmzJ27evIl58+bhqaeeQn5+Po4cOYK0tDT06NEDhw4dwnPPPYeJEydi0qRJAPDYq4VLly7FggULMGrUKCxduhT379/H+++/j6CgIMTFxaFly5aafRUKBV544QVMnDgRs2fPxpEjR/DBBx/Azs4O7733ns45ExmrGzduAABatWql2Xb48GE899xzeOqpp7B+/XrY2dnhu+++w4gRI1BYWFjv4wDu3LkDR0dHLFu2DM7OzsjKysL//vc/PPXUU0hMTNR026nt75033ngDn3/+OXbt2qXZFygtXvbv34/p06fDzMwMAHDlyhWEhIRoipGLFy/ik08+wcmTJ/H7778DKO3GU1BQgD179uD48eOa81X2PZyRkYEePXqgpKQEH3zwAXx8fPDzzz9jzpw5uHbtmqZtK7NmzRq0bt0aq1at0rxfSEgIbty4UWF3ZwCYNGkSOnXqhBdffBEzZ87E6NGjK20rn+TAgQOIi4vDkiVL0KhRIyxfvhzDhw/HpUuX0KxZMwCl7VfPnj3h5OSEJUuWoGXLlkhLS8OPP/6IkpISvWw/6SECNQjp6ekCAGHkyJHlXlMqlYJCodA81Gq15rVFixYJACp8NG/eXOs8AITp06dXGkOfPn2Edu3aVfhaRkaGAEBYtGiRTnmVxT5x4kTB399fs/3IkSMCAGHhwoWPPb5du3ZCnz59ym2/ceOGAEDYvHmzZltYWJhgaWkpZGdna7YlJSUJAIQvv/zysTHm5+cL1tbWwueff67Zvnv3bgGAcPjw4XLHjB8/XvD29tY8P3TokABAWL58udZ+O3fuFAAIGzdu1Gzz9vYWLCwshOTkZM22oqIiwcHBQZgyZUqlcT58/ODBg7W2bd68WQAg3LhxQ2v74cOHy+XQp08fAYDw119/ae3btm1bYeDAgZrnS5YsEQAI0dHRlcbyuN+LR2N68OCBYGlpKYSEhGjtl5KSIshkMmH06NGabePHjxcACLt27dLaNyQkRPDz86s0HiJjVvZv6sSJE4JCoRDy8vKEQ4cOCW5ubkLv3r0FhUKh2bd169aCv7+/1jZBEIQhQ4YI7u7ugkqlEgTh3++I3bt3V/q+j2s7Hvc9+ThKpVIoKSkRWrZsKcyaNUuzvba/dwRBELp06SL06NFDa7+1a9cKAIRz585V+B5qtVpQKBRCbGysAEA4c+aM5rXp06cLlf155u3tLYwfP17zfP78+RV+306dOlWQSCTCpUuXBEH4t03r0KGDoFQqNfudPHlSACDs2LGjwvcrU3b8ihUrtLY/2laVKfvb4WEABFdXVyE3N1ezLT09XTAxMRGWLl2q2davXz/B3t5euHfvXqXx6Gv7SYLArlCEgIAAmJmZaR7//e9/y+3z66+/Ii4uTush1owQu3fvxtNPP41GjRrB1NQUZmZm2LRpk1Z3l4MHDwIApk+fXmvv+8Ybb6CoqAg7d+7UbNu8eTNkMhlGjx6t2Zafn4958+ahRYsWMDU1hampKRo1aoSCgoJyXXKqquxq1qNXAV955RVYW1uX66LVuXNneHl5aZ5bWFigVatWWt2x6pKbmxu6deumta1jx45a73/w4EG0atUKzz77bK285/Hjx1FUVFTuZ+Tp6Yl+/fqV+xlJJBI8//zzj42RqCHq3r07zMzMYGNjg+eeew6NGzfG/v37YWpa2snh6tWruHjxIsaMGQMAUCqVmkdISAjS0tJw6dKleo1ZqVTi448/Rtu2bWFubg5TU1OYm5vjypUr5dqG2vzeAYDXX38dx44d08p58+bN6Nq1q9ZMiNevX8fo0aPh5uYGqVQKMzMz9OnTBwBq1Da0bdu23PfthAkTIAiCpu0oM3jwYK2eBmV32uvre69v376wsbHRPHd1dYWLi4vm/QsLCxEbG4tXX3211sayGFr7aehYWDQQTk5OsLS0rPAfxvbt2xEXF6cZe1CRTp06ITAwUOtR2dSxlTE1NYVKparwtbJuVmW3jCvz/fff49VXX0WTJk0QERGB48ePIy4uDm+88QaKi4s1+2VkZEAqlcLNzU2nGB+nXbt26Nq1KzZv3gygtHtYREQEhg4dCgcHB81+o0ePxurVqzFp0iT88ssvOHnyJOLi4uDs7IyioqJqvff9+/dhampa7otWIpHAzc0N9+/f19ru6OhY7hwymaza76+rqrx/RkaGpt9ubSj7GVTUZcDDw6Pcz8jKygoWFhblYnz494ioIdq6dSvi4uLw+++/Y8qUKbhw4QJGjRqleb1srMWcOXO0LkqZmZlh2rRpAEqnEK8qqVRa47YhLCwM7777LoYNG4affvoJf/31F+Li4tCpU6c6/d4BgDFjxkAmk2n6+CclJSEuLk5roHt+fj569eqFv/76Cx9++CFiYmIQFxeH77//HgBq1DZU9p1X9vrDHv1uLusCpC9tw4MHD6BSqWq9bTCk9tPQcYxFAyGVStGvXz9ERUUhLS1N64uobdu2AFDn6wG4uroiLi4OgiCUG9SVmpqq2edxIiIi4Ovri507d2qd49EBt87OzlCpVEhPT6/VaQFff/11TJs2DRcuXMD169eRlpam1Xjk5OTg559/xqJFizB//nyt+LKysqr9vo6OjlAqlcjIyND6chQEAenp6ejatWu1z10VZX+AP/pz1uWPh0c5Ozvj9u3bNYrrYWWNQVpaWrnX7ty506BmNSOqiTZt2mgGbPft2xcqlQpff/019uzZg5dfflnzbyk8PBwvvvhihefQZSpSV1dXTRvwKF3ahnHjxuHjjz/W2p6ZmQl7e3vN89r+3gGAxo0bY+jQodi6dSs+/PBDbN68GRYWFlrF2O+//447d+4gJiZGc5cCQLnBw7pydHSs9DsPQJ1/71lYWFQ44UV12wYHBwdIpdJabxvEbD8bGt6xaEDCw8OhUqkQGhqqmaWiPj377LPIzc3FoUOHyr22a9cumJiYoF+/fo89h0Qigbm5uVZRkZ6eXm5WqEGDBgEonbHpcXS9CjFq1ChYWFhgy5Yt2LJlC5o0aYLg4GCt+ARBKDew7euvvy53RU6XK0VlA8YjIiK0tu/duxcFBQV1Pv1f2QwbZTNflXncXa4nGTRoEC5fvlzuVv3DdPkZBQUFwdLSstzP6Pbt2/j999/1fopEIn21fPlyNG7cGO+99x7UajX8/PzQsmVLnDlzptyd7LLHw91dnuTZZ5/F4cOHkZGRobVdEATs3r0bPj4+aNGixWPPIZFIyn3vHjhwoFzBUtvfO2Vef/113LlzB5GRkYiIiMDw4cO1CpqyNuvRGDds2FCj9+/fvz+SkpJw6tQpre1bt26FRCJB3759q5xDdfj4+ODevXtaM4aVlJTgl19+qdb5LC0t0adPH+zevfuxxYkhtZ8NDe9YNCBPP/001qxZg5kzZ6JLly74v//7P7Rr1w4mJiZIS0vD3r17AaDCxXcSEhIqnDGibdu2Wvtfu3atwhVW27ZtizFjxmDt2rV49dVXMX/+fHTt2hVFRUWIjIzEV199hZkzZ2pmhajMkCFD8P3332PatGl4+eWXcevWLXzwwQdwd3fXWhm2V69eGDt2LD788EPcvXsXQ4YMgUwmQ2JiIqysrDBz5kwAQIcOHfDdd99h586daNasGSwsLNChQ4dK39/e3h7Dhw/Hli1bkJ2djTlz5sDE5N/63NbWFr1798aKFSvg5OQEHx8fxMbGYtOmTVqNDABNV7KNGzfCxsYGFhYW8PX1rfA27IABAzBw4EDMmzcPubm5ePrppzWzWvj7+2Ps2LGP/bnVVNeuXeHn54c5c+ZAqVSicePG2LdvH/74449qn/Ott97Czp07MXToUMyfPx/dunVDUVERYmNjMWTIEE1fXG9vb+zfvx/9+/eHg4OD5uf6KHt7e7z77rtYsGABxo0bh1GjRuH+/ftYvHgxLCwssGjRohr8BIgarsaNGyM8PBxz587F9u3b8dprr2HDhg0YNGgQBg4ciAkTJqBJkybIysrChQsXcOrUKezevVvrHJVNadqnTx+89957+Omnn/DUU09h/vz5aNmyJdLT0/HVV18hLi6uSlPYDhkyBFu2bEHr1q3RsWNHJCQkYMWKFeW61NT2906Z4OBgNG3aFNOmTUN6enq59T569OiBxo0bIzQ0FIsWLYKZmRm+/fZbnDlzpty5ytqgTz75BIMGDYJUKkXHjh0rnCZ+1qxZ2Lp1KwYPHowlS5bA29sbBw4cwNq1azF16lStmbzqwogRI/Dee+9h5MiRePvtt1FcXIwvvvii0q5tVfHpp5+iZ8+emt+HFi1a4O7du/jxxx+xYcMG2NjYGFT72eCIOXKcxHH69Gnh9ddfF3x9fQWZTCZYWFgILVq0EMaNGyf89ttvWvs+blYoPDKzxuP2K5tdIzc3V5g7d67QsmVLwdzcXLCyshICAwOF9evXa81G9TjLli0TfHx8BJlMJrRp00b46quvKpyBQqVSCZ999pnQvn17wdzcXLCzsxOCgoKEn376SbPPzZs3heDgYMHGxkYAoJlJoqJZocpERUVp8rp8+XK512/fvi289NJLQuPGjQUbGxvhueeeE/7+++9ys3kIgiCsWrVK8PX1FaRSqdb7VTTTRlFRkTBv3jzB29tbMDMzE9zd3YWpU6cKDx480NqvolmdBKF0tqaKZsB6VGXHX758WQgODhZsbW0FZ2dnYebMmcKBAwcqnBWqotm/KsrpwYMHwn/+8x/By8tLMDMzE1xcXITBgwcLFy9e1Ozz66+/Cv7+/oJMJhMAaH6Glc1U9fXXXwsdO3bUfOZDhw4Vzp8/Xy4Wa2vrcjFW9HtE1FCU/ZuKi4sr91pRUZHg5eUltGzZUjOr0JkzZ4RXX31VcHFxEczMzAQ3NzehX79+wvr16zXHlc0KVdmj7LvjypUrwmuvvSa4u7sLpqamgr29vRAcHFyuTarMgwcPhIkTJwouLi6ClZWV0LNnT+Ho0aMVfu/VxfeOIAjCggULBACCp6enZlashx07dkwICgoSrKysBGdnZ2HSpEnCqVOnyrU1crlcmDRpkuDs7CxIJBKt96uoHUlOThZGjx4tODo6CmZmZoKfn5+wYsUKrRgqm9VJEIQqzcj4uOMjIyOFzp07C5aWlkKzZs2E1atXVzorVEWzf1WUU1JSkvDKK68Ijo6Ogrm5ueDl5SVMmDBBKC4u1uyjj+0nCYJEEAShjmoWIiIiIiJqIDjGgoiIiIiIaoyFBRERERER1RgLCyIiIiIiqjEWFkREREREVGMsLIiIiIiIqMZYWBARERERUY01uAXy1Go17ty5AxsbG63Vm4mIGjJBEJCXlwcPDw+tRR8bGrYRRETadGkfGlxhcefOHXh6eoodBhGRXrp161a51YobErYRREQVq0r70OAKCxsbGwClPxxbW1udjlUoFIiKikJwcDDMzMzqIrx6YQx5MAf9YQx5GEMOQM3yyM3Nhaenp+Y7sqFq6G2EMeQAGEcezEF/GEMe9dU+NLjCouzWtq2tbbUaDSsrK9ja2hrsLxZgHHkwB/1hDHkYQw5A7eTR0Lv/NPQ2whhyAIwjD+agP4whj/pqHxpuR1oiIiIiIqo1LCyIiIiIiKjGRC0s1q1bh44dO2puOQcFBeHgwYOPPSY2NhYBAQGwsLBAs2bNsH79+nqKloiI6gvbByIiwyNqYdG0aVMsW7YM8fHxiI+PR79+/TB06FCcP3++wv1v3LiBkJAQ9OrVC4mJiViwYAHefPNN7N27t54jJyKiusT2gYjI8Ig6ePv555/Xev7RRx9h3bp1OHHiBNq1a1du//Xr18PLywurVq0CALRp0wbx8fFYuXIlXnrppfoImYiI6gHbByIiw6M3s0KpVCrs3r0bBQUFCAoKqnCf48ePIzg4WGvbwIEDsWnTJigUigpHucvlcsjlcs3z3NxcAKWj4xUKhU4xlu2v63H6xhjyYA76wxjyMIYc1GoBX/5+Be6K6uWhz7nXVftARNRQJKZkIy5DgpA6fh/RC4tz584hKCgIxcXFaNSoEfbt24e2bdtWuG96ejpcXV21trm6ukKpVCIzMxPu7u7ljlm6dCkWL15cbntUVBSsrKyqFXN0dHS1jtM3xpAHc9AfxpCHIedw8JYJDt02gbOFFBbSaJjq2NG1sLCwbgKrgbpuHwBefHqUMeQAGEcezEF/GHoeGXlyzPjuNO7lSdEmLgWvdvXS6Xhd8ha9sPDz88Pp06eRnZ2NvXv3Yvz48YiNja208Xh0Dl1BECrcXiY8PBxhYWGa52WLfAQHB1drjvLo6GgMGDDAoK9+GUMezEF/GEMehp7Dwb/Tcej4WQDAs03UGDRQ9zzK/qDWJ3XdPgC8+FQZY8gBMI48mIP+MMQ8VGpgTZIU9/IkcLUUYJr+NyIj/9bpHLpceBK9sDA3N0eLFi0AAIGBgYiLi8Pnn3+ODRs2lNvXzc0N6enpWtvu3bsHU1NTODo6Vnh+mUwGmUxWbruZmVm1/4CoybH6xBjyYA76wxjyMMQc/k7NwdzvSxuJCUFe8Mf1auWhj3nXdfsA8OLTo4whB8A48mAO+sOQ8/gw8iKu5aXA2lyKiX5yPP9c3V54Er2weJQgCFq3pR8WFBSEn376SWtbVFQUAgMDDe6DJiKqqYw8Of5vazyKFWr0buWMeQNbIeqX62KHVWfqon3gxaeKGUMOgHHkwRz0h6Hlsf90Kv53PAUAsOKlDlDcjK/zC0+iTje7YMECHD16FDdv3sS5c+ewcOFCxMTEYMyYMQBKrySNGzdOs39oaCiSk5MRFhaGCxcu4JtvvsGmTZswZ84csVIgIhKFXKlCaEQC7uQUo5mTNb4c5Q9TqfGsecr2gYio+pLu5GLe3tIusjP6tsCAti718r6i3rG4e/cuxo4di7S0NNjZ2aFjx444dOgQBgwYAABIS0tDSkqKZn9fX19ERkZi1qxZWLNmDTw8PPDFF19wKkEialAEQcC7P/yNhOQHsLEwxVfjA2FnaWawAwsrwvaBiKh6sgtLMCXi37vZswa0glqlrJf3FrWw2LRp02Nf37JlS7ltffr0walTp+ooIiIi/bf5z5vYFX8bJhJg9eguaO7cSOyQah3bByIi3anUAv7z3WncyiqCp4MlvhjZGVITCdSq+nl/47lvTkTUABy9koEPDyQBABaEtEGfVs4iR0RERPpi1a+XEXs5AxZmJtjwWiDsrczr9f1ZWBARGYgbmQWY/u0pqAXg5YCmmNjTV+yQiIhIT0SdT8eXv18FACx7sSPaeug2s11tYGFBRGQAcosVmPS/OOQWK9HFyx4fDW//2PUZiIio4biWkY+wXWcAABN6+GCYfxNR4mBhQUSk51RqAf/ZkYhrGQVwt7PA+rEBkJlKxQ6LiIj0QL5cidBtCciXK9HNxwELB7cRLRYWFkREem75Lxdx+FIGZKYm2Dg2EC42FmKHREREekAQBMzdcwZX7uXD1VaG1WP8YSbi1OMsLIiI9NgPianYEFu66N3ylzuiQ1M7kSMiIiJ9seHIdUSeS4eZVIJ1rwWIfuGJhQURkZ46cysbc/9Z4GjqM80xtLM4fWaJiEj//HElE8sPXQQALHq+Hbp4NRY5IhYWRER66V5uMf5vWzxKlGr0b+2COcF+YodERER64lZWIWbuKJ0l8NXAphjzlJfYIQFgYUFEpHfkShWmRCTgbq4cLVwaYdU/CxwREREVK1SY+m0CHhQq0LGpHZYM1Z9ZAllYEBHpEUEQ8M6+v5GYkg1bC1N8NS4QNhZmYodFRER6QBAELNz3N/5OzYWDtTnWvRYACzP9mSWQhQURkR7ZcuwmdifchokEWD26C3ydrMUOiYiI9ETEiWTsPfVPGzHKH03sLcUOSQsLCyIiPfHn1Ux8eOACAGBBSBv0buUsckRERKQvEpKzsPinJADA/EGt0aOFk8gRlcfCgohID6TcL8T07aegUgt4sUsTTOzpK3ZIRESkJ+7lFmNqxCko1QIGd3TH5F7NxA6pQiwsiIhEViBXYvLWeGQXKtCpqR0+Ht5BbwbiERGRuEqUakz79hTu5cnRyrURlr/UUW/bCBYWREQiUqsFhO06jUt38+BsI8OGsYF6NRCPiIjE9XHkBcQnP4CNzBQbxgbCWmYqdkiVYmFBRCSiL3+/il/O34W51ATrXwuAm524q6YSEZH++P7UbWw5dhMA8NmIzno/oQcLCyIikUSdT8dnv14GAHw4rD0CvMVfNZWIiPTD36k5CP/+HADgzf4t8WxbV5EjejIWFkREIrh8Nw+zdp4GAEzo4YNXu3qKGxAREemNBwUlCI1IgFypRl8/Z7zVv6XYIVUJCwsionqWU6jA/22NR0GJCkHNHLFwcBuxQyIiIj2hUgt487tE3H5QBG9HK6wa4Q8TE/0crP0oUQuLpUuXomvXrrCxsYGLiwuGDRuGS5cuPfaYmJgYSCSSco+LFy/WU9RERNWnUguY+V0ibt4vRBN7S6wZ0wVmUl7jISKiUv+NuoSjVzJhaSbF+tcCYGdlJnZIVSZqaxYbG4vp06fjxIkTiI6OhlKpRHBwMAoKCp547KVLl5CWlqZ5tGxpGLeIiKhhW/HLJRy5nAELMxNsHBcAB2tzsUPSS7zwREQN0aG/07A25hoAYNlLHdDG3VbkiHQj6nxVhw4d0nq+efNmuLi4ICEhAb17937ssS4uLrC3t6/D6IiIatdPZ+5gfWxpg7H85U5o52EnckT6q+zCU9euXaFUKrFw4UIEBwcjKSkJ1taPnxXl0qVLsLX9tzF2duYK5kSk/67ey8fsXWcAAG887YuhnZuIHJHu9Goi3JycHACAg4PDE/f19/dHcXEx2rZti3feeQd9+/atcD+5XA65XK55npubCwBQKBRQKBQ6xVe2v67H6RtjyIM56A9jyKM+criQloe395Q2GJN7+mBQW+daf7+a5KFvnx8vPBFRQ5JXrMCUbaVj757ydUB4SGuxQ6oWvSksBEFAWFgYevbsifbt21e6n7u7OzZu3IiAgADI5XJs27YN/fv3R0xMTIWNzdKlS7F48eJy26OiomBlZVWtWKOjo6t1nL4xhjyYg/4whjzqKocCBbDynBTFCgla26nRVnkVkZFX6+S9gOrlUVhYWAeR1J66uPBERKQP1GoBc3afwbWMArjZWhj02Du9KSxmzJiBs2fP4o8//njsfn5+fvDz89M8DwoKwq1bt7By5coKC4vw8HCEhYVpnufm5sLT0xPBwcFat8qrQqFQIDo6GgMGDICZmeEMpHmUMeTBHPSHMeRRlzkoVWpM3HoKWfIseDlYIiK0O+ws6+bnVJM8yu7m6qO6uvAE8K72o4whB8A48mAO+qOu81gfex2/nL8LM6kEX47sCDuZicHe0daLwmLmzJn48ccfceTIETRt2lTn47t3746IiIgKX5PJZJDJZOW2m5mZVfsPiJocq0+MIQ/moD+MIY+6yOGTX5Jw7HoWrMyl+GpcVzjZVu9OqS6qk4c+f3Z1deEJ4F3tyhhDDoBx5MEc9Edd5HExW4L1F0wASPCitxJ3zh3DnXO1/jYadX1HW9TCQhAEzJw5E/v27UNMTAx8fX2rdZ7ExES4u7vXcnRERDWz/3Qqvv7jBgDgv690gp+bjcgRGZ66vPAE8K72o4whB8A48mAO+qOu8rj1oBCL1v0FAQq8GtAEHw5rV2vnflR93dEWtbCYPn06tm/fjv3798PGxgbp6ekAADs7O1haWgIo/dJPTU3F1q1bAQCrVq2Cj48P2rVrh5KSEkRERGDv3r3Yu3evaHkQET3q79QczNt7FgAwvW9zDOrAix+6qK8LT7yrXTFjyAEwjjyYg/6ozTyKSlSYseMssosU6ORpjw+Gd4CZqbRWzv04dX1HW9TCYt26dQCAZ555Rmv75s2bMWHCBABAWloaUlJSNK+VlJRgzpw5SE1NhaWlJdq1a4cDBw4gJCSkvsImInqsrIISTNmWgGKFGs/4OSNsgN+TDyItvPBERMZKEAQs3HcOSWm5cLQ2x7oxXSCrh6KiPojeFepJtmzZovV87ty5mDt3bh1FRERUM0qVGjN3nEJqdhF8HK3w+Uh/SE0kYodlcHjhiYiM1dbjyfg+MRVSEwlWj+4CD3tLsUOqNXoxeJuIyFgs/+US/rx6H1bmUmwYG1hnM0AZO154IiJjFHczCx/8nAQACB/UGkHNHUWOqHYZ5iS5RER66Mczd7DxyHUAwEoO1iYioofczS3GtG9PQakW8HwnD0zsWb2xY/qMhQURUS24kJaLeXtKB2tPfaY5QjhYm4iI/lGiVGPat6eQkSdHazcbfPJSB0gkxtdNloUFEVEN5RQqMGVbAooUKvRq6YQ5wRysTURE//rg5yQkJD+ArYUpNowNgJW5cY5GYGFBRFQDKrWAN79LREpWIZo2tsQXHKxNREQP2ZNwG9tOJEMiAT4f6Q9vR2uxQ6ozLCyIiGpg1a+XEXs5AxZmJtg4NhCNrc3FDomIiPTE36k5WLCvdCntt/q3Qt/WLiJHVLdYWBARVVPU+XR8+ftVAMDSFzugrYduKzUTEZHxKlvTqESpRv/WLpjZr4XYIdU5FhZERNVwLSMfYbvOAAAm9PDBcP+mIkdERET6QqlS480diZo1jT4d0RkmDaCbLAsLIiIdFciVCN2WgHy5Et18HLBwcBuxQyIiIj2yMuoy/riaCUuzhrWmEQsLIiIdCIKAuXvO4sq9fLjayrB6jD/MpPwqJSKiUgfPpWF97DUAwPKXOzaoNY3YGhIR6eDrozdw4FwazKQSrB3TBS42FmKHREREeuLK3TzM2V3aTXZyL18838lD5IjqFwsLIqIqOn7tPpYevAAAeHdIWwR4O4gcERER6Yvc4tI1jQpKVAhq5oh5z7UWO6R6x8KCiKgK0nKKMGP7KagF4EX/Jhjb3VvskIiISE+o1QJm7zqD65kF8LCzwOrR/jBtgN1kG17GREQ6KlGqMe3bU7hfUII27rb4aHgHSCTGP7sHERFVzZrDVxGddBfmUhOsey0Ajo1kYockChYWRERP8OGBJCSmZMPWwhTrX+sCS3Op2CEREZGeOHzpHj799TIA4INh7dDJ017cgETEwoKI6DH2Jd7G1uPJAIBVIzvD29Fa5IiIiEhfpNwvxH92JEIQgNFPeWFEVy+xQxIVCwsiokpcSMtF+PfnAABv9muBfq1dRY6IiIj0RWGJEv+3LR65xUp09rTHoufbih2S6FhYEBFVIKdIgakRCShWqNG7lTP+82wrsUMiIiI9IQgCwr8/h4vpeXBqZI51r3WBzJTdZEUtLJYuXYquXbvCxsYGLi4uGDZsGC5duvTE42JjYxEQEAALCws0a9YM69evr4doiaihEAQBc3afwc37hWhib4nPR3SG1ISDtYmIqNTmP29i/+k7kJpIsGZ0F7jbWYodkl4QtbCIjY3F9OnTceLECURHR0OpVCI4OBgFBQWVHnPjxg2EhISgV69eSExMxIIFC/Dmm29i79699Rg5ERmz9bHXH5rdowsaW5uLHRIREemJv67fx0eRpWsaLQxpg6eaOYockf4wFfPNDx06pPV88+bNcHFxQUJCAnr37l3hMevXr4eXlxdWrVoFAGjTpg3i4+OxcuVKvPTSS3UdMhEZuePX7mPFLxcBAO+/0A4dm9qLGxAREemN9JxiTN9+Ciq1gKGdPfD60z5ih6RX9GqMRU5ODgDAwaHy1WyPHz+O4OBgrW0DBw5EfHw8FApFncZHRMbtbm4xZu4oXQTv5YCmGNXNU+yQiIhIT8iVaoRGJCAzvwSt3Wyw9EWuafQoUe9YPEwQBISFhaFnz55o3759pfulp6fD1VV7ZhZXV1colUpkZmbC3d1d6zW5XA65XK55npubCwBQKBQ6FyJl+xt6AWMMeTAH/WEMeSgUCqjUwJvfndE0GO+F+EGpVIodmk5q8lno2+e3dOlSfP/997h48SIsLS3Ro0cPfPLJJ/Dz83vscbGxsQgLC8P58+fh4eGBuXPnIjQ0tJ6iJiJj9mHkRZy+Vbqm0YaxAbAy15s/o/WG3vxEZsyYgbNnz+KPP/544r6PVoeCIFS4HShtnBYvXlxue1RUFKysrKoVa3R0dLWO0zfGkAdz0B+GnsePKSY4lZYDC6mAl90e4PCvv4gdUrVV57MoLCysg0iqr2wMXteuXaFUKrFw4UIEBwcjKSkJ1tYVryVSNgZv8uTJiIiIwJ9//olp06bB2dmZXWWJqEaO35Xgu+u3IZEAn4/y55pGldCLwmLmzJn48ccfceTIETRt2vSx+7q5uSE9PV1r271792BqagpHx/KDZ8LDwxEWFqZ5npubC09PTwQHB8PW1lanOBUKBaKjozFgwACYmZnpdKw+MYY8mIP+MIY8Is/eQczxvwEAn77qjwFtXUSOqHpq8lmU3c3VFxyDR0T64uztHOy+UTp6YNazrdDXzzDbiPogamEhCAJmzpyJffv2ISYmBr6+vk88JigoCD/99JPWtqioKAQGBlbYkMpkMshksnLbzczMqv1HUE2O1SfGkAdz0B+GmseNzAIs/LF0sPaknj4I6dRE5Ihqrjqfhb5/djUZg7dp0yYoFIoKc2R3WW3GkANgHHkwB/1wP1+O6TtOQyVI0LeVI6b09DbIfOqrq6yohcX06dOxfft27N+/HzY2Npo7EXZ2drC0LJ0PODw8HKmpqdi6dSsAIDQ0FKtXr0ZYWBgmT56M48ePY9OmTdixY4doeRCRYSoqUWFqRALy5Uo0txEw+9kWYodEFairMXgAu8tWxhhyAIwjD+YgHpUArEsyQXquCVwsBAy0u4tDhw6KHVaN1HVXWVELi3Xr1gEAnnnmGa3tmzdvxoQJEwAAaWlpSElJ0bzm6+uLyMhIzJo1C2vWrIGHhwe++OIL3uYmIp29t/9vzaqp41sVwlSqVxPl0T/qagwewO6yjzKGHADjyIM5iG/ZoUu4kpsMSzMpJvrJ8cIgw8wDqL+usqJ3hXqSLVu2lNvWp08fnDp1qg4iIqKGYlfcLexOuA0TCfDZKx2RdfGE2CFRBepyDB7A7rKVMYYcAOPIgzmI4+ezd7Dpz2QAwCcvtoOQcsog83hUXXeV5eU5Impwku7k4t39pYO1Zwf7oXuzyvvtkzgEQcCMGTPw/fff4/fff6/yGLxHb/M/bgweEVFFLqXnYe6eswCA0D7NMai9m8gRGQ4WFkTUoOQVKzDt2wTIlWr09XPG1D7NxQ6JKjB9+nRERERg+/btmjF46enpKCoq0uwTHh6OcePGaZ6HhoYiOTkZYWFhuHDhAr755hts2rQJc+bMESMFIjJAOUUKTNkWj8ISFXq2cMKc4FZih2RQWFgQUYMhCALm7T2Lm/cL0cTeEp++2hkmJlw1VR+tW7cOOTk5eOaZZ+Du7q557Ny5U7NPZWPwYmJi0LlzZ3zwwQccg0dEVaZWCwjbeVrTRnwxyp9j73Sk8xgLQRAQGxuLo0eP4ubNmygsLISzszP8/f3x7LPPwtPTsy7iJCKqsf8du4nIc+kwk0qwerQ/Glubix0SVYJj8Iiovn35+1X8dvEeZKYm2DA2AA5sI3RW5TKsqKgIH3/8MTw9PTFo0CAcOHAA2dnZkEqluHr1KhYtWgRfX1+EhITgxAkOgiQi/XL6VjY+irwAAFgQ0gb+Xo1FjoiIiPTF7xfvYtVvlwEAHw3vgPZN7ESOyDBV+Y5Fq1at8NRTT2H9+vUYOHBghQPhkpOTsX37dowYMQLvvPMOJk+eXKvBEhFVR3ZhCaZ/ewoKlYBB7d0woYeP2CEREZGeuJlZgLe+Ow1BAMZ298bLAY+fgY4qV+XC4uDBg49dmAgAvL29ER4ejtmzZyM5ObnGwRER1ZQgCJiz+wxSs4vg7WiFT17uWOmaBlRzOTk52LdvX4XdZQcOHIgePXqIHSIRkUaBXIkp2xKQW6xEgHdjvDukrdghGbQqd4V6UlHxMHNzc7Rs2bJaARER1aavjl7HrxfuwdzUBGtGd4GtBacdrQtpaWmYPHky3N3dsWTJEhQUFKBz587o378/mjZtisOHD2PAgAFo27at1gBsIiKxlE3oceluHpwaybB2TBeYm3Kwdk1Ua4G8d999F++//z6kUqnW9pycHISGhmLHjh21EhwRUU3E38zCJ4cuAQAWPd+WfWbrUKdOnTBu3DicPHmy0gtRRUVF+OGHH/Dpp5/i1q1bnAaWiES16Y8b+PlsGkxNJFj3Whe42lqIHZLBq1ZhsXXrVkRHR+Pbb79F8+alc8DHxMRg3LhxaNKkSa0GSERUHVkFJZi5IxEqtYAXOnlgdDcvsUMyaufPn4ezs/Nj97G0tMSoUaMwatQoZGRk1FNkRETlHbuWiaUHLwIA3h3SFl19uFBqbajW/Z6zZ8/Cx8cHnTt3xldffYW3334bwcHBmDBhAv7444/ajpGISCdqtYCwXaeRllOMZk7W+PjFDhxXUceeVFSUKZtGtqr7ExHVtjvZRZi5vfTC04v+TTAuyFvskIxGtQoLOzs7fPfdd3jzzTcxZcoUfP755zh48CCWLFlSrnsUEVF923DkOmIuZUBmaoI1Y7qgkaxaN2epmsaOHYv8/Pxy22/evInevXuLEBERUalihQpTIxJwv6AEbd1t8dFwXniqTdUeofLll1/is88+w6hRo9CsWTO8+eabOHPmTG3GRkSks7ibWVgZVTquYvEL7dDG3VbkiBqepKQkdOjQAX/++adm2//+9z906tQJrq6uIkZGRA3d+z+ex5nbObC3MsOGsQGwNOcF8dpUrcJi0KBBWLx4MbZu3Ypvv/0WiYmJ6N27N7p3747ly5fXdoxERFWSVVCiub09rLMHRnT1FDukBumvv/7CiBEj0K9fPyxYsACvvPIKZsyYgc8++wx79uwROzwiaqB2nEzBd3G3IJEAX4z0h6eDldghGZ1q9Q9QKpU4e/YsPDw8AJQOyFu3bh2GDBmCSZMmYe7cubUaJBHRk5SNq0jPLUYzZ2ve3haRqakpli1bBplMhg8++ACmpqaIjY1FUFCQ2KERUQOVmPIAi/afBwDMCfZD71Yc51UXqnXHIjo6WlNUPGzw4ME4d+5cjYMiItLVxqMPjasY3QXWHFchGoVCgdmzZ+OTTz5BeHg4goKCMHz4cERGRoodGhE1QBl5ckyNOIUSlRrBbV0x7ZnmYodktGq95XVycgJQOvMHrxYSUX1ISM7Cil9Kx1W8z3EVogsMDERhYSFiYmLQvXt3CIKA5cuX48UXX8Qbb7yBtWvXih0iETUQCpUaM7afQnpuMZo7W+O/r3bi36d1qMp3LNq0aYPt27ejpKTksftduXIFU6dOxSeffFLj4IiInuTBQ+MqXujkgZEcVyG6wMBAnD59Gt27dwcASCQSzJs3DydOnMCRI0dEjo6IGpJlBy/irxtZaCQzxYaxgbCxMBM7JKNW5TsWa9aswbx58zB9+nQEBwcjMDAQHh4esLCwwIMHD5CUlIQ//vgDSUlJmDFjBqZNm1aXcRMRQRAEvL3nDO7kFMOX61XojU2bNlW4vXPnzkhISKjnaIioodp/OhWb/rgBAFj5Ske0cGkkckTGr8p3LPr164e4uDgcOHAAbm5u2L59O2bMmIExY8bg/fffx5UrVzBu3Djcvn0by5Ytg63tk7siHDlyBM8//zw8PDwgkUjwww8/PHb/mJgYSCSSco+LFy9WNQ0iMiKb/riBXy/cg7mpCVaP9ud6FSIqKCio0n4ymUyn/YmIquNiei7m7y0d9zvtmeZ4rr27yBE1DDq3wj169ECPHj1q5c0LCgrQqVMnvP7663jppZeqfNylS5e0Cheu4ErU8Jy+lY1PDpVeVHh3SFu087ATOaKGrUWLFpg5cyYmTJhQ4eQeQOkdpl9//RWffvopevfujfDw8HqOkogagpxCBaZsS0CRQoVeLZ0wO9hP7JAaDFEv7w0aNAiDBg3S+TgXFxfY29vXfkBEZBByihSYueMUFCoBIR3c8NpTXmKH1ODFxMTgnXfeweLFi9G5c+cKu8seP34cZmZmCA8Px//93/+JHTIRGSG1WsBbOxORfL8QTRtb4ouR/pCasItsfdGpsFiyZEmF2+3s7ODn54fg4GCYmFR7Me8q8/f3R3FxMdq2bYt33nkHffv2rXRfuVwOuVyueZ6bmwugdDpEhUKh0/uW7a/rcfrGGPJgDvqjvvMQBAFzd5/BrawiNG1siQ+ebwOlUlmjc/KzqHnufn5+2L17N27fvo3du3fjyJEjOHbsGIqKiuDk5AR/f3989dVXCAkJqZd2gogaplW/XcHhf6YeX/9aABpbm4sdUoOiU2Gxb9++CrdnZ2cjNTUV7dq1wy+//AIXF5daCe5R7u7u2LhxIwICAiCXy7Ft2zb0798fMTEx6N27d4XHLF26FIsXLy63PSoqClZW1VtxMTo6ulrH6RtjyIM56I/6yuNougS/3JBCKhHwatM8/HG49t63IX8WhYWFtfLeTZs2xaxZszBr1qxaOR8RUVVFJ93FF79dAQB8PLwD2jdhF9n6plNhkZiYWOlraWlpGD16NBYsWICvv/66xoFVxM/PD35+//aTCwoKwq1bt7By5cpKC4vw8HCEhYVpnufm5sLT0xPBwcFVGmD+MIVCgejoaAwYMABmZoY7XZkx5MEc9Ed95pGUlos5G/4CIGDec63xeg/vWjkvP4t/7+bqkyNHjmDFihVISEhAWloa9u3bh2HDhlW6f0xMTIV3sC9cuIDWrVvXYaREJLbrGfkI23kaADA+yBsvBTQVN6AGqtbGWLi7u+PDDz/E2LFja+uUVdK9e3dERERU+rpMJtPMQvIwMzOzav8BUZNj9Ykx5MEc9Edd55EvV2LWrnNQqAT0b+2Cyb2b1/rUsg35s6iNvN94440Kt5d1l33ttdfQqFHVp3vkBB9EVBUFciWmbEtAnlyJrj6NsXBwW7FDarBqdfB2kyZNcO/evdo85RMlJibC3Z1TiBEZM0EQ8M6+c7ieWQB3OwusfIUrp+qjBw8eVLj9xo0b+Pbbb/HBBx/g6NGjaNasWZXOxwk+iOhJBEHA3D1nceVePlxsZFgzugvMTTmOSyy1WlicOXMGPj4+Vd4/Pz8fV69e1Ty/ceMGTp8+DQcHB3h5eSE8PBypqanYunUrAGDVqlXw8fFBu3btUFJSgoiICOzduxd79+6tzTSISM/sTriNH07fgdREgi9G+XMwnp6qbBweABQVFWHcuHGYP38+du3aVadx6DLBBxEZtq+OXseBc2kwk0qw7rUucLG1EDukBk2nwqKyPrg5OTmIi4vD7NmzMWnSpCqfLz4+XusLv2wsxPjx47FlyxakpaUhJSVF83pJSQnmzJmD1NRUWFpaol27djhw4ABCQkJ0SYOIDMiVu3lYtP88ACBsQCt09XEQOSKqDktLS8ybNw8vvvhinb1HdSb44MyB2owhB8A48mAOT3b8+n0sO1i6ntHCQX7o6GFTJ+/V0D8LXY7RqbCwt7evtPuBRCLBlClTMHfu3Cqf75lnnoEgCJW+vmXLFq3nc+fO1en8RGTYihUqzNieqFnkaGqf5mKHRDXg4OCA7OzsOjt/dSb44MyBFTOGHADjyIM5VCxLDqw8K4VakKCbsxr2mX8jMvLvWn+fhzXUz0KXWQN1KiwOHz5c4XZbW1u0bNkSMpkMaWlp8PLiYlVEVHOLf0rCpbt5cGokw6evdoYJFzkyaMeOHUPz5vVbHD5pgg/OHKjNGHIAjCMP5lA5uUKFUZviUKDMRTsPG2ya1A0WZtJaO/+jGvpnocusgToVFn369Hns62fOnEGXLl2gUql0OS0RUTk/n72DHSdTIJEAq0Z0hrNN+dndSL+cPXu2wu1l3WU//vhjfPjhh/Ua05Mm+ODMgRUzhhwA48iDOWgTBAEL9yfhXGouGluZYcPYQNhY1c+4iob6Weiyf60O3iYiqg0p9wsRvvccAGDaM83Rs6WTyBFRVXTu3BkSiaTCLq7Ozs6YN28eQkNDq3w+TvBBRI/afjIFu+Jvw0QCfDmqC5o2rl6XRaobLCyISK+UKNWYueMU8uRKBHo3xqxnW4kdElXRjRs3KtxuZ2cHe3t7FBQU4MiRI5WOd3gUJ/ggooedSnmA938sncxj7nOtedFJD7GwICK9svzQRZy5nQM7SzN8PsofplLOR24ovL0fvxL61atX0bdv3yp3l+UEH0RU5l5eMaZGJEChEjCovRum9K7aejhUv3QqLCrrP1vm0qVLNQqGiBq23y7cxdd/lF71XvFyRzSxtxQ5IiIiEptCpcaMbxNxN1eOli6NsIKLpOotnQqLx/WfLdvOD5qIqiMtpwizd58BAEzo4YPgdm4iR0RERPrg48gLOHkzCzYyU6wfG4BGMna40Vc6fTKV9Z8lIqoJpUqN/+w4jexCBdo3sUV4SGuxQyIiIj2wL/E2Nv95EwDw31c7oblzI3EDosfSqbB4Uv9ZIqLq+OK3Kzh5MwuNZKZYPaoLZKZ1Nx851Z0ff/zxsa/z4hQR6eL8nRzM/2eGwJn9WvBOtgHQqbBYvnw5Zs6cCUvL0n7PR44cwVNPPaWZAzwvLw/z5s3D2rVraz9SIjJKx65m4svDpVOKfjS8PXycrEWOiKpr2LBhT9yH3WWJqCqyC0sQGpEAuVKNPq2c8RZnCDQIOk23Eh4ejry8PM3zIUOGIDU1VfO8sLAQGzZsqL3oiMioZebL8Z+dpyEIwMiunhjauYnYIVENqNXqJz64gCoRPYlKLeDN707jVlYRPB0s8fnIzpCa8KKEIdCpsHh00PbjpgEkInoctVpA2K4zyMiTo5VrIyx6vp3YIRERkR74LPoyjlzOgIWZCda/FgB7K3OxQ6Iq4gTxRCSKDUeuaxqO1aO7wNKc4yqMybZt2/D000/Dw8MDycnJAIDPPvsM+/fvFzkyItJnv5xPx+p/uscue7Ej2nnYiRwR6YKFBRHVu4TkLKyMKl33ZvEL7dDK1UbkiKg2rVu3DmFhYQgJCUF2dram+1Pjxo2xatUqcYMjIr119V4+Zu8qnXb89ad9MMyf3WMNjc4TAX/99ddo1Kh0qi+lUoktW7bAyal0SfWHx18QEVUku7AEb+44DZVawNDOHng10FPskKiWffnll/jqq68wbNgwLFu2TLM9MDAQc+bMETEyItJX+XIlQiMSkC9XopuPAxaEtBE7JKoGnQoLLy8vfPXVV5rnbm5u2LZtW7l9iIgqIggC3t5zFqnZRfBxtMJHwztwliAjdOPGDfj7+5fbLpPJUFBQIEJERKTPBEHAnF1ncPVePlxtZVg9xh9mUnaqMUQ6FRY3b96sozCIqCHY/OdNRCfdhbm0dFwFV081Tr6+vjh9+nS5tY8OHjyINm14FZKItK2PvY5D59NhJpVg3WsBcLGxEDskqiadWvXi4mL8+uuvGDJkCIDS6Wflcvm/JzM1xZIlS2BhwV8IItJ25lY2lh68AABYOLgN2jfhgDxj9fbbb2P69OkoLi6GIAg4efIkduzYgY8//hibNm0SOzwi0iNHr2RgxS8XAQDvv9AOXbwaixwR1YROhcX//vc//Pzzz5rCYvXq1WjXrp1mwbyLFy/Czc0NYWFhtR8pERmsnCIFZuw4BYVKwHPt3DAuyPvJB5HBev3116FUKjF37lwUFhZi9OjRaNKkCb788kv06tVL7PCISE/cyirEmzsSoRaAVwObYnQ3dqc3dDp1YPv222/xxhtvaG3bvn07Dh8+jMOHD2PFihXYvXt3lc935MgRPP/88/Dw8IBEIsEPP/zwxGNiY2MREBAACwsLNGvWDOvXr9clBSKqZ4IgYP7es5qFjj55uSPHVTQAkydPRnJyMu7du4f09HScPHkSiYmJaNGihdihEZEeKFaoMPXbBDwoVKBjUzssGdqebYMR0KmwuHz5Mlq1+ndJdQsLC5iY/HuKbt26ISkpqcrnKygoQKdOnbB69eoq7X/jxg2EhISgV69eSExMxIIFC/Dmm29i7969VU+CiOrVthPJOPh3ad/Z1aO6wM7STOyQqI5kZ2djzJgxcHZ2hoeHB7744gs4ODhgzZo1aNGiBU6cOIFvvvlG7DCJSGSCIGDhvr/xd2ouHKzNse61AFiYcS0jY6BTV6icnByYmv57SEZGhtbrarVaa8zFkwwaNAiDBg2q8v7r16+Hl5eXZh70Nm3aID4+HitXrsRLL71U5fMQUf04dzsHH/5cOq5i/qA26ORpL25AVKcWLFiAI0eOYPz48Th06BBmzZqFQ4cOobi4GJGRkejTp4/YIRKRHoj4KwV7T92GiQRYPcofTewtxQ6JaolOhUXTpk3x999/w8/Pr8LXz549i6ZNm9ZKYBU5fvw4goODtbYNHDgQmzZtgkKhgJlZ+Suhcrlcq9jJzc0FACgUCigUCp3ev2x/XY/TN8aQB3PQH5XlkVeswLRvE1CiUmNAGxeM7dZEb3M19s9Cl2Nr4sCBA9i8eTOeffZZTJs2DS1atECrVq24KB4RaSQkZ2HJT+cBAPMHtUaPFk4iR0S1SafCIiQkBO+99x4GDx5cbuanoqIiLF68GIMHD67VAB+Wnp4OV1dXrW2urq5QKpXIzMyEu7t7uWOWLl2KxYsXl9seFRUFKyurasURHR1dreP0jTHkwRz0x8N5CAKw5bIJbj0wgYNMQL9Gd3Dw4B0Ro6saY/wsqqqwsLDG73vnzh20bdsWANCsWTNYWFhg0qRJNT4vERmHe7nFmBpROpHH4A7umNyrmdghUS3TqbBYsGABdu3aBT8/P8yYMQOtWrWCRCLBxYsXsXr1aiiVSixYsKCuYgWAcgN7BEGocHuZ8PBwrVmqcnNz4enpieDgYNja2ur03gqFAtHR0RgwYECFd0cMhTHkwRz0R0V5bD2RgtNZF2EmlWDjhKfQqal+Ty1rzJ9FVZXdza0JtVqt9b5SqRTW1tY1Pi8RGb4SpRrTvj2Fe3lytHJthOWcyMMo6VRYuLq64tixY5g6dSrmz5+v9Uf9gAEDsHbt2nJ3FGqTm5sb0tPTtbbdu3cPpqamcHR0rPAYmUwGmUxWbruZmVm1/4CoybH6xBjyYA76oyyPM7eysezQJQBA+KA2CPQ1nNvcxvZZ6HpMTQmCgAkTJmi+c4uLixEaGlquuPj++++rdL4jR45gxYoVSEhIQFpaGvbt24dhw4Y99pjY2FiEhYXh/Pnz8PDwwNy5cxEaGlqtfIio9nwceQHxyQ9gIzPFhrGBsOYCqUZJ50/V19cXhw4dQlZWFq5evQoAaNGiBRwcHGo9uEcFBQXhp59+0toWFRWFwMBAo/hjgMjQ5RQqMO3bf9ereP1pH7FDono0fvx4reevvfZajc5XNnPg66+/XqUJOspmDpw8eTIiIiLw559/Ytq0aXB2duYEH0Qi+uH0HWw5dhMA8NmIzvB14p1MY1XtctHBwQHdunWr0Zvn5+drihOgtFE4ffo0HBwc4OXlhfDwcKSmpmLr1q0AgNDQUKxevRphYWGYPHkyjh8/jk2bNmHHjh01ioOIak4QBMzZcxap2UXwcrDC8ld4m7uh2bx5c62ejzMHEhm+2wXAF/tLlyJ4s39LPNu27nq2kPh0WseitsXHx8Pf3x/+/v4AgLCwMPj7++O9994DAKSlpSElJUWzv6+vLyIjIxETE4POnTvjgw8+wBdffMEGg0gPbPozGdFJd2EuNcHaMV1ga8G7iFS/Kps5MD4+3uBn/CIyRA8KS7DpkhRypRp9/ZzxVv+WYodEdUzUDm7PPPOMZpxGRbZs2VJuW58+fXDq1Kk6jIqIdHUtF1jz1xUAwHvPt0X7Jvo9WJuMU3VmDuSU5NqMIQfAOPIw9BxUagGzdp5BllwCz8aWWPFSe6hUSqhUYkemO0P/LID6m46cI2eIqEYy8+XYclkKlVrAcP8mGPOUl9ghUQOm68yBnJK8YsaQA2AceRhqDj+lmODPVBOYmwgY7ZmHPw8bZh4PM9TP4mF1PR05CwsiqjaVWkDY7nPIVUjQ0sUaHw1vz3EVJJrqzBzIKcm1GUMOgHHkYcg5/HL+Ln49fgYAMKq5GuOHGV4ODzPkz6JMfU1HzsKCiKrtv1GXcPx6FsxNBHw5sjOszPmVQuKpzsyBnJK8YsaQA2AceRhaDlfv5WPe938DAN7o4Y1OwjWDy6EyxpBHXU9HLurgbSIyXNFJd7E25hqA0itSzZ05fSDVrvz8fJw+fRqnT58G8O/MgWWTeoSHh2PcuHGa/UNDQ5GcnIywsDBcuHAB33zzDTZt2oQ5c+aIET5Rg5NXrMCUbfEoKFGhezMHvB3MwdoNDS8vEpHOku8XIGzXaQDA+CAvdMF1cQMioxQfH4++fftqnpd1WRo/fjy2bNlS6cyBs2bNwpo1a+Dh4cGZA4nqiVotYM7uM7iWUQB3OwusHt0FplJev25oWFgQkU6KSlQIjTiFvGIlArwbY25wK/waxcKCah9nDiQyHOtir+GX86VTjq97LQBOjWQGPYsSVQ9LSSKqMkEQsHDfOVxIy4VTI3OsGd0F5qb8GiEiashiL2dgZdQlAMCSoe3Q2dNe3IBINPyLgIiqbOvxZHyfmAqpiQRfjuoCNzsLsUMiIiIR3coqxJs7EiEIwKhunhjZjVOON2QsLIioSk7eyMIHPycBAMIHtUZQ84qn7yQiooahqESFKdsSkFOkQCdPeyx6vp3YIZHIWFgQ0ROl5xRj2renoFQLGNLRHRN7+oodEhERiaisa2xSWi4crc2xbkwXWJhJxQ6LRMbCgogeq1ihwpSIBGTmy+HnaoNPXurIRfCIiBq4h7vGrh7dBR72lmKHRHqAhQURVUoQBLy3/2+cuZUNWwtTbBwXAGsZJ5MjImrI4m6yayxVjIUFEVUq4kQydsXfhokE+HJ0F3g7chE8IqKG7G7uv11jn+/kwa6xpIWFBRFV6MT1+1j8U+kVqXnPtUafVs4iR0RERGIqUaoxNSIBGXlytHazwScvdWDXWNLCwoKIyrmVVYipEQmaK1L/17uZ2CEREZHIPvg5CadSSrvGbhgbACtzdo0lbSwsiEhLvlyJyVvj8aBQgQ5N7LCcg7WJiBq83fG3sO1EMiQS4POR/uwaSxViYUFEGmq1gLCdp3ExPQ/ONjJsHBcAS3NOH0hE1JCdu52DhT/8DQCY9Wwr9G3tInJEpK9YWBCRxsqoS4hKugtzqQk2jA2Aux2nDyQiasiyCkoQGpGAEqUaz7ZxxYy+LcQOifSY6IXF2rVr4evrCwsLCwQEBODo0aOV7hsTEwOJRFLucfHixXqMmMg47Um4jbUx1wAAy17qgC5ejUWOiIiIxKRUqfHmjkSkZhfB18kan47oBBMTdo2lyolaWOzcuRNvvfUWFi5ciMTERPTq1QuDBg1CSkrKY4+7dOkS0tLSNI+WLVvWU8RExunkjSyEf38WADCjbwu82KWpyBEREZHYVkZdxh9XM2FlLsX61wJga2Emdkik50QtLD799FNMnDgRkyZNQps2bbBq1Sp4enpi3bp1jz3OxcUFbm5umodUyj7gRNV1M7MAU7bFQ6ESENLBDWEDWokdEhERiSzyXBrWx5bexV7+ckf4udmIHBEZAtEKi5KSEiQkJCA4OFhre3BwMI4dO/bYY/39/eHu7o7+/fvj8OHDdRkmkVHLKijBhM0n8aBQgY5N7fDfVzrzNjcRUQN35W4e5uw+AwD4v97NMKSjh8gRkaEQbQLizMxMqFQquLq6am13dXVFenp6hce4u7tj48aNCAgIgFwux7Zt29C/f3/ExMSgd+/eFR4jl8shl8s1z3NzcwEACoUCCoVCp5jL9tf1OH1jDHkwh5qTK1SY/L8E3LxfiCb2Flg/ujNMJWooFGqdziN2HrXBGHIAapaHoedORLUjt1iBKdsSUFiiQo/mjpg70E/skMiAiL6yyaPz4wuCUOmc+X5+fvDz+/cXPCgoCLdu3cLKlSsrLSyWLl2KxYsXl9seFRUFKyurasUcHR1dreP0jTHkwRyqRy0AW6+YIPG+CSylAsZ55yPu6G81Oic/C/1RnTwKCwvrIBIiMiSlU46fwfXMAnjYWeDLUf4wlYo+zw8ZENEKCycnJ0il0nJ3J+7du1fuLsbjdO/eHREREZW+Hh4ejrCwMM3z3NxceHp6Ijg4GLa2tjrFrFAoEB0djQEDBsDMzHAHMBlDHsyhZpYevITE+8kwk0qwYVwAgpo5Vvtc/Cz0R03yKLubS0QN15rDV/HrhbswNzXB+rEBcGwkEzskMjCiFRbm5uYICAhAdHQ0hg8frtkeHR2NoUOHVvk8iYmJcHd3r/R1mUwGmaz8PwwzM7Nq/wFRk2P1iTHkwRx0t/HINXxzLBlA6YC83n5utXJefhb6ozp5GEPeRFR9hy/dw6e/XgYAfDi0PTo2tRc3IDJIonaFCgsLw9ixYxEYGIigoCBs3LgRKSkpCA0NBVB6tyE1NRVbt24FAKxatQo+Pj5o164dSkpKEBERgb1792Lv3r1ipkFkMPYl3sbHkaXrviwIaY3h/pxWloiooUu+X4D/7EiEIACjn/LCq109xQ6JDJSoHedGjBiBVatWYcmSJejcuTOOHDmCyMhIeHt7AwDS0tK01rQoKSnBnDlz0LFjR/Tq1Qt//PEHDhw4gBdffFGsFIgMxuGL9/D27tK1Kib29MXkXs1EjojoybiIKlHdKixRYsq2BOQWK+HvZY9Fz7cVOyQyYKIP3p42bRqmTZtW4WtbtmzRej537lzMnTu3HqIiMi4nb2QhNCIBSrWAFzp5YGFIm0onSSDSF2WLqK5duxZPP/00NmzYgEGDBiEpKQleXl6VHnfp0iWtMXTOzs71ES6RwREEAeHfn8PF9Dw4NTLHujEBkJlybTCqPg71JzJyf6fmYOKWOMiVavRr7YL/vtqJa1WQQeAiqkR1a/OfN7H/9B1ITSRYM7oL3OwsxA6JDJzodyyIqO5cvZeH8d+cRJ5ciW4+DlgzugvMOHUgGYCyRVTnz5+vtb2qi6gWFxejbdu2eOedd9C3b99K9+VaR9qMIQfAOPKo6xz+upGFjyIvAADmP9cKXTxta/29jOFzAIwjj/pa54iFBZGRupFZgNFf/YX7BSVo52GLrycEwtKcV27JMNTXIqpc66hixpADYBx51EUO2XJgxTkpVGoJApzUcM46j8jI87X+PmWM4XMAjCOPul7niIUFkRG6lVWI0V+dwL08OVq72WDbxKdga8HpRMnw1PUiqlzrSJsx5AAYRx51lYNcqcaYTXHIV+SgtZsNNk/uVmcXnYzhcwCMI4/6WueIhQWRkbmVVYhRX51AWk4xmjtbI2LSU3CwNhc7LCKd1NciqlzrqGLGkANgHHnUdg6Lfj6HM7dzYGthio1jA2FrXffjKozhcwCMI4+6XueIna2JjEjK/UKM3HgCtx8UwcfRCtsnd4cTV04lA/TwIqoPi46ORo8ePap8nictokrUkOyMS8H2v1IgkQCfj/KHl2P1uvsRVYZ3LIiMROmYitI7Fc2crLF9cne42nKGDzJcXESVqPacuZWNd/eXjqMIe7YV+vq5iBwRGSMWFkRG4PLdPLz29V+4lydHC5dG2D75KbjYsKggwzZixAjcv38fS5YsQVpaGtq3b1+lRVRTU1NhaWmJdu3a4cCBAwgJCRErBSK9cD9fjqkRCShRqjGgrSum920hdkhkpFhYEBm4M7eyMX7zSWQXKuDnaoNvJz/F7k9kNLiIKlHNKFVqzNyRiDv/3M3mWkZUl1hYEBmwY9cyMfl/8SgoUaGzpz22vN4V9lYcqE1ERKWW/3IJx67dh7W5FBvGBnCGQKpTLCyIDNTPZ+8gbOcZlKjUeLqFIzaODYS1jP+kiYio1M9n72DjkesAgJWvdEJLVxuRIyJjx79CiAyMIAj4+ugNzYqpz7Vzw6qRnWFhxsXviIio1KX0PMzdcxYAENqnOQZ14OxoVPdYWBAZEKVKjQ8PXMCWYzcBABN6+ODdIW0hZX9ZIiL6R06RAlO2xaOwRIWeLZwwJ7iV2CFRA8HCgshA5BQpMHNHIo5czgAAvDO4DSb29K10FWIiImp41GoBYTtP4+b9QjSxt8QXo/xhKuWyZVQ/WFgQGYAbmQWY+L84XM8ogIWZCT59tTNCeFubiIge8eXvV/HbxXuQmZpgw9gAOFhzQg+qPywsiPTcbxfuYtbO08gtVsLdzgJfjQtE+yZ2YodFRER65veLd7Hqt8sAgI+Gd2BbQfWOhQWRnlKpBXwafQlrDl8DAPh72WPD2AAufEdEROXczCzAf747DUEAxnb3xssBTcUOiRogFhZEeuhubjFm7TyNY9fuAygdpL0gpA3MTdlPloiItBWWKDFlWwLyipUI8G6Md4e0FTskaqBYWBDpmeiku5i75wweFCpgZS7Fspc64oVOHmKHRUREekgQBMzdcxaX7ubB2UaGtWO68CIUiUb037y1a9fC19cXFhYWCAgIwNGjRx+7f2xsLAICAmBhYYFmzZph/fr19RQpUd3KlyuxcN85TN4ajweFCrTzsMWPM3qyqCAiokpt+uMGfj6bBlMTCdaO6QJXW3aXJfGIWljs3LkTb731FhYuXIjExET06tULgwYNQkpKSoX737hxAyEhIejVqxcSExOxYMECvPnmm9i7d289R05Uu45eycDAz47g279Kf/en9G6G76f1QAuXRiJHRkRE+urYtUwsPXgRAPDukLbo6uMgckTU0InaFerTTz/FxIkTMWnSJADAqlWr8Msvv2DdunVYunRpuf3Xr18PLy8vrFq1CgDQpk0bxMfHY+XKlXjppZfqM3SiWpGvAML3nceeU6kAgKaNLbH8pY7o0cJJ5MiIiEif3ckuwsztiVCpBbzYpQnGBXmLHRKReIVFSUkJEhISMH/+fK3twcHBOHbsWIXHHD9+HMHBwVrbBg4ciE2bNkGhUMDMzKzcMXK5HHK5XPM8NzcXAKBQKKBQKHSKeV3MVSTcNMHpyAswNzWF1EQCUxMJTKX/PExMYCaVwEz68H9NYG5qAnOpCWSm/z4szKSQmZnAwlQKS7PSfeprobOyvHXNX58Yeg4qtYAdJ5Ox4rQUhcrSomJsdy/MfrYFrGWmBpWXoX8WgHHkANQsD0PPnaghKVaoMDUiAfcLStDW3RYfD+/AxVJJL4hWWGRmZkKlUsHV1VVru6urK9LT0ys8Jj09vcL9lUolMjMz4e5efsGwpUuXYvHixeW2R0VFwcrKSqeYd5yRIq3QBLFpt3Q6riokEGBuAsikgLkUkP3z/zKpAAspYCEFLKWAhakASylgaQpYmQJWpgKsTAHrf56b6PC9Eh0dXet51DdDzOFyjgT7k01wu0ACQAIPKwGv+KrQTHIdsb9dFzu8ajPEz+JRxpADUL08CgsL6yASIqoL7/94Hmdu58DeygwbxgbAwkwqdkhEAPRgVqhHK2xBEB5bdVe0f0Xby4SHhyMsLEzzPDc3F56enggODoatra1Osabb3kDcuUvw8vaGIDGBUqWGUi2UPlRqKFSl/69QqaFUlf63RKVGibL0IX/oUaxUoVihhkpdGr8ACeRqQK4GoHXhsOqVgkQC2FmYwcHaDA7W5nC0NodjI3M4WcvgZGMO50YyONvI4GgpReKJI3gueECFd3kMgUKhQHR0NAYMMJwcktJysTLqCo5eLZ1CtpFMioHuJVj0Wj9YymQiR1d9hvhZPMoYcgBqlkfZ3Vwi0m87Tqbgu7hbMJEAX4z0h6eDbhdJieqSaIWFk5MTpFJpubsT9+7dK3dXooybm1uF+5uamsLR0bHCY2QyGWQV/NFmZmamc8P7Rk9fuOVeQEhIm1r740OhUqNIoUJxiQqFJSoUlChR9M//58uVyJcrUSBXIq9YibxiBfKKlcgtViC3SImcIgWyi0qQXVi6XRCA7CIFsosUuJ75+KuPEkjxyfljcLO3hLutBdztLdDE3rL00dgSTRtbobGVmd7fWq3O51jfztzKxpe/X8WvF+4CAMykEox5yhuhvbzx15HfYCmT6X0OVWEIn8WTGEMOQPXyMIa8iYxdYsoDLNp/HgAwZ6AferdyFjkiIm2iFRbm5uYICAhAdHQ0hg8frtkeHR2NoUOHVnhMUFAQfvrpJ61tUVFRCAwMNNhGsWwchq1FzeJXqNTILlTgQWEJsgpKcD+/BPcL5MjML0FGnvyfRzHu5sqRkS+HSg3czZPjbp4cZyo5p5W5FJ6NreDpYAUvByt4OVjC28kaPo7WaNrYEmZS0Wcr1ltqtYDDl+5hy7GbOHolE0DpHaUhHT0wJ7gVvB2t2aediIiqLCNPjqkRp1CiUmNgO1dM7dNc7JCIyhG1K1RYWBjGjh2LwMBABAUFYePGjUhJSUFoaCiA0m5Mqamp2Lp1KwAgNDQUq1evRlhYGCZPnozjx49j06ZN2LFjh5hp6AUzqQmcbUq7Oj1JsbwEu388iHZdn0ZGgRLpOcW4k12E1LLHgyLcy5OjsESFS3fzcOluXrlzSE0kaNrYEj6O1vB1skYz59L/+jpZw8POEia6DPYwIhl5cvyQmIqIv5KRfL/0rpHURIJhnZtgWt/maO7M6WOJiEg3CpUaM7afQnpuMZo7W2PlK530vkcBNUyiFhYjRozA/fv3sWTJEqSlpaF9+/aIjIyEt3fplGlpaWlaa1r4+voiMjISs2bNwpo1a+Dh4YEvvviCU83qSGoiga050KGJXaV3eooVKqRmF+H2gyKkZBUi5X4Bku8XIiWrEDfvF6BYoUby/UIk3y9E7OUMrWMtzEzg42iN5s6N0NzZGs1dGqGZUyM0c7aGtUz0YT21Ll+uxOGL9/BDYipiLmdoxs3YWphiZDcvjO3uzT6wRERUbcsOXsRfN7JgbS7FhrEBsKlhLweiuiL6X3nTpk3DtGnTKnxty5Yt5bb16dMHp06dquOoyMJM+k9hUP4Ku1ot4F6eHDcyC3DzfgFuZhbgemYBrmfkIyWrEMUKNS6m5+Fievk7HW62FmjmXFp0NHO2RjPnRmjmZA0Pe0tIDegux62sQvxxNRO/Jt3F0auZKFGqNa919rTHq4GeGObvAStz0f+JERm0tWvXYsWKFUhLS0O7du2watUq9OrVq9L9Y2NjERYWhvPnz8PDwwNz587V3AUnMkQ/nU3Dpj9uAAD++2pntHCxETkiosrxrx7SmYmJBG52FnCzs0BQc+1B80qVGrcfFOF6Zj6uZxTgWkY+rt4r/f/7BSVIzy1Gem4xjl27r3WcudQE3o5W8Ha0hq+TFbwcreH9z9gOD3tLmJuKN55DrRZwNSMfiSkPkJiSjePX72u6OZXxcbRCSAd3vNilKVfLJqolO3fuxFtvvYW1a9fi6aefxoYNGzBo0CAkJSXBy8ur3P43btxASEgIJk+ejIiICPz555+YNm0anJ2deWebDNKNPGDDD6WDtaf3bY7n2ruJHBHR47GwoFplKjWBj5M1fJys0a+19ms5hQpczcjH9Yx8zR2OG5kFuJlZiBKVGlfu5ePKvfxy55RIAFcbCzRpXDprlbudBZwamSH1vgRON7PgZm8NR2tz2FiYVfuuR4lSjayCEqTllHb/uvWgENczCnD5bh6u3M1HkUKltb/URAJ/T3v0buWMge3c0Mq1Efu7EtWyTz/9FBMnTsSkSZMAAKtWrcIvv/yCdevWYenSpeX2X79+Pby8vLBq1SoAQJs2bRAfH4+VK1eysCCDUiBXYsWhi/jf31IIUKNXSyeEDfATOyyiJ2JhQfXGzsoMAd6NEeDdWGu7Si0g9UERbt4vQPL9AtzILERKVkHp2I5/ulaV3elISH7w0JFSbLkcr3kmkQC2FmawsTCFlbkUVuamkJmWzrplKpVAAkCpFqBSC5Ar1SiQK1FYokJ2YQlyi5WPjd3STIqOTe3g79UYgd6N8VQzB/ZxJapDJSUlSEhIwPz587W2BwcH49ixYxUec/z4cQQHB2ttGzhwIDZt2gSFQlHhmDK5XA65XK55Xraeh0Kh0GnmtsSUbKyNuYaMTBPsy0yAxIC6dj5MUAsGnwNg+HlcSMtDeq4cgARDOrhi8fNtoVYpoVY98VC9UvZvyNBnQTSGPGqSgy7HsLAg0UlNJPBytIKXoxUA7Tm5BUFAZn7JPwPJC5GeU4y0nGLceVCISynpUJtbIzO/BPny0nU8cooUyCmq3j98qYkEzo1k8HQoXcfD29EKfq42aOVmA28HK5hyel2iepOZmQmVSlVuXSNXV9dy6xmVSU9Pr3B/pVKJzMxMuLu7lztm6dKlWLx4cbntUVFRsLKq+qQLZ+5LEHNFCsAEeHD/ifvrN2PIATD0PBxkAl71VaNNo1T8cThV7HBqJDo6WuwQaoUx5FGdHAoLH7822sNYWJBek0gkmml0O3vaa7YrFApERqYiJKQnzMzMUKJU/1NUlCCvuHSRwXy5EiX/rIKuVAtQCwJMTSSQmkhgLjWBtcwU1jJT2FmawtFaBjtLswY7TS6Rvnq0i6EgCI/tdljR/hVtLxMeHo6wsDDN89zcXHh6eiI4OBi2trZVjrPjgyL4XslAUtJ5tG3bDlKptMrH6hOVSmXwOQCGn4eVuRQ9m9njz9jfMWDAAINdq0uhUCA6OtqgcwCMI4+a5FB2J7cqWFiQUTA3rfo6HkSk/5ycnCCVSsvdnbh37165uxJl3NzcKtzf1NQUjo6OFR4jk8kgk5X/3tB19XJfFzM0bWyJyMy/EdLNy6D/+DD0HADjyKOs+4muv4v6yBhyAIwjj+rkoMv+7NtBRER6x9zcHAEBAeVu20dHR6NHjx4VHhMUFFRu/6ioKAQGBhr8HwNERIaAhQUREemlsLAwfP311/jmm29w4cIFzJo1CykpKZp1KcLDwzFu3DjN/qGhoUhOTkZYWBguXLiAb775Bps2bcKcOXPESoGIqEFhVygiItJLI0aMwP3797FkyRKkpaWhffv2iIyMhLe3NwAgLS0NKSkpmv19fX0RGRmJWbNmYc2aNfDw8MAXX3zBqWaJiOoJCwsiItJb06ZNw7Rp0yp8bcuWLeW29enTB6dOnarjqIiIqCLsCkVERERERDXGwoKIiIiIiGqswXWFKpvTXJc5ecsoFAoUFhYiNzfXoGcYMYY8mIP+MIY8jCEHoGZ5lH0nln1HNlQNvY0whhwA48iDOegPY8ijvtqHBldY5OXlAQA8PT1FjoSISP/k5eXBzs5O7DBEwzaCiKhiVWkfJEIDuzylVqtx584d2NjYPHb11oqUrch669YtnVZk1TfGkAdz0B/GkIcx5ADULA9BEJCXlwcPDw+YmDTcXrINvY0whhwA48iDOegPY8ijvtqHBnfHwsTEBE2bNq3ROWxtbQ32F+thxpAHc9AfxpCHMeQAVD+PhnynogzbiFLGkANgHHkwB/1hDHnUdfvQcC9LERERERFRrWFhQURERERENcbCQgcymQyLFi2CTCYTO5QaMYY8mIP+MIY8jCEHwHjyMFTG8PM3hhwA48iDOegPY8ijvnJocIO3iYiIiIio9vGOBRERERER1RgLCyIiIiIiqjEWFkREREREVGMsLKrphRdegJeXFywsLODu7o6xY8fizp07Yoelk5s3b2LixInw9fWFpaUlmjdvjkWLFqGkpETs0HTy0UcfoUePHrCysoK9vb3Y4VTZ2rVr4evrCwsLCwQEBODo0aNih6STI0eO4Pnnn4eHhwckEgl++OEHsUPS2dKlS9G1a1fY2NjAxcUFw4YNw6VLl8QOSyfr1q1Dx44dNXOTBwUF4eDBg2KH1eAZehthLO0DYJhtBNsH8RlD+wDUfxvBwqKa+vbti127duHSpUvYu3cvrl27hpdfflnssHRy8eJFqNVqbNiwAefPn8dnn32G9evXY8GCBWKHppOSkhK88sormDp1qtihVNnOnTvx1ltvYeHChUhMTESvXr0waNAgpKSkiB1alRUUFKBTp05YvXq12KFUW2xsLKZPn44TJ04gOjoaSqUSwcHBKCgoEDu0KmvatCmWLVuG+Ph4xMfHo1+/fhg6dCjOnz8vdmgNmqG3EcbSPgCG10awfdAPxtA+ACK0EQLViv379wsSiUQoKSkRO5QaWb58ueDr6yt2GNWyefNmwc7OTuwwqqRbt25CaGio1rbWrVsL8+fPFymimgEg7Nu3T+wwauzevXsCACE2NlbsUGqkcePGwtdffy12GPQQY2gjDLl9EATDaSPYPugnY2kfBKFu2wjesagFWVlZ+Pbbb9GjRw+YmZmJHU6N5OTkwMHBQewwjFpJSQkSEhIQHBystT04OBjHjh0TKSoCSn//ARjsvwGVSoXvvvsOBQUFCAoKEjsc+oextBFsH+oe2wf9ZejtA1A/bQQLixqYN28erK2t4ejoiJSUFOzfv1/skGrk2rVr+PLLLxEaGip2KEYtMzMTKpUKrq6uWttdXV2Rnp4uUlQkCALCwsLQs2dPtG/fXuxwdHLu3Dk0atQIMpkMoaGh2LdvH9q2bSt2WA2eMbURbB/qB9sH/WTI7QNQv20EC4uHvP/++5BIJI99xMfHa/Z/++23kZiYiKioKEilUowbNw6CHqw3qGseAHDnzh0899xzeOWVVzBp0iSRIv9XdXIwNBKJROu5IAjltlH9mTFjBs6ePYsdO3aIHYrO/Pz8cPr0aZw4cQJTp07F+PHjkZSUJHZYRscY2ghjaB8A428j2D7oF0NuH4D6bSNM6+SsBmrGjBkYOXLkY/fx8fHR/L+TkxOcnJzQqlUrtGnTBp6enjhx4oToXRB0zePOnTvo27cvgoKCsHHjxjqOrmp0zcGQODk5QSqVlrv6dO/evXJXqah+zJw5Ez/++COOHDmCpk2bih2OzszNzdGiRQsAQGBgIOLi4vD5559jw4YNIkdmXIyhjTCG9gEw3jaC7YP+MfT2AajfNoKFxUPKGoHqKLsKJZfLazOkatElj9TUVPTt2xcBAQHYvHkzTEz04yZWTT4LfWdubo6AgABER0dj+PDhmu3R0dEYOnSoiJE1PIIgYObMmdi3bx9iYmLg6+srdki1QhAEvfguMjbG0EYYQ/sAGG8bwfZBfxhr+wDUbRvBwqIaTp48iZMnT6Jnz55o3Lgxrl+/jvfeew/NmzcX/W6FLu7cuYNnnnkGXl5eWLlyJTIyMjSvubm5iRiZblJSUpCVlYWUlBSoVCqcPn0aANCiRQs0atRI3OAqERYWhrFjxyIwMFBzJTAlJcWg+i/n5+fj6tWrmuc3btzA6dOn4eDgAC8vLxEjq7rp06dj+/bt2L9/P2xsbDRXCe3s7GBpaSlydFWzYMECDBo0CJ6ensjLy8N3332HmJgYHDp0SOzQGixjaCOMpX0ADK+NYPugH4yhfQBEaCPqZK4pI3f27Fmhb9++goODgyCTyQQfHx8hNDRUuH37ttih6WTz5s0CgAofhmT8+PEV5nD48GGxQ3usNWvWCN7e3oK5ubnQpUsXg5vC7vDhwxX+3MePHy92aFVW2e//5s2bxQ6tyt544w3N75Gzs7PQv39/ISoqSuywGjRjaCOMpX0QBMNsI9g+iM8Y2gdBqP82QiIIejDamIiIiIiIDJr+dJgkIiIiIiKDxcKCiIiIiIhqjIUFERERERHVGAsLIiIiIiKqMRYWRERERERUYywsiIiIiIioxlhYEBERERFRjbGwICIiIiKiGmNhQURERERENcbCgoiIiIiIaoyFBRERERER1RgLC6J6lpGRATc3N3z88ceabX/99RfMzc0RFRUlYmRERCQmtg9k6CSCIAhiB0HU0ERGRmLYsGE4duwYWrduDX9/fwwePBirVq0SOzQiIhIR2wcyZCwsiEQyffp0/Prrr+jatSvOnDmDuLg4WFhYiB0WERGJjO0DGSoWFkQiKSoqQvv27XHr1i3Ex8ejY8eOYodERER6gO0DGSqOsSASyfXr13Hnzh2o1WokJyeLHQ4REekJtg9kqHjHgkgEJSUl6NatGzp37ozWrVvj008/xblz5+Dq6ip2aEREJCK2D2TIWFgQieDtt9/Gnj17cObMGTRq1Ah9+/aFjY0Nfv75Z7FDIyIiEbF9IEPGrlBE9SwmJgarVq3Ctm3bYGtrCxMTE2zbtg1//PEH1q1bJ3Z4REQkErYPZOh4x4KIiIiIiGqMdyyIiIiIiKjGWFgQEREREVGNsbAgIiIiIqIaY2FBREREREQ1xsKCiIiIiIhqjIUFERERERHVGAsLIiIiIiKqMRYWRERERERUYywsiIiIiIioxlhYEBERERFRjbGwICIiIiKiGmNhQURERERENfb/ekvaz9NGdVQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# Some sample data\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "e7c2032d-eedd-46f2-86be-c36f6a38173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9ef3f6ba-5a83-48d1-89f8-c19974e97b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(GPT_CONFIG_124M[\"emb_dim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "1e3c8273-c7bf-43f8-926b-8441ebd59671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768) #A\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "0812d00b-ee70-4e45-9105-0fa5a93bd4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPT ARCHITECTURE PART 4: SHORTCUT CONNECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f050ac29-aa95-4344-8ef8-1e73f33c56c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of the current layer\n",
    "            layer_output = layer(x)\n",
    "            # Check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "63857679-4873-43ee-bcdf-36adce0cf986",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123) # specify random seed for the initial weights for reproducibility\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7165628c-2b33-45c2-acb1-87896c0a270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # Calculate loss based on how close the target\n",
    "    # and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    \n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "8d63da2d-98db-4cd2-99c1-16ef2b6fee26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173584925942123\n",
      "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
      "layers.2.0.weight has gradient mean of 0.0007152040489017963\n",
      "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "87c76272-8e9b-4798-afc7-6c6890f981ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.3289699852466583\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "da47caa7-ee15-4b4e-aea8-22cd5f4f7140",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPT ARCHITECTURE PART 5: CODING ATTENTION AND LINEAR LAYERS IN A TRANSFORMER BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "d6313dc1-8b77-4988-bb0a-83167539339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d0d8450e-4497-498d-a077-bdefc633b385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768) #A\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "95566d28-8c05-4d5a-8b29-ca426e02bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPT ARCHITECTURE PART 6: ENTIRE GPT MODEL ARCHITECTURE IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "909d4e47-e5e0-42d2-b355-f0c3916dfc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "8df41a00-db14-4064-8364-336c76ebc553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3613,  0.4222, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "5dfa8967-51f8-4d7a-bfef-1dce2f9ba8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "59a5fca4-275d-4c1a-b3b5-d90b8ca17149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "01476056-e9e4-4a4c-a19e-30c4def16a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "e5c49f90-82e7-40ac-9bfe-dfea8f4d5ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4 #A\n",
    "total_size_mb = total_size_bytes / (1024 * 1024) #B\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "9860d0e9-e1ce-4c53-abe9-7b2d43d0111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPT ARCHITECTURE PART 7: GENERATING TEXT FROM OUTPUT TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "89680630-2b27-4d79-96fb-24c29ee83921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "1c1961ed-2167-4cb2-8800-80188dd85b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #A\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "d509ed7a-4acc-46c2-bac9-b03a750ffdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval() #A\n",
    "out = generate_text_simple(\n",
    "model=model,\n",
    "idx=encoded_tensor,\n",
    "max_new_tokens=6,\n",
    "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "cdaa0f57-bc6f-4f2b-acc6-c5789aa0b634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "7b73ca60-0657-4a87-871f-e888f670cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EVALUATING GENERATIVE TEXT MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f2c6cf8f-f0a4-4ec1-b8e7-cc7fa81c9949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you Aeiman Byeswickattributeometer inspector Normandy freezerigrate\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "41ca848a-dc03-4536-970b-344d7fcd9134",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating the text generation loss: cross-entropy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "0842d268-42fb-4bb9-b4f6-f5b7ae678fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f6b85ba1-8bff-41a0-8967-8553e35d8169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "3f497689-629f-4381-ba84-4e59525747ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[36397],\n",
      "         [39619],\n",
      "         [20610]],\n",
      "\n",
      "        [[ 8615],\n",
      "         [49289],\n",
      "         [47105]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "bf9aa439-3015-4f4f-ade2-5ece06284a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Gathering SerbianFriday\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "21e477f5-1f91-4557-81e0-c9f4e1180c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "9fb149c5-2b09-46fe-8ef8-716d76a10fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([    0.0000,     0.0000,     0.0000])\n",
      "Text 2: tensor([    0.0000,     0.0000,     0.0000])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "d6f06f2a-0a93-412c-b88c-dccfeb7aa6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.6600, -10.7936, -11.3531, -10.0591, -11.0276, -11.3658])\n"
     ]
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "6acc8557-89e0-4c4f-91f8-54961d21ae50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.8765)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d422fda3-5a1d-4798-a9aa-6b85646c85ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8765)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "0134f383-f820-4a69-b2c2-af9b2747d133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "aa73726a-6597-49e0-93f7-dd97c5623363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "5d5b9e91-3082-47d8-b92e-5ae7d5fdf4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8765)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "0ef86176-a675-4514-beb6-cc4bfc343bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "792e34b6-33b3-4fcd-b72e-7230fc632cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(52918.7773)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "f86c4424-787c-4781-8fd3-d9dd3a125fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "1c79d2ac-7098-4e71-83dd-dce0b1901ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "e04b72cc-eda7-47d2-a306-0140e82e6bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# First 100 characters\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "66e64a30-8368-4ba6-b070-ee1d4ab32edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# Last 100 characters\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "51ed61ea-bcd3-4049-980e-5d299806d87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "74291f4b-fc23-4452-bc3d-8a5163795fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementing the DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "01bef886-c3c7-4136-92f7-d2ed3f3b7030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "d6e8a5a4-1c18-4751-9c8b-5fa1a8a20350",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "e2ba3af1-afb1-4ab1-baa5-7d09fdaba256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a4d002bc-5139-464a-9ab5-d45ac5a8b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "81c899e7-ff30-42ea-b265-f278cad945e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "9\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "34addfdf-a685-48ba-9b9d-f90f7f2774ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "e4da95fd-eca6-4383-a6ba-00a93aad39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "e2270575-c58c-4254-8abb-91fc0cbbba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "b0d6801b-414e-4ec9-98d9-f4331aecc1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n",
      "Training loss: 10.98758347829183\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "86468a46-7ed6-43cf-9db7-bb5897d6b375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING LOOP FOR THE LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "f849f1de-05af-42bf-aafb-c58021816d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0: \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "331cb80c-2b99-482c-a5a3-c829965ebc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "3c0fb5cf-9b6b-42a5-8b42-396d6244e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "4cb3a582-3364-4cef-b516-804f7cbcc6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[     0.3374,     -0.1778,     -0.3035,  ...,     -0.3181,\n",
      "             -1.3936,      0.5226],\n",
      "        [     0.2579,      0.3420,     -0.8168,  ...,     -0.4098,\n",
      "              0.4978,     -0.3721],\n",
      "        [     0.7957,      0.5350,      0.9427,  ...,     -1.0749,\n",
      "              0.0955,     -1.4138],\n",
      "        ...,\n",
      "        [    -0.7128,     -0.5019,      1.4119,  ...,     -0.1498,\n",
      "             -0.4898,     -1.0620],\n",
      "        [     2.0646,      1.1190,      0.3849,  ...,     -0.7202,\n",
      "             -0.5570,      0.9864],\n",
      "        [     0.0011,     -0.7532,     -0.1792,  ...,     -0.3244,\n",
      "              0.2606,      0.5889]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.8769,  0.2550,  0.8441,  ..., -1.0354,  1.3085,  1.7957],\n",
      "        [-1.0029,  0.0995,  1.2459,  ...,  1.5453, -0.1126, -1.5197],\n",
      "        [ 1.3317,  0.7561,  0.9077,  ...,  0.0830,  1.8336, -2.2225],\n",
      "        ...,\n",
      "        [ 1.1003, -0.5333,  0.5827,  ...,  0.7884,  1.1323, -0.3501],\n",
      "        [ 1.0171,  0.3694, -1.3678,  ..., -0.6988, -0.9380, -1.0564],\n",
      "        [-0.5017,  0.7875,  1.0353,  ...,  1.8956, -0.9677, -0.1236]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[     0.0283,     -0.0332,      0.0125,  ...,      0.0348,\n",
      "              0.0103,      0.0164],\n",
      "        [    -0.0212,     -0.0001,     -0.0106,  ...,     -0.0059,\n",
      "              0.0134,     -0.0315],\n",
      "        [     0.0190,     -0.0124,     -0.0083,  ...,     -0.0237,\n",
      "              0.0043,      0.0235],\n",
      "        ...,\n",
      "        [     0.0133,      0.0099,      0.0012,  ...,      0.0215,\n",
      "             -0.0251,      0.0123],\n",
      "        [    -0.0120,     -0.0322,      0.0083,  ...,      0.0032,\n",
      "              0.0013,     -0.0242],\n",
      "        [    -0.0021,     -0.0241,      0.0218,  ...,      0.0221,\n",
      "             -0.0203,     -0.0166]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0266,  0.0049, -0.0182,  ...,  0.0070, -0.0124, -0.0275],\n",
      "        [ 0.0156, -0.0022, -0.0125,  ..., -0.0274,  0.0311,  0.0285],\n",
      "        [ 0.0044, -0.0063, -0.0033,  ..., -0.0279, -0.0054, -0.0342],\n",
      "        ...,\n",
      "        [ 0.0150, -0.0191,  0.0103,  ..., -0.0287,  0.0078,  0.0257],\n",
      "        [ 0.0301, -0.0164,  0.0020,  ...,  0.0142, -0.0351,  0.0306],\n",
      "        [-0.0109, -0.0126, -0.0245,  ...,  0.0004,  0.0029,  0.0042]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0115, -0.0161,  0.0170,  ..., -0.0193, -0.0269,  0.0054],\n",
      "        [ 0.0125, -0.0345, -0.0224,  ..., -0.0216,  0.0346,  0.0022],\n",
      "        [-0.0311, -0.0035, -0.0185,  ...,  0.0320,  0.0299, -0.0143],\n",
      "        ...,\n",
      "        [-0.0225, -0.0181,  0.0014,  ..., -0.0070,  0.0272,  0.0243],\n",
      "        [ 0.0238, -0.0182, -0.0289,  ...,  0.0255, -0.0353,  0.0074],\n",
      "        [-0.0251, -0.0006,  0.0302,  ..., -0.0309,  0.0350,  0.0207]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0301,  0.0241,  0.0034,  ..., -0.0299, -0.0174,  0.0045],\n",
      "        [ 0.0273,  0.0173, -0.0071,  ...,  0.0114,  0.0329,  0.0273],\n",
      "        [-0.0012,  0.0062,  0.0189,  ..., -0.0198,  0.0092, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0180, -0.0353, -0.0344,  ..., -0.0247,  0.0071,  0.0232],\n",
      "        [ 0.0301,  0.0354,  0.0320,  ...,  0.0084,  0.0132,  0.0334],\n",
      "        [-0.0122, -0.0111, -0.0168,  ..., -0.0063,  0.0201,  0.0099]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([     0.0200,     -0.0237,     -0.0298,     -0.0212,      0.0042,\n",
      "            -0.0132,     -0.0251,     -0.0235,     -0.0212,     -0.0134,\n",
      "            -0.0342,      0.0042,     -0.0310,      0.0277,     -0.0026,\n",
      "            -0.0287,      0.0333,      0.0232,      0.0226,     -0.0360,\n",
      "             0.0084,     -0.0193,     -0.0211,     -0.0332,     -0.0339,\n",
      "             0.0205,     -0.0315,      0.0016,      0.0082,     -0.0242,\n",
      "            -0.0137,      0.0227,     -0.0209,      0.0264,     -0.0261,\n",
      "             0.0160,     -0.0290,     -0.0159,      0.0210,      0.0000,\n",
      "             0.0213,      0.0155,      0.0209,     -0.0279,      0.0155,\n",
      "            -0.0232,      0.0223,      0.0347,      0.0093,     -0.0116,\n",
      "            -0.0223,      0.0158,     -0.0280,      0.0252,      0.0058,\n",
      "             0.0277,      0.0314,     -0.0122,      0.0258,     -0.0285,\n",
      "            -0.0193,     -0.0110,      0.0314,      0.0253,      0.0026,\n",
      "             0.0205,     -0.0013,     -0.0173,      0.0277,     -0.0181,\n",
      "            -0.0310,      0.0343,      0.0167,     -0.0324,     -0.0361,\n",
      "             0.0200,     -0.0245,     -0.0124,     -0.0188,     -0.0161,\n",
      "             0.0224,     -0.0031,     -0.0038,      0.0235,     -0.0014,\n",
      "            -0.0140,     -0.0175,     -0.0006,     -0.0330,     -0.0347,\n",
      "            -0.0152,      0.0194,      0.0338,     -0.0040,      0.0239,\n",
      "             0.0163,      0.0189,      0.0205,     -0.0066,      0.0135,\n",
      "             0.0136,      0.0226,     -0.0150,      0.0006,     -0.0313,\n",
      "             0.0165,     -0.0355,      0.0075,      0.0041,     -0.0358,\n",
      "            -0.0295,      0.0214,     -0.0146,      0.0038,     -0.0102,\n",
      "             0.0167,     -0.0144,      0.0065,      0.0325,      0.0343,\n",
      "            -0.0282,     -0.0332,     -0.0062,     -0.0028,     -0.0211,\n",
      "             0.0296,      0.0329,      0.0094,     -0.0038,     -0.0016,\n",
      "            -0.0348,     -0.0135,     -0.0271,     -0.0326,     -0.0352,\n",
      "             0.0191,     -0.0296,      0.0127,      0.0270,     -0.0045,\n",
      "            -0.0153,      0.0274,     -0.0195,      0.0296,     -0.0327,\n",
      "            -0.0029,      0.0117,      0.0272,      0.0210,     -0.0310,\n",
      "             0.0074,      0.0312,     -0.0044,     -0.0027,      0.0280,\n",
      "             0.0092,      0.0064,      0.0331,     -0.0328,      0.0268,\n",
      "            -0.0285,      0.0179,      0.0162,      0.0220,     -0.0052,\n",
      "             0.0353,     -0.0109,     -0.0112,      0.0351,     -0.0041,\n",
      "             0.0157,      0.0178,     -0.0064,      0.0251,     -0.0135,\n",
      "             0.0251,      0.0206,      0.0034,      0.0109,      0.0038,\n",
      "             0.0338,      0.0128,      0.0299,      0.0138,     -0.0175,\n",
      "             0.0126,     -0.0218,     -0.0332,      0.0288,     -0.0344,\n",
      "            -0.0176,      0.0349,     -0.0249,     -0.0173,      0.0253,\n",
      "            -0.0129,     -0.0259,      0.0275,     -0.0151,      0.0156,\n",
      "            -0.0052,     -0.0265,     -0.0235,      0.0296,      0.0007,\n",
      "            -0.0193,      0.0296,      0.0007,     -0.0032,      0.0233,\n",
      "             0.0309,      0.0051,      0.0015,     -0.0258,     -0.0163,\n",
      "             0.0116,      0.0256,     -0.0317,     -0.0165,      0.0183,\n",
      "             0.0345,     -0.0244,     -0.0009,     -0.0132,      0.0283,\n",
      "             0.0178,      0.0123,     -0.0359,     -0.0001,      0.0266,\n",
      "            -0.0118,      0.0209,     -0.0321,      0.0180,      0.0100,\n",
      "            -0.0194,     -0.0046,      0.0037,     -0.0167,      0.0307,\n",
      "             0.0327,      0.0209,     -0.0323,      0.0190,     -0.0122,\n",
      "            -0.0126,      0.0254,      0.0077,      0.0191,      0.0342,\n",
      "             0.0258,      0.0319,      0.0148,      0.0031,      0.0334,\n",
      "            -0.0098,      0.0023,      0.0196,     -0.0009,      0.0044,\n",
      "             0.0311,      0.0041,     -0.0311,      0.0353,     -0.0039,\n",
      "             0.0177,     -0.0242,      0.0351,      0.0331,      0.0202,\n",
      "            -0.0124,     -0.0267,      0.0077,      0.0225,     -0.0100,\n",
      "             0.0214,     -0.0160,      0.0356,     -0.0104,     -0.0219,\n",
      "            -0.0144,     -0.0170,     -0.0243,     -0.0097,      0.0076,\n",
      "            -0.0306,     -0.0207,      0.0046,     -0.0001,      0.0093,\n",
      "            -0.0085,     -0.0133,     -0.0004,     -0.0311,      0.0282,\n",
      "            -0.0341,      0.0079,     -0.0202,      0.0357,      0.0300,\n",
      "             0.0246,     -0.0231,     -0.0214,      0.0264,     -0.0077,\n",
      "             0.0351,      0.0117,      0.0101,     -0.0055,      0.0208,\n",
      "            -0.0236,      0.0361,      0.0237,     -0.0210,      0.0094,\n",
      "            -0.0069,      0.0100,      0.0011,      0.0302,      0.0257,\n",
      "             0.0163,     -0.0288,     -0.0140,      0.0309,     -0.0160,\n",
      "             0.0290,     -0.0355,     -0.0006,      0.0098,      0.0046,\n",
      "             0.0154,      0.0025,     -0.0187,      0.0218,      0.0203,\n",
      "             0.0238,      0.0220,      0.0018,      0.0171,     -0.0061,\n",
      "            -0.0016,      0.0334,      0.0100,     -0.0175,      0.0356,\n",
      "            -0.0080,      0.0215,      0.0035,     -0.0268,     -0.0020,\n",
      "            -0.0137,     -0.0023,      0.0143,     -0.0026,      0.0073,\n",
      "             0.0099,      0.0014,      0.0124,     -0.0209,      0.0019,\n",
      "            -0.0314,     -0.0002,      0.0021,     -0.0269,     -0.0131,\n",
      "             0.0043,     -0.0110,      0.0119,      0.0114,      0.0059,\n",
      "            -0.0267,     -0.0073,      0.0200,      0.0034,     -0.0060,\n",
      "            -0.0011,      0.0068,      0.0180,      0.0224,     -0.0022,\n",
      "             0.0092,     -0.0173,      0.0120,     -0.0273,     -0.0119,\n",
      "            -0.0116,      0.0113,      0.0280,      0.0095,     -0.0290,\n",
      "            -0.0316,      0.0136,      0.0284,     -0.0316,      0.0150,\n",
      "            -0.0241,      0.0237,     -0.0008,      0.0309,      0.0028,\n",
      "            -0.0175,      0.0193,     -0.0206,      0.0022,     -0.0189,\n",
      "             0.0039,      0.0067,     -0.0058,     -0.0058,      0.0114,\n",
      "            -0.0039,     -0.0061,     -0.0305,      0.0038,     -0.0239,\n",
      "             0.0196,     -0.0304,      0.0119,     -0.0014,      0.0253,\n",
      "            -0.0173,      0.0230,     -0.0274,      0.0192,      0.0170,\n",
      "             0.0223,     -0.0284,      0.0190,      0.0340,     -0.0015,\n",
      "             0.0299,     -0.0278,      0.0324,      0.0300,     -0.0345,\n",
      "            -0.0054,     -0.0129,      0.0115,     -0.0249,      0.0207,\n",
      "            -0.0046,     -0.0195,      0.0257,      0.0109,      0.0330,\n",
      "             0.0257,     -0.0115,      0.0004,      0.0239,     -0.0048,\n",
      "            -0.0357,      0.0033,      0.0349,      0.0136,     -0.0288,\n",
      "             0.0011,     -0.0028,      0.0132,     -0.0153,      0.0173,\n",
      "             0.0002,     -0.0325,     -0.0320,     -0.0172,     -0.0099,\n",
      "             0.0320,     -0.0274,      0.0095,      0.0013,      0.0081,\n",
      "             0.0286,     -0.0353,     -0.0341,      0.0124,      0.0250,\n",
      "             0.0349,      0.0322,     -0.0199,      0.0356,     -0.0210,\n",
      "            -0.0352,     -0.0356,     -0.0322,     -0.0253,      0.0127,\n",
      "            -0.0203,      0.0327,     -0.0314,      0.0254,     -0.0292,\n",
      "            -0.0035,     -0.0031,     -0.0281,     -0.0275,      0.0086,\n",
      "             0.0055,      0.0046,     -0.0212,     -0.0197,     -0.0095,\n",
      "             0.0234,     -0.0349,      0.0286,      0.0126,     -0.0348,\n",
      "             0.0183,      0.0309,      0.0318,      0.0264,      0.0186,\n",
      "             0.0005,     -0.0295,      0.0083,     -0.0065,      0.0121,\n",
      "             0.0045,      0.0331,      0.0066,     -0.0200,      0.0093,\n",
      "             0.0060,      0.0093,     -0.0090,     -0.0105,      0.0189,\n",
      "             0.0150,     -0.0305,      0.0063,      0.0279,      0.0264,\n",
      "             0.0215,      0.0305,     -0.0133,      0.0249,     -0.0314,\n",
      "             0.0099,      0.0162,     -0.0308,     -0.0261,     -0.0338,\n",
      "             0.0019,      0.0083,      0.0126,     -0.0155,      0.0009,\n",
      "            -0.0010,      0.0069,      0.0289,     -0.0102,     -0.0354,\n",
      "            -0.0022,     -0.0080,     -0.0353,      0.0011,     -0.0240,\n",
      "            -0.0076,      0.0037,      0.0104,     -0.0019,     -0.0120,\n",
      "            -0.0165,     -0.0221,      0.0346,     -0.0074,     -0.0290,\n",
      "            -0.0043,     -0.0250,      0.0010,     -0.0004,      0.0026,\n",
      "             0.0023,      0.0222,      0.0360,     -0.0154,     -0.0205,\n",
      "             0.0178,     -0.0306,     -0.0035,     -0.0006,     -0.0199,\n",
      "             0.0040,      0.0056,     -0.0241,     -0.0245,     -0.0091,\n",
      "             0.0229,     -0.0042,     -0.0076,     -0.0149,      0.0249,\n",
      "             0.0212,      0.0166,     -0.0093,      0.0151,      0.0256,\n",
      "            -0.0177,     -0.0235,      0.0114,     -0.0195,      0.0256,\n",
      "            -0.0213,     -0.0142,     -0.0220,     -0.0011,      0.0297,\n",
      "            -0.0082,      0.0143,      0.0348,     -0.0009,      0.0229,\n",
      "            -0.0183,      0.0023,      0.0092,      0.0274,     -0.0032,\n",
      "            -0.0050,     -0.0175,     -0.0236,      0.0000,      0.0124,\n",
      "             0.0162,     -0.0040,      0.0076,     -0.0128,     -0.0111,\n",
      "            -0.0316,     -0.0057,      0.0328,      0.0204,      0.0090,\n",
      "            -0.0197,      0.0176,      0.0044,     -0.0006,      0.0079,\n",
      "             0.0253,      0.0292,     -0.0019,      0.0092,     -0.0060,\n",
      "             0.0228,     -0.0139,     -0.0035,      0.0334,      0.0077,\n",
      "             0.0077,      0.0330,     -0.0217,     -0.0278,     -0.0189,\n",
      "             0.0162,      0.0295,      0.0218,      0.0250,      0.0045,\n",
      "             0.0204,     -0.0262,     -0.0137,      0.0179,      0.0202,\n",
      "            -0.0236,      0.0334,     -0.0037,      0.0093,     -0.0208,\n",
      "             0.0110,      0.0254,      0.0147,      0.0223,      0.0348,\n",
      "            -0.0003,      0.0109,     -0.0255,      0.0098,     -0.0267,\n",
      "            -0.0150,     -0.0023,     -0.0188,      0.0040,      0.0303,\n",
      "            -0.0154,     -0.0232,     -0.0048,     -0.0237,      0.0254,\n",
      "             0.0085,     -0.0183,      0.0219,      0.0052,      0.0347,\n",
      "            -0.0103,     -0.0207,      0.0095,     -0.0264,      0.0203,\n",
      "            -0.0049,     -0.0303,      0.0199,     -0.0004,      0.0192,\n",
      "            -0.0091,      0.0259,      0.0244,     -0.0179,     -0.0264,\n",
      "             0.0293,     -0.0258,      0.0246,     -0.0196,      0.0293,\n",
      "             0.0324,      0.0299,      0.0043,      0.0258,      0.0056,\n",
      "            -0.0112,      0.0008,      0.0072,      0.0221,      0.0009,\n",
      "             0.0181,     -0.0319,     -0.0348,      0.0168,     -0.0305,\n",
      "             0.0360,     -0.0235,     -0.0339,     -0.0309,     -0.0130,\n",
      "            -0.0034,     -0.0298,      0.0204,     -0.0350,     -0.0006,\n",
      "            -0.0200,     -0.0285,     -0.0120,     -0.0049,      0.0098,\n",
      "            -0.0163,     -0.0254,     -0.0032,      0.0185,      0.0183,\n",
      "             0.0097,      0.0158,      0.0047,      0.0101,     -0.0195,\n",
      "             0.0188,      0.0305,      0.0274,      0.0154,      0.0080,\n",
      "            -0.0136,      0.0093,     -0.0169,     -0.0186,     -0.0136,\n",
      "             0.0341,     -0.0295,      0.0229,     -0.0314,      0.0129,\n",
      "            -0.0132,     -0.0345,      0.0227], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0090, -0.0287, -0.0344,  ..., -0.0360,  0.0031, -0.0080],\n",
      "        [-0.0122, -0.0287, -0.0022,  ...,  0.0148, -0.0062,  0.0047],\n",
      "        [-0.0023,  0.0247,  0.0178,  ...,  0.0313, -0.0130, -0.0243],\n",
      "        ...,\n",
      "        [-0.0128,  0.0130,  0.0253,  ...,  0.0313, -0.0141,  0.0171],\n",
      "        [-0.0223, -0.0013, -0.0113,  ...,  0.0085, -0.0196,  0.0128],\n",
      "        [ 0.0264, -0.0036,  0.0240,  ...,  0.0245, -0.0034,  0.0032]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0176, 0.0330, 0.0337,  ..., 0.0245, 0.0124, 0.0359],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0090, -0.0067, -0.0003,  ...,  0.0145, -0.0069,  0.0099],\n",
      "        [ 0.0019,  0.0042,  0.0157,  ..., -0.0068,  0.0090, -0.0055],\n",
      "        [ 0.0106, -0.0105, -0.0093,  ...,  0.0171, -0.0160, -0.0025],\n",
      "        ...,\n",
      "        [ 0.0071,  0.0033,  0.0014,  ...,  0.0045,  0.0111,  0.0140],\n",
      "        [-0.0011, -0.0174, -0.0087,  ...,  0.0107, -0.0042,  0.0132],\n",
      "        [-0.0014,  0.0087,  0.0174,  ..., -0.0074, -0.0014,  0.0013]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([     0.0143,     -0.0178,     -0.0005,     -0.0156,      0.0076,\n",
      "            -0.0005,     -0.0152,      0.0003,     -0.0064,     -0.0124,\n",
      "            -0.0060,     -0.0133,      0.0129,     -0.0121,     -0.0058,\n",
      "            -0.0137,      0.0178,      0.0117,     -0.0016,     -0.0143,\n",
      "            -0.0097,     -0.0080,     -0.0049,     -0.0141,      0.0029,\n",
      "            -0.0068,      0.0101,     -0.0109,      0.0014,      0.0020,\n",
      "             0.0061,     -0.0032,     -0.0139,      0.0154,      0.0141,\n",
      "             0.0081,      0.0068,      0.0126,     -0.0141,      0.0132,\n",
      "             0.0066,     -0.0124,      0.0177,      0.0158,     -0.0176,\n",
      "             0.0075,     -0.0044,     -0.0148,      0.0159,      0.0136,\n",
      "             0.0048,     -0.0130,     -0.0066,      0.0144,      0.0134,\n",
      "            -0.0034,      0.0044,      0.0127,      0.0163,     -0.0172,\n",
      "            -0.0136,      0.0159,     -0.0163,     -0.0026,     -0.0018,\n",
      "            -0.0034,     -0.0147,      0.0063,      0.0129,      0.0060,\n",
      "            -0.0025,      0.0106,      0.0101,      0.0026,     -0.0059,\n",
      "            -0.0126,      0.0077,      0.0079,     -0.0173,     -0.0011,\n",
      "            -0.0066,     -0.0114,      0.0113,     -0.0002,     -0.0023,\n",
      "            -0.0012,     -0.0003,     -0.0179,      0.0158,     -0.0135,\n",
      "             0.0154,     -0.0145,      0.0136,      0.0100,      0.0150,\n",
      "             0.0145,      0.0139,      0.0121,      0.0028,     -0.0090,\n",
      "             0.0010,     -0.0062,      0.0049,     -0.0055,     -0.0135,\n",
      "             0.0025,      0.0097,      0.0070,     -0.0078,     -0.0141,\n",
      "            -0.0025,      0.0167,      0.0093,      0.0051,      0.0126,\n",
      "             0.0058,      0.0042,      0.0048,      0.0179,     -0.0127,\n",
      "             0.0140,     -0.0017,     -0.0159,     -0.0137,      0.0007,\n",
      "             0.0174,      0.0164,     -0.0084,     -0.0102,     -0.0034,\n",
      "             0.0028,     -0.0084,     -0.0058,      0.0061,      0.0158,\n",
      "             0.0001,     -0.0048,      0.0160,     -0.0153,      0.0131,\n",
      "            -0.0166,      0.0168,      0.0101,      0.0122,      0.0176,\n",
      "            -0.0080,     -0.0008,      0.0090,     -0.0065,     -0.0171,\n",
      "            -0.0111,     -0.0009,      0.0039,      0.0107,      0.0054,\n",
      "            -0.0106,      0.0075,      0.0097,      0.0177,     -0.0072,\n",
      "            -0.0114,      0.0092,      0.0085,     -0.0022,      0.0037,\n",
      "             0.0074,     -0.0100,     -0.0085,     -0.0110,     -0.0132,\n",
      "             0.0099,      0.0069,      0.0046,      0.0073,      0.0155,\n",
      "             0.0100,      0.0132,      0.0108,      0.0126,     -0.0145,\n",
      "            -0.0033,     -0.0170,      0.0180,      0.0069,      0.0063,\n",
      "            -0.0122,     -0.0087,     -0.0069,     -0.0009,      0.0026,\n",
      "             0.0107,      0.0052,      0.0044,     -0.0020,     -0.0124,\n",
      "            -0.0102,     -0.0018,     -0.0114,     -0.0015,     -0.0035,\n",
      "             0.0019,      0.0093,     -0.0021,      0.0113,     -0.0031,\n",
      "             0.0109,     -0.0163,     -0.0130,      0.0158,     -0.0170,\n",
      "             0.0160,     -0.0047,     -0.0170,     -0.0018,     -0.0160,\n",
      "            -0.0123,     -0.0101,      0.0082,     -0.0036,      0.0135,\n",
      "             0.0083,      0.0172,      0.0006,      0.0151,      0.0111,\n",
      "            -0.0154,      0.0025,     -0.0115,      0.0092,     -0.0138,\n",
      "            -0.0019,      0.0159,     -0.0155,      0.0140,     -0.0141,\n",
      "            -0.0014,      0.0144,      0.0010,     -0.0127,      0.0007,\n",
      "            -0.0113,     -0.0125,      0.0178,     -0.0070,      0.0096,\n",
      "             0.0018,      0.0110,      0.0156,     -0.0011,     -0.0162,\n",
      "            -0.0049,      0.0031,      0.0008,      0.0074,     -0.0115,\n",
      "             0.0065,      0.0161,      0.0042,      0.0159,     -0.0114,\n",
      "             0.0094,      0.0066,     -0.0178,      0.0006,      0.0068,\n",
      "            -0.0060,     -0.0170,      0.0114,     -0.0135,      0.0168,\n",
      "            -0.0137,     -0.0100,     -0.0179,     -0.0003,      0.0128,\n",
      "             0.0083,      0.0051,     -0.0119,      0.0060,      0.0043,\n",
      "             0.0159,      0.0052,     -0.0023,      0.0089,     -0.0075,\n",
      "             0.0160,     -0.0142,     -0.0178,     -0.0036,     -0.0021,\n",
      "            -0.0060,      0.0126,     -0.0008,      0.0008,     -0.0077,\n",
      "             0.0059,      0.0108,     -0.0055,      0.0055,      0.0082,\n",
      "            -0.0111,      0.0109,      0.0135,      0.0151,      0.0136,\n",
      "             0.0154,     -0.0092,      0.0052,      0.0015,     -0.0153,\n",
      "            -0.0011,     -0.0107,      0.0174,     -0.0047,      0.0038,\n",
      "             0.0177,     -0.0156,     -0.0150,      0.0022,     -0.0130,\n",
      "             0.0026,      0.0122,      0.0118,      0.0062,     -0.0036,\n",
      "             0.0057,      0.0122,      0.0023,      0.0018,     -0.0148,\n",
      "             0.0124,      0.0093,      0.0021,     -0.0044,     -0.0010,\n",
      "             0.0134,     -0.0035,      0.0101,     -0.0055,     -0.0012,\n",
      "             0.0050,      0.0072,     -0.0144,     -0.0146,     -0.0153,\n",
      "            -0.0129,     -0.0180,      0.0028,      0.0092,     -0.0177,\n",
      "            -0.0010,     -0.0060,      0.0024,      0.0007,      0.0065,\n",
      "             0.0020,      0.0045,      0.0048,      0.0136,      0.0178,\n",
      "            -0.0029,      0.0083,      0.0100,      0.0111,     -0.0079,\n",
      "            -0.0090,     -0.0040,      0.0037,      0.0091,     -0.0141,\n",
      "            -0.0177,     -0.0118,     -0.0081,     -0.0141,      0.0025,\n",
      "             0.0152,     -0.0119,     -0.0017,     -0.0004,      0.0023,\n",
      "             0.0035,      0.0056,      0.0126,      0.0061,     -0.0071,\n",
      "             0.0139,     -0.0039,      0.0116,      0.0019,     -0.0102,\n",
      "            -0.0038,     -0.0031,     -0.0123,      0.0111,     -0.0075,\n",
      "             0.0174,      0.0001,     -0.0110,      0.0170,     -0.0010,\n",
      "             0.0042,     -0.0028,      0.0045,     -0.0106,     -0.0153,\n",
      "            -0.0120,      0.0158,      0.0054,     -0.0050,      0.0134,\n",
      "            -0.0020,     -0.0044,      0.0045,     -0.0061,      0.0135,\n",
      "            -0.0109,      0.0159,      0.0048,     -0.0018,      0.0142,\n",
      "             0.0127,      0.0096,      0.0004,     -0.0121,     -0.0058,\n",
      "             0.0173,      0.0087,      0.0061,     -0.0080,     -0.0024,\n",
      "             0.0164,      0.0137,      0.0056,     -0.0170,     -0.0134,\n",
      "             0.0135,      0.0028,     -0.0075,     -0.0102,     -0.0142,\n",
      "            -0.0081,      0.0096,     -0.0124,     -0.0006,     -0.0124,\n",
      "             0.0004,      0.0089,     -0.0065,     -0.0135,     -0.0114,\n",
      "             0.0018,     -0.0117,     -0.0021,      0.0148,      0.0143,\n",
      "             0.0069,     -0.0083,      0.0118,      0.0111,      0.0155,\n",
      "             0.0071,      0.0123,      0.0046,     -0.0109,      0.0027,\n",
      "            -0.0053,      0.0100,     -0.0107,      0.0120,     -0.0151,\n",
      "             0.0054,     -0.0017,      0.0002,     -0.0123,     -0.0121,\n",
      "             0.0115,      0.0109,     -0.0078,      0.0098,     -0.0049,\n",
      "             0.0109,      0.0082,      0.0110,     -0.0114,      0.0150,\n",
      "            -0.0100,      0.0141,     -0.0091,     -0.0115,      0.0100,\n",
      "             0.0071,      0.0051,      0.0032,      0.0086,      0.0101,\n",
      "            -0.0065,      0.0079,      0.0109,      0.0008,     -0.0140,\n",
      "            -0.0124,      0.0091,      0.0101,      0.0090,      0.0162,\n",
      "             0.0013,     -0.0076,     -0.0118,      0.0026,      0.0064,\n",
      "            -0.0005,     -0.0094,      0.0151,     -0.0078,      0.0056,\n",
      "             0.0033,     -0.0004,     -0.0073,      0.0054,     -0.0094,\n",
      "            -0.0107,      0.0157,     -0.0118,      0.0085,     -0.0005,\n",
      "            -0.0110,      0.0089,     -0.0175,     -0.0121,     -0.0167,\n",
      "             0.0059,     -0.0024,     -0.0003,     -0.0087,     -0.0093,\n",
      "             0.0155,     -0.0059,      0.0167,      0.0091,     -0.0117,\n",
      "            -0.0026,      0.0009,      0.0124,      0.0056,      0.0064,\n",
      "             0.0067,     -0.0118,     -0.0132,      0.0001,     -0.0178,\n",
      "            -0.0174,      0.0175,     -0.0048,      0.0013,     -0.0045,\n",
      "            -0.0066,     -0.0086,      0.0051,      0.0132,     -0.0025,\n",
      "             0.0055,      0.0032,      0.0128,     -0.0085,     -0.0058,\n",
      "            -0.0020,     -0.0028,     -0.0021,     -0.0103,      0.0028,\n",
      "             0.0037,      0.0160,      0.0020,     -0.0046,     -0.0074,\n",
      "             0.0030,      0.0158,     -0.0079,     -0.0153,      0.0139,\n",
      "            -0.0116,      0.0076,      0.0129,      0.0087,     -0.0014,\n",
      "             0.0158,     -0.0141,      0.0152,      0.0016,     -0.0163,\n",
      "            -0.0053,      0.0059,     -0.0103,      0.0021,     -0.0141,\n",
      "            -0.0065,      0.0103,      0.0008,     -0.0168,     -0.0175,\n",
      "             0.0037,     -0.0119,      0.0096,     -0.0112,     -0.0137,\n",
      "            -0.0053,      0.0178,     -0.0005,      0.0064,     -0.0104,\n",
      "            -0.0143,      0.0002,      0.0061,      0.0056,     -0.0072,\n",
      "            -0.0164,      0.0141,     -0.0002,     -0.0100,      0.0158,\n",
      "             0.0073,     -0.0060,      0.0142,      0.0031,      0.0071,\n",
      "            -0.0065,      0.0021,     -0.0124,     -0.0033,      0.0093,\n",
      "            -0.0078,      0.0170,     -0.0122,     -0.0000,      0.0087,\n",
      "             0.0102,     -0.0126,     -0.0096,      0.0017,      0.0067,\n",
      "             0.0136,     -0.0120,     -0.0090,      0.0021,      0.0060,\n",
      "             0.0124,     -0.0045,     -0.0152,     -0.0167,     -0.0112,\n",
      "             0.0080,     -0.0051,     -0.0164,      0.0101,      0.0120,\n",
      "             0.0176,     -0.0166,      0.0097,     -0.0076,     -0.0115,\n",
      "             0.0022,      0.0140,      0.0142,      0.0085,     -0.0042,\n",
      "            -0.0156,      0.0046,      0.0170,      0.0060,     -0.0040,\n",
      "            -0.0042,      0.0156,      0.0084,     -0.0093,     -0.0133,\n",
      "            -0.0064,      0.0088,     -0.0000,     -0.0164,      0.0015,\n",
      "             0.0168,     -0.0011,     -0.0041,      0.0078,      0.0096,\n",
      "            -0.0146,     -0.0036,     -0.0025,     -0.0007,     -0.0136,\n",
      "             0.0070,      0.0145,     -0.0043,     -0.0156,     -0.0127,\n",
      "             0.0061,     -0.0039,      0.0102,     -0.0095,      0.0097,\n",
      "             0.0050,      0.0105,     -0.0108,     -0.0043,     -0.0063,\n",
      "            -0.0145,     -0.0159,     -0.0148,      0.0070,      0.0033,\n",
      "            -0.0059,      0.0166,      0.0046,     -0.0098,     -0.0094,\n",
      "            -0.0165,      0.0047,     -0.0105,     -0.0124,     -0.0062,\n",
      "             0.0097,      0.0052,     -0.0100,     -0.0127,      0.0030,\n",
      "            -0.0009,     -0.0116,     -0.0179,      0.0170,     -0.0057,\n",
      "            -0.0005,      0.0073,     -0.0005,     -0.0030,      0.0083,\n",
      "             0.0039,     -0.0053,     -0.0103,      0.0110,     -0.0159,\n",
      "            -0.0169,     -0.0069,      0.0154,      0.0151,     -0.0025,\n",
      "            -0.0070,     -0.0095,     -0.0138,      0.0140,     -0.0100,\n",
      "             0.0052,     -0.0047,      0.0076,      0.0103,      0.0141,\n",
      "             0.0064,      0.0002,     -0.0140,      0.0013,     -0.0110,\n",
      "            -0.0141,      0.0072,     -0.0122,     -0.0120,     -0.0041,\n",
      "            -0.0152,     -0.0100,     -0.0004], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0014, -0.0185, -0.0274,  ..., -0.0335, -0.0231,  0.0215],\n",
      "        [ 0.0051,  0.0113,  0.0072,  ..., -0.0049, -0.0191, -0.0080],\n",
      "        [-0.0184,  0.0212,  0.0305,  ...,  0.0035,  0.0297,  0.0088],\n",
      "        ...,\n",
      "        [ 0.0313,  0.0330, -0.0181,  ...,  0.0297,  0.0001, -0.0250],\n",
      "        [-0.0058, -0.0040, -0.0252,  ..., -0.0290, -0.0078, -0.0297],\n",
      "        [ 0.0005,  0.0100, -0.0057,  ..., -0.0335,  0.0334,  0.0015]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0151, -0.0277, -0.0339,  ..., -0.0276,  0.0181, -0.0308],\n",
      "        [ 0.0359, -0.0352,  0.0189,  ..., -0.0292, -0.0157, -0.0196],\n",
      "        [ 0.0010,  0.0265, -0.0135,  ...,  0.0311, -0.0235,  0.0288],\n",
      "        ...,\n",
      "        [ 0.0023,  0.0113,  0.0009,  ...,  0.0310, -0.0093,  0.0282],\n",
      "        [-0.0004, -0.0021,  0.0163,  ...,  0.0002,  0.0226,  0.0039],\n",
      "        [-0.0049, -0.0300, -0.0137,  ..., -0.0193, -0.0361, -0.0099]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0154, -0.0066,  0.0188,  ...,  0.0124,  0.0092,  0.0001],\n",
      "        [ 0.0101,  0.0074, -0.0322,  ..., -0.0106, -0.0124,  0.0085],\n",
      "        [-0.0242, -0.0106,  0.0334,  ...,  0.0266, -0.0147, -0.0014],\n",
      "        ...,\n",
      "        [ 0.0088,  0.0354, -0.0253,  ...,  0.0290,  0.0173, -0.0311],\n",
      "        [-0.0076,  0.0197, -0.0273,  ..., -0.0123,  0.0277,  0.0246],\n",
      "        [ 0.0264,  0.0199,  0.0315,  ..., -0.0125,  0.0351,  0.0149]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[     0.0353,     -0.0359,     -0.0191,  ...,     -0.0357,\n",
      "             -0.0298,     -0.0010],\n",
      "        [     0.0057,     -0.0275,     -0.0326,  ...,      0.0133,\n",
      "              0.0303,     -0.0294],\n",
      "        [     0.0130,      0.0341,      0.0076,  ...,     -0.0134,\n",
      "             -0.0085,      0.0018],\n",
      "        ...,\n",
      "        [     0.0086,     -0.0220,     -0.0317,  ...,     -0.0049,\n",
      "              0.0055,     -0.0186],\n",
      "        [     0.0337,      0.0058,     -0.0231,  ...,      0.0228,\n",
      "              0.0066,     -0.0034],\n",
      "        [     0.0000,      0.0144,      0.0061,  ...,     -0.0309,\n",
      "              0.0199,     -0.0000]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([     0.0218,     -0.0206,     -0.0117,     -0.0233,     -0.0279,\n",
      "             0.0168,     -0.0062,      0.0144,     -0.0135,     -0.0192,\n",
      "             0.0285,      0.0015,      0.0025,      0.0116,     -0.0102,\n",
      "             0.0260,      0.0059,     -0.0098,     -0.0021,     -0.0173,\n",
      "            -0.0177,     -0.0156,      0.0018,      0.0209,     -0.0337,\n",
      "            -0.0036,      0.0271,     -0.0035,     -0.0153,     -0.0188,\n",
      "             0.0197,      0.0113,      0.0017,     -0.0207,     -0.0028,\n",
      "             0.0256,     -0.0336,      0.0211,     -0.0003,      0.0026,\n",
      "             0.0324,      0.0212,      0.0141,     -0.0350,     -0.0134,\n",
      "            -0.0280,     -0.0103,      0.0196,     -0.0174,     -0.0354,\n",
      "             0.0221,     -0.0182,     -0.0336,     -0.0168,      0.0242,\n",
      "            -0.0136,      0.0134,      0.0266,     -0.0133,      0.0259,\n",
      "             0.0168,     -0.0076,      0.0339,     -0.0215,      0.0177,\n",
      "            -0.0064,     -0.0020,     -0.0250,     -0.0110,     -0.0010,\n",
      "            -0.0129,      0.0130,      0.0033,      0.0330,     -0.0205,\n",
      "             0.0031,     -0.0209,      0.0316,      0.0355,     -0.0116,\n",
      "            -0.0050,      0.0263,     -0.0069,     -0.0041,     -0.0020,\n",
      "            -0.0325,     -0.0350,     -0.0217,     -0.0190,      0.0040,\n",
      "            -0.0100,     -0.0139,     -0.0069,     -0.0353,      0.0064,\n",
      "             0.0072,     -0.0213,      0.0357,     -0.0325,     -0.0317,\n",
      "             0.0262,     -0.0153,     -0.0112,     -0.0313,      0.0297,\n",
      "            -0.0259,      0.0238,      0.0218,      0.0215,      0.0030,\n",
      "            -0.0270,      0.0009,      0.0131,      0.0123,     -0.0137,\n",
      "             0.0322,      0.0256,      0.0294,      0.0360,     -0.0149,\n",
      "            -0.0232,     -0.0018,      0.0023,      0.0195,      0.0353,\n",
      "             0.0073,      0.0103,      0.0250,      0.0302,     -0.0042,\n",
      "            -0.0211,     -0.0327,     -0.0338,     -0.0239,      0.0299,\n",
      "             0.0314,     -0.0306,      0.0068,     -0.0289,      0.0066,\n",
      "            -0.0042,     -0.0133,      0.0333,     -0.0031,      0.0200,\n",
      "             0.0198,      0.0110,      0.0123,     -0.0234,      0.0270,\n",
      "             0.0073,     -0.0325,     -0.0166,     -0.0318,     -0.0274,\n",
      "            -0.0163,     -0.0322,     -0.0151,      0.0253,      0.0010,\n",
      "             0.0286,     -0.0210,     -0.0032,     -0.0062,     -0.0068,\n",
      "             0.0316,      0.0190,     -0.0211,     -0.0157,     -0.0174,\n",
      "            -0.0240,     -0.0314,      0.0281,      0.0011,      0.0261,\n",
      "             0.0315,      0.0084,     -0.0234,     -0.0098,      0.0183,\n",
      "            -0.0003,     -0.0244,     -0.0178,     -0.0043,      0.0237,\n",
      "             0.0239,     -0.0199,     -0.0349,     -0.0043,     -0.0182,\n",
      "             0.0045,      0.0050,      0.0295,     -0.0358,      0.0179,\n",
      "             0.0015,      0.0355,     -0.0324,     -0.0188,     -0.0160,\n",
      "            -0.0165,     -0.0265,      0.0330,      0.0162,     -0.0156,\n",
      "             0.0124,     -0.0115,     -0.0187,     -0.0090,      0.0274,\n",
      "             0.0207,     -0.0210,     -0.0301,      0.0285,     -0.0134,\n",
      "             0.0111,      0.0028,      0.0203,      0.0244,      0.0195,\n",
      "            -0.0067,      0.0084,     -0.0197,     -0.0177,      0.0175,\n",
      "            -0.0078,     -0.0118,     -0.0014,      0.0136,     -0.0128,\n",
      "             0.0277,     -0.0171,     -0.0070,      0.0224,     -0.0152,\n",
      "            -0.0120,      0.0058,      0.0033,      0.0074,      0.0325,\n",
      "             0.0068,     -0.0288,     -0.0146,      0.0300,     -0.0273,\n",
      "             0.0319,      0.0315,     -0.0160,     -0.0356,     -0.0143,\n",
      "             0.0288,     -0.0255,      0.0112,     -0.0057,      0.0067,\n",
      "             0.0279,      0.0173,     -0.0224,     -0.0151,     -0.0301,\n",
      "             0.0183,      0.0102,     -0.0268,      0.0119,      0.0170,\n",
      "            -0.0024,     -0.0009,      0.0334,      0.0196,     -0.0310,\n",
      "            -0.0118,      0.0276,      0.0360,      0.0216,     -0.0285,\n",
      "            -0.0292,      0.0133,      0.0011,      0.0079,     -0.0253,\n",
      "            -0.0211,      0.0333,     -0.0194,     -0.0304,      0.0358,\n",
      "            -0.0108,     -0.0288,     -0.0349,      0.0222,     -0.0120,\n",
      "             0.0249,     -0.0299,      0.0216,      0.0172,      0.0356,\n",
      "            -0.0206,     -0.0271,      0.0228,      0.0127,     -0.0011,\n",
      "             0.0157,      0.0098,     -0.0313,     -0.0082,     -0.0042,\n",
      "             0.0231,      0.0044,     -0.0357,     -0.0222,     -0.0254,\n",
      "            -0.0092,      0.0096,     -0.0197,      0.0072,      0.0034,\n",
      "            -0.0015,      0.0252,      0.0102,      0.0251,      0.0339,\n",
      "             0.0181,     -0.0057,      0.0063,      0.0306,     -0.0150,\n",
      "            -0.0118,     -0.0248,     -0.0207,     -0.0177,     -0.0235,\n",
      "            -0.0083,     -0.0308,     -0.0359,     -0.0341,     -0.0218,\n",
      "             0.0353,      0.0138,     -0.0173,      0.0179,      0.0052,\n",
      "             0.0214,      0.0314,      0.0303,      0.0120,      0.0039,\n",
      "             0.0086,      0.0346,     -0.0228,     -0.0149,     -0.0288,\n",
      "             0.0087,      0.0171,      0.0233,      0.0293,      0.0314,\n",
      "             0.0039,      0.0222,     -0.0030,     -0.0112,     -0.0054,\n",
      "            -0.0354,     -0.0233,     -0.0234,      0.0249,     -0.0185,\n",
      "             0.0136,     -0.0249,      0.0271,     -0.0317,     -0.0336,\n",
      "             0.0255,      0.0355,     -0.0321,      0.0105,     -0.0220,\n",
      "             0.0351,     -0.0114,     -0.0230,     -0.0182,     -0.0351,\n",
      "             0.0061,      0.0100,     -0.0327,      0.0241,      0.0055,\n",
      "            -0.0212,      0.0187,     -0.0197,      0.0036,      0.0085,\n",
      "             0.0151,      0.0134,     -0.0289,      0.0270,      0.0047,\n",
      "             0.0078,     -0.0136,      0.0223,      0.0144,     -0.0213,\n",
      "             0.0247,     -0.0130,     -0.0341,     -0.0031,     -0.0143,\n",
      "             0.0187,     -0.0349,      0.0183,      0.0101,      0.0237,\n",
      "            -0.0095,     -0.0126,     -0.0145,     -0.0067,      0.0165,\n",
      "             0.0099,     -0.0088,     -0.0311,     -0.0184,     -0.0359,\n",
      "             0.0110,     -0.0139,      0.0290,     -0.0272,     -0.0274,\n",
      "            -0.0346,     -0.0071,     -0.0208,      0.0223,      0.0210,\n",
      "             0.0208,     -0.0013,     -0.0196,      0.0013,     -0.0147,\n",
      "            -0.0313,      0.0157,     -0.0200,      0.0310,      0.0139,\n",
      "            -0.0115,      0.0127,      0.0174,     -0.0013,     -0.0087,\n",
      "             0.0100,     -0.0013,     -0.0159,     -0.0308,      0.0096,\n",
      "             0.0226,     -0.0043,      0.0333,      0.0344,     -0.0110,\n",
      "             0.0072,     -0.0171,     -0.0084,     -0.0056,      0.0343,\n",
      "            -0.0343,     -0.0096,      0.0125,      0.0253,      0.0002,\n",
      "             0.0252,      0.0210,     -0.0334,      0.0229,      0.0172,\n",
      "            -0.0024,      0.0019,      0.0108,      0.0062,      0.0102,\n",
      "            -0.0357,     -0.0027,      0.0097,     -0.0144,      0.0000,\n",
      "            -0.0018,      0.0193,     -0.0105,      0.0319,     -0.0315,\n",
      "            -0.0234,      0.0080,     -0.0313,      0.0333,      0.0114,\n",
      "             0.0258,      0.0095,     -0.0326,      0.0304,      0.0045,\n",
      "             0.0088,     -0.0044,      0.0359,      0.0302,     -0.0205,\n",
      "             0.0356,     -0.0285,     -0.0248,      0.0286,      0.0067,\n",
      "            -0.0236,      0.0194,      0.0129,     -0.0221,     -0.0173,\n",
      "            -0.0035,     -0.0349,     -0.0089,      0.0300,      0.0075,\n",
      "            -0.0265,     -0.0203,     -0.0049,     -0.0253,     -0.0240,\n",
      "            -0.0235,     -0.0104,      0.0113,      0.0235,     -0.0018,\n",
      "             0.0222,     -0.0184,      0.0323,     -0.0122,      0.0337,\n",
      "             0.0125,      0.0254,     -0.0032,     -0.0210,     -0.0063,\n",
      "             0.0091,      0.0223,     -0.0254,     -0.0298,     -0.0193,\n",
      "            -0.0218,      0.0067,      0.0219,      0.0333,      0.0338,\n",
      "             0.0187,      0.0023,      0.0168,     -0.0295,     -0.0261,\n",
      "             0.0041,      0.0034,      0.0269,      0.0191,      0.0220,\n",
      "            -0.0134,     -0.0261,      0.0280,     -0.0344,      0.0127,\n",
      "             0.0205,     -0.0080,      0.0206,     -0.0074,      0.0262,\n",
      "            -0.0190,      0.0073,      0.0051,     -0.0032,     -0.0216,\n",
      "             0.0083,      0.0256,      0.0279,     -0.0047,      0.0005,\n",
      "            -0.0231,      0.0029,     -0.0077,     -0.0229,      0.0052,\n",
      "            -0.0123,      0.0146,     -0.0351,      0.0244,     -0.0285,\n",
      "             0.0179,      0.0033,      0.0022,     -0.0285,     -0.0126,\n",
      "             0.0003,     -0.0207,     -0.0175,     -0.0252,     -0.0072,\n",
      "             0.0283,      0.0316,     -0.0192,      0.0176,      0.0338,\n",
      "             0.0253,      0.0227,      0.0165,      0.0185,     -0.0264,\n",
      "             0.0274,     -0.0357,      0.0265,     -0.0277,      0.0110,\n",
      "            -0.0059,      0.0150,      0.0099,      0.0358,      0.0056,\n",
      "             0.0331,     -0.0295,     -0.0003,     -0.0088,      0.0040,\n",
      "             0.0136,      0.0105,      0.0352,     -0.0254,     -0.0308,\n",
      "            -0.0128,      0.0322,     -0.0297,     -0.0136,     -0.0048,\n",
      "            -0.0192,      0.0240,     -0.0346,     -0.0056,     -0.0280,\n",
      "             0.0106,      0.0060,      0.0209,     -0.0063,      0.0287,\n",
      "            -0.0172,     -0.0165,      0.0264,      0.0198,      0.0129,\n",
      "             0.0306,      0.0328,      0.0024,      0.0289,      0.0077,\n",
      "            -0.0075,      0.0025,      0.0123,     -0.0056,      0.0328,\n",
      "            -0.0011,      0.0012,     -0.0031,     -0.0022,     -0.0154,\n",
      "            -0.0050,      0.0084,      0.0085,     -0.0006,     -0.0101,\n",
      "             0.0081,     -0.0134,     -0.0241,      0.0109,      0.0194,\n",
      "             0.0195,     -0.0066,      0.0102,     -0.0032,      0.0085,\n",
      "            -0.0273,     -0.0251,     -0.0242,      0.0216,     -0.0287,\n",
      "            -0.0199,      0.0188,     -0.0172,     -0.0255,     -0.0007,\n",
      "             0.0140,     -0.0231,      0.0352,      0.0022,      0.0185,\n",
      "             0.0091,      0.0357,     -0.0259,     -0.0155,     -0.0312,\n",
      "             0.0024,      0.0332,      0.0031,     -0.0195,      0.0323,\n",
      "            -0.0122,     -0.0160,      0.0071,     -0.0331,     -0.0255,\n",
      "             0.0272,      0.0106,     -0.0171,      0.0345,      0.0210,\n",
      "             0.0298,     -0.0221,      0.0156,      0.0072,     -0.0019,\n",
      "             0.0313,      0.0091,     -0.0128,      0.0144,      0.0196,\n",
      "            -0.0092,      0.0039,      0.0275,     -0.0096,     -0.0023,\n",
      "             0.0108,      0.0097,      0.0217,     -0.0042,      0.0160,\n",
      "             0.0125,      0.0188,     -0.0026,      0.0119,     -0.0135,\n",
      "            -0.0202,     -0.0014,      0.0177,      0.0253,     -0.0065,\n",
      "            -0.0243,     -0.0149,      0.0057,      0.0191,     -0.0144,\n",
      "            -0.0098,      0.0326,     -0.0152,     -0.0145,     -0.0293,\n",
      "             0.0008,      0.0110,      0.0297,     -0.0205,     -0.0151,\n",
      "            -0.0299,     -0.0228,      0.0051,     -0.0351,      0.0089,\n",
      "            -0.0109,     -0.0227,     -0.0102,     -0.0138,     -0.0308,\n",
      "            -0.0315,     -0.0066,     -0.0159], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0325,  0.0296,  0.0218,  ..., -0.0352,  0.0202, -0.0197],\n",
      "        [-0.0185,  0.0096,  0.0291,  ...,  0.0355, -0.0157,  0.0173],\n",
      "        [ 0.0201,  0.0265, -0.0092,  ...,  0.0267, -0.0339,  0.0283],\n",
      "        ...,\n",
      "        [-0.0187,  0.0135,  0.0178,  ...,  0.0119, -0.0206, -0.0047],\n",
      "        [ 0.0306,  0.0217, -0.0068,  ...,  0.0355,  0.0052,  0.0159],\n",
      "        [ 0.0346, -0.0163, -0.0118,  ..., -0.0217, -0.0356,  0.0189]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0226,  0.0064, -0.0112,  ...,  0.0065, -0.0293,  0.0102],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0146,  0.0016, -0.0081,  ..., -0.0112,  0.0026,  0.0111],\n",
      "        [-0.0139,  0.0019,  0.0157,  ...,  0.0027,  0.0129, -0.0093],\n",
      "        [ 0.0161, -0.0070,  0.0006,  ..., -0.0088,  0.0092,  0.0141],\n",
      "        ...,\n",
      "        [-0.0024,  0.0033, -0.0114,  ..., -0.0026,  0.0168,  0.0042],\n",
      "        [-0.0060,  0.0032,  0.0127,  ...,  0.0125, -0.0086, -0.0016],\n",
      "        [ 0.0148,  0.0173,  0.0152,  ...,  0.0163,  0.0179, -0.0070]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([     0.0007,     -0.0160,     -0.0093,     -0.0045,     -0.0099,\n",
      "            -0.0114,      0.0042,     -0.0039,     -0.0176,     -0.0042,\n",
      "             0.0112,     -0.0020,      0.0067,     -0.0023,      0.0078,\n",
      "            -0.0141,     -0.0162,     -0.0098,     -0.0009,      0.0067,\n",
      "            -0.0033,      0.0019,     -0.0003,      0.0128,      0.0100,\n",
      "            -0.0116,      0.0079,     -0.0010,      0.0089,     -0.0163,\n",
      "            -0.0050,      0.0081,      0.0084,      0.0085,     -0.0143,\n",
      "             0.0169,     -0.0023,     -0.0133,      0.0083,      0.0118,\n",
      "            -0.0076,     -0.0017,      0.0143,      0.0028,      0.0015,\n",
      "            -0.0155,      0.0024,     -0.0014,     -0.0127,     -0.0022,\n",
      "             0.0099,      0.0138,     -0.0056,     -0.0008,      0.0092,\n",
      "             0.0163,      0.0130,     -0.0101,     -0.0173,      0.0166,\n",
      "             0.0173,      0.0045,      0.0085,     -0.0132,     -0.0044,\n",
      "             0.0036,     -0.0136,      0.0015,      0.0004,      0.0179,\n",
      "            -0.0175,      0.0163,     -0.0000,     -0.0101,      0.0080,\n",
      "            -0.0008,     -0.0001,     -0.0096,     -0.0062,     -0.0141,\n",
      "             0.0179,      0.0019,     -0.0160,     -0.0119,     -0.0103,\n",
      "            -0.0041,     -0.0017,      0.0068,      0.0162,      0.0092,\n",
      "             0.0057,      0.0050,     -0.0171,     -0.0051,     -0.0012,\n",
      "             0.0114,      0.0131,      0.0092,      0.0141,     -0.0029,\n",
      "             0.0065,     -0.0118,     -0.0023,      0.0063,      0.0147,\n",
      "             0.0039,      0.0048,      0.0040,     -0.0178,      0.0131,\n",
      "            -0.0150,      0.0095,     -0.0109,     -0.0002,     -0.0118,\n",
      "             0.0048,      0.0023,      0.0180,     -0.0116,      0.0060,\n",
      "             0.0061,      0.0085,     -0.0040,      0.0017,      0.0060,\n",
      "            -0.0107,      0.0036,      0.0070,     -0.0090,      0.0062,\n",
      "             0.0095,      0.0097,     -0.0126,      0.0071,      0.0089,\n",
      "             0.0056,      0.0024,      0.0055,      0.0011,      0.0087,\n",
      "            -0.0012,     -0.0097,      0.0139,      0.0020,     -0.0091,\n",
      "             0.0171,     -0.0053,      0.0147,      0.0013,     -0.0131,\n",
      "            -0.0088,      0.0117,     -0.0166,      0.0127,      0.0045,\n",
      "             0.0167,      0.0083,      0.0174,     -0.0002,      0.0018,\n",
      "             0.0069,     -0.0107,     -0.0091,     -0.0055,      0.0137,\n",
      "             0.0125,     -0.0035,      0.0090,     -0.0018,      0.0086,\n",
      "             0.0124,     -0.0064,      0.0162,     -0.0045,     -0.0077,\n",
      "             0.0037,     -0.0099,      0.0131,      0.0072,      0.0074,\n",
      "            -0.0164,      0.0059,     -0.0145,     -0.0079,     -0.0122,\n",
      "            -0.0168,      0.0134,      0.0138,     -0.0156,      0.0146,\n",
      "             0.0109,     -0.0140,      0.0011,     -0.0087,     -0.0157,\n",
      "            -0.0157,      0.0077,      0.0020,     -0.0096,     -0.0043,\n",
      "             0.0163,      0.0168,      0.0048,     -0.0143,      0.0146,\n",
      "             0.0068,      0.0158,      0.0138,     -0.0077,      0.0028,\n",
      "             0.0152,      0.0035,      0.0069,      0.0128,     -0.0053,\n",
      "            -0.0141,     -0.0160,      0.0074,      0.0052,     -0.0018,\n",
      "            -0.0159,      0.0006,     -0.0119,      0.0135,      0.0093,\n",
      "            -0.0086,      0.0129,     -0.0177,      0.0173,     -0.0163,\n",
      "            -0.0057,      0.0049,     -0.0167,     -0.0021,      0.0045,\n",
      "            -0.0049,      0.0076,     -0.0119,      0.0033,     -0.0024,\n",
      "             0.0035,      0.0011,     -0.0088,      0.0171,     -0.0008,\n",
      "             0.0156,     -0.0155,      0.0116,     -0.0107,      0.0143,\n",
      "            -0.0039,     -0.0012,     -0.0039,      0.0136,      0.0068,\n",
      "             0.0024,     -0.0033,     -0.0078,      0.0164,     -0.0020,\n",
      "             0.0083,     -0.0159,      0.0124,      0.0046,     -0.0029,\n",
      "            -0.0174,      0.0166,     -0.0135,     -0.0161,     -0.0073,\n",
      "             0.0167,     -0.0093,      0.0180,      0.0177,     -0.0057,\n",
      "            -0.0111,      0.0114,     -0.0178,      0.0076,     -0.0111,\n",
      "            -0.0067,      0.0045,     -0.0136,      0.0023,      0.0072,\n",
      "             0.0094,     -0.0161,      0.0021,     -0.0034,      0.0015,\n",
      "            -0.0155,      0.0120,     -0.0147,      0.0119,     -0.0056,\n",
      "            -0.0100,      0.0169,      0.0005,      0.0037,      0.0095,\n",
      "             0.0122,      0.0016,     -0.0127,      0.0019,      0.0007,\n",
      "             0.0178,      0.0086,     -0.0066,     -0.0172,      0.0062,\n",
      "            -0.0153,     -0.0108,     -0.0077,      0.0015,     -0.0085,\n",
      "            -0.0065,     -0.0089,     -0.0036,      0.0040,     -0.0062,\n",
      "             0.0090,     -0.0106,      0.0045,     -0.0089,     -0.0013,\n",
      "            -0.0049,      0.0013,      0.0004,      0.0112,     -0.0023,\n",
      "             0.0113,      0.0017,      0.0155,     -0.0171,     -0.0170,\n",
      "            -0.0143,     -0.0063,      0.0171,     -0.0066,      0.0079,\n",
      "            -0.0111,     -0.0155,      0.0031,      0.0071,     -0.0153,\n",
      "             0.0108,     -0.0085,     -0.0121,      0.0087,     -0.0037,\n",
      "            -0.0045,     -0.0104,     -0.0019,     -0.0107,      0.0020,\n",
      "             0.0145,      0.0154,      0.0053,     -0.0015,     -0.0066,\n",
      "             0.0078,      0.0031,      0.0000,      0.0121,     -0.0073,\n",
      "             0.0084,     -0.0040,     -0.0136,     -0.0010,     -0.0083,\n",
      "             0.0136,     -0.0155,      0.0172,     -0.0088,     -0.0178,\n",
      "            -0.0079,      0.0121,     -0.0139,     -0.0026,     -0.0118,\n",
      "            -0.0123,      0.0012,     -0.0068,     -0.0101,      0.0038,\n",
      "            -0.0097,      0.0064,      0.0039,     -0.0163,      0.0178,\n",
      "            -0.0169,      0.0002,      0.0165,     -0.0179,      0.0124,\n",
      "             0.0163,     -0.0151,     -0.0043,     -0.0131,     -0.0010,\n",
      "            -0.0016,      0.0052,     -0.0158,     -0.0058,     -0.0094,\n",
      "             0.0098,      0.0128,      0.0151,     -0.0132,     -0.0031,\n",
      "            -0.0074,      0.0178,     -0.0093,     -0.0052,      0.0115,\n",
      "            -0.0160,     -0.0148,      0.0146,     -0.0163,     -0.0093,\n",
      "            -0.0016,     -0.0168,      0.0065,      0.0061,     -0.0012,\n",
      "            -0.0072,      0.0169,      0.0121,      0.0043,     -0.0125,\n",
      "            -0.0017,     -0.0040,     -0.0163,     -0.0057,      0.0009,\n",
      "             0.0152,      0.0132,      0.0144,     -0.0003,      0.0063,\n",
      "             0.0143,      0.0139,     -0.0149,      0.0008,     -0.0106,\n",
      "             0.0128,     -0.0118,      0.0039,     -0.0123,     -0.0022,\n",
      "            -0.0075,     -0.0116,      0.0097,      0.0087,     -0.0169,\n",
      "            -0.0124,      0.0136,     -0.0069,      0.0084,      0.0031,\n",
      "             0.0068,      0.0088,     -0.0010,      0.0154,      0.0079,\n",
      "            -0.0032,      0.0005,     -0.0003,      0.0058,     -0.0071,\n",
      "             0.0015,      0.0048,      0.0017,      0.0004,      0.0144,\n",
      "             0.0119,     -0.0090,     -0.0011,     -0.0067,      0.0149,\n",
      "             0.0041,      0.0089,     -0.0035,     -0.0178,     -0.0117,\n",
      "             0.0175,     -0.0004,      0.0052,     -0.0136,     -0.0093,\n",
      "            -0.0180,     -0.0035,     -0.0053,      0.0011,      0.0031,\n",
      "            -0.0032,     -0.0138,     -0.0130,      0.0162,      0.0069,\n",
      "             0.0060,      0.0179,     -0.0146,      0.0116,     -0.0040,\n",
      "             0.0011,      0.0121,     -0.0007,     -0.0097,     -0.0074,\n",
      "             0.0022,     -0.0031,      0.0152,     -0.0085,     -0.0089,\n",
      "             0.0170,     -0.0022,      0.0002,      0.0020,     -0.0146,\n",
      "            -0.0151,     -0.0096,      0.0084,     -0.0049,     -0.0061,\n",
      "            -0.0148,     -0.0005,      0.0026,      0.0121,     -0.0141,\n",
      "            -0.0154,      0.0052,      0.0113,      0.0000,     -0.0073,\n",
      "            -0.0152,     -0.0040,     -0.0069,      0.0107,      0.0131,\n",
      "             0.0134,      0.0024,      0.0071,     -0.0070,      0.0141,\n",
      "            -0.0070,     -0.0129,      0.0162,      0.0118,     -0.0163,\n",
      "             0.0011,      0.0050,     -0.0088,      0.0088,      0.0117,\n",
      "             0.0016,     -0.0127,      0.0141,     -0.0173,      0.0153,\n",
      "             0.0009,      0.0119,     -0.0067,      0.0177,      0.0065,\n",
      "            -0.0054,     -0.0137,     -0.0046,     -0.0103,     -0.0017,\n",
      "             0.0024,     -0.0009,      0.0125,     -0.0067,     -0.0080,\n",
      "            -0.0157,     -0.0084,     -0.0083,      0.0097,      0.0001,\n",
      "            -0.0025,      0.0116,     -0.0141,     -0.0130,      0.0118,\n",
      "             0.0144,     -0.0053,      0.0071,      0.0021,     -0.0131,\n",
      "             0.0006,      0.0136,      0.0163,     -0.0086,      0.0077,\n",
      "             0.0118,     -0.0110,      0.0118,     -0.0037,     -0.0053,\n",
      "             0.0061,      0.0124,      0.0045,     -0.0076,     -0.0166,\n",
      "             0.0152,     -0.0140,      0.0025,     -0.0164,      0.0064,\n",
      "             0.0095,      0.0179,      0.0067,      0.0050,     -0.0021,\n",
      "             0.0089,     -0.0038,     -0.0073,      0.0043,     -0.0150,\n",
      "             0.0089,      0.0012,     -0.0152,     -0.0020,     -0.0131,\n",
      "            -0.0058,     -0.0099,     -0.0103,     -0.0030,      0.0057,\n",
      "             0.0098,      0.0028,      0.0068,     -0.0082,      0.0004,\n",
      "             0.0022,      0.0114,     -0.0044,     -0.0079,     -0.0085,\n",
      "            -0.0065,     -0.0143,     -0.0044,     -0.0105,     -0.0126,\n",
      "             0.0056,     -0.0170,     -0.0127,     -0.0078,      0.0025,\n",
      "             0.0008,      0.0010,     -0.0020,      0.0047,     -0.0030,\n",
      "             0.0075,     -0.0104,      0.0152,      0.0048,     -0.0148,\n",
      "            -0.0013,     -0.0020,     -0.0143,      0.0156,     -0.0131,\n",
      "            -0.0125,     -0.0096,      0.0024,     -0.0111,     -0.0137,\n",
      "             0.0097,     -0.0056,     -0.0131,     -0.0110,      0.0054,\n",
      "            -0.0148,     -0.0096,      0.0083,      0.0165,      0.0068,\n",
      "             0.0033,     -0.0045,      0.0064,      0.0028,     -0.0148,\n",
      "             0.0050,      0.0023,     -0.0120,      0.0047,     -0.0030,\n",
      "             0.0176,      0.0154,     -0.0009,      0.0153,     -0.0135,\n",
      "            -0.0011,      0.0073,     -0.0129,      0.0170,      0.0113,\n",
      "            -0.0084,      0.0168,      0.0064,     -0.0153,     -0.0091,\n",
      "            -0.0069,      0.0003,      0.0030,     -0.0161,     -0.0049,\n",
      "             0.0131,      0.0123,     -0.0146,     -0.0066,      0.0157,\n",
      "             0.0067,      0.0142,      0.0035,      0.0180,      0.0048,\n",
      "            -0.0017,     -0.0044,      0.0031,     -0.0069,      0.0057,\n",
      "             0.0036,      0.0144,      0.0043,     -0.0030,     -0.0138,\n",
      "            -0.0153,      0.0051,     -0.0145,     -0.0136,      0.0121,\n",
      "            -0.0102,     -0.0008,      0.0173,      0.0158,      0.0023,\n",
      "             0.0077,      0.0087,      0.0160,      0.0124,     -0.0071,\n",
      "             0.0097,      0.0102,      0.0167,     -0.0047,      0.0002,\n",
      "             0.0121,     -0.0180,      0.0066,     -0.0162,      0.0051,\n",
      "            -0.0038,     -0.0004,     -0.0055,      0.0036,     -0.0123,\n",
      "            -0.0048,     -0.0144,      0.0101,      0.0121,     -0.0094,\n",
      "            -0.0149,     -0.0080,     -0.0102], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0181, -0.0075,  0.0042,  ...,  0.0008, -0.0227, -0.0305],\n",
      "        [-0.0147, -0.0307,  0.0298,  ...,  0.0245, -0.0252,  0.0177],\n",
      "        [-0.0208, -0.0050,  0.0131,  ...,  0.0204,  0.0151, -0.0300],\n",
      "        ...,\n",
      "        [ 0.0174, -0.0227,  0.0089,  ...,  0.0358,  0.0205, -0.0272],\n",
      "        [-0.0062,  0.0120, -0.0050,  ...,  0.0166, -0.0232,  0.0141],\n",
      "        [ 0.0155, -0.0161, -0.0205,  ..., -0.0192, -0.0043,  0.0078]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0264, -0.0033,  0.0135,  ...,  0.0151,  0.0345, -0.0213],\n",
      "        [ 0.0135, -0.0188,  0.0294,  ..., -0.0137,  0.0251,  0.0035],\n",
      "        [-0.0151, -0.0184,  0.0031,  ...,  0.0267, -0.0170,  0.0258],\n",
      "        ...,\n",
      "        [ 0.0171, -0.0292,  0.0325,  ...,  0.0132, -0.0274, -0.0211],\n",
      "        [-0.0045, -0.0263, -0.0312,  ...,  0.0308,  0.0007,  0.0283],\n",
      "        [ 0.0024, -0.0169,  0.0084,  ...,  0.0035,  0.0142,  0.0311]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0143, -0.0205, -0.0265,  ...,  0.0211,  0.0167,  0.0293],\n",
      "        [ 0.0227, -0.0118,  0.0084,  ..., -0.0328,  0.0327,  0.0219],\n",
      "        [-0.0035,  0.0122, -0.0246,  ...,  0.0011,  0.0237,  0.0025],\n",
      "        ...,\n",
      "        [ 0.0073,  0.0269, -0.0235,  ...,  0.0020, -0.0297,  0.0027],\n",
      "        [-0.0129, -0.0207, -0.0085,  ...,  0.0305,  0.0102,  0.0002],\n",
      "        [ 0.0001,  0.0177,  0.0044,  ..., -0.0075,  0.0215, -0.0291]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0009,  0.0263, -0.0240,  ...,  0.0241,  0.0313,  0.0291],\n",
      "        [-0.0069,  0.0137, -0.0211,  ...,  0.0041, -0.0099, -0.0298],\n",
      "        [ 0.0161, -0.0221, -0.0058,  ..., -0.0228, -0.0086, -0.0320],\n",
      "        ...,\n",
      "        [ 0.0353, -0.0318, -0.0093,  ...,  0.0338, -0.0090,  0.0298],\n",
      "        [ 0.0074, -0.0332, -0.0271,  ..., -0.0024,  0.0064, -0.0200],\n",
      "        [ 0.0191, -0.0309, -0.0353,  ...,  0.0233, -0.0058, -0.0180]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([    -0.0084,      0.0134,      0.0149,     -0.0296,      0.0262,\n",
      "            -0.0229,     -0.0107,     -0.0005,      0.0307,     -0.0061,\n",
      "            -0.0018,      0.0134,     -0.0280,      0.0304,      0.0076,\n",
      "            -0.0357,      0.0179,     -0.0195,     -0.0130,      0.0241,\n",
      "             0.0100,      0.0174,      0.0021,     -0.0287,     -0.0032,\n",
      "            -0.0193,      0.0341,      0.0171,     -0.0291,     -0.0205,\n",
      "             0.0180,     -0.0323,     -0.0014,      0.0096,      0.0361,\n",
      "             0.0002,      0.0153,      0.0017,     -0.0009,      0.0235,\n",
      "            -0.0276,      0.0110,      0.0030,      0.0191,     -0.0068,\n",
      "             0.0026,      0.0189,      0.0340,     -0.0065,      0.0158,\n",
      "            -0.0051,      0.0055,     -0.0255,     -0.0145,     -0.0039,\n",
      "             0.0345,      0.0046,     -0.0139,     -0.0205,     -0.0177,\n",
      "             0.0188,      0.0283,     -0.0273,     -0.0032,      0.0164,\n",
      "             0.0078,      0.0285,     -0.0310,     -0.0198,      0.0218,\n",
      "            -0.0359,      0.0124,      0.0256,      0.0133,      0.0336,\n",
      "             0.0211,     -0.0357,     -0.0284,     -0.0015,     -0.0294,\n",
      "            -0.0100,      0.0050,     -0.0335,      0.0118,      0.0158,\n",
      "            -0.0265,     -0.0205,      0.0359,      0.0172,     -0.0219,\n",
      "            -0.0192,     -0.0262,      0.0243,     -0.0017,     -0.0018,\n",
      "            -0.0324,      0.0222,     -0.0113,     -0.0192,      0.0193,\n",
      "            -0.0189,     -0.0233,      0.0252,     -0.0069,     -0.0324,\n",
      "            -0.0321,     -0.0002,      0.0356,      0.0084,      0.0316,\n",
      "            -0.0256,     -0.0031,      0.0121,     -0.0109,      0.0141,\n",
      "            -0.0338,     -0.0200,      0.0088,     -0.0024,     -0.0068,\n",
      "            -0.0196,      0.0314,     -0.0051,     -0.0007,      0.0041,\n",
      "            -0.0057,     -0.0125,     -0.0227,      0.0188,     -0.0135,\n",
      "            -0.0304,     -0.0095,     -0.0245,     -0.0196,     -0.0081,\n",
      "             0.0217,      0.0329,      0.0234,      0.0271,      0.0268,\n",
      "            -0.0289,     -0.0018,     -0.0239,     -0.0070,      0.0270,\n",
      "            -0.0080,     -0.0303,     -0.0006,      0.0238,     -0.0226,\n",
      "             0.0116,     -0.0258,     -0.0210,      0.0010,      0.0317,\n",
      "            -0.0253,     -0.0257,      0.0074,      0.0037,      0.0070,\n",
      "             0.0117,      0.0130,     -0.0163,     -0.0308,      0.0025,\n",
      "            -0.0355,     -0.0120,      0.0134,     -0.0068,     -0.0345,\n",
      "            -0.0300,      0.0125,     -0.0340,     -0.0090,     -0.0040,\n",
      "             0.0308,      0.0135,      0.0351,     -0.0111,     -0.0320,\n",
      "             0.0006,     -0.0015,      0.0022,     -0.0333,     -0.0031,\n",
      "             0.0010,     -0.0076,     -0.0123,      0.0001,     -0.0192,\n",
      "             0.0107,      0.0138,      0.0304,      0.0338,      0.0155,\n",
      "            -0.0282,      0.0061,     -0.0231,     -0.0214,      0.0225,\n",
      "             0.0152,      0.0097,     -0.0006,     -0.0160,     -0.0095,\n",
      "             0.0283,      0.0299,      0.0011,      0.0194,      0.0288,\n",
      "            -0.0102,     -0.0298,      0.0286,      0.0274,      0.0108,\n",
      "            -0.0135,     -0.0080,      0.0230,      0.0016,      0.0243,\n",
      "            -0.0293,     -0.0118,      0.0265,      0.0198,     -0.0140,\n",
      "            -0.0189,      0.0043,      0.0206,     -0.0200,     -0.0188,\n",
      "            -0.0177,     -0.0097,     -0.0243,      0.0190,      0.0194,\n",
      "            -0.0208,     -0.0024,      0.0277,      0.0154,     -0.0331,\n",
      "            -0.0184,      0.0311,     -0.0064,     -0.0129,     -0.0289,\n",
      "            -0.0173,     -0.0331,     -0.0214,      0.0248,     -0.0090,\n",
      "            -0.0159,     -0.0280,      0.0341,      0.0150,      0.0250,\n",
      "            -0.0312,      0.0258,      0.0157,     -0.0159,     -0.0104,\n",
      "            -0.0204,     -0.0254,      0.0347,     -0.0029,     -0.0195,\n",
      "             0.0140,     -0.0277,     -0.0285,      0.0224,      0.0238,\n",
      "             0.0121,     -0.0185,     -0.0079,      0.0027,     -0.0155,\n",
      "            -0.0113,      0.0041,      0.0218,     -0.0122,     -0.0182,\n",
      "            -0.0172,      0.0107,      0.0358,     -0.0351,     -0.0150,\n",
      "             0.0196,      0.0327,      0.0347,     -0.0033,      0.0304,\n",
      "            -0.0178,     -0.0290,     -0.0204,     -0.0289,     -0.0220,\n",
      "             0.0064,      0.0014,     -0.0039,      0.0094,      0.0300,\n",
      "             0.0077,     -0.0354,      0.0318,      0.0319,      0.0226,\n",
      "             0.0289,     -0.0144,      0.0279,      0.0065,      0.0345,\n",
      "             0.0114,      0.0035,      0.0200,      0.0180,      0.0233,\n",
      "             0.0108,     -0.0346,      0.0075,     -0.0125,      0.0341,\n",
      "             0.0076,     -0.0159,     -0.0177,     -0.0234,      0.0184,\n",
      "            -0.0015,     -0.0248,      0.0082,      0.0128,     -0.0265,\n",
      "             0.0268,      0.0037,      0.0018,     -0.0132,      0.0206,\n",
      "             0.0350,      0.0055,      0.0032,      0.0078,      0.0177,\n",
      "             0.0121,      0.0172,     -0.0019,      0.0007,      0.0266,\n",
      "            -0.0239,      0.0170,     -0.0035,      0.0242,     -0.0105,\n",
      "            -0.0120,     -0.0137,     -0.0178,     -0.0074,      0.0041,\n",
      "             0.0193,     -0.0103,     -0.0148,     -0.0315,      0.0150,\n",
      "            -0.0082,      0.0197,     -0.0009,      0.0125,     -0.0075,\n",
      "             0.0293,      0.0310,     -0.0141,      0.0015,     -0.0144,\n",
      "            -0.0247,      0.0186,      0.0285,      0.0196,     -0.0083,\n",
      "            -0.0154,      0.0302,      0.0149,      0.0137,     -0.0041,\n",
      "            -0.0359,      0.0184,     -0.0305,      0.0214,     -0.0087,\n",
      "             0.0208,      0.0344,      0.0342,     -0.0216,      0.0067,\n",
      "             0.0083,     -0.0151,     -0.0027,     -0.0129,     -0.0162,\n",
      "             0.0129,      0.0160,      0.0340,     -0.0132,      0.0232,\n",
      "            -0.0094,      0.0265,      0.0005,     -0.0042,     -0.0359,\n",
      "             0.0080,     -0.0296,      0.0228,     -0.0327,      0.0105,\n",
      "             0.0230,     -0.0290,     -0.0270,      0.0124,      0.0341,\n",
      "            -0.0096,     -0.0154,      0.0104,      0.0063,     -0.0229,\n",
      "             0.0020,      0.0312,      0.0352,     -0.0319,     -0.0355,\n",
      "            -0.0121,      0.0040,      0.0183,      0.0343,      0.0027,\n",
      "             0.0000,      0.0155,     -0.0214,      0.0216,     -0.0234,\n",
      "            -0.0165,     -0.0033,      0.0146,     -0.0165,     -0.0329,\n",
      "            -0.0002,     -0.0084,      0.0152,      0.0333,     -0.0334,\n",
      "            -0.0128,     -0.0132,     -0.0298,      0.0207,     -0.0141,\n",
      "            -0.0266,      0.0127,      0.0093,      0.0291,      0.0133,\n",
      "            -0.0073,     -0.0333,      0.0237,      0.0170,     -0.0201,\n",
      "            -0.0310,     -0.0200,      0.0200,      0.0046,      0.0088,\n",
      "            -0.0123,     -0.0037,      0.0140,      0.0053,      0.0095,\n",
      "             0.0130,      0.0211,      0.0358,      0.0245,     -0.0009,\n",
      "            -0.0209,     -0.0143,      0.0348,      0.0280,      0.0283,\n",
      "            -0.0346,      0.0059,      0.0148,      0.0283,      0.0292,\n",
      "             0.0325,     -0.0111,      0.0057,      0.0264,      0.0283,\n",
      "            -0.0145,     -0.0031,     -0.0105,     -0.0026,      0.0206,\n",
      "            -0.0038,      0.0177,     -0.0300,     -0.0296,     -0.0181,\n",
      "             0.0006,      0.0218,     -0.0339,     -0.0270,      0.0001,\n",
      "            -0.0251,      0.0221,     -0.0149,     -0.0215,     -0.0176,\n",
      "             0.0076,      0.0268,      0.0070,      0.0251,      0.0259,\n",
      "             0.0121,     -0.0137,      0.0099,     -0.0308,     -0.0146,\n",
      "            -0.0357,      0.0345,     -0.0325,     -0.0103,      0.0038,\n",
      "             0.0198,     -0.0242,     -0.0169,      0.0323,      0.0014,\n",
      "            -0.0097,      0.0244,     -0.0202,      0.0067,     -0.0026,\n",
      "             0.0280,      0.0343,     -0.0242,     -0.0314,     -0.0214,\n",
      "             0.0125,      0.0230,     -0.0239,      0.0332,      0.0129,\n",
      "             0.0342,      0.0092,      0.0207,     -0.0107,      0.0356,\n",
      "             0.0310,      0.0010,      0.0231,      0.0227,     -0.0078,\n",
      "             0.0297,     -0.0128,      0.0218,     -0.0172,     -0.0220,\n",
      "             0.0194,     -0.0175,      0.0101,     -0.0142,     -0.0120,\n",
      "            -0.0250,      0.0216,      0.0259,      0.0166,     -0.0192,\n",
      "             0.0151,     -0.0194,     -0.0240,     -0.0160,     -0.0144,\n",
      "            -0.0304,     -0.0160,     -0.0035,      0.0002,      0.0168,\n",
      "            -0.0035,      0.0070,      0.0123,     -0.0314,     -0.0115,\n",
      "             0.0241,      0.0031,     -0.0353,      0.0089,     -0.0248,\n",
      "             0.0003,     -0.0317,      0.0079,      0.0007,     -0.0283,\n",
      "             0.0010,      0.0191,      0.0230,     -0.0011,     -0.0281,\n",
      "            -0.0341,     -0.0144,      0.0080,      0.0018,      0.0260,\n",
      "            -0.0093,      0.0072,     -0.0092,     -0.0082,      0.0314,\n",
      "             0.0005,     -0.0319,     -0.0109,     -0.0140,      0.0226,\n",
      "             0.0263,     -0.0068,      0.0201,     -0.0012,     -0.0149,\n",
      "             0.0350,      0.0235,     -0.0147,      0.0151,      0.0281,\n",
      "            -0.0186,     -0.0341,      0.0132,     -0.0132,     -0.0057,\n",
      "            -0.0021,      0.0119,     -0.0157,      0.0123,     -0.0065,\n",
      "             0.0244,     -0.0305,     -0.0171,     -0.0029,     -0.0238,\n",
      "             0.0291,     -0.0254,     -0.0271,     -0.0324,      0.0099,\n",
      "             0.0346,     -0.0291,     -0.0162,      0.0273,      0.0307,\n",
      "             0.0098,     -0.0322,     -0.0048,      0.0024,     -0.0118,\n",
      "             0.0186,     -0.0277,     -0.0098,      0.0148,      0.0224,\n",
      "            -0.0127,     -0.0170,     -0.0288,      0.0112,     -0.0095,\n",
      "             0.0093,     -0.0032,     -0.0264,      0.0142,     -0.0249,\n",
      "             0.0334,      0.0215,      0.0330,      0.0102,      0.0118,\n",
      "            -0.0028,     -0.0199,      0.0191,      0.0155,     -0.0046,\n",
      "            -0.0051,      0.0274,     -0.0303,      0.0244,     -0.0294,\n",
      "             0.0191,     -0.0063,      0.0089,      0.0204,     -0.0205,\n",
      "             0.0147,     -0.0250,      0.0170,      0.0111,     -0.0159,\n",
      "            -0.0359,      0.0343,     -0.0345,      0.0005,     -0.0043,\n",
      "            -0.0241,      0.0034,      0.0355,     -0.0179,     -0.0117,\n",
      "             0.0202,      0.0291,     -0.0045,      0.0080,      0.0040,\n",
      "             0.0065,     -0.0003,     -0.0258,      0.0187,      0.0196,\n",
      "             0.0359,     -0.0242,     -0.0287,     -0.0215,      0.0235,\n",
      "            -0.0177,      0.0170,     -0.0358,      0.0207,      0.0355,\n",
      "             0.0196,     -0.0329,     -0.0242,      0.0158,      0.0263,\n",
      "            -0.0099,      0.0183,     -0.0020,      0.0116,     -0.0050,\n",
      "            -0.0203,      0.0258,     -0.0216,     -0.0203,      0.0301,\n",
      "             0.0188,     -0.0185,      0.0285,      0.0293,     -0.0058,\n",
      "            -0.0247,     -0.0266,     -0.0355,      0.0245,     -0.0084,\n",
      "            -0.0115,      0.0297,      0.0094,     -0.0103,     -0.0029,\n",
      "             0.0302,      0.0297,     -0.0092,      0.0230,     -0.0297,\n",
      "             0.0296,     -0.0226,      0.0334,     -0.0183,      0.0224,\n",
      "             0.0320,      0.0002,     -0.0150], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0142, -0.0260,  0.0183,  ..., -0.0064, -0.0190,  0.0081],\n",
      "        [ 0.0138, -0.0269, -0.0218,  ...,  0.0071,  0.0143, -0.0340],\n",
      "        [-0.0328,  0.0211, -0.0270,  ...,  0.0318,  0.0113, -0.0008],\n",
      "        ...,\n",
      "        [ 0.0223, -0.0130, -0.0195,  ..., -0.0010, -0.0010,  0.0139],\n",
      "        [ 0.0292,  0.0182,  0.0146,  ...,  0.0109, -0.0037,  0.0152],\n",
      "        [ 0.0171,  0.0146,  0.0257,  ..., -0.0261,  0.0206,  0.0278]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0357, -0.0162, -0.0006,  ..., -0.0282,  0.0233,  0.0282],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0014, -0.0167,  0.0170,  ..., -0.0134, -0.0061,  0.0110],\n",
      "        [ 0.0016,  0.0103, -0.0100,  ...,  0.0043,  0.0077, -0.0169],\n",
      "        [-0.0022, -0.0123,  0.0033,  ..., -0.0141, -0.0079, -0.0064],\n",
      "        ...,\n",
      "        [ 0.0054,  0.0084,  0.0045,  ...,  0.0168, -0.0122,  0.0054],\n",
      "        [ 0.0104,  0.0074,  0.0130,  ..., -0.0026, -0.0151, -0.0144],\n",
      "        [ 0.0011, -0.0080,  0.0054,  ...,  0.0049, -0.0107, -0.0018]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([    -0.0087,      0.0179,     -0.0165,      0.0085,      0.0089,\n",
      "            -0.0170,      0.0075,     -0.0079,      0.0119,     -0.0049,\n",
      "             0.0052,      0.0092,     -0.0080,     -0.0016,      0.0081,\n",
      "            -0.0124,      0.0108,      0.0170,     -0.0152,     -0.0016,\n",
      "             0.0048,     -0.0008,      0.0129,     -0.0062,      0.0051,\n",
      "             0.0084,      0.0156,      0.0118,      0.0102,      0.0125,\n",
      "            -0.0126,      0.0120,     -0.0125,     -0.0153,      0.0172,\n",
      "             0.0028,      0.0035,     -0.0018,      0.0056,     -0.0072,\n",
      "            -0.0135,     -0.0020,      0.0002,     -0.0157,      0.0012,\n",
      "            -0.0123,      0.0103,     -0.0034,     -0.0078,     -0.0083,\n",
      "            -0.0144,     -0.0087,     -0.0177,     -0.0059,      0.0083,\n",
      "            -0.0028,      0.0144,      0.0012,     -0.0054,     -0.0045,\n",
      "            -0.0036,      0.0019,      0.0053,      0.0100,      0.0175,\n",
      "            -0.0058,     -0.0095,     -0.0150,      0.0126,      0.0147,\n",
      "             0.0122,      0.0075,     -0.0079,      0.0044,      0.0083,\n",
      "            -0.0176,      0.0043,     -0.0142,      0.0120,      0.0088,\n",
      "             0.0074,     -0.0170,      0.0152,      0.0021,     -0.0160,\n",
      "            -0.0057,      0.0177,      0.0094,     -0.0052,     -0.0175,\n",
      "             0.0000,     -0.0002,      0.0089,      0.0170,      0.0037,\n",
      "             0.0023,      0.0150,     -0.0061,      0.0172,     -0.0080,\n",
      "            -0.0066,      0.0016,     -0.0006,     -0.0054,     -0.0067,\n",
      "            -0.0027,     -0.0126,     -0.0150,     -0.0152,      0.0100,\n",
      "            -0.0002,      0.0163,     -0.0175,      0.0084,      0.0028,\n",
      "            -0.0093,      0.0033,     -0.0095,      0.0021,     -0.0131,\n",
      "            -0.0036,     -0.0028,      0.0055,     -0.0115,      0.0094,\n",
      "            -0.0077,      0.0174,      0.0102,      0.0150,      0.0072,\n",
      "            -0.0046,     -0.0143,      0.0089,     -0.0116,      0.0070,\n",
      "            -0.0145,      0.0055,     -0.0129,     -0.0071,      0.0115,\n",
      "             0.0132,      0.0141,      0.0095,      0.0178,      0.0146,\n",
      "            -0.0061,      0.0112,     -0.0054,      0.0134,      0.0028,\n",
      "            -0.0153,     -0.0020,      0.0112,     -0.0048,      0.0018,\n",
      "            -0.0066,     -0.0156,      0.0096,      0.0094,      0.0030,\n",
      "            -0.0039,     -0.0110,     -0.0099,      0.0123,     -0.0115,\n",
      "            -0.0145,      0.0060,     -0.0171,      0.0139,     -0.0144,\n",
      "            -0.0074,      0.0015,     -0.0054,      0.0037,     -0.0117,\n",
      "            -0.0153,     -0.0046,      0.0167,     -0.0125,     -0.0160,\n",
      "            -0.0010,     -0.0067,     -0.0098,      0.0168,      0.0003,\n",
      "             0.0029,     -0.0122,     -0.0022,      0.0051,     -0.0069,\n",
      "            -0.0039,     -0.0044,     -0.0045,     -0.0005,      0.0126,\n",
      "            -0.0041,      0.0137,     -0.0117,      0.0073,     -0.0087,\n",
      "            -0.0019,      0.0131,     -0.0080,     -0.0082,      0.0060,\n",
      "             0.0021,     -0.0081,      0.0065,      0.0167,      0.0039,\n",
      "             0.0091,      0.0020,     -0.0166,      0.0030,      0.0115,\n",
      "            -0.0083,     -0.0111,     -0.0110,      0.0144,     -0.0090,\n",
      "            -0.0047,      0.0113,      0.0054,     -0.0042,     -0.0019,\n",
      "            -0.0028,      0.0108,      0.0099,      0.0068,     -0.0014,\n",
      "            -0.0174,     -0.0160,     -0.0074,      0.0127,     -0.0152,\n",
      "            -0.0037,      0.0023,     -0.0133,     -0.0140,     -0.0013,\n",
      "            -0.0066,      0.0024,      0.0111,     -0.0097,     -0.0060,\n",
      "             0.0180,      0.0007,      0.0084,     -0.0068,     -0.0002,\n",
      "            -0.0174,      0.0155,      0.0125,      0.0040,     -0.0098,\n",
      "             0.0129,     -0.0170,     -0.0147,      0.0036,      0.0132,\n",
      "             0.0013,     -0.0138,      0.0145,     -0.0054,     -0.0069,\n",
      "             0.0048,     -0.0065,     -0.0137,     -0.0109,      0.0137,\n",
      "             0.0107,      0.0081,     -0.0086,      0.0168,      0.0025,\n",
      "            -0.0014,     -0.0080,     -0.0031,      0.0086,     -0.0030,\n",
      "             0.0127,     -0.0133,     -0.0102,     -0.0059,      0.0004,\n",
      "             0.0024,     -0.0055,     -0.0025,      0.0066,     -0.0155,\n",
      "             0.0162,      0.0029,     -0.0125,     -0.0176,      0.0004,\n",
      "             0.0159,     -0.0146,      0.0060,     -0.0095,      0.0093,\n",
      "             0.0007,      0.0117,      0.0139,     -0.0069,      0.0025,\n",
      "            -0.0121,     -0.0166,      0.0096,      0.0098,      0.0103,\n",
      "            -0.0111,      0.0102,     -0.0168,      0.0079,     -0.0012,\n",
      "             0.0048,     -0.0114,     -0.0171,      0.0018,      0.0083,\n",
      "            -0.0015,     -0.0014,     -0.0178,      0.0141,     -0.0109,\n",
      "             0.0055,     -0.0007,     -0.0173,      0.0103,     -0.0093,\n",
      "             0.0020,      0.0072,     -0.0072,     -0.0136,     -0.0132,\n",
      "             0.0007,      0.0129,     -0.0052,      0.0047,     -0.0137,\n",
      "            -0.0163,     -0.0086,      0.0004,      0.0102,      0.0015,\n",
      "            -0.0035,     -0.0124,      0.0148,     -0.0021,     -0.0110,\n",
      "            -0.0081,      0.0056,     -0.0139,      0.0115,      0.0036,\n",
      "            -0.0019,     -0.0017,      0.0007,     -0.0026,     -0.0086,\n",
      "             0.0103,     -0.0034,      0.0140,     -0.0161,      0.0003,\n",
      "            -0.0144,      0.0116,      0.0030,      0.0137,      0.0051,\n",
      "             0.0012,      0.0169,     -0.0177,      0.0175,      0.0047,\n",
      "             0.0020,     -0.0077,      0.0113,      0.0113,     -0.0024,\n",
      "            -0.0115,      0.0060,      0.0056,      0.0050,     -0.0107,\n",
      "            -0.0085,     -0.0032,     -0.0080,      0.0116,      0.0161,\n",
      "             0.0165,     -0.0158,     -0.0081,      0.0164,      0.0150,\n",
      "             0.0106,     -0.0045,      0.0017,      0.0021,     -0.0158,\n",
      "             0.0072,      0.0161,      0.0031,      0.0029,      0.0072,\n",
      "            -0.0059,      0.0043,     -0.0146,     -0.0048,      0.0170,\n",
      "            -0.0053,      0.0030,      0.0153,      0.0034,      0.0113,\n",
      "            -0.0172,     -0.0150,      0.0174,     -0.0097,     -0.0155,\n",
      "            -0.0178,     -0.0038,      0.0030,     -0.0083,     -0.0032,\n",
      "            -0.0047,     -0.0173,     -0.0070,     -0.0119,     -0.0106,\n",
      "             0.0172,      0.0063,     -0.0164,      0.0097,     -0.0170,\n",
      "             0.0063,     -0.0054,     -0.0025,     -0.0128,     -0.0112,\n",
      "             0.0112,      0.0116,      0.0070,      0.0035,      0.0167,\n",
      "             0.0123,     -0.0173,      0.0111,     -0.0091,      0.0122,\n",
      "             0.0003,      0.0001,      0.0105,      0.0095,     -0.0132,\n",
      "             0.0076,     -0.0122,     -0.0108,      0.0139,      0.0169,\n",
      "             0.0006,     -0.0100,     -0.0180,      0.0107,     -0.0003,\n",
      "             0.0012,     -0.0157,      0.0117,      0.0026,     -0.0140,\n",
      "            -0.0121,      0.0066,      0.0066,      0.0009,      0.0023,\n",
      "             0.0101,      0.0164,     -0.0119,     -0.0033,     -0.0005,\n",
      "             0.0076,     -0.0069,      0.0128,      0.0044,      0.0174,\n",
      "            -0.0044,      0.0149,      0.0028,     -0.0137,      0.0033,\n",
      "             0.0137,     -0.0165,     -0.0163,      0.0125,     -0.0053,\n",
      "            -0.0073,     -0.0046,      0.0140,     -0.0007,     -0.0096,\n",
      "            -0.0013,     -0.0060,      0.0084,      0.0160,     -0.0145,\n",
      "            -0.0049,     -0.0081,      0.0059,     -0.0001,      0.0156,\n",
      "             0.0099,     -0.0115,     -0.0018,     -0.0115,     -0.0168,\n",
      "            -0.0088,      0.0087,     -0.0029,     -0.0144,      0.0015,\n",
      "            -0.0103,     -0.0173,     -0.0098,      0.0148,     -0.0146,\n",
      "             0.0038,     -0.0175,      0.0028,     -0.0057,      0.0138,\n",
      "            -0.0171,      0.0066,      0.0176,      0.0157,     -0.0052,\n",
      "             0.0068,     -0.0109,     -0.0060,      0.0028,      0.0147,\n",
      "            -0.0156,      0.0140,     -0.0172,     -0.0154,      0.0105,\n",
      "            -0.0084,     -0.0098,      0.0069,      0.0084,     -0.0115,\n",
      "            -0.0146,     -0.0092,     -0.0085,     -0.0058,      0.0136,\n",
      "             0.0067,      0.0057,     -0.0056,      0.0025,     -0.0097,\n",
      "            -0.0176,      0.0104,     -0.0018,      0.0145,     -0.0143,\n",
      "            -0.0022,      0.0170,     -0.0012,      0.0045,      0.0113,\n",
      "             0.0070,      0.0159,     -0.0170,     -0.0050,      0.0009,\n",
      "            -0.0118,      0.0013,      0.0132,      0.0004,     -0.0163,\n",
      "             0.0138,      0.0117,     -0.0091,      0.0076,      0.0101,\n",
      "            -0.0051,      0.0033,      0.0037,      0.0164,      0.0007,\n",
      "            -0.0158,     -0.0051,      0.0037,      0.0071,      0.0120,\n",
      "            -0.0090,     -0.0129,      0.0105,      0.0139,     -0.0015,\n",
      "             0.0085,     -0.0040,      0.0039,      0.0087,     -0.0046,\n",
      "            -0.0018,     -0.0068,      0.0164,     -0.0145,      0.0025,\n",
      "             0.0001,      0.0078,     -0.0154,     -0.0176,      0.0155,\n",
      "             0.0051,      0.0161,     -0.0145,      0.0110,      0.0178,\n",
      "            -0.0175,      0.0162,     -0.0006,     -0.0143,      0.0049,\n",
      "            -0.0087,     -0.0118,      0.0121,      0.0026,     -0.0141,\n",
      "             0.0073,     -0.0098,     -0.0156,      0.0170,      0.0038,\n",
      "            -0.0165,     -0.0081,     -0.0117,      0.0092,      0.0165,\n",
      "            -0.0163,     -0.0155,      0.0158,     -0.0058,     -0.0170,\n",
      "            -0.0047,     -0.0161,      0.0043,     -0.0079,     -0.0097,\n",
      "             0.0131,      0.0118,     -0.0067,     -0.0084,     -0.0081,\n",
      "             0.0072,     -0.0029,      0.0005,     -0.0108,     -0.0109,\n",
      "            -0.0149,      0.0101,     -0.0091,      0.0024,     -0.0170,\n",
      "            -0.0131,      0.0087,      0.0163,      0.0007,      0.0029,\n",
      "             0.0159,     -0.0031,      0.0010,     -0.0041,     -0.0120,\n",
      "            -0.0077,     -0.0175,      0.0154,      0.0101,      0.0148,\n",
      "             0.0025,     -0.0176,     -0.0003,      0.0008,     -0.0126,\n",
      "            -0.0179,      0.0048,     -0.0098,     -0.0013,      0.0072,\n",
      "            -0.0041,     -0.0115,     -0.0074,      0.0081,      0.0093,\n",
      "             0.0110,      0.0098,     -0.0009,     -0.0064,      0.0137,\n",
      "            -0.0114,     -0.0151,     -0.0015,      0.0065,     -0.0082,\n",
      "             0.0112,     -0.0178,      0.0081,      0.0005,     -0.0122,\n",
      "            -0.0069,     -0.0128,      0.0095,     -0.0023,     -0.0083,\n",
      "             0.0104,      0.0050,     -0.0090,     -0.0108,      0.0161,\n",
      "             0.0122,     -0.0178,     -0.0092,      0.0022,      0.0130,\n",
      "            -0.0133,     -0.0134,     -0.0059,     -0.0046,      0.0180,\n",
      "            -0.0001,      0.0131,     -0.0124,      0.0119,      0.0084,\n",
      "             0.0090,      0.0145,     -0.0062,      0.0158,     -0.0148,\n",
      "            -0.0144,     -0.0004,     -0.0128,      0.0160,      0.0020,\n",
      "            -0.0069,     -0.0022,     -0.0088,      0.0085,      0.0062,\n",
      "             0.0039,      0.0096,      0.0138,     -0.0047,     -0.0038,\n",
      "            -0.0128,      0.0052,     -0.0092,      0.0148,      0.0138,\n",
      "            -0.0087,      0.0163,     -0.0115,      0.0138,      0.0036,\n",
      "            -0.0074,     -0.0077,      0.0064], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0102, -0.0322,  0.0283,  ...,  0.0240, -0.0230,  0.0346],\n",
      "        [ 0.0117,  0.0167,  0.0180,  ..., -0.0216, -0.0080, -0.0186],\n",
      "        [ 0.0359,  0.0041, -0.0322,  ..., -0.0334, -0.0257,  0.0205],\n",
      "        ...,\n",
      "        [ 0.0177,  0.0170,  0.0213,  ...,  0.0359, -0.0011, -0.0209],\n",
      "        [-0.0164, -0.0013,  0.0015,  ..., -0.0234, -0.0100,  0.0008],\n",
      "        [-0.0296,  0.0317,  0.0119,  ..., -0.0034, -0.0071, -0.0253]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0044, -0.0314,  0.0292,  ..., -0.0063, -0.0111, -0.0145],\n",
      "        [ 0.0242,  0.0219,  0.0168,  ...,  0.0037, -0.0240, -0.0287],\n",
      "        [ 0.0357, -0.0302,  0.0177,  ...,  0.0089, -0.0107, -0.0244],\n",
      "        ...,\n",
      "        [ 0.0281,  0.0338,  0.0307,  ..., -0.0213,  0.0273,  0.0057],\n",
      "        [ 0.0329, -0.0282, -0.0177,  ..., -0.0041,  0.0294, -0.0121],\n",
      "        [ 0.0220, -0.0095,  0.0359,  ...,  0.0172,  0.0178, -0.0108]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0173,  0.0241,  0.0262,  ...,  0.0306,  0.0186,  0.0309],\n",
      "        [ 0.0283, -0.0234,  0.0063,  ..., -0.0345, -0.0200,  0.0111],\n",
      "        [-0.0153,  0.0078, -0.0298,  ..., -0.0094,  0.0249, -0.0025],\n",
      "        ...,\n",
      "        [-0.0015,  0.0205, -0.0077,  ...,  0.0327, -0.0243, -0.0235],\n",
      "        [-0.0013,  0.0282, -0.0335,  ..., -0.0295,  0.0190, -0.0300],\n",
      "        [-0.0334, -0.0347,  0.0321,  ..., -0.0024, -0.0325,  0.0321]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0178,  0.0136, -0.0270,  ...,  0.0209, -0.0082,  0.0216],\n",
      "        [ 0.0218, -0.0172,  0.0330,  ...,  0.0281,  0.0224, -0.0286],\n",
      "        [ 0.0092,  0.0069, -0.0326,  ...,  0.0301, -0.0019, -0.0243],\n",
      "        ...,\n",
      "        [-0.0205,  0.0133, -0.0130,  ...,  0.0034,  0.0223,  0.0086],\n",
      "        [ 0.0222,  0.0214,  0.0308,  ..., -0.0229, -0.0119,  0.0265],\n",
      "        [ 0.0188, -0.0309, -0.0154,  ...,  0.0179,  0.0256, -0.0023]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([     0.0055,      0.0117,     -0.0259,     -0.0221,     -0.0082,\n",
      "             0.0249,     -0.0309,      0.0003,     -0.0236,     -0.0231,\n",
      "            -0.0276,     -0.0212,     -0.0192,      0.0155,     -0.0082,\n",
      "             0.0220,      0.0314,      0.0104,     -0.0081,      0.0268,\n",
      "            -0.0285,      0.0151,     -0.0138,     -0.0073,     -0.0287,\n",
      "             0.0109,      0.0202,     -0.0286,     -0.0306,     -0.0148,\n",
      "             0.0291,     -0.0161,      0.0199,      0.0006,     -0.0137,\n",
      "            -0.0307,      0.0239,      0.0320,      0.0077,     -0.0286,\n",
      "            -0.0053,      0.0296,     -0.0152,      0.0146,     -0.0138,\n",
      "            -0.0167,      0.0315,     -0.0291,     -0.0360,      0.0122,\n",
      "             0.0223,      0.0250,      0.0307,     -0.0126,      0.0046,\n",
      "             0.0055,     -0.0339,     -0.0350,      0.0293,      0.0009,\n",
      "             0.0100,      0.0286,     -0.0323,      0.0154,      0.0081,\n",
      "            -0.0226,     -0.0178,     -0.0093,      0.0218,     -0.0070,\n",
      "            -0.0174,      0.0150,      0.0281,     -0.0324,      0.0204,\n",
      "             0.0197,      0.0145,     -0.0101,     -0.0356,     -0.0351,\n",
      "             0.0263,      0.0115,     -0.0181,     -0.0275,      0.0178,\n",
      "             0.0342,      0.0125,     -0.0043,     -0.0331,     -0.0155,\n",
      "             0.0321,     -0.0105,      0.0252,     -0.0106,     -0.0336,\n",
      "            -0.0036,     -0.0214,      0.0277,     -0.0342,     -0.0047,\n",
      "             0.0104,     -0.0011,     -0.0321,     -0.0077,      0.0321,\n",
      "            -0.0133,     -0.0274,     -0.0167,     -0.0192,     -0.0151,\n",
      "             0.0130,      0.0281,      0.0054,      0.0107,      0.0059,\n",
      "            -0.0103,     -0.0102,     -0.0051,     -0.0233,     -0.0055,\n",
      "            -0.0081,      0.0141,      0.0340,     -0.0358,      0.0222,\n",
      "             0.0328,     -0.0011,      0.0011,     -0.0175,     -0.0095,\n",
      "             0.0346,      0.0163,      0.0283,     -0.0005,      0.0192,\n",
      "             0.0213,      0.0135,      0.0032,     -0.0136,     -0.0104,\n",
      "            -0.0287,      0.0291,     -0.0353,     -0.0080,     -0.0289,\n",
      "             0.0204,     -0.0308,      0.0115,     -0.0005,     -0.0126,\n",
      "            -0.0172,     -0.0326,      0.0287,      0.0252,      0.0112,\n",
      "             0.0233,      0.0071,     -0.0065,      0.0135,     -0.0292,\n",
      "             0.0229,     -0.0191,     -0.0164,     -0.0272,      0.0322,\n",
      "            -0.0062,      0.0346,      0.0016,      0.0274,     -0.0259,\n",
      "             0.0168,     -0.0265,     -0.0202,      0.0242,      0.0263,\n",
      "            -0.0093,     -0.0230,     -0.0179,     -0.0308,     -0.0254,\n",
      "            -0.0345,     -0.0234,      0.0181,     -0.0046,      0.0208,\n",
      "             0.0162,     -0.0093,     -0.0292,      0.0224,      0.0125,\n",
      "             0.0282,     -0.0194,      0.0091,     -0.0004,     -0.0015,\n",
      "            -0.0010,     -0.0089,      0.0263,      0.0130,      0.0017,\n",
      "             0.0319,      0.0006,      0.0305,      0.0046,      0.0169,\n",
      "             0.0003,     -0.0095,     -0.0266,     -0.0061,     -0.0345,\n",
      "             0.0163,      0.0201,      0.0295,      0.0269,     -0.0213,\n",
      "             0.0156,     -0.0191,     -0.0025,      0.0350,     -0.0341,\n",
      "            -0.0190,     -0.0221,      0.0065,     -0.0073,     -0.0006,\n",
      "            -0.0342,      0.0048,      0.0276,      0.0256,      0.0298,\n",
      "             0.0269,      0.0037,      0.0256,     -0.0075,      0.0047,\n",
      "            -0.0286,      0.0166,     -0.0028,      0.0315,      0.0133,\n",
      "            -0.0213,      0.0242,      0.0319,     -0.0331,      0.0134,\n",
      "            -0.0061,      0.0171,      0.0161,     -0.0263,      0.0132,\n",
      "            -0.0336,     -0.0161,      0.0180,     -0.0233,     -0.0199,\n",
      "            -0.0079,     -0.0205,     -0.0197,     -0.0022,     -0.0239,\n",
      "            -0.0147,      0.0041,      0.0339,      0.0005,      0.0000,\n",
      "            -0.0286,     -0.0343,     -0.0121,     -0.0095,     -0.0030,\n",
      "            -0.0035,     -0.0140,     -0.0195,     -0.0275,      0.0137,\n",
      "            -0.0176,     -0.0240,      0.0358,      0.0303,     -0.0268,\n",
      "            -0.0037,     -0.0236,      0.0225,      0.0189,     -0.0067,\n",
      "            -0.0178,     -0.0262,      0.0207,      0.0074,     -0.0111,\n",
      "            -0.0235,      0.0042,     -0.0198,      0.0138,      0.0224,\n",
      "             0.0021,      0.0076,     -0.0103,      0.0224,     -0.0076,\n",
      "            -0.0104,      0.0334,      0.0188,      0.0258,     -0.0085,\n",
      "            -0.0339,      0.0172,     -0.0202,     -0.0207,     -0.0032,\n",
      "             0.0221,      0.0179,     -0.0128,      0.0011,      0.0092,\n",
      "             0.0020,      0.0337,     -0.0235,      0.0235,      0.0343,\n",
      "             0.0243,      0.0223,      0.0161,     -0.0169,     -0.0256,\n",
      "            -0.0316,     -0.0312,     -0.0226,      0.0160,     -0.0067,\n",
      "             0.0053,     -0.0260,      0.0254,      0.0138,      0.0036,\n",
      "             0.0338,     -0.0226,      0.0272,      0.0303,      0.0192,\n",
      "             0.0161,      0.0125,      0.0083,     -0.0239,      0.0259,\n",
      "            -0.0331,      0.0003,      0.0054,      0.0269,      0.0244,\n",
      "            -0.0281,      0.0295,     -0.0140,      0.0195,      0.0135,\n",
      "            -0.0265,     -0.0134,     -0.0206,     -0.0281,     -0.0012,\n",
      "            -0.0020,      0.0333,      0.0318,      0.0014,     -0.0184,\n",
      "             0.0166,     -0.0206,      0.0162,      0.0043,     -0.0075,\n",
      "             0.0224,      0.0298,      0.0047,     -0.0225,     -0.0269,\n",
      "             0.0284,     -0.0273,      0.0236,      0.0154,      0.0349,\n",
      "             0.0256,     -0.0285,      0.0117,     -0.0326,      0.0095,\n",
      "            -0.0296,      0.0299,      0.0141,     -0.0025,      0.0268,\n",
      "            -0.0149,     -0.0197,     -0.0324,      0.0307,      0.0149,\n",
      "             0.0304,     -0.0332,      0.0127,     -0.0162,      0.0225,\n",
      "             0.0347,      0.0233,     -0.0056,     -0.0259,      0.0013,\n",
      "             0.0069,     -0.0197,     -0.0353,     -0.0099,     -0.0087,\n",
      "            -0.0313,      0.0166,     -0.0031,      0.0141,      0.0073,\n",
      "            -0.0177,      0.0342,      0.0245,      0.0126,     -0.0124,\n",
      "             0.0090,      0.0302,     -0.0051,      0.0216,      0.0305,\n",
      "            -0.0036,     -0.0198,     -0.0220,     -0.0356,     -0.0071,\n",
      "            -0.0102,     -0.0189,      0.0261,     -0.0099,     -0.0151,\n",
      "             0.0270,      0.0203,     -0.0074,     -0.0339,      0.0325,\n",
      "            -0.0130,      0.0229,      0.0116,      0.0318,      0.0246,\n",
      "             0.0232,      0.0060,     -0.0003,      0.0021,     -0.0298,\n",
      "            -0.0028,     -0.0130,      0.0265,     -0.0219,      0.0234,\n",
      "             0.0221,      0.0134,     -0.0204,     -0.0134,     -0.0301,\n",
      "             0.0068,      0.0213,     -0.0000,     -0.0199,     -0.0060,\n",
      "             0.0153,     -0.0344,     -0.0262,      0.0275,     -0.0258,\n",
      "            -0.0298,     -0.0083,     -0.0300,      0.0090,      0.0226,\n",
      "             0.0306,      0.0098,     -0.0177,      0.0261,      0.0267,\n",
      "            -0.0017,     -0.0238,      0.0018,      0.0232,     -0.0301,\n",
      "             0.0150,     -0.0290,     -0.0054,      0.0351,      0.0291,\n",
      "             0.0316,     -0.0304,     -0.0202,     -0.0258,     -0.0046,\n",
      "             0.0351,      0.0181,      0.0082,      0.0110,      0.0295,\n",
      "             0.0140,     -0.0167,      0.0259,     -0.0212,     -0.0110,\n",
      "             0.0322,      0.0330,      0.0149,     -0.0235,      0.0037,\n",
      "            -0.0265,     -0.0027,     -0.0323,      0.0210,      0.0355,\n",
      "            -0.0056,     -0.0242,      0.0352,     -0.0037,     -0.0095,\n",
      "            -0.0159,      0.0301,     -0.0105,      0.0118,     -0.0231,\n",
      "            -0.0306,      0.0087,      0.0194,     -0.0297,     -0.0147,\n",
      "            -0.0246,     -0.0324,      0.0181,      0.0337,      0.0107,\n",
      "             0.0285,      0.0122,     -0.0318,     -0.0281,      0.0227,\n",
      "            -0.0023,     -0.0134,     -0.0047,      0.0233,     -0.0037,\n",
      "             0.0317,     -0.0138,     -0.0278,      0.0122,     -0.0050,\n",
      "             0.0047,     -0.0117,      0.0222,      0.0313,     -0.0245,\n",
      "             0.0200,     -0.0325,      0.0055,     -0.0025,     -0.0200,\n",
      "             0.0019,      0.0234,      0.0059,     -0.0259,      0.0013,\n",
      "            -0.0351,     -0.0085,     -0.0209,     -0.0201,     -0.0109,\n",
      "            -0.0263,      0.0241,     -0.0202,      0.0082,      0.0096,\n",
      "             0.0049,     -0.0334,      0.0342,     -0.0194,      0.0307,\n",
      "            -0.0197,      0.0087,     -0.0316,     -0.0341,     -0.0096,\n",
      "             0.0176,     -0.0291,      0.0328,     -0.0040,      0.0105,\n",
      "             0.0287,     -0.0284,     -0.0299,      0.0102,     -0.0141,\n",
      "            -0.0269,      0.0196,      0.0200,      0.0339,     -0.0164,\n",
      "            -0.0214,      0.0287,     -0.0017,      0.0129,      0.0221,\n",
      "             0.0261,     -0.0074,      0.0106,      0.0332,     -0.0061,\n",
      "             0.0026,      0.0344,     -0.0268,      0.0334,     -0.0172,\n",
      "             0.0015,     -0.0025,      0.0009,     -0.0361,      0.0294,\n",
      "            -0.0268,     -0.0060,      0.0002,      0.0123,      0.0345,\n",
      "             0.0335,      0.0352,      0.0224,     -0.0089,      0.0074,\n",
      "            -0.0333,     -0.0203,     -0.0344,      0.0357,      0.0145,\n",
      "             0.0243,      0.0233,     -0.0243,      0.0169,      0.0201,\n",
      "            -0.0293,      0.0279,     -0.0163,      0.0081,      0.0276,\n",
      "             0.0021,      0.0259,      0.0262,      0.0294,      0.0164,\n",
      "            -0.0052,      0.0015,     -0.0029,     -0.0066,      0.0117,\n",
      "             0.0212,     -0.0223,      0.0313,     -0.0138,      0.0107,\n",
      "            -0.0016,     -0.0163,     -0.0069,     -0.0034,      0.0121,\n",
      "             0.0005,      0.0108,     -0.0065,     -0.0348,     -0.0154,\n",
      "            -0.0288,     -0.0157,     -0.0219,     -0.0024,      0.0322,\n",
      "            -0.0316,     -0.0335,      0.0309,      0.0110,     -0.0035,\n",
      "             0.0212,      0.0128,     -0.0314,     -0.0332,      0.0072,\n",
      "             0.0085,     -0.0267,     -0.0025,      0.0073,     -0.0160,\n",
      "             0.0151,     -0.0082,     -0.0061,     -0.0292,      0.0171,\n",
      "             0.0186,     -0.0110,     -0.0260,      0.0095,     -0.0342,\n",
      "            -0.0181,      0.0066,      0.0173,     -0.0103,     -0.0011,\n",
      "             0.0152,      0.0315,      0.0173,     -0.0330,      0.0164,\n",
      "            -0.0334,     -0.0059,     -0.0092,     -0.0281,      0.0344,\n",
      "             0.0126,      0.0355,     -0.0041,      0.0103,      0.0184,\n",
      "            -0.0320,     -0.0012,      0.0118,     -0.0164,      0.0078,\n",
      "            -0.0166,     -0.0288,     -0.0344,     -0.0286,     -0.0221,\n",
      "            -0.0325,      0.0027,      0.0259,      0.0180,     -0.0098,\n",
      "            -0.0147,      0.0343,      0.0245,     -0.0058,     -0.0099,\n",
      "             0.0332,     -0.0118,     -0.0338,      0.0223,      0.0213,\n",
      "             0.0259,      0.0146,     -0.0072,     -0.0095,     -0.0122,\n",
      "             0.0226,      0.0330,      0.0247,      0.0097,      0.0165,\n",
      "             0.0133,     -0.0114,     -0.0051,     -0.0235,      0.0179,\n",
      "             0.0232,      0.0257,      0.0119,      0.0006,      0.0225,\n",
      "            -0.0130,     -0.0220,     -0.0102], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0340,  0.0185,  0.0150,  ..., -0.0357, -0.0038, -0.0032],\n",
      "        [-0.0050, -0.0349,  0.0025,  ..., -0.0175, -0.0331, -0.0230],\n",
      "        [-0.0317,  0.0138,  0.0015,  ...,  0.0258,  0.0358, -0.0170],\n",
      "        ...,\n",
      "        [ 0.0119,  0.0287, -0.0293,  ...,  0.0214,  0.0078, -0.0030],\n",
      "        [-0.0051,  0.0157, -0.0243,  ...,  0.0346, -0.0166,  0.0227],\n",
      "        [ 0.0130, -0.0061, -0.0322,  ...,  0.0134,  0.0097,  0.0325]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0027, -0.0286, -0.0152,  ...,  0.0302, -0.0172, -0.0354],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0038, -0.0036,  0.0172,  ..., -0.0154, -0.0012, -0.0097],\n",
      "        [-0.0123, -0.0036,  0.0149,  ..., -0.0003,  0.0040,  0.0146],\n",
      "        [-0.0164, -0.0038, -0.0130,  ...,  0.0159, -0.0041,  0.0007],\n",
      "        ...,\n",
      "        [ 0.0118,  0.0032,  0.0070,  ...,  0.0047,  0.0019,  0.0135],\n",
      "        [ 0.0136, -0.0043,  0.0128,  ...,  0.0018, -0.0085,  0.0098],\n",
      "        [ 0.0096, -0.0092, -0.0055,  ...,  0.0166,  0.0122, -0.0144]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([     0.0135,      0.0013,     -0.0004,      0.0131,      0.0038,\n",
      "             0.0152,     -0.0116,     -0.0133,      0.0128,      0.0030,\n",
      "            -0.0071,     -0.0067,     -0.0011,     -0.0173,     -0.0131,\n",
      "            -0.0063,     -0.0064,      0.0165,     -0.0046,     -0.0050,\n",
      "            -0.0002,     -0.0080,     -0.0113,     -0.0081,      0.0162,\n",
      "            -0.0076,     -0.0126,     -0.0007,      0.0048,     -0.0036,\n",
      "             0.0141,     -0.0177,      0.0060,      0.0026,      0.0116,\n",
      "             0.0027,      0.0140,      0.0110,      0.0096,      0.0074,\n",
      "             0.0152,     -0.0061,      0.0136,      0.0046,      0.0057,\n",
      "             0.0056,     -0.0052,      0.0033,     -0.0146,     -0.0028,\n",
      "             0.0164,     -0.0119,     -0.0005,     -0.0028,     -0.0020,\n",
      "            -0.0011,     -0.0036,     -0.0033,      0.0062,     -0.0139,\n",
      "            -0.0173,     -0.0099,     -0.0042,     -0.0179,     -0.0149,\n",
      "             0.0030,      0.0136,     -0.0136,      0.0149,      0.0177,\n",
      "            -0.0121,      0.0050,      0.0062,      0.0017,      0.0139,\n",
      "             0.0041,      0.0157,      0.0145,     -0.0031,      0.0022,\n",
      "             0.0130,     -0.0074,     -0.0014,      0.0070,      0.0144,\n",
      "            -0.0145,     -0.0154,     -0.0005,     -0.0007,     -0.0063,\n",
      "            -0.0124,      0.0007,     -0.0155,     -0.0084,     -0.0074,\n",
      "             0.0071,      0.0092,      0.0104,     -0.0125,      0.0015,\n",
      "            -0.0147,     -0.0063,      0.0105,     -0.0006,      0.0116,\n",
      "            -0.0020,     -0.0160,     -0.0062,     -0.0019,      0.0117,\n",
      "            -0.0049,     -0.0106,      0.0034,      0.0019,     -0.0143,\n",
      "             0.0094,      0.0101,     -0.0116,      0.0081,     -0.0048,\n",
      "             0.0088,      0.0104,     -0.0065,     -0.0179,     -0.0057,\n",
      "            -0.0128,      0.0156,     -0.0137,      0.0165,      0.0137,\n",
      "             0.0096,     -0.0134,     -0.0176,      0.0006,      0.0110,\n",
      "            -0.0125,     -0.0091,     -0.0132,     -0.0102,     -0.0137,\n",
      "             0.0037,      0.0113,     -0.0052,      0.0014,     -0.0168,\n",
      "             0.0142,     -0.0117,      0.0110,     -0.0084,      0.0006,\n",
      "             0.0142,     -0.0162,     -0.0115,     -0.0125,     -0.0055,\n",
      "             0.0055,     -0.0168,     -0.0050,     -0.0057,     -0.0096,\n",
      "            -0.0087,      0.0063,     -0.0045,      0.0056,      0.0044,\n",
      "             0.0017,      0.0027,     -0.0152,     -0.0132,     -0.0069,\n",
      "            -0.0054,     -0.0088,     -0.0001,     -0.0011,      0.0025,\n",
      "            -0.0064,      0.0086,     -0.0119,     -0.0029,      0.0056,\n",
      "             0.0142,      0.0029,      0.0022,      0.0172,      0.0003,\n",
      "             0.0119,     -0.0180,      0.0023,      0.0139,     -0.0101,\n",
      "             0.0118,      0.0180,      0.0095,      0.0179,      0.0039,\n",
      "            -0.0018,      0.0160,     -0.0172,      0.0128,     -0.0114,\n",
      "            -0.0095,     -0.0005,      0.0164,     -0.0002,      0.0104,\n",
      "             0.0055,     -0.0031,     -0.0119,     -0.0091,      0.0180,\n",
      "             0.0130,      0.0042,      0.0120,      0.0113,      0.0170,\n",
      "            -0.0105,      0.0129,      0.0159,      0.0115,      0.0068,\n",
      "            -0.0093,     -0.0003,      0.0061,      0.0076,     -0.0086,\n",
      "             0.0011,      0.0125,     -0.0011,      0.0033,     -0.0066,\n",
      "             0.0135,     -0.0083,     -0.0048,      0.0158,      0.0160,\n",
      "             0.0033,      0.0155,      0.0117,      0.0072,     -0.0114,\n",
      "            -0.0124,     -0.0041,     -0.0125,      0.0069,      0.0012,\n",
      "             0.0065,      0.0037,      0.0116,      0.0072,     -0.0146,\n",
      "             0.0061,     -0.0155,      0.0146,     -0.0091,      0.0049,\n",
      "            -0.0171,      0.0125,      0.0092,     -0.0030,     -0.0112,\n",
      "            -0.0158,     -0.0127,     -0.0075,     -0.0165,     -0.0179,\n",
      "             0.0083,     -0.0021,     -0.0176,      0.0046,     -0.0153,\n",
      "             0.0051,     -0.0176,     -0.0154,      0.0145,      0.0167,\n",
      "             0.0086,      0.0029,     -0.0072,     -0.0157,     -0.0048,\n",
      "            -0.0074,     -0.0046,     -0.0126,      0.0029,      0.0001,\n",
      "            -0.0120,      0.0107,     -0.0079,     -0.0129,     -0.0013,\n",
      "            -0.0129,     -0.0148,     -0.0175,     -0.0012,     -0.0108,\n",
      "             0.0077,     -0.0036,      0.0165,      0.0030,     -0.0168,\n",
      "             0.0146,     -0.0038,      0.0118,      0.0133,      0.0126,\n",
      "            -0.0063,     -0.0176,      0.0051,      0.0042,      0.0043,\n",
      "             0.0088,     -0.0136,      0.0086,     -0.0138,     -0.0079,\n",
      "             0.0128,      0.0067,      0.0130,      0.0004,     -0.0160,\n",
      "             0.0017,     -0.0082,     -0.0147,      0.0061,     -0.0178,\n",
      "            -0.0110,     -0.0036,      0.0111,      0.0039,     -0.0060,\n",
      "            -0.0014,      0.0163,      0.0168,      0.0180,      0.0003,\n",
      "            -0.0104,     -0.0057,     -0.0122,      0.0092,     -0.0019,\n",
      "            -0.0177,      0.0064,      0.0094,      0.0142,     -0.0023,\n",
      "             0.0178,     -0.0145,     -0.0065,     -0.0060,      0.0083,\n",
      "            -0.0138,      0.0143,     -0.0022,     -0.0077,     -0.0049,\n",
      "             0.0133,     -0.0121,     -0.0117,      0.0091,      0.0162,\n",
      "            -0.0134,      0.0098,     -0.0007,     -0.0158,      0.0083,\n",
      "            -0.0046,      0.0099,      0.0058,     -0.0113,      0.0037,\n",
      "            -0.0108,     -0.0149,     -0.0108,     -0.0027,      0.0158,\n",
      "            -0.0170,      0.0175,     -0.0036,     -0.0135,      0.0014,\n",
      "            -0.0087,     -0.0130,      0.0066,     -0.0098,     -0.0178,\n",
      "             0.0178,      0.0070,     -0.0074,      0.0174,      0.0154,\n",
      "             0.0075,      0.0158,     -0.0035,     -0.0137,     -0.0076,\n",
      "             0.0126,     -0.0128,     -0.0062,     -0.0127,     -0.0126,\n",
      "             0.0058,     -0.0065,      0.0072,     -0.0061,     -0.0045,\n",
      "            -0.0095,     -0.0002,      0.0048,     -0.0057,     -0.0004,\n",
      "             0.0034,      0.0029,     -0.0060,     -0.0157,      0.0086,\n",
      "             0.0076,      0.0070,     -0.0023,      0.0132,     -0.0082,\n",
      "            -0.0060,     -0.0074,      0.0149,     -0.0020,      0.0042,\n",
      "            -0.0009,      0.0122,     -0.0057,     -0.0078,      0.0150,\n",
      "             0.0039,     -0.0125,      0.0164,      0.0096,     -0.0164,\n",
      "             0.0175,      0.0111,      0.0146,     -0.0029,      0.0152,\n",
      "            -0.0177,      0.0107,      0.0081,     -0.0099,     -0.0045,\n",
      "             0.0035,     -0.0006,     -0.0012,     -0.0115,      0.0035,\n",
      "             0.0080,      0.0020,      0.0135,      0.0177,     -0.0101,\n",
      "             0.0146,      0.0006,      0.0051,      0.0094,     -0.0017,\n",
      "             0.0041,      0.0156,     -0.0130,      0.0062,     -0.0127,\n",
      "             0.0016,     -0.0055,     -0.0075,      0.0066,     -0.0012,\n",
      "            -0.0143,     -0.0111,     -0.0089,      0.0147,      0.0145,\n",
      "             0.0088,     -0.0023,      0.0126,     -0.0027,     -0.0030,\n",
      "            -0.0074,      0.0039,      0.0029,      0.0027,      0.0101,\n",
      "             0.0134,     -0.0111,     -0.0162,     -0.0014,      0.0140,\n",
      "            -0.0165,      0.0176,     -0.0179,     -0.0049,      0.0004,\n",
      "             0.0045,     -0.0007,     -0.0115,     -0.0057,     -0.0107,\n",
      "            -0.0048,     -0.0004,     -0.0136,     -0.0002,      0.0086,\n",
      "             0.0073,      0.0066,      0.0132,      0.0052,      0.0095,\n",
      "            -0.0143,      0.0071,      0.0015,      0.0076,      0.0038,\n",
      "             0.0043,     -0.0094,     -0.0021,      0.0023,     -0.0077,\n",
      "             0.0151,     -0.0039,     -0.0004,      0.0162,     -0.0048,\n",
      "             0.0109,     -0.0057,      0.0063,      0.0038,      0.0126,\n",
      "             0.0080,     -0.0098,      0.0108,     -0.0093,      0.0077,\n",
      "            -0.0180,     -0.0104,      0.0135,     -0.0136,     -0.0000,\n",
      "            -0.0118,      0.0126,      0.0036,      0.0002,     -0.0076,\n",
      "             0.0119,     -0.0127,      0.0140,      0.0028,     -0.0137,\n",
      "            -0.0139,      0.0049,      0.0171,     -0.0077,      0.0134,\n",
      "             0.0158,      0.0140,     -0.0069,     -0.0176,      0.0061,\n",
      "            -0.0003,      0.0056,      0.0138,     -0.0177,      0.0180,\n",
      "            -0.0059,     -0.0067,     -0.0085,      0.0032,      0.0085,\n",
      "            -0.0065,     -0.0168,     -0.0070,     -0.0088,     -0.0108,\n",
      "             0.0015,     -0.0071,      0.0079,      0.0086,     -0.0079,\n",
      "            -0.0177,      0.0011,     -0.0022,     -0.0036,     -0.0072,\n",
      "            -0.0035,      0.0090,     -0.0109,      0.0072,      0.0099,\n",
      "             0.0180,      0.0125,      0.0076,      0.0142,     -0.0082,\n",
      "             0.0110,      0.0099,      0.0059,     -0.0152,     -0.0070,\n",
      "            -0.0019,      0.0089,      0.0092,      0.0006,     -0.0031,\n",
      "            -0.0098,     -0.0059,     -0.0075,     -0.0144,     -0.0015,\n",
      "            -0.0091,     -0.0106,      0.0054,      0.0149,      0.0139,\n",
      "             0.0065,     -0.0111,     -0.0134,     -0.0163,     -0.0179,\n",
      "            -0.0054,      0.0084,      0.0072,     -0.0133,      0.0136,\n",
      "            -0.0152,      0.0033,     -0.0109,     -0.0084,     -0.0052,\n",
      "            -0.0021,      0.0157,      0.0072,     -0.0083,     -0.0110,\n",
      "             0.0052,     -0.0145,      0.0011,     -0.0089,      0.0164,\n",
      "             0.0020,     -0.0169,      0.0091,      0.0179,      0.0147,\n",
      "            -0.0160,     -0.0015,      0.0127,      0.0178,     -0.0034,\n",
      "             0.0045,     -0.0118,      0.0119,      0.0034,     -0.0053,\n",
      "            -0.0097,      0.0090,      0.0017,      0.0106,      0.0049,\n",
      "             0.0098,     -0.0094,     -0.0104,      0.0132,     -0.0019,\n",
      "             0.0018,     -0.0128,      0.0053,      0.0036,     -0.0100,\n",
      "             0.0129,     -0.0145,      0.0133,     -0.0111,     -0.0176,\n",
      "             0.0133,     -0.0073,      0.0108,      0.0143,      0.0010,\n",
      "            -0.0059,      0.0159,     -0.0127,      0.0098,      0.0027,\n",
      "            -0.0103,      0.0078,     -0.0135,     -0.0179,      0.0069,\n",
      "            -0.0179,      0.0116,      0.0158,      0.0086,      0.0086,\n",
      "            -0.0043,      0.0158,     -0.0154,      0.0101,      0.0007,\n",
      "            -0.0025,     -0.0161,     -0.0075,     -0.0058,      0.0139,\n",
      "            -0.0090,      0.0052,      0.0150,      0.0010,      0.0024,\n",
      "             0.0102,     -0.0126,      0.0109,     -0.0038,      0.0152,\n",
      "            -0.0009,      0.0056,      0.0012,     -0.0165,      0.0027,\n",
      "             0.0092,     -0.0174,      0.0122,      0.0090,     -0.0074,\n",
      "            -0.0152,      0.0096,     -0.0048,     -0.0009,     -0.0172,\n",
      "             0.0026,      0.0119,      0.0073,     -0.0112,     -0.0037,\n",
      "             0.0114,      0.0044,      0.0116,     -0.0020,      0.0067,\n",
      "             0.0009,      0.0115,      0.0084,     -0.0118,     -0.0026,\n",
      "            -0.0033,     -0.0173,      0.0071,     -0.0092,      0.0116,\n",
      "             0.0129,     -0.0090,      0.0042,     -0.0170,     -0.0053,\n",
      "            -0.0068,     -0.0166,     -0.0130,     -0.0032,      0.0177,\n",
      "             0.0042,      0.0097,      0.0117,     -0.0073,      0.0014,\n",
      "             0.0109,      0.0114,     -0.0178], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0011,  0.0042, -0.0308,  ..., -0.0151,  0.0022,  0.0039],\n",
      "        [ 0.0031, -0.0102, -0.0051,  ...,  0.0218, -0.0080, -0.0349],\n",
      "        [-0.0061,  0.0236, -0.0198,  ...,  0.0136, -0.0067, -0.0006],\n",
      "        ...,\n",
      "        [ 0.0019, -0.0222,  0.0185,  ..., -0.0143,  0.0026,  0.0264],\n",
      "        [-0.0043,  0.0035, -0.0030,  ..., -0.0006, -0.0126, -0.0261],\n",
      "        [ 0.0120,  0.0045,  0.0150,  ..., -0.0296, -0.0117, -0.0356]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0213,  0.0027,  0.0172,  ...,  0.0014, -0.0066,  0.0109],\n",
      "        [ 0.0081,  0.0340, -0.0361,  ...,  0.0279,  0.0065, -0.0247],\n",
      "        [-0.0271,  0.0315,  0.0349,  ..., -0.0207, -0.0067, -0.0296],\n",
      "        ...,\n",
      "        [-0.0264, -0.0256,  0.0302,  ..., -0.0252, -0.0011,  0.0333],\n",
      "        [-0.0122, -0.0239,  0.0169,  ...,  0.0251, -0.0029,  0.0355],\n",
      "        [-0.0003, -0.0270, -0.0290,  ..., -0.0308, -0.0188, -0.0052]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0325,  0.0330,  0.0041,  ..., -0.0066, -0.0020, -0.0258],\n",
      "        [-0.0232, -0.0032,  0.0340,  ...,  0.0127,  0.0109, -0.0010],\n",
      "        [ 0.0008,  0.0049, -0.0192,  ..., -0.0187,  0.0321, -0.0335],\n",
      "        ...,\n",
      "        [ 0.0355, -0.0141, -0.0288,  ...,  0.0162, -0.0104,  0.0008],\n",
      "        [ 0.0134,  0.0264,  0.0326,  ..., -0.0338, -0.0252,  0.0339],\n",
      "        [ 0.0254,  0.0200,  0.0316,  ..., -0.0011,  0.0264, -0.0136]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0207, -0.0129,  0.0185,  ..., -0.0328, -0.0153, -0.0070],\n",
      "        [-0.0215,  0.0010, -0.0284,  ..., -0.0277, -0.0094, -0.0026],\n",
      "        [-0.0223, -0.0333, -0.0243,  ...,  0.0141,  0.0289,  0.0163],\n",
      "        ...,\n",
      "        [-0.0144,  0.0097, -0.0038,  ..., -0.0083, -0.0139,  0.0299],\n",
      "        [-0.0188, -0.0092,  0.0335,  ..., -0.0305,  0.0108,  0.0261],\n",
      "        [ 0.0353,  0.0178, -0.0082,  ...,  0.0151,  0.0115, -0.0162]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([    -0.0010,     -0.0057,      0.0169,     -0.0267,     -0.0312,\n",
      "             0.0333,      0.0167,      0.0183,      0.0261,     -0.0019,\n",
      "            -0.0148,     -0.0240,      0.0050,     -0.0090,      0.0272,\n",
      "            -0.0171,      0.0124,     -0.0168,      0.0158,     -0.0041,\n",
      "            -0.0082,      0.0324,      0.0288,      0.0147,      0.0067,\n",
      "            -0.0348,      0.0012,     -0.0199,     -0.0255,     -0.0116,\n",
      "            -0.0221,     -0.0022,      0.0025,     -0.0104,      0.0139,\n",
      "            -0.0295,     -0.0016,      0.0116,     -0.0046,      0.0016,\n",
      "            -0.0047,      0.0033,     -0.0235,     -0.0341,     -0.0323,\n",
      "            -0.0320,     -0.0326,      0.0038,     -0.0264,      0.0121,\n",
      "            -0.0042,      0.0084,      0.0199,      0.0338,      0.0247,\n",
      "            -0.0319,     -0.0237,     -0.0280,     -0.0044,      0.0273,\n",
      "            -0.0275,     -0.0162,      0.0007,     -0.0353,     -0.0286,\n",
      "             0.0144,      0.0264,      0.0037,     -0.0242,      0.0028,\n",
      "             0.0195,     -0.0286,     -0.0323,     -0.0153,      0.0227,\n",
      "            -0.0357,      0.0195,      0.0139,      0.0349,      0.0343,\n",
      "             0.0195,      0.0056,     -0.0024,      0.0070,     -0.0220,\n",
      "             0.0042,     -0.0030,     -0.0057,     -0.0336,     -0.0236,\n",
      "             0.0034,     -0.0001,      0.0033,     -0.0310,     -0.0139,\n",
      "             0.0297,      0.0339,      0.0090,     -0.0252,     -0.0014,\n",
      "            -0.0084,      0.0039,     -0.0249,      0.0017,     -0.0266,\n",
      "            -0.0315,      0.0228,      0.0160,     -0.0313,     -0.0329,\n",
      "            -0.0290,      0.0141,      0.0097,      0.0178,     -0.0103,\n",
      "             0.0077,     -0.0320,     -0.0229,     -0.0117,     -0.0235,\n",
      "            -0.0076,      0.0077,      0.0216,     -0.0192,     -0.0321,\n",
      "            -0.0231,     -0.0161,     -0.0096,     -0.0138,     -0.0260,\n",
      "             0.0315,     -0.0189,      0.0353,      0.0084,     -0.0295,\n",
      "             0.0033,      0.0172,      0.0217,     -0.0320,      0.0220,\n",
      "            -0.0258,      0.0155,     -0.0251,     -0.0292,      0.0347,\n",
      "            -0.0017,     -0.0219,     -0.0109,      0.0044,     -0.0182,\n",
      "             0.0104,     -0.0177,     -0.0333,     -0.0313,      0.0272,\n",
      "             0.0203,     -0.0346,     -0.0267,      0.0272,      0.0270,\n",
      "             0.0002,      0.0102,     -0.0138,     -0.0049,     -0.0286,\n",
      "            -0.0078,      0.0197,      0.0039,     -0.0149,      0.0333,\n",
      "            -0.0050,      0.0255,      0.0298,     -0.0305,     -0.0121,\n",
      "             0.0233,     -0.0014,      0.0255,     -0.0204,     -0.0218,\n",
      "            -0.0009,      0.0041,      0.0331,      0.0085,      0.0080,\n",
      "            -0.0353,      0.0209,     -0.0076,      0.0307,     -0.0182,\n",
      "             0.0206,     -0.0256,      0.0338,      0.0016,      0.0157,\n",
      "             0.0257,      0.0139,      0.0007,      0.0162,      0.0060,\n",
      "            -0.0159,      0.0214,      0.0151,      0.0029,      0.0088,\n",
      "             0.0261,     -0.0092,     -0.0067,      0.0163,      0.0269,\n",
      "            -0.0085,      0.0332,      0.0256,      0.0052,     -0.0107,\n",
      "            -0.0296,     -0.0295,      0.0337,      0.0264,     -0.0174,\n",
      "             0.0032,     -0.0246,      0.0359,      0.0353,     -0.0120,\n",
      "             0.0247,     -0.0209,      0.0276,      0.0339,     -0.0020,\n",
      "             0.0117,     -0.0157,     -0.0196,      0.0081,      0.0330,\n",
      "             0.0185,      0.0250,      0.0271,      0.0043,      0.0111,\n",
      "             0.0106,      0.0030,     -0.0199,      0.0140,      0.0266,\n",
      "             0.0130,      0.0068,      0.0003,     -0.0059,     -0.0341,\n",
      "             0.0124,      0.0339,     -0.0283,     -0.0028,     -0.0049,\n",
      "             0.0071,      0.0289,     -0.0099,      0.0087,      0.0133,\n",
      "             0.0184,      0.0301,      0.0167,     -0.0281,     -0.0177,\n",
      "            -0.0083,     -0.0236,      0.0311,      0.0089,      0.0135,\n",
      "            -0.0015,      0.0125,      0.0192,      0.0204,     -0.0034,\n",
      "             0.0319,     -0.0101,      0.0182,     -0.0252,     -0.0280,\n",
      "             0.0014,     -0.0058,     -0.0154,     -0.0058,     -0.0273,\n",
      "             0.0114,     -0.0170,      0.0026,      0.0359,      0.0191,\n",
      "            -0.0298,     -0.0206,     -0.0330,      0.0127,      0.0080,\n",
      "            -0.0162,      0.0251,      0.0329,      0.0218,     -0.0161,\n",
      "             0.0357,     -0.0360,     -0.0132,      0.0253,     -0.0133,\n",
      "            -0.0114,      0.0029,     -0.0057,     -0.0210,      0.0064,\n",
      "             0.0139,     -0.0284,      0.0236,     -0.0105,     -0.0209,\n",
      "            -0.0089,      0.0072,      0.0300,      0.0316,     -0.0249,\n",
      "             0.0026,     -0.0328,      0.0228,     -0.0054,      0.0294,\n",
      "            -0.0154,      0.0146,      0.0056,      0.0203,     -0.0271,\n",
      "            -0.0131,      0.0300,     -0.0117,      0.0127,      0.0146,\n",
      "            -0.0115,     -0.0262,      0.0095,     -0.0180,     -0.0017,\n",
      "             0.0218,     -0.0330,      0.0338,      0.0359,      0.0250,\n",
      "            -0.0339,      0.0001,      0.0270,     -0.0164,     -0.0140,\n",
      "             0.0268,      0.0126,      0.0267,     -0.0077,      0.0031,\n",
      "            -0.0305,     -0.0104,     -0.0072,     -0.0260,     -0.0140,\n",
      "            -0.0251,      0.0181,     -0.0129,     -0.0126,      0.0111,\n",
      "             0.0213,     -0.0319,      0.0007,      0.0020,     -0.0249,\n",
      "            -0.0277,      0.0320,     -0.0277,     -0.0335,      0.0145,\n",
      "             0.0037,      0.0165,      0.0108,     -0.0341,     -0.0130,\n",
      "            -0.0114,      0.0178,      0.0240,      0.0323,      0.0344,\n",
      "            -0.0353,     -0.0025,     -0.0112,      0.0138,      0.0256,\n",
      "            -0.0044,     -0.0045,     -0.0301,     -0.0082,      0.0201,\n",
      "             0.0359,     -0.0307,     -0.0096,      0.0057,     -0.0264,\n",
      "            -0.0267,     -0.0250,      0.0267,     -0.0087,     -0.0293,\n",
      "             0.0013,     -0.0296,      0.0035,     -0.0113,     -0.0246,\n",
      "             0.0012,      0.0154,     -0.0069,     -0.0206,      0.0064,\n",
      "             0.0150,     -0.0359,     -0.0133,      0.0094,     -0.0103,\n",
      "             0.0339,      0.0150,      0.0036,      0.0256,      0.0313,\n",
      "            -0.0334,     -0.0075,      0.0234,     -0.0353,      0.0322,\n",
      "            -0.0254,     -0.0184,      0.0181,      0.0270,      0.0207,\n",
      "             0.0200,      0.0211,     -0.0260,      0.0036,     -0.0242,\n",
      "             0.0200,      0.0299,      0.0292,     -0.0043,      0.0024,\n",
      "             0.0040,     -0.0150,     -0.0193,      0.0350,      0.0000,\n",
      "            -0.0111,     -0.0021,     -0.0156,      0.0115,     -0.0019,\n",
      "             0.0029,      0.0344,     -0.0054,     -0.0326,     -0.0059,\n",
      "             0.0174,      0.0190,      0.0197,     -0.0044,     -0.0212,\n",
      "            -0.0154,      0.0131,      0.0075,      0.0164,      0.0319,\n",
      "            -0.0001,      0.0195,     -0.0005,      0.0341,     -0.0292,\n",
      "            -0.0287,     -0.0261,     -0.0020,      0.0143,     -0.0185,\n",
      "            -0.0285,      0.0188,      0.0154,     -0.0261,     -0.0255,\n",
      "             0.0021,      0.0288,      0.0322,      0.0195,      0.0253,\n",
      "             0.0240,      0.0010,     -0.0336,     -0.0253,     -0.0141,\n",
      "            -0.0049,      0.0093,     -0.0356,      0.0282,     -0.0268,\n",
      "             0.0012,      0.0131,     -0.0001,      0.0120,      0.0271,\n",
      "             0.0229,      0.0346,     -0.0065,      0.0111,      0.0072,\n",
      "            -0.0032,     -0.0203,      0.0303,      0.0359,      0.0351,\n",
      "             0.0204,      0.0094,      0.0126,     -0.0275,     -0.0009,\n",
      "             0.0133,      0.0330,      0.0327,      0.0277,     -0.0076,\n",
      "            -0.0360,      0.0071,     -0.0325,     -0.0187,      0.0303,\n",
      "             0.0296,      0.0095,     -0.0355,      0.0340,      0.0245,\n",
      "             0.0201,      0.0043,     -0.0269,     -0.0091,      0.0222,\n",
      "             0.0251,      0.0036,      0.0074,      0.0187,     -0.0038,\n",
      "            -0.0165,      0.0329,     -0.0078,      0.0317,      0.0035,\n",
      "            -0.0334,      0.0087,     -0.0296,     -0.0198,     -0.0057,\n",
      "            -0.0127,      0.0325,     -0.0202,      0.0003,     -0.0081,\n",
      "            -0.0067,      0.0107,      0.0121,     -0.0153,      0.0146,\n",
      "            -0.0099,     -0.0003,      0.0010,      0.0187,     -0.0252,\n",
      "             0.0138,     -0.0324,      0.0250,     -0.0097,      0.0289,\n",
      "             0.0317,     -0.0296,      0.0101,     -0.0178,     -0.0035,\n",
      "            -0.0245,     -0.0242,     -0.0016,     -0.0316,      0.0203,\n",
      "             0.0050,      0.0153,      0.0026,     -0.0314,     -0.0317,\n",
      "             0.0230,     -0.0008,      0.0164,      0.0135,      0.0170,\n",
      "             0.0028,      0.0179,     -0.0030,     -0.0156,     -0.0237,\n",
      "             0.0352,     -0.0003,      0.0182,      0.0137,     -0.0009,\n",
      "             0.0283,     -0.0115,     -0.0182,      0.0197,     -0.0027,\n",
      "            -0.0324,      0.0031,      0.0001,      0.0217,     -0.0109,\n",
      "            -0.0118,     -0.0141,     -0.0069,      0.0041,     -0.0179,\n",
      "            -0.0123,     -0.0318,      0.0138,      0.0147,      0.0324,\n",
      "            -0.0353,      0.0299,      0.0156,      0.0271,      0.0072,\n",
      "             0.0211,      0.0115,      0.0335,     -0.0104,     -0.0111,\n",
      "             0.0358,     -0.0225,      0.0110,     -0.0187,      0.0084,\n",
      "             0.0227,     -0.0145,     -0.0233,      0.0294,     -0.0359,\n",
      "             0.0048,     -0.0152,      0.0086,      0.0310,     -0.0077,\n",
      "             0.0330,     -0.0138,      0.0251,     -0.0351,     -0.0150,\n",
      "            -0.0027,      0.0148,     -0.0038,      0.0212,     -0.0019,\n",
      "             0.0166,      0.0098,      0.0047,     -0.0134,     -0.0290,\n",
      "            -0.0275,     -0.0125,     -0.0177,      0.0270,     -0.0357,\n",
      "            -0.0233,      0.0248,      0.0043,     -0.0301,      0.0142,\n",
      "             0.0176,      0.0133,     -0.0206,      0.0271,      0.0329,\n",
      "            -0.0286,     -0.0275,      0.0138,     -0.0270,      0.0095,\n",
      "             0.0274,     -0.0288,     -0.0194,     -0.0253,      0.0188,\n",
      "            -0.0177,     -0.0303,      0.0258,     -0.0245,     -0.0296,\n",
      "            -0.0298,     -0.0193,     -0.0217,     -0.0112,      0.0180,\n",
      "            -0.0195,     -0.0168,     -0.0055,      0.0097,     -0.0300,\n",
      "            -0.0281,     -0.0017,      0.0268,      0.0019,     -0.0147,\n",
      "            -0.0342,      0.0173,      0.0246,     -0.0220,     -0.0327,\n",
      "            -0.0105,     -0.0280,      0.0213,      0.0036,      0.0101,\n",
      "             0.0329,     -0.0293,     -0.0253,     -0.0085,      0.0071,\n",
      "            -0.0332,      0.0243,     -0.0138,     -0.0318,     -0.0097,\n",
      "             0.0323,      0.0334,      0.0156,      0.0292,     -0.0215,\n",
      "             0.0165,     -0.0045,      0.0349,      0.0268,      0.0223,\n",
      "            -0.0200,     -0.0141,      0.0206,     -0.0317,      0.0300,\n",
      "            -0.0324,     -0.0109,      0.0069,     -0.0072,     -0.0103,\n",
      "            -0.0195,     -0.0287,     -0.0193,     -0.0317,     -0.0323,\n",
      "            -0.0030,      0.0295,      0.0155,     -0.0201,      0.0286,\n",
      "            -0.0244,     -0.0294,     -0.0304,      0.0037,      0.0112,\n",
      "            -0.0299,      0.0297,     -0.0210], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0032, -0.0109,  0.0035,  ...,  0.0075,  0.0216,  0.0146],\n",
      "        [ 0.0312, -0.0219, -0.0158,  ...,  0.0359, -0.0185, -0.0101],\n",
      "        [ 0.0046, -0.0198, -0.0341,  ...,  0.0112, -0.0112,  0.0285],\n",
      "        ...,\n",
      "        [ 0.0209, -0.0332,  0.0323,  ..., -0.0280,  0.0070,  0.0182],\n",
      "        [-0.0276,  0.0227, -0.0068,  ..., -0.0349,  0.0236,  0.0123],\n",
      "        [-0.0203,  0.0294, -0.0119,  ..., -0.0176, -0.0003,  0.0010]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0227, -0.0213, -0.0055,  ...,  0.0119,  0.0337, -0.0036],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0098, -0.0132,  0.0138,  ...,  0.0138, -0.0015, -0.0051],\n",
      "        [-0.0080,  0.0066,  0.0109,  ..., -0.0164,  0.0119, -0.0073],\n",
      "        [ 0.0106,  0.0165, -0.0160,  ...,  0.0158,  0.0046, -0.0127],\n",
      "        ...,\n",
      "        [ 0.0066, -0.0094,  0.0041,  ..., -0.0121, -0.0120, -0.0104],\n",
      "        [-0.0065,  0.0067, -0.0022,  ...,  0.0004, -0.0134,  0.0075],\n",
      "        [-0.0115,  0.0171,  0.0111,  ..., -0.0079, -0.0085,  0.0029]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([     0.0029,      0.0072,     -0.0099,     -0.0153,      0.0157,\n",
      "             0.0116,     -0.0173,      0.0041,      0.0122,     -0.0156,\n",
      "             0.0074,     -0.0016,     -0.0018,     -0.0076,     -0.0122,\n",
      "             0.0160,      0.0121,     -0.0091,     -0.0116,      0.0076,\n",
      "             0.0000,      0.0106,     -0.0022,     -0.0163,      0.0143,\n",
      "            -0.0087,      0.0022,     -0.0096,      0.0059,      0.0045,\n",
      "             0.0073,      0.0133,     -0.0155,      0.0060,     -0.0123,\n",
      "            -0.0164,      0.0124,      0.0002,     -0.0140,     -0.0017,\n",
      "             0.0176,      0.0033,     -0.0087,     -0.0034,      0.0007,\n",
      "            -0.0066,     -0.0057,     -0.0156,      0.0176,     -0.0065,\n",
      "            -0.0091,     -0.0108,      0.0111,     -0.0044,     -0.0156,\n",
      "            -0.0163,     -0.0123,      0.0175,      0.0063,      0.0164,\n",
      "             0.0092,      0.0097,     -0.0132,     -0.0163,     -0.0125,\n",
      "             0.0148,      0.0001,     -0.0103,     -0.0074,     -0.0068,\n",
      "             0.0069,     -0.0075,     -0.0017,     -0.0032,      0.0163,\n",
      "            -0.0122,      0.0012,      0.0095,      0.0070,     -0.0042,\n",
      "            -0.0052,     -0.0173,     -0.0094,     -0.0114,     -0.0077,\n",
      "             0.0069,      0.0083,     -0.0024,     -0.0178,      0.0016,\n",
      "            -0.0143,      0.0175,     -0.0042,      0.0039,     -0.0025,\n",
      "             0.0158,      0.0030,      0.0054,      0.0168,      0.0005,\n",
      "            -0.0035,      0.0014,      0.0074,      0.0032,     -0.0005,\n",
      "            -0.0126,     -0.0177,     -0.0124,     -0.0020,     -0.0052,\n",
      "             0.0047,     -0.0043,      0.0077,      0.0106,      0.0105,\n",
      "             0.0097,     -0.0126,     -0.0101,     -0.0125,      0.0178,\n",
      "             0.0048,      0.0010,      0.0065,      0.0140,     -0.0079,\n",
      "            -0.0063,      0.0016,      0.0096,     -0.0045,      0.0140,\n",
      "             0.0033,     -0.0128,      0.0113,     -0.0140,      0.0056,\n",
      "             0.0127,      0.0159,     -0.0090,      0.0073,     -0.0004,\n",
      "            -0.0059,     -0.0156,      0.0097,      0.0029,     -0.0080,\n",
      "             0.0046,      0.0091,     -0.0003,      0.0023,     -0.0078,\n",
      "            -0.0100,      0.0159,      0.0057,      0.0078,      0.0044,\n",
      "             0.0003,      0.0011,     -0.0154,     -0.0104,     -0.0017,\n",
      "            -0.0173,      0.0176,      0.0167,      0.0037,     -0.0132,\n",
      "            -0.0083,      0.0158,     -0.0152,      0.0134,     -0.0038,\n",
      "             0.0100,      0.0116,      0.0137,     -0.0131,     -0.0058,\n",
      "             0.0090,     -0.0026,      0.0032,     -0.0131,      0.0171,\n",
      "             0.0174,      0.0042,     -0.0137,      0.0068,      0.0013,\n",
      "             0.0127,     -0.0129,     -0.0138,     -0.0075,      0.0131,\n",
      "            -0.0136,     -0.0155,      0.0038,      0.0120,      0.0090,\n",
      "             0.0156,      0.0149,      0.0012,      0.0106,      0.0168,\n",
      "             0.0110,     -0.0113,     -0.0161,     -0.0122,      0.0126,\n",
      "            -0.0140,      0.0119,      0.0102,      0.0088,     -0.0136,\n",
      "             0.0078,      0.0077,      0.0059,      0.0114,     -0.0173,\n",
      "             0.0014,     -0.0005,      0.0097,     -0.0143,      0.0090,\n",
      "             0.0023,      0.0155,      0.0085,      0.0179,     -0.0114,\n",
      "            -0.0081,      0.0045,      0.0001,     -0.0163,      0.0085,\n",
      "            -0.0109,      0.0007,     -0.0086,     -0.0043,      0.0111,\n",
      "            -0.0038,     -0.0106,      0.0171,      0.0112,     -0.0068,\n",
      "             0.0133,     -0.0141,      0.0144,     -0.0167,      0.0048,\n",
      "             0.0082,      0.0029,      0.0065,     -0.0123,      0.0013,\n",
      "             0.0176,     -0.0040,      0.0152,     -0.0154,     -0.0174,\n",
      "            -0.0021,     -0.0133,     -0.0073,     -0.0025,     -0.0108,\n",
      "             0.0121,      0.0056,     -0.0128,      0.0068,      0.0028,\n",
      "             0.0116,      0.0066,      0.0167,      0.0135,      0.0066,\n",
      "             0.0091,     -0.0067,     -0.0049,      0.0129,     -0.0178,\n",
      "            -0.0132,      0.0108,      0.0134,     -0.0029,      0.0023,\n",
      "             0.0028,     -0.0147,      0.0060,      0.0156,     -0.0012,\n",
      "            -0.0180,      0.0154,     -0.0146,      0.0103,      0.0135,\n",
      "             0.0037,      0.0084,      0.0050,     -0.0029,      0.0134,\n",
      "             0.0138,     -0.0059,      0.0045,      0.0007,      0.0016,\n",
      "            -0.0040,      0.0030,     -0.0081,     -0.0072,      0.0173,\n",
      "            -0.0105,      0.0069,     -0.0005,      0.0029,      0.0109,\n",
      "            -0.0126,     -0.0097,     -0.0047,     -0.0092,      0.0037,\n",
      "             0.0021,      0.0013,     -0.0158,      0.0150,      0.0043,\n",
      "             0.0036,     -0.0034,     -0.0091,     -0.0049,     -0.0138,\n",
      "            -0.0143,      0.0134,     -0.0104,     -0.0158,      0.0068,\n",
      "            -0.0111,      0.0011,      0.0029,      0.0022,      0.0056,\n",
      "            -0.0088,      0.0041,      0.0071,     -0.0116,     -0.0074,\n",
      "             0.0074,     -0.0154,      0.0131,      0.0161,     -0.0009,\n",
      "            -0.0014,      0.0057,     -0.0144,      0.0108,      0.0158,\n",
      "             0.0142,      0.0060,      0.0110,     -0.0043,      0.0100,\n",
      "             0.0158,      0.0009,     -0.0002,     -0.0162,      0.0016,\n",
      "             0.0028,      0.0152,     -0.0009,     -0.0025,      0.0151,\n",
      "            -0.0134,     -0.0009,     -0.0167,     -0.0166,      0.0119,\n",
      "             0.0135,      0.0146,     -0.0086,     -0.0080,     -0.0065,\n",
      "             0.0106,     -0.0061,      0.0148,     -0.0004,      0.0055,\n",
      "            -0.0086,     -0.0056,      0.0166,      0.0008,      0.0145,\n",
      "            -0.0163,      0.0013,     -0.0034,      0.0101,     -0.0123,\n",
      "            -0.0140,     -0.0083,      0.0145,     -0.0102,      0.0007,\n",
      "            -0.0030,     -0.0178,     -0.0179,     -0.0140,      0.0036,\n",
      "            -0.0080,     -0.0019,     -0.0142,      0.0133,     -0.0055,\n",
      "            -0.0130,     -0.0170,     -0.0005,      0.0107,     -0.0160,\n",
      "             0.0052,      0.0151,      0.0034,     -0.0146,      0.0064,\n",
      "             0.0179,     -0.0008,      0.0107,      0.0077,      0.0085,\n",
      "             0.0108,     -0.0038,      0.0156,     -0.0157,     -0.0023,\n",
      "            -0.0049,      0.0057,     -0.0157,      0.0078,      0.0059,\n",
      "            -0.0137,     -0.0084,      0.0097,     -0.0126,     -0.0130,\n",
      "             0.0013,      0.0044,      0.0172,      0.0078,     -0.0035,\n",
      "            -0.0168,     -0.0036,      0.0073,      0.0176,      0.0164,\n",
      "             0.0091,      0.0040,     -0.0149,      0.0075,      0.0102,\n",
      "            -0.0078,     -0.0086,     -0.0073,      0.0082,     -0.0110,\n",
      "            -0.0073,      0.0074,     -0.0007,     -0.0162,     -0.0076,\n",
      "             0.0078,     -0.0066,     -0.0097,      0.0013,     -0.0110,\n",
      "            -0.0026,      0.0142,     -0.0018,     -0.0160,      0.0044,\n",
      "             0.0143,     -0.0018,     -0.0117,     -0.0045,      0.0041,\n",
      "             0.0159,     -0.0180,      0.0080,      0.0116,      0.0046,\n",
      "             0.0010,     -0.0008,     -0.0172,      0.0112,      0.0034,\n",
      "             0.0138,     -0.0106,     -0.0052,      0.0019,     -0.0066,\n",
      "             0.0018,      0.0047,      0.0104,     -0.0092,     -0.0018,\n",
      "             0.0004,      0.0057,     -0.0119,     -0.0138,     -0.0131,\n",
      "            -0.0044,     -0.0113,     -0.0103,     -0.0058,     -0.0106,\n",
      "            -0.0083,     -0.0131,     -0.0120,     -0.0025,     -0.0119,\n",
      "             0.0090,      0.0072,      0.0103,      0.0177,      0.0046,\n",
      "             0.0140,     -0.0082,     -0.0135,     -0.0003,      0.0171,\n",
      "            -0.0035,      0.0029,     -0.0044,     -0.0067,      0.0075,\n",
      "            -0.0078,     -0.0028,     -0.0036,      0.0160,      0.0025,\n",
      "            -0.0078,     -0.0140,      0.0018,      0.0101,     -0.0048,\n",
      "             0.0100,      0.0071,     -0.0004,     -0.0078,      0.0036,\n",
      "            -0.0153,      0.0006,     -0.0154,      0.0116,      0.0074,\n",
      "             0.0158,     -0.0100,     -0.0143,     -0.0006,      0.0133,\n",
      "             0.0014,     -0.0029,      0.0144,      0.0110,     -0.0103,\n",
      "             0.0103,      0.0043,     -0.0032,     -0.0111,      0.0118,\n",
      "             0.0066,     -0.0068,     -0.0012,      0.0035,      0.0034,\n",
      "            -0.0052,     -0.0078,      0.0141,      0.0169,      0.0038,\n",
      "             0.0104,      0.0078,      0.0172,     -0.0096,     -0.0045,\n",
      "             0.0088,     -0.0171,      0.0014,     -0.0037,     -0.0151,\n",
      "             0.0028,      0.0145,      0.0083,      0.0076,     -0.0150,\n",
      "            -0.0135,      0.0064,      0.0086,     -0.0023,      0.0079,\n",
      "            -0.0002,     -0.0026,      0.0151,      0.0015,      0.0161,\n",
      "            -0.0154,     -0.0039,      0.0015,     -0.0023,     -0.0070,\n",
      "            -0.0169,     -0.0036,      0.0011,      0.0011,      0.0023,\n",
      "            -0.0007,     -0.0178,      0.0020,      0.0115,     -0.0010,\n",
      "            -0.0134,     -0.0115,      0.0068,      0.0178,      0.0036,\n",
      "            -0.0115,     -0.0012,     -0.0090,     -0.0064,      0.0135,\n",
      "            -0.0006,      0.0147,     -0.0005,      0.0125,     -0.0176,\n",
      "             0.0110,     -0.0177,      0.0006,     -0.0174,     -0.0042,\n",
      "            -0.0071,     -0.0137,     -0.0087,      0.0095,      0.0101,\n",
      "             0.0074,      0.0003,     -0.0077,      0.0142,      0.0063,\n",
      "             0.0120,      0.0163,      0.0139,      0.0173,     -0.0131,\n",
      "            -0.0131,      0.0062,     -0.0129,     -0.0054,     -0.0005,\n",
      "             0.0053,      0.0119,     -0.0148,      0.0088,     -0.0163,\n",
      "             0.0091,     -0.0044,      0.0028,     -0.0131,     -0.0150,\n",
      "             0.0116,      0.0047,      0.0077,      0.0014,      0.0117,\n",
      "             0.0099,      0.0131,      0.0031,     -0.0107,     -0.0178,\n",
      "             0.0178,     -0.0160,      0.0135,     -0.0096,     -0.0087,\n",
      "             0.0123,      0.0153,      0.0091,      0.0107,      0.0082,\n",
      "             0.0069,     -0.0170,      0.0134,      0.0100,      0.0051,\n",
      "             0.0006,      0.0177,      0.0169,     -0.0039,      0.0128,\n",
      "            -0.0151,     -0.0020,     -0.0131,      0.0110,      0.0136,\n",
      "             0.0037,     -0.0017,     -0.0088,      0.0019,      0.0139,\n",
      "            -0.0030,     -0.0178,      0.0154,      0.0013,     -0.0023,\n",
      "            -0.0073,      0.0087,     -0.0140,      0.0176,      0.0031,\n",
      "            -0.0113,     -0.0177,     -0.0134,     -0.0094,      0.0071,\n",
      "            -0.0051,      0.0147,      0.0115,      0.0121,     -0.0127,\n",
      "            -0.0047,      0.0031,     -0.0022,      0.0012,     -0.0043,\n",
      "            -0.0047,      0.0135,      0.0121,     -0.0126,      0.0081,\n",
      "            -0.0092,     -0.0074,     -0.0055,     -0.0125,      0.0174,\n",
      "            -0.0069,      0.0075,      0.0001,     -0.0130,      0.0099,\n",
      "             0.0040,      0.0022,     -0.0010,      0.0084,      0.0058,\n",
      "             0.0027,     -0.0110,      0.0027,     -0.0121,     -0.0099,\n",
      "             0.0041,      0.0155,      0.0117,      0.0039,      0.0133,\n",
      "             0.0154,      0.0175,     -0.0060,     -0.0007,      0.0097,\n",
      "            -0.0065,      0.0175,     -0.0177,      0.0056,     -0.0171,\n",
      "             0.0079,     -0.0001,     -0.0011], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0218, -0.0057,  0.0185,  ...,  0.0114, -0.0089,  0.0233],\n",
      "        [-0.0336,  0.0022,  0.0058,  ...,  0.0343, -0.0210,  0.0360],\n",
      "        [ 0.0220,  0.0132,  0.0198,  ...,  0.0174,  0.0340, -0.0035],\n",
      "        ...,\n",
      "        [-0.0315,  0.0139,  0.0009,  ..., -0.0351, -0.0008,  0.0221],\n",
      "        [-0.0260,  0.0289,  0.0320,  ...,  0.0213,  0.0303, -0.0319],\n",
      "        [ 0.0071, -0.0281, -0.0268,  ..., -0.0260, -0.0227, -0.0272]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0190, -0.0193, -0.0233,  ...,  0.0253,  0.0098, -0.0309],\n",
      "        [-0.0252,  0.0194, -0.0096,  ...,  0.0095,  0.0345, -0.0299],\n",
      "        [-0.0291,  0.0097,  0.0154,  ...,  0.0138,  0.0003, -0.0248],\n",
      "        ...,\n",
      "        [ 0.0222,  0.0164, -0.0010,  ..., -0.0102, -0.0110,  0.0323],\n",
      "        [-0.0170,  0.0222, -0.0201,  ...,  0.0042,  0.0037, -0.0028],\n",
      "        [-0.0015, -0.0276, -0.0253,  ...,  0.0151,  0.0032, -0.0002]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0296,  0.0335, -0.0281,  ..., -0.0228,  0.0355, -0.0332],\n",
      "        [-0.0250, -0.0164, -0.0123,  ...,  0.0192,  0.0241, -0.0191],\n",
      "        [ 0.0146,  0.0319,  0.0089,  ..., -0.0091,  0.0321,  0.0150],\n",
      "        ...,\n",
      "        [-0.0237,  0.0295,  0.0036,  ...,  0.0104, -0.0277, -0.0122],\n",
      "        [-0.0278, -0.0081,  0.0326,  ...,  0.0319, -0.0008, -0.0055],\n",
      "        [-0.0104, -0.0319,  0.0327,  ...,  0.0220,  0.0036,  0.0009]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0011, -0.0254,  0.0096,  ..., -0.0057,  0.0033, -0.0025],\n",
      "        [ 0.0136, -0.0162, -0.0133,  ...,  0.0213, -0.0019,  0.0080],\n",
      "        [-0.0192, -0.0134,  0.0069,  ...,  0.0020, -0.0263,  0.0114],\n",
      "        ...,\n",
      "        [-0.0359, -0.0139, -0.0262,  ..., -0.0284, -0.0178, -0.0296],\n",
      "        [-0.0288,  0.0111, -0.0151,  ...,  0.0076, -0.0158, -0.0034],\n",
      "        [-0.0271, -0.0255, -0.0182,  ...,  0.0087,  0.0207,  0.0213]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([    -0.0343,     -0.0092,     -0.0183,     -0.0359,     -0.0063,\n",
      "             0.0163,      0.0150,     -0.0080,     -0.0025,      0.0094,\n",
      "            -0.0280,      0.0018,      0.0136,      0.0247,      0.0241,\n",
      "            -0.0234,      0.0237,     -0.0329,      0.0043,     -0.0221,\n",
      "             0.0316,     -0.0074,      0.0043,     -0.0213,     -0.0235,\n",
      "            -0.0192,      0.0320,     -0.0124,      0.0148,     -0.0219,\n",
      "            -0.0331,     -0.0327,     -0.0111,      0.0347,      0.0162,\n",
      "            -0.0346,      0.0148,     -0.0208,     -0.0101,      0.0029,\n",
      "            -0.0094,     -0.0253,      0.0123,      0.0100,     -0.0084,\n",
      "             0.0156,      0.0209,     -0.0191,      0.0244,      0.0307,\n",
      "            -0.0345,      0.0290,     -0.0108,      0.0285,      0.0302,\n",
      "            -0.0321,      0.0170,     -0.0075,     -0.0170,      0.0240,\n",
      "            -0.0099,     -0.0355,      0.0237,     -0.0028,     -0.0095,\n",
      "             0.0345,     -0.0076,      0.0332,      0.0094,     -0.0003,\n",
      "            -0.0021,     -0.0213,      0.0269,     -0.0164,     -0.0082,\n",
      "            -0.0174,      0.0153,     -0.0276,     -0.0179,      0.0163,\n",
      "             0.0010,      0.0124,     -0.0199,     -0.0242,      0.0153,\n",
      "             0.0231,      0.0328,     -0.0194,     -0.0097,      0.0179,\n",
      "            -0.0014,     -0.0032,     -0.0032,     -0.0048,     -0.0098,\n",
      "            -0.0043,      0.0257,     -0.0118,     -0.0108,     -0.0340,\n",
      "             0.0097,      0.0284,      0.0162,      0.0359,     -0.0037,\n",
      "            -0.0126,     -0.0166,      0.0070,      0.0018,     -0.0300,\n",
      "             0.0147,      0.0157,      0.0075,      0.0140,      0.0182,\n",
      "            -0.0227,     -0.0061,      0.0140,     -0.0135,      0.0108,\n",
      "             0.0257,      0.0077,     -0.0358,     -0.0246,     -0.0120,\n",
      "             0.0188,      0.0348,     -0.0345,      0.0172,     -0.0185,\n",
      "            -0.0250,      0.0001,      0.0359,      0.0349,      0.0183,\n",
      "             0.0202,     -0.0112,     -0.0125,      0.0263,      0.0266,\n",
      "            -0.0238,     -0.0024,      0.0238,     -0.0088,      0.0267,\n",
      "            -0.0148,     -0.0212,     -0.0347,     -0.0206,     -0.0149,\n",
      "            -0.0022,      0.0276,      0.0326,      0.0339,      0.0160,\n",
      "            -0.0178,     -0.0039,     -0.0188,      0.0081,      0.0333,\n",
      "            -0.0280,     -0.0033,     -0.0319,     -0.0315,     -0.0192,\n",
      "            -0.0097,      0.0255,     -0.0147,     -0.0089,      0.0203,\n",
      "             0.0270,     -0.0167,     -0.0116,      0.0135,      0.0154,\n",
      "             0.0130,      0.0287,     -0.0196,     -0.0242,      0.0084,\n",
      "             0.0348,      0.0084,      0.0009,      0.0007,      0.0294,\n",
      "             0.0172,      0.0008,     -0.0237,      0.0191,      0.0179,\n",
      "             0.0145,      0.0198,     -0.0247,     -0.0182,     -0.0130,\n",
      "             0.0121,     -0.0303,     -0.0027,     -0.0328,     -0.0197,\n",
      "             0.0222,     -0.0106,      0.0070,      0.0037,      0.0083,\n",
      "             0.0022,      0.0296,     -0.0327,      0.0034,     -0.0249,\n",
      "            -0.0030,     -0.0040,      0.0262,      0.0308,     -0.0236,\n",
      "             0.0349,     -0.0318,      0.0197,     -0.0205,     -0.0289,\n",
      "            -0.0331,     -0.0180,     -0.0193,      0.0099,      0.0355,\n",
      "             0.0002,      0.0263,      0.0097,      0.0316,     -0.0181,\n",
      "             0.0201,     -0.0341,      0.0124,     -0.0038,     -0.0181,\n",
      "             0.0354,     -0.0031,     -0.0090,     -0.0018,     -0.0173,\n",
      "            -0.0327,      0.0052,      0.0217,     -0.0062,      0.0218,\n",
      "            -0.0359,     -0.0024,     -0.0275,     -0.0100,     -0.0092,\n",
      "            -0.0049,      0.0277,      0.0089,     -0.0091,      0.0292,\n",
      "            -0.0189,     -0.0026,      0.0236,      0.0239,     -0.0066,\n",
      "             0.0047,      0.0207,     -0.0028,     -0.0301,     -0.0268,\n",
      "            -0.0281,     -0.0034,     -0.0319,     -0.0040,     -0.0099,\n",
      "            -0.0128,      0.0302,     -0.0315,     -0.0172,     -0.0356,\n",
      "             0.0030,      0.0230,     -0.0175,     -0.0019,      0.0004,\n",
      "            -0.0278,      0.0183,     -0.0306,      0.0314,     -0.0341,\n",
      "             0.0256,     -0.0310,      0.0185,      0.0296,     -0.0217,\n",
      "             0.0224,      0.0086,     -0.0057,      0.0215,     -0.0164,\n",
      "            -0.0057,     -0.0334,      0.0324,      0.0101,     -0.0149,\n",
      "            -0.0166,      0.0106,      0.0129,      0.0163,      0.0069,\n",
      "             0.0245,      0.0062,      0.0216,      0.0315,     -0.0022,\n",
      "            -0.0229,     -0.0247,      0.0178,     -0.0347,      0.0044,\n",
      "            -0.0350,      0.0193,      0.0296,     -0.0129,      0.0345,\n",
      "            -0.0042,     -0.0291,     -0.0087,     -0.0048,      0.0046,\n",
      "             0.0097,     -0.0240,      0.0146,      0.0062,      0.0196,\n",
      "            -0.0086,     -0.0330,      0.0329,     -0.0039,      0.0269,\n",
      "             0.0142,     -0.0192,      0.0206,      0.0061,     -0.0237,\n",
      "             0.0337,      0.0051,     -0.0086,      0.0205,     -0.0103,\n",
      "             0.0343,     -0.0050,      0.0247,     -0.0236,      0.0131,\n",
      "            -0.0349,      0.0148,      0.0101,      0.0139,     -0.0069,\n",
      "            -0.0074,     -0.0098,     -0.0189,      0.0011,     -0.0327,\n",
      "             0.0215,     -0.0180,     -0.0190,      0.0012,      0.0146,\n",
      "            -0.0358,     -0.0147,      0.0254,      0.0087,      0.0278,\n",
      "            -0.0167,      0.0310,     -0.0082,     -0.0055,      0.0145,\n",
      "            -0.0184,     -0.0197,     -0.0305,      0.0014,      0.0263,\n",
      "            -0.0146,      0.0164,      0.0159,     -0.0253,      0.0094,\n",
      "            -0.0075,     -0.0109,     -0.0138,     -0.0160,     -0.0287,\n",
      "            -0.0179,      0.0149,     -0.0060,     -0.0302,      0.0207,\n",
      "             0.0037,     -0.0026,     -0.0178,     -0.0203,      0.0000,\n",
      "            -0.0220,      0.0333,      0.0209,      0.0310,      0.0093,\n",
      "             0.0000,      0.0197,      0.0262,      0.0234,     -0.0066,\n",
      "             0.0175,     -0.0073,     -0.0315,      0.0175,      0.0134,\n",
      "            -0.0038,      0.0309,      0.0005,     -0.0207,      0.0143,\n",
      "             0.0272,      0.0264,     -0.0275,     -0.0009,     -0.0014,\n",
      "            -0.0309,     -0.0331,      0.0094,     -0.0185,     -0.0194,\n",
      "            -0.0176,      0.0043,      0.0147,     -0.0301,     -0.0305,\n",
      "            -0.0282,     -0.0106,     -0.0213,     -0.0152,     -0.0047,\n",
      "            -0.0194,      0.0008,     -0.0005,      0.0302,      0.0184,\n",
      "             0.0311,     -0.0098,     -0.0248,      0.0322,      0.0112,\n",
      "             0.0177,     -0.0147,     -0.0060,     -0.0280,      0.0245,\n",
      "             0.0194,      0.0331,     -0.0059,     -0.0063,     -0.0185,\n",
      "            -0.0325,      0.0209,      0.0240,     -0.0148,      0.0329,\n",
      "             0.0323,     -0.0166,      0.0264,     -0.0337,     -0.0124,\n",
      "            -0.0012,     -0.0066,      0.0020,     -0.0180,      0.0054,\n",
      "             0.0133,     -0.0143,      0.0313,     -0.0281,      0.0241,\n",
      "             0.0073,     -0.0106,      0.0183,     -0.0048,     -0.0080,\n",
      "            -0.0181,     -0.0007,     -0.0359,     -0.0185,      0.0165,\n",
      "             0.0194,      0.0109,     -0.0223,      0.0338,     -0.0241,\n",
      "             0.0352,      0.0105,      0.0037,      0.0335,     -0.0145,\n",
      "            -0.0034,      0.0064,      0.0221,     -0.0331,      0.0070,\n",
      "             0.0018,     -0.0254,     -0.0150,      0.0063,      0.0305,\n",
      "             0.0281,     -0.0328,     -0.0087,      0.0299,     -0.0145,\n",
      "            -0.0179,      0.0166,      0.0121,     -0.0075,     -0.0164,\n",
      "             0.0176,     -0.0292,      0.0041,     -0.0269,     -0.0309,\n",
      "             0.0226,     -0.0251,      0.0283,     -0.0221,     -0.0327,\n",
      "            -0.0179,      0.0024,     -0.0284,      0.0052,     -0.0144,\n",
      "            -0.0165,      0.0049,      0.0227,     -0.0306,      0.0157,\n",
      "            -0.0337,     -0.0286,     -0.0017,     -0.0215,     -0.0191,\n",
      "             0.0244,      0.0067,      0.0275,     -0.0220,     -0.0184,\n",
      "            -0.0142,      0.0233,     -0.0076,      0.0322,      0.0194,\n",
      "             0.0242,      0.0156,     -0.0260,      0.0261,      0.0168,\n",
      "             0.0020,      0.0335,     -0.0289,      0.0024,     -0.0186,\n",
      "             0.0245,     -0.0124,      0.0246,      0.0253,     -0.0205,\n",
      "            -0.0147,     -0.0085,     -0.0307,      0.0084,     -0.0337,\n",
      "            -0.0275,     -0.0334,      0.0048,      0.0026,     -0.0139,\n",
      "            -0.0224,      0.0065,     -0.0056,     -0.0197,     -0.0074,\n",
      "             0.0015,      0.0224,     -0.0221,      0.0028,     -0.0186,\n",
      "            -0.0186,      0.0163,     -0.0026,      0.0343,     -0.0040,\n",
      "             0.0183,     -0.0135,     -0.0071,      0.0149,      0.0306,\n",
      "            -0.0071,      0.0175,     -0.0196,     -0.0259,     -0.0049,\n",
      "            -0.0082,     -0.0103,     -0.0068,      0.0192,     -0.0049,\n",
      "             0.0029,      0.0153,     -0.0076,      0.0351,     -0.0207,\n",
      "            -0.0044,      0.0310,     -0.0325,      0.0317,     -0.0317,\n",
      "            -0.0185,     -0.0352,      0.0061,      0.0126,     -0.0055,\n",
      "             0.0022,     -0.0256,      0.0249,     -0.0013,      0.0336,\n",
      "            -0.0012,      0.0165,      0.0177,      0.0109,      0.0255,\n",
      "             0.0357,     -0.0348,     -0.0211,     -0.0040,     -0.0334,\n",
      "            -0.0333,     -0.0143,      0.0295,      0.0157,     -0.0237,\n",
      "             0.0038,      0.0329,      0.0340,      0.0350,      0.0303,\n",
      "            -0.0036,      0.0149,      0.0050,      0.0261,      0.0028,\n",
      "            -0.0098,      0.0247,     -0.0059,      0.0268,      0.0221,\n",
      "             0.0112,      0.0026,     -0.0136,     -0.0115,     -0.0269,\n",
      "            -0.0317,     -0.0342,      0.0010,     -0.0233,     -0.0111,\n",
      "            -0.0178,     -0.0005,      0.0331,     -0.0160,     -0.0158,\n",
      "            -0.0312,     -0.0099,      0.0309,      0.0002,      0.0205,\n",
      "             0.0197,      0.0186,     -0.0350,      0.0342,      0.0076,\n",
      "            -0.0321,      0.0197,     -0.0165,     -0.0123,     -0.0222,\n",
      "             0.0247,     -0.0221,     -0.0026,      0.0078,      0.0325,\n",
      "             0.0108,     -0.0175,     -0.0160,      0.0002,     -0.0009,\n",
      "             0.0324,     -0.0268,      0.0211,      0.0117,      0.0078,\n",
      "             0.0232,     -0.0182,      0.0052,     -0.0171,      0.0169,\n",
      "             0.0340,      0.0241,      0.0219,      0.0126,     -0.0304,\n",
      "            -0.0244,      0.0054,     -0.0010,      0.0165,      0.0253,\n",
      "            -0.0047,     -0.0119,      0.0057,     -0.0120,     -0.0146,\n",
      "             0.0267,     -0.0355,      0.0029,      0.0163,     -0.0176,\n",
      "            -0.0213,     -0.0350,      0.0200,     -0.0185,      0.0277,\n",
      "            -0.0352,     -0.0111,     -0.0008,      0.0294,     -0.0055,\n",
      "             0.0213,     -0.0037,     -0.0057,      0.0344,     -0.0260,\n",
      "            -0.0266,     -0.0237,     -0.0036,      0.0294,     -0.0095,\n",
      "             0.0099,     -0.0018,      0.0024,      0.0296,      0.0057,\n",
      "            -0.0184,     -0.0340,     -0.0076,     -0.0300,      0.0206,\n",
      "            -0.0274,      0.0288,      0.0293,     -0.0055,      0.0296,\n",
      "            -0.0137,     -0.0231,     -0.0046], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0128, -0.0352, -0.0110,  ..., -0.0336, -0.0274, -0.0047],\n",
      "        [ 0.0091, -0.0357, -0.0153,  ..., -0.0161, -0.0177,  0.0179],\n",
      "        [ 0.0306, -0.0278, -0.0188,  ...,  0.0102,  0.0109, -0.0034],\n",
      "        ...,\n",
      "        [-0.0286, -0.0348,  0.0314,  ...,  0.0110,  0.0185, -0.0143],\n",
      "        [ 0.0045, -0.0343,  0.0151,  ..., -0.0071,  0.0263,  0.0044],\n",
      "        [ 0.0174,  0.0191, -0.0092,  ..., -0.0077, -0.0037,  0.0153]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0328,  0.0020,  0.0100,  ...,  0.0082, -0.0233, -0.0013],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0158,  0.0122, -0.0015,  ..., -0.0115,  0.0058,  0.0023],\n",
      "        [-0.0092,  0.0018,  0.0058,  ...,  0.0012,  0.0051,  0.0103],\n",
      "        [-0.0102,  0.0006,  0.0012,  ..., -0.0174,  0.0117,  0.0016],\n",
      "        ...,\n",
      "        [-0.0012, -0.0036, -0.0058,  ...,  0.0176,  0.0088,  0.0132],\n",
      "        [-0.0022,  0.0065, -0.0061,  ..., -0.0179, -0.0111, -0.0022],\n",
      "        [ 0.0039,  0.0114, -0.0132,  ..., -0.0071,  0.0165,  0.0168]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([     0.0003,      0.0067,      0.0072,      0.0039,      0.0102,\n",
      "             0.0072,     -0.0092,      0.0077,      0.0030,     -0.0068,\n",
      "             0.0133,     -0.0038,     -0.0099,     -0.0079,     -0.0157,\n",
      "             0.0027,     -0.0089,      0.0173,      0.0166,      0.0115,\n",
      "            -0.0086,      0.0154,      0.0016,     -0.0068,     -0.0157,\n",
      "             0.0053,     -0.0178,     -0.0076,      0.0068,     -0.0166,\n",
      "            -0.0017,      0.0161,      0.0157,      0.0071,     -0.0103,\n",
      "            -0.0003,     -0.0094,      0.0030,     -0.0020,      0.0153,\n",
      "             0.0125,     -0.0034,      0.0047,     -0.0112,     -0.0040,\n",
      "            -0.0020,     -0.0131,     -0.0173,      0.0072,     -0.0086,\n",
      "            -0.0072,      0.0065,      0.0094,     -0.0047,      0.0017,\n",
      "            -0.0140,      0.0075,     -0.0144,     -0.0008,      0.0052,\n",
      "            -0.0155,     -0.0131,     -0.0034,      0.0136,     -0.0131,\n",
      "            -0.0092,      0.0063,      0.0168,      0.0079,      0.0052,\n",
      "             0.0178,     -0.0172,     -0.0050,      0.0058,      0.0012,\n",
      "             0.0109,     -0.0014,      0.0054,      0.0174,     -0.0095,\n",
      "             0.0093,     -0.0088,      0.0071,     -0.0164,     -0.0108,\n",
      "            -0.0180,     -0.0091,      0.0137,     -0.0134,     -0.0053,\n",
      "             0.0051,     -0.0027,     -0.0144,     -0.0005,     -0.0157,\n",
      "             0.0067,      0.0041,     -0.0134,     -0.0066,      0.0173,\n",
      "            -0.0037,     -0.0041,     -0.0005,     -0.0036,     -0.0085,\n",
      "            -0.0095,     -0.0107,     -0.0017,     -0.0127,      0.0027,\n",
      "             0.0069,     -0.0000,     -0.0008,     -0.0028,      0.0081,\n",
      "            -0.0037,      0.0008,     -0.0038,     -0.0134,      0.0083,\n",
      "            -0.0015,      0.0120,      0.0028,     -0.0148,      0.0058,\n",
      "             0.0112,     -0.0004,     -0.0052,     -0.0170,     -0.0069,\n",
      "             0.0087,      0.0010,      0.0152,     -0.0024,      0.0148,\n",
      "            -0.0030,      0.0128,      0.0119,     -0.0169,      0.0045,\n",
      "             0.0162,     -0.0003,     -0.0131,     -0.0151,     -0.0046,\n",
      "            -0.0030,     -0.0126,      0.0106,     -0.0050,     -0.0049,\n",
      "            -0.0065,      0.0077,      0.0064,     -0.0137,      0.0108,\n",
      "             0.0169,      0.0049,      0.0067,     -0.0135,      0.0085,\n",
      "            -0.0027,      0.0088,     -0.0169,      0.0098,      0.0001,\n",
      "             0.0007,     -0.0126,     -0.0075,     -0.0089,     -0.0158,\n",
      "            -0.0120,      0.0009,      0.0172,      0.0144,      0.0155,\n",
      "            -0.0001,     -0.0162,     -0.0153,     -0.0072,      0.0041,\n",
      "             0.0047,     -0.0087,      0.0157,     -0.0091,      0.0011,\n",
      "             0.0160,     -0.0051,     -0.0111,      0.0081,      0.0176,\n",
      "             0.0028,     -0.0137,      0.0017,     -0.0082,      0.0138,\n",
      "             0.0081,     -0.0164,     -0.0127,      0.0107,      0.0161,\n",
      "            -0.0096,      0.0155,      0.0140,     -0.0170,      0.0114,\n",
      "             0.0020,      0.0047,      0.0083,     -0.0024,      0.0116,\n",
      "            -0.0079,     -0.0075,      0.0179,      0.0147,     -0.0140,\n",
      "             0.0136,     -0.0138,      0.0018,      0.0154,     -0.0048,\n",
      "             0.0093,      0.0179,      0.0151,     -0.0028,     -0.0169,\n",
      "             0.0093,      0.0036,      0.0034,      0.0080,      0.0062,\n",
      "             0.0010,      0.0074,     -0.0119,     -0.0056,      0.0022,\n",
      "            -0.0136,      0.0146,      0.0106,      0.0004,     -0.0097,\n",
      "             0.0139,     -0.0002,     -0.0098,     -0.0010,      0.0073,\n",
      "             0.0161,     -0.0012,      0.0065,     -0.0075,      0.0048,\n",
      "             0.0051,      0.0138,     -0.0044,      0.0099,     -0.0137,\n",
      "            -0.0109,     -0.0129,     -0.0043,      0.0166,     -0.0067,\n",
      "             0.0003,     -0.0132,      0.0063,     -0.0163,     -0.0080,\n",
      "            -0.0132,      0.0162,      0.0031,      0.0004,     -0.0028,\n",
      "            -0.0177,      0.0170,      0.0155,     -0.0051,      0.0076,\n",
      "             0.0028,      0.0176,     -0.0123,     -0.0084,      0.0139,\n",
      "             0.0178,      0.0053,     -0.0072,     -0.0080,      0.0061,\n",
      "             0.0058,      0.0062,      0.0120,      0.0041,     -0.0096,\n",
      "             0.0155,     -0.0143,     -0.0056,      0.0003,     -0.0163,\n",
      "            -0.0180,     -0.0013,     -0.0016,      0.0005,     -0.0107,\n",
      "            -0.0033,      0.0130,     -0.0130,      0.0034,     -0.0094,\n",
      "             0.0152,     -0.0095,     -0.0147,     -0.0155,      0.0013,\n",
      "             0.0013,      0.0119,     -0.0029,     -0.0084,      0.0073,\n",
      "             0.0027,      0.0025,     -0.0103,      0.0070,     -0.0003,\n",
      "             0.0139,      0.0152,     -0.0168,      0.0131,     -0.0087,\n",
      "             0.0012,     -0.0018,      0.0124,     -0.0010,     -0.0000,\n",
      "            -0.0100,      0.0152,      0.0070,     -0.0167,     -0.0118,\n",
      "            -0.0149,     -0.0130,     -0.0050,     -0.0136,     -0.0161,\n",
      "            -0.0147,     -0.0170,      0.0077,      0.0175,     -0.0175,\n",
      "            -0.0140,      0.0018,     -0.0169,      0.0030,     -0.0129,\n",
      "            -0.0151,     -0.0031,     -0.0005,      0.0033,     -0.0167,\n",
      "            -0.0119,     -0.0038,      0.0146,      0.0011,     -0.0072,\n",
      "            -0.0171,     -0.0138,     -0.0134,      0.0163,     -0.0108,\n",
      "             0.0083,     -0.0134,      0.0093,     -0.0094,     -0.0139,\n",
      "             0.0001,     -0.0044,     -0.0065,      0.0141,      0.0118,\n",
      "            -0.0048,     -0.0047,     -0.0165,      0.0175,      0.0061,\n",
      "            -0.0039,     -0.0001,     -0.0178,      0.0076,      0.0143,\n",
      "             0.0157,     -0.0101,      0.0016,     -0.0146,     -0.0171,\n",
      "            -0.0008,      0.0121,      0.0109,     -0.0072,      0.0071,\n",
      "             0.0024,      0.0066,      0.0018,     -0.0093,     -0.0081,\n",
      "             0.0057,      0.0090,      0.0085,      0.0142,     -0.0004,\n",
      "            -0.0133,      0.0152,     -0.0031,      0.0044,      0.0002,\n",
      "             0.0055,     -0.0106,     -0.0138,      0.0163,      0.0112,\n",
      "             0.0118,      0.0058,      0.0082,     -0.0068,     -0.0178,\n",
      "             0.0150,     -0.0176,      0.0003,      0.0112,      0.0027,\n",
      "             0.0066,      0.0067,     -0.0055,      0.0108,     -0.0113,\n",
      "             0.0050,     -0.0035,     -0.0054,      0.0076,     -0.0121,\n",
      "             0.0041,      0.0180,     -0.0085,      0.0072,      0.0102,\n",
      "             0.0167,     -0.0041,      0.0087,     -0.0064,      0.0003,\n",
      "             0.0045,     -0.0104,     -0.0014,      0.0153,      0.0145,\n",
      "            -0.0086,     -0.0073,      0.0102,     -0.0050,      0.0125,\n",
      "            -0.0133,      0.0129,      0.0171,     -0.0048,     -0.0061,\n",
      "            -0.0078,     -0.0174,     -0.0045,      0.0171,     -0.0102,\n",
      "            -0.0010,     -0.0126,     -0.0123,     -0.0018,      0.0149,\n",
      "            -0.0037,     -0.0095,      0.0101,     -0.0076,      0.0058,\n",
      "            -0.0179,     -0.0046,      0.0054,      0.0074,      0.0164,\n",
      "            -0.0057,     -0.0077,     -0.0084,      0.0037,      0.0045,\n",
      "            -0.0048,     -0.0178,     -0.0002,     -0.0170,     -0.0070,\n",
      "            -0.0145,      0.0022,     -0.0032,      0.0015,     -0.0074,\n",
      "             0.0053,      0.0039,     -0.0001,      0.0010,     -0.0084,\n",
      "            -0.0090,      0.0164,      0.0033,     -0.0085,     -0.0040,\n",
      "             0.0071,     -0.0087,      0.0147,     -0.0107,     -0.0099,\n",
      "             0.0016,     -0.0031,      0.0086,     -0.0160,      0.0042,\n",
      "             0.0179,      0.0102,     -0.0115,     -0.0144,     -0.0149,\n",
      "            -0.0161,     -0.0030,     -0.0142,     -0.0119,      0.0014,\n",
      "            -0.0043,      0.0017,      0.0151,      0.0066,     -0.0131,\n",
      "            -0.0126,      0.0073,      0.0061,     -0.0007,     -0.0164,\n",
      "            -0.0070,      0.0142,      0.0007,     -0.0117,     -0.0047,\n",
      "            -0.0079,      0.0046,      0.0120,     -0.0138,     -0.0154,\n",
      "             0.0176,     -0.0139,     -0.0161,     -0.0118,      0.0088,\n",
      "             0.0018,      0.0017,      0.0150,     -0.0065,      0.0084,\n",
      "            -0.0117,     -0.0126,     -0.0135,      0.0178,     -0.0087,\n",
      "             0.0004,     -0.0028,     -0.0087,      0.0158,      0.0081,\n",
      "            -0.0115,      0.0061,     -0.0128,      0.0156,     -0.0055,\n",
      "             0.0019,      0.0164,     -0.0116,      0.0022,      0.0131,\n",
      "            -0.0011,      0.0056,     -0.0046,      0.0164,     -0.0157,\n",
      "            -0.0178,     -0.0088,      0.0024,     -0.0138,     -0.0161,\n",
      "            -0.0038,     -0.0109,      0.0001,     -0.0080,      0.0068,\n",
      "            -0.0076,     -0.0167,     -0.0107,     -0.0067,      0.0057,\n",
      "             0.0151,     -0.0078,     -0.0040,     -0.0078,     -0.0045,\n",
      "            -0.0102,     -0.0171,     -0.0041,      0.0150,      0.0097,\n",
      "             0.0105,     -0.0130,     -0.0018,     -0.0098,      0.0155,\n",
      "             0.0118,     -0.0050,     -0.0005,     -0.0048,      0.0143,\n",
      "            -0.0087,     -0.0038,      0.0116,     -0.0074,      0.0146,\n",
      "             0.0030,     -0.0040,      0.0077,     -0.0070,     -0.0180,\n",
      "             0.0179,     -0.0016,      0.0030,     -0.0156,     -0.0126,\n",
      "            -0.0141,      0.0153,     -0.0066,     -0.0143,      0.0005,\n",
      "             0.0064,     -0.0053,     -0.0086,      0.0078,      0.0069,\n",
      "            -0.0127,     -0.0068,     -0.0104,     -0.0180,     -0.0072,\n",
      "            -0.0042,      0.0061,     -0.0122,      0.0084,     -0.0006,\n",
      "            -0.0118,     -0.0172,     -0.0137,     -0.0139,      0.0146,\n",
      "            -0.0048,     -0.0009,      0.0139,     -0.0147,     -0.0174,\n",
      "             0.0141,     -0.0164,     -0.0088,     -0.0126,      0.0151,\n",
      "            -0.0160,      0.0115,     -0.0169,     -0.0016,      0.0167,\n",
      "            -0.0042,     -0.0132,     -0.0075,     -0.0037,     -0.0040,\n",
      "             0.0046,     -0.0038,      0.0104,     -0.0029,     -0.0104,\n",
      "            -0.0114,      0.0104,     -0.0114,      0.0178,      0.0173,\n",
      "             0.0139,     -0.0059,     -0.0103,     -0.0057,      0.0076,\n",
      "             0.0117,     -0.0092,     -0.0052,      0.0006,      0.0172,\n",
      "            -0.0024,     -0.0011,      0.0145,     -0.0133,      0.0068,\n",
      "             0.0080,     -0.0176,     -0.0036,      0.0129,     -0.0093,\n",
      "             0.0115,     -0.0137,      0.0175,     -0.0073,     -0.0115,\n",
      "             0.0023,      0.0078,     -0.0139,      0.0117,     -0.0139,\n",
      "            -0.0092,      0.0138,      0.0066,     -0.0017,     -0.0113,\n",
      "             0.0119,      0.0040,     -0.0139,     -0.0070,     -0.0068,\n",
      "             0.0032,      0.0029,      0.0022,      0.0019,     -0.0112,\n",
      "             0.0148,     -0.0057,      0.0081,     -0.0046,      0.0130,\n",
      "             0.0078,      0.0089,      0.0114,     -0.0019,     -0.0171,\n",
      "             0.0028,     -0.0002,      0.0129,      0.0038,     -0.0014,\n",
      "            -0.0030,     -0.0172,     -0.0012,      0.0035,     -0.0137,\n",
      "             0.0064,      0.0119,     -0.0134,     -0.0105,      0.0068,\n",
      "            -0.0014,      0.0039,      0.0018,      0.0158,     -0.0108,\n",
      "            -0.0024,     -0.0160,     -0.0108,     -0.0134,     -0.0165,\n",
      "             0.0174,     -0.0152,      0.0151], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0005,  0.0110, -0.0223,  ..., -0.0198, -0.0105,  0.0005],\n",
      "        [-0.0169,  0.0028,  0.0249,  ..., -0.0261, -0.0329,  0.0261],\n",
      "        [ 0.0178, -0.0356, -0.0327,  ..., -0.0360,  0.0244, -0.0283],\n",
      "        ...,\n",
      "        [-0.0152,  0.0213, -0.0182,  ..., -0.0054, -0.0316, -0.0127],\n",
      "        [ 0.0053,  0.0327, -0.0272,  ...,  0.0161, -0.0217,  0.0102],\n",
      "        [ 0.0258,  0.0355,  0.0243,  ..., -0.0216, -0.0002,  0.0138]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0334,  0.0053,  0.0175,  ..., -0.0358,  0.0010,  0.0068],\n",
      "        [-0.0107,  0.0270, -0.0217,  ...,  0.0223, -0.0012, -0.0164],\n",
      "        [-0.0006,  0.0299,  0.0271,  ..., -0.0305,  0.0250, -0.0199],\n",
      "        ...,\n",
      "        [ 0.0059, -0.0063, -0.0081,  ...,  0.0292, -0.0292,  0.0086],\n",
      "        [ 0.0336,  0.0309, -0.0335,  ...,  0.0207,  0.0331,  0.0328],\n",
      "        [-0.0265,  0.0153, -0.0168,  ...,  0.0131,  0.0068, -0.0010]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0088, -0.0208, -0.0203,  ...,  0.0114,  0.0106, -0.0249],\n",
      "        [ 0.0049,  0.0218,  0.0298,  ..., -0.0294, -0.0107,  0.0165],\n",
      "        [-0.0187, -0.0107, -0.0320,  ...,  0.0230, -0.0292, -0.0100],\n",
      "        ...,\n",
      "        [-0.0075,  0.0205, -0.0034,  ...,  0.0191,  0.0282,  0.0337],\n",
      "        [ 0.0318, -0.0294,  0.0014,  ...,  0.0009,  0.0092,  0.0343],\n",
      "        [ 0.0191, -0.0251,  0.0043,  ..., -0.0189, -0.0301,  0.0008]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0195, -0.0354,  0.0070,  ..., -0.0155,  0.0049, -0.0356],\n",
      "        [ 0.0146,  0.0056, -0.0146,  ..., -0.0339,  0.0179,  0.0208],\n",
      "        [-0.0264, -0.0234,  0.0350,  ...,  0.0214,  0.0269,  0.0190],\n",
      "        ...,\n",
      "        [ 0.0261,  0.0112, -0.0296,  ..., -0.0138,  0.0052, -0.0241],\n",
      "        [-0.0304,  0.0264,  0.0323,  ..., -0.0348, -0.0092, -0.0075],\n",
      "        [-0.0267, -0.0094,  0.0010,  ...,  0.0185,  0.0089, -0.0103]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([     0.0074,      0.0267,      0.0206,      0.0173,      0.0084,\n",
      "             0.0216,     -0.0082,      0.0061,     -0.0049,     -0.0276,\n",
      "            -0.0125,      0.0291,     -0.0340,      0.0120,      0.0349,\n",
      "            -0.0123,      0.0079,     -0.0279,     -0.0050,      0.0198,\n",
      "            -0.0143,     -0.0281,     -0.0163,     -0.0335,      0.0103,\n",
      "            -0.0121,      0.0295,      0.0042,      0.0060,     -0.0113,\n",
      "             0.0183,     -0.0227,     -0.0128,      0.0033,      0.0068,\n",
      "            -0.0305,      0.0321,     -0.0057,      0.0020,     -0.0145,\n",
      "            -0.0057,      0.0065,     -0.0099,      0.0048,     -0.0025,\n",
      "             0.0192,     -0.0072,     -0.0281,     -0.0076,      0.0098,\n",
      "             0.0215,     -0.0065,     -0.0295,     -0.0267,      0.0102,\n",
      "             0.0021,     -0.0205,      0.0198,      0.0330,     -0.0180,\n",
      "            -0.0077,      0.0143,     -0.0267,      0.0329,     -0.0302,\n",
      "             0.0330,      0.0049,      0.0246,      0.0299,      0.0112,\n",
      "            -0.0068,      0.0280,      0.0242,     -0.0211,      0.0091,\n",
      "             0.0321,      0.0001,      0.0022,     -0.0087,     -0.0180,\n",
      "             0.0327,      0.0066,      0.0291,     -0.0094,     -0.0277,\n",
      "            -0.0133,      0.0177,      0.0319,      0.0321,      0.0163,\n",
      "             0.0260,     -0.0292,     -0.0339,      0.0104,      0.0115,\n",
      "            -0.0168,     -0.0318,     -0.0210,      0.0285,      0.0298,\n",
      "             0.0225,     -0.0343,     -0.0337,      0.0315,      0.0102,\n",
      "             0.0251,     -0.0117,      0.0045,     -0.0285,      0.0156,\n",
      "            -0.0200,     -0.0135,      0.0249,      0.0161,     -0.0035,\n",
      "            -0.0240,     -0.0248,      0.0246,      0.0067,      0.0057,\n",
      "             0.0320,      0.0344,      0.0280,      0.0158,      0.0256,\n",
      "             0.0261,      0.0222,     -0.0244,      0.0303,     -0.0201,\n",
      "            -0.0104,      0.0176,     -0.0256,      0.0184,     -0.0107,\n",
      "             0.0280,      0.0347,      0.0302,      0.0194,     -0.0047,\n",
      "             0.0053,      0.0348,      0.0014,      0.0243,      0.0237,\n",
      "             0.0214,      0.0231,      0.0234,     -0.0260,      0.0354,\n",
      "            -0.0271,      0.0036,     -0.0214,     -0.0212,     -0.0063,\n",
      "             0.0327,     -0.0320,      0.0265,     -0.0139,      0.0285,\n",
      "             0.0021,     -0.0030,     -0.0262,     -0.0246,     -0.0016,\n",
      "            -0.0232,     -0.0066,      0.0318,      0.0049,     -0.0302,\n",
      "            -0.0222,      0.0264,     -0.0199,     -0.0230,      0.0095,\n",
      "            -0.0326,      0.0000,      0.0337,     -0.0222,      0.0045,\n",
      "            -0.0327,     -0.0234,      0.0193,     -0.0290,      0.0026,\n",
      "            -0.0084,     -0.0241,     -0.0114,     -0.0004,     -0.0321,\n",
      "            -0.0173,     -0.0252,     -0.0035,      0.0190,      0.0110,\n",
      "             0.0091,      0.0062,      0.0319,     -0.0027,     -0.0057,\n",
      "             0.0249,     -0.0339,      0.0238,     -0.0272,      0.0099,\n",
      "             0.0260,      0.0085,     -0.0257,     -0.0091,      0.0017,\n",
      "             0.0035,      0.0191,     -0.0238,      0.0116,     -0.0057,\n",
      "             0.0292,     -0.0217,      0.0215,      0.0199,     -0.0217,\n",
      "            -0.0305,      0.0313,      0.0273,     -0.0269,      0.0162,\n",
      "            -0.0136,      0.0343,     -0.0327,      0.0039,     -0.0232,\n",
      "            -0.0273,     -0.0094,     -0.0263,     -0.0170,     -0.0352,\n",
      "             0.0032,     -0.0059,      0.0240,      0.0039,      0.0265,\n",
      "            -0.0043,      0.0037,     -0.0048,     -0.0309,      0.0028,\n",
      "            -0.0326,     -0.0204,     -0.0129,      0.0199,      0.0039,\n",
      "             0.0131,      0.0178,      0.0268,     -0.0329,     -0.0016,\n",
      "             0.0178,     -0.0059,      0.0279,      0.0338,      0.0264,\n",
      "             0.0190,     -0.0004,      0.0171,     -0.0218,     -0.0220,\n",
      "             0.0011,     -0.0257,      0.0009,      0.0173,      0.0256,\n",
      "            -0.0329,     -0.0250,      0.0320,     -0.0236,      0.0157,\n",
      "             0.0299,     -0.0024,      0.0305,     -0.0262,      0.0042,\n",
      "            -0.0324,     -0.0007,      0.0086,     -0.0319,      0.0101,\n",
      "             0.0128,      0.0314,     -0.0152,      0.0047,     -0.0090,\n",
      "            -0.0261,     -0.0058,     -0.0195,     -0.0282,     -0.0146,\n",
      "             0.0170,      0.0076,     -0.0218,      0.0189,     -0.0356,\n",
      "             0.0099,      0.0316,     -0.0354,     -0.0213,     -0.0016,\n",
      "            -0.0280,      0.0248,     -0.0228,     -0.0161,     -0.0068,\n",
      "             0.0050,     -0.0116,      0.0145,     -0.0357,     -0.0282,\n",
      "             0.0146,      0.0154,     -0.0330,      0.0232,      0.0309,\n",
      "             0.0210,      0.0296,     -0.0079,     -0.0276,     -0.0329,\n",
      "            -0.0314,      0.0304,     -0.0035,      0.0146,      0.0164,\n",
      "            -0.0256,     -0.0046,      0.0234,     -0.0251,      0.0294,\n",
      "             0.0128,      0.0025,     -0.0022,     -0.0230,      0.0107,\n",
      "            -0.0350,      0.0305,     -0.0071,      0.0285,      0.0299,\n",
      "             0.0166,      0.0029,     -0.0281,      0.0041,      0.0322,\n",
      "             0.0297,      0.0258,     -0.0064,      0.0314,      0.0018,\n",
      "            -0.0018,      0.0295,      0.0046,     -0.0044,     -0.0191,\n",
      "            -0.0084,     -0.0009,     -0.0310,      0.0201,     -0.0001,\n",
      "            -0.0009,     -0.0031,     -0.0202,     -0.0359,      0.0155,\n",
      "             0.0321,     -0.0357,      0.0313,      0.0031,      0.0097,\n",
      "            -0.0116,      0.0111,      0.0052,     -0.0060,     -0.0004,\n",
      "            -0.0129,     -0.0188,      0.0326,     -0.0208,     -0.0000,\n",
      "             0.0045,     -0.0102,      0.0202,      0.0030,     -0.0053,\n",
      "            -0.0284,     -0.0355,      0.0277,      0.0208,      0.0199,\n",
      "            -0.0110,     -0.0254,     -0.0321,      0.0033,      0.0024,\n",
      "             0.0033,      0.0286,      0.0329,      0.0225,     -0.0190,\n",
      "             0.0266,      0.0357,      0.0276,     -0.0027,      0.0341,\n",
      "            -0.0189,     -0.0031,      0.0337,     -0.0087,     -0.0081,\n",
      "             0.0131,     -0.0229,      0.0029,      0.0050,     -0.0049,\n",
      "            -0.0076,      0.0251,      0.0088,     -0.0088,     -0.0181,\n",
      "            -0.0014,      0.0210,     -0.0359,      0.0119,     -0.0212,\n",
      "             0.0157,     -0.0061,     -0.0289,     -0.0259,     -0.0225,\n",
      "            -0.0339,     -0.0120,     -0.0078,     -0.0222,     -0.0357,\n",
      "            -0.0291,      0.0212,     -0.0119,     -0.0212,     -0.0153,\n",
      "             0.0060,      0.0272,      0.0023,     -0.0350,     -0.0029,\n",
      "            -0.0111,     -0.0043,      0.0201,     -0.0025,     -0.0040,\n",
      "            -0.0178,     -0.0105,     -0.0342,      0.0168,      0.0177,\n",
      "            -0.0170,      0.0353,      0.0339,     -0.0162,     -0.0252,\n",
      "            -0.0089,      0.0200,      0.0342,     -0.0254,     -0.0216,\n",
      "            -0.0201,     -0.0161,      0.0149,      0.0030,     -0.0134,\n",
      "             0.0136,     -0.0226,      0.0238,      0.0207,     -0.0134,\n",
      "             0.0286,     -0.0311,     -0.0230,     -0.0010,      0.0257,\n",
      "            -0.0125,      0.0206,     -0.0027,      0.0066,      0.0308,\n",
      "            -0.0084,      0.0308,     -0.0147,      0.0333,     -0.0321,\n",
      "             0.0340,      0.0090,     -0.0175,      0.0080,     -0.0361,\n",
      "             0.0356,      0.0192,      0.0072,      0.0040,      0.0001,\n",
      "             0.0086,      0.0342,      0.0353,      0.0308,     -0.0141,\n",
      "            -0.0105,      0.0258,      0.0154,     -0.0227,      0.0091,\n",
      "             0.0292,      0.0313,     -0.0207,     -0.0224,     -0.0125,\n",
      "             0.0260,     -0.0031,     -0.0011,      0.0169,      0.0155,\n",
      "             0.0319,     -0.0267,     -0.0323,      0.0006,     -0.0255,\n",
      "            -0.0077,      0.0266,     -0.0027,     -0.0095,      0.0005,\n",
      "            -0.0012,     -0.0297,      0.0314,     -0.0246,     -0.0216,\n",
      "            -0.0129,      0.0196,      0.0265,     -0.0126,      0.0009,\n",
      "            -0.0169,     -0.0165,     -0.0230,      0.0003,      0.0057,\n",
      "            -0.0135,      0.0066,      0.0060,     -0.0168,      0.0204,\n",
      "            -0.0275,     -0.0015,      0.0258,     -0.0170,      0.0049,\n",
      "             0.0268,      0.0275,      0.0197,     -0.0055,     -0.0026,\n",
      "            -0.0234,     -0.0036,      0.0017,     -0.0306,     -0.0078,\n",
      "             0.0116,      0.0218,      0.0043,     -0.0063,      0.0348,\n",
      "             0.0304,      0.0190,     -0.0196,      0.0281,      0.0206,\n",
      "             0.0191,     -0.0138,      0.0196,     -0.0332,     -0.0275,\n",
      "             0.0209,      0.0338,     -0.0333,      0.0227,      0.0083,\n",
      "            -0.0016,      0.0340,     -0.0352,     -0.0157,      0.0183,\n",
      "             0.0200,     -0.0026,     -0.0281,     -0.0225,      0.0320,\n",
      "            -0.0055,      0.0170,     -0.0167,     -0.0361,      0.0297,\n",
      "            -0.0299,     -0.0212,     -0.0338,      0.0239,     -0.0202,\n",
      "            -0.0045,     -0.0149,     -0.0328,     -0.0144,     -0.0011,\n",
      "             0.0169,      0.0129,      0.0111,     -0.0269,     -0.0080,\n",
      "            -0.0156,      0.0149,     -0.0162,      0.0226,     -0.0266,\n",
      "            -0.0126,     -0.0164,      0.0092,      0.0087,     -0.0297,\n",
      "            -0.0029,     -0.0094,      0.0329,     -0.0336,      0.0241,\n",
      "             0.0194,      0.0331,     -0.0232,      0.0100,      0.0279,\n",
      "             0.0234,      0.0107,     -0.0173,     -0.0336,     -0.0163,\n",
      "             0.0054,     -0.0049,      0.0278,     -0.0341,     -0.0186,\n",
      "             0.0285,     -0.0121,      0.0263,     -0.0301,     -0.0317,\n",
      "            -0.0028,      0.0203,      0.0307,      0.0203,     -0.0135,\n",
      "            -0.0148,      0.0311,     -0.0087,     -0.0048,      0.0192,\n",
      "             0.0120,      0.0292,     -0.0170,      0.0234,     -0.0169,\n",
      "             0.0088,     -0.0317,     -0.0208,      0.0264,      0.0021,\n",
      "             0.0155,      0.0284,     -0.0343,      0.0243,     -0.0264,\n",
      "             0.0204,      0.0011,      0.0249,     -0.0103,     -0.0264,\n",
      "            -0.0317,      0.0235,     -0.0355,     -0.0312,      0.0287,\n",
      "            -0.0214,      0.0008,     -0.0211,     -0.0099,      0.0082,\n",
      "             0.0053,      0.0025,     -0.0137,      0.0276,      0.0327,\n",
      "             0.0018,      0.0257,     -0.0318,      0.0138,      0.0097,\n",
      "            -0.0015,     -0.0289,      0.0102,     -0.0262,      0.0273,\n",
      "            -0.0303,      0.0206,     -0.0248,      0.0047,      0.0139,\n",
      "            -0.0173,     -0.0041,      0.0224,     -0.0124,      0.0044,\n",
      "            -0.0191,     -0.0155,     -0.0232,     -0.0220,      0.0068,\n",
      "            -0.0041,     -0.0117,     -0.0215,     -0.0002,     -0.0271,\n",
      "            -0.0110,      0.0324,      0.0260,      0.0013,      0.0126,\n",
      "            -0.0048,      0.0173,      0.0033,      0.0038,      0.0166,\n",
      "            -0.0007,     -0.0136,      0.0221,     -0.0288,     -0.0252,\n",
      "             0.0003,     -0.0259,     -0.0344,     -0.0094,      0.0353,\n",
      "             0.0264,      0.0139,      0.0179,     -0.0182,      0.0331,\n",
      "            -0.0186,      0.0079,     -0.0219,     -0.0310,      0.0108,\n",
      "             0.0335,     -0.0316,      0.0155,      0.0022,     -0.0251,\n",
      "            -0.0120,     -0.0178,      0.0338], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[    -0.0166,     -0.0103,     -0.0099,  ...,     -0.0117,\n",
      "              0.0286,     -0.0296],\n",
      "        [    -0.0300,     -0.0000,      0.0279,  ...,      0.0105,\n",
      "              0.0114,      0.0147],\n",
      "        [    -0.0242,      0.0222,     -0.0090,  ...,      0.0359,\n",
      "              0.0026,     -0.0191],\n",
      "        ...,\n",
      "        [     0.0124,     -0.0181,      0.0049,  ...,      0.0288,\n",
      "             -0.0249,      0.0327],\n",
      "        [     0.0224,     -0.0024,      0.0117,  ...,     -0.0268,\n",
      "             -0.0197,     -0.0061],\n",
      "        [     0.0095,     -0.0337,     -0.0095,  ...,     -0.0178,\n",
      "              0.0243,      0.0123]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([    -0.0148,     -0.0032,     -0.0056,  ...,     -0.0032,\n",
      "             0.0066,      0.0001], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0051, -0.0157, -0.0006,  ...,  0.0094,  0.0113, -0.0089],\n",
      "        [-0.0002, -0.0148,  0.0022,  ...,  0.0138, -0.0150, -0.0168],\n",
      "        [ 0.0046,  0.0109,  0.0160,  ...,  0.0178, -0.0173, -0.0095],\n",
      "        ...,\n",
      "        [ 0.0121,  0.0018,  0.0064,  ..., -0.0026, -0.0172,  0.0092],\n",
      "        [-0.0050,  0.0024,  0.0054,  ...,  0.0096,  0.0055, -0.0064],\n",
      "        [-0.0072, -0.0124,  0.0050,  ...,  0.0055,  0.0081,  0.0156]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([     0.0043,     -0.0137,     -0.0089,      0.0107,      0.0027,\n",
      "             0.0157,      0.0016,     -0.0117,      0.0000,      0.0169,\n",
      "            -0.0088,     -0.0007,     -0.0007,      0.0064,      0.0148,\n",
      "             0.0132,     -0.0016,     -0.0148,     -0.0155,      0.0019,\n",
      "            -0.0163,      0.0077,      0.0108,     -0.0142,     -0.0072,\n",
      "            -0.0046,      0.0108,     -0.0153,      0.0035,      0.0065,\n",
      "             0.0161,     -0.0033,      0.0136,      0.0157,     -0.0042,\n",
      "             0.0088,     -0.0069,     -0.0029,      0.0017,     -0.0041,\n",
      "            -0.0170,      0.0162,     -0.0058,      0.0029,      0.0015,\n",
      "            -0.0060,      0.0012,     -0.0055,     -0.0104,     -0.0064,\n",
      "            -0.0163,      0.0104,      0.0011,      0.0053,     -0.0072,\n",
      "             0.0125,      0.0116,     -0.0005,      0.0070,     -0.0020,\n",
      "            -0.0043,     -0.0179,      0.0093,      0.0151,     -0.0126,\n",
      "             0.0039,      0.0176,     -0.0079,      0.0024,      0.0147,\n",
      "            -0.0160,     -0.0043,      0.0008,     -0.0025,     -0.0071,\n",
      "            -0.0116,      0.0038,     -0.0166,      0.0179,     -0.0017,\n",
      "             0.0120,      0.0011,      0.0154,     -0.0146,      0.0163,\n",
      "            -0.0048,      0.0032,      0.0079,      0.0140,     -0.0087,\n",
      "             0.0060,      0.0175,      0.0085,      0.0131,     -0.0002,\n",
      "             0.0127,     -0.0165,     -0.0072,      0.0017,      0.0061,\n",
      "             0.0118,      0.0076,      0.0128,      0.0022,     -0.0132,\n",
      "             0.0018,     -0.0082,     -0.0024,      0.0121,     -0.0054,\n",
      "            -0.0078,     -0.0172,      0.0151,     -0.0067,      0.0026,\n",
      "             0.0134,      0.0043,      0.0180,      0.0016,     -0.0028,\n",
      "            -0.0165,     -0.0156,      0.0105,     -0.0057,     -0.0072,\n",
      "             0.0093,     -0.0001,     -0.0174,      0.0107,     -0.0104,\n",
      "            -0.0015,     -0.0123,      0.0014,     -0.0144,     -0.0082,\n",
      "            -0.0078,     -0.0166,      0.0060,      0.0082,      0.0021,\n",
      "             0.0124,      0.0037,     -0.0105,     -0.0138,      0.0162,\n",
      "             0.0102,      0.0059,      0.0150,      0.0170,      0.0096,\n",
      "             0.0025,      0.0142,      0.0086,      0.0141,      0.0017,\n",
      "            -0.0050,      0.0063,     -0.0151,     -0.0023,     -0.0023,\n",
      "            -0.0158,      0.0137,      0.0173,      0.0084,      0.0105,\n",
      "            -0.0175,     -0.0105,     -0.0038,     -0.0093,     -0.0144,\n",
      "             0.0061,     -0.0151,      0.0095,     -0.0137,      0.0164,\n",
      "            -0.0066,      0.0004,      0.0165,     -0.0043,      0.0091,\n",
      "            -0.0098,      0.0019,     -0.0120,     -0.0085,     -0.0134,\n",
      "            -0.0062,     -0.0152,     -0.0098,     -0.0035,      0.0160,\n",
      "             0.0141,      0.0157,     -0.0033,      0.0002,     -0.0178,\n",
      "             0.0030,     -0.0161,      0.0098,      0.0057,     -0.0012,\n",
      "             0.0125,      0.0020,      0.0173,      0.0073,     -0.0172,\n",
      "            -0.0133,      0.0035,      0.0121,     -0.0054,     -0.0042,\n",
      "             0.0136,      0.0143,     -0.0079,      0.0049,      0.0075,\n",
      "            -0.0044,     -0.0104,     -0.0069,     -0.0033,     -0.0052,\n",
      "            -0.0025,     -0.0070,      0.0086,      0.0030,      0.0025,\n",
      "            -0.0076,     -0.0145,      0.0066,     -0.0085,     -0.0023,\n",
      "            -0.0092,     -0.0169,      0.0026,     -0.0103,     -0.0161,\n",
      "            -0.0119,      0.0008,     -0.0129,      0.0033,     -0.0170,\n",
      "            -0.0162,     -0.0138,     -0.0016,      0.0171,     -0.0104,\n",
      "             0.0137,     -0.0162,      0.0083,      0.0086,     -0.0053,\n",
      "            -0.0145,     -0.0052,      0.0008,     -0.0173,      0.0046,\n",
      "             0.0081,     -0.0150,      0.0082,      0.0028,      0.0078,\n",
      "             0.0162,     -0.0133,      0.0103,      0.0026,     -0.0162,\n",
      "             0.0064,      0.0097,     -0.0151,     -0.0049,      0.0041,\n",
      "            -0.0026,     -0.0006,     -0.0072,      0.0094,     -0.0135,\n",
      "             0.0103,      0.0148,      0.0084,     -0.0127,     -0.0115,\n",
      "            -0.0171,      0.0043,      0.0171,      0.0106,     -0.0125,\n",
      "             0.0150,     -0.0070,     -0.0167,      0.0081,      0.0153,\n",
      "             0.0120,     -0.0059,     -0.0016,     -0.0002,     -0.0167,\n",
      "            -0.0107,     -0.0118,      0.0136,     -0.0105,     -0.0124,\n",
      "             0.0165,     -0.0138,      0.0171,     -0.0163,     -0.0158,\n",
      "            -0.0131,     -0.0049,      0.0053,     -0.0163,      0.0030,\n",
      "             0.0069,     -0.0074,     -0.0137,      0.0009,     -0.0135,\n",
      "            -0.0089,     -0.0091,      0.0082,     -0.0088,      0.0101,\n",
      "             0.0147,      0.0029,      0.0179,     -0.0000,     -0.0058,\n",
      "            -0.0072,      0.0172,      0.0018,      0.0128,      0.0081,\n",
      "             0.0105,     -0.0140,      0.0044,      0.0074,      0.0026,\n",
      "            -0.0126,     -0.0045,     -0.0144,      0.0092,     -0.0118,\n",
      "            -0.0052,     -0.0038,     -0.0164,     -0.0079,     -0.0019,\n",
      "             0.0019,     -0.0066,     -0.0050,      0.0180,      0.0036,\n",
      "             0.0106,      0.0006,     -0.0066,     -0.0104,      0.0042,\n",
      "             0.0089,      0.0022,     -0.0090,      0.0139,     -0.0082,\n",
      "            -0.0008,      0.0042,     -0.0157,      0.0114,     -0.0110,\n",
      "            -0.0057,      0.0127,     -0.0084,      0.0019,      0.0147,\n",
      "             0.0020,     -0.0002,     -0.0023,     -0.0076,      0.0108,\n",
      "             0.0067,     -0.0035,     -0.0076,     -0.0002,     -0.0032,\n",
      "            -0.0039,     -0.0067,      0.0033,     -0.0119,     -0.0031,\n",
      "             0.0064,     -0.0026,     -0.0069,     -0.0108,     -0.0098,\n",
      "            -0.0089,      0.0168,      0.0042,      0.0062,     -0.0105,\n",
      "             0.0152,      0.0164,      0.0132,      0.0075,     -0.0164,\n",
      "            -0.0019,      0.0022,     -0.0157,      0.0012,      0.0154,\n",
      "            -0.0094,     -0.0011,      0.0107,      0.0135,      0.0089,\n",
      "             0.0103,     -0.0128,      0.0056,     -0.0048,     -0.0019,\n",
      "            -0.0018,     -0.0102,     -0.0169,     -0.0102,     -0.0108,\n",
      "            -0.0024,      0.0102,      0.0078,     -0.0030,      0.0017,\n",
      "            -0.0011,      0.0115,     -0.0102,      0.0173,      0.0036,\n",
      "             0.0170,      0.0046,     -0.0042,      0.0062,     -0.0134,\n",
      "            -0.0052,     -0.0120,     -0.0113,      0.0075,      0.0031,\n",
      "            -0.0143,     -0.0165,     -0.0053,     -0.0073,     -0.0020,\n",
      "            -0.0012,      0.0028,     -0.0031,     -0.0064,      0.0125,\n",
      "             0.0126,      0.0133,     -0.0176,     -0.0053,      0.0006,\n",
      "            -0.0152,      0.0153,     -0.0011,      0.0155,      0.0104,\n",
      "             0.0016,      0.0027,     -0.0122,      0.0005,      0.0015,\n",
      "            -0.0091,      0.0100,      0.0116,      0.0159,      0.0081,\n",
      "            -0.0026,     -0.0175,     -0.0115,     -0.0012,      0.0048,\n",
      "            -0.0142,     -0.0025,     -0.0125,      0.0057,      0.0117,\n",
      "             0.0170,     -0.0142,      0.0157,      0.0028,     -0.0042,\n",
      "             0.0117,      0.0100,      0.0099,      0.0157,     -0.0110,\n",
      "            -0.0044,     -0.0020,     -0.0142,     -0.0059,      0.0146,\n",
      "            -0.0176,      0.0133,      0.0022,      0.0020,     -0.0029,\n",
      "            -0.0105,      0.0132,      0.0123,     -0.0040,      0.0067,\n",
      "             0.0152,      0.0023,     -0.0014,     -0.0077,     -0.0035,\n",
      "            -0.0166,     -0.0022,      0.0161,      0.0078,      0.0096,\n",
      "            -0.0034,     -0.0014,      0.0125,      0.0154,      0.0001,\n",
      "             0.0037,     -0.0135,     -0.0086,     -0.0141,      0.0155,\n",
      "             0.0077,     -0.0085,      0.0062,      0.0180,     -0.0145,\n",
      "            -0.0017,     -0.0089,     -0.0167,     -0.0073,     -0.0122,\n",
      "            -0.0008,      0.0168,     -0.0170,      0.0070,     -0.0006,\n",
      "            -0.0158,     -0.0056,      0.0052,     -0.0169,     -0.0056,\n",
      "             0.0141,      0.0082,      0.0055,      0.0015,     -0.0080,\n",
      "            -0.0037,      0.0080,      0.0002,      0.0144,     -0.0091,\n",
      "            -0.0064,     -0.0056,     -0.0007,     -0.0134,      0.0083,\n",
      "            -0.0110,     -0.0022,     -0.0089,      0.0086,      0.0094,\n",
      "            -0.0124,      0.0172,     -0.0167,      0.0047,     -0.0106,\n",
      "            -0.0106,      0.0064,     -0.0146,      0.0032,     -0.0072,\n",
      "            -0.0014,      0.0054,      0.0159,      0.0054,      0.0145,\n",
      "             0.0047,     -0.0155,     -0.0027,     -0.0058,      0.0169,\n",
      "            -0.0059,     -0.0034,     -0.0010,     -0.0108,      0.0048,\n",
      "            -0.0026,      0.0042,     -0.0020,      0.0093,     -0.0040,\n",
      "             0.0105,     -0.0060,      0.0168,     -0.0028,     -0.0177,\n",
      "            -0.0124,     -0.0082,     -0.0006,     -0.0105,      0.0075,\n",
      "             0.0045,     -0.0039,      0.0088,     -0.0078,      0.0177,\n",
      "            -0.0027,     -0.0060,     -0.0146,     -0.0119,     -0.0170,\n",
      "             0.0122,      0.0018,      0.0065,      0.0082,      0.0022,\n",
      "            -0.0060,     -0.0014,      0.0131,      0.0049,      0.0172,\n",
      "            -0.0087,      0.0177,      0.0148,      0.0117,     -0.0151,\n",
      "            -0.0067,      0.0133,      0.0154,      0.0069,      0.0143,\n",
      "             0.0115,      0.0029,      0.0166,     -0.0172,     -0.0102,\n",
      "            -0.0089,     -0.0035,      0.0065,     -0.0126,     -0.0100,\n",
      "             0.0122,      0.0165,     -0.0084,      0.0014,      0.0143,\n",
      "             0.0105,      0.0152,      0.0045,      0.0101,      0.0174,\n",
      "            -0.0100,     -0.0137,     -0.0079,      0.0094,     -0.0026,\n",
      "             0.0025,      0.0078,      0.0173,     -0.0075,      0.0143,\n",
      "             0.0080,      0.0163,     -0.0037,     -0.0012,     -0.0006,\n",
      "             0.0092,      0.0170,     -0.0160,     -0.0175,      0.0106,\n",
      "             0.0081,     -0.0107,      0.0090,     -0.0173,     -0.0024,\n",
      "            -0.0036,     -0.0102,     -0.0172,      0.0093,     -0.0029,\n",
      "             0.0177,     -0.0144,     -0.0063,     -0.0128,     -0.0116,\n",
      "            -0.0081,     -0.0165,      0.0152,      0.0090,     -0.0156,\n",
      "            -0.0096,      0.0160,      0.0169,      0.0026,      0.0040,\n",
      "             0.0053,     -0.0086,      0.0095,     -0.0092,      0.0161,\n",
      "            -0.0072,     -0.0016,      0.0095,     -0.0001,     -0.0085,\n",
      "             0.0068,      0.0047,     -0.0032,      0.0168,      0.0011,\n",
      "             0.0140,      0.0030,     -0.0090,      0.0108,     -0.0146,\n",
      "            -0.0134,      0.0130,     -0.0081,      0.0047,      0.0022,\n",
      "            -0.0075,     -0.0026,      0.0015,     -0.0141,      0.0090,\n",
      "             0.0167,     -0.0036,      0.0147,     -0.0121,     -0.0082,\n",
      "            -0.0061,     -0.0129,     -0.0121,     -0.0063,      0.0023,\n",
      "             0.0097,      0.0083,     -0.0037,     -0.0120,     -0.0036,\n",
      "            -0.0176,      0.0048,     -0.0180,      0.0112,     -0.0099,\n",
      "            -0.0039,     -0.0000,     -0.0126,     -0.0030,      0.0111,\n",
      "            -0.0046,     -0.0066,      0.0142,     -0.0170,     -0.0137,\n",
      "             0.0015,      0.0077,     -0.0108,     -0.0043,     -0.0062,\n",
      "            -0.0091,     -0.0052,      0.0144], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0098,  0.0205, -0.0138,  ..., -0.0069,  0.0180, -0.0016],\n",
      "        [ 0.0290, -0.0335,  0.0059,  ..., -0.0022, -0.0075, -0.0345],\n",
      "        [ 0.0123, -0.0221, -0.0127,  ..., -0.0048,  0.0268, -0.0316],\n",
      "        ...,\n",
      "        [ 0.0121, -0.0260, -0.0354,  ..., -0.0313, -0.0211, -0.0181],\n",
      "        [ 0.0193, -0.0151, -0.0255,  ..., -0.0169,  0.0355, -0.0172],\n",
      "        [-0.0049, -0.0345, -0.0007,  ..., -0.0178,  0.0200, -0.0167]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0218,  0.0157, -0.0052,  ..., -0.0102, -0.0070,  0.0110],\n",
      "        [-0.0183,  0.0137, -0.0168,  ...,  0.0355, -0.0243,  0.0099],\n",
      "        [-0.0015,  0.0154, -0.0284,  ..., -0.0197,  0.0325,  0.0103],\n",
      "        ...,\n",
      "        [-0.0150,  0.0132, -0.0172,  ...,  0.0158,  0.0275, -0.0225],\n",
      "        [ 0.0229,  0.0195,  0.0049,  ..., -0.0276,  0.0347, -0.0327],\n",
      "        [ 0.0247, -0.0060, -0.0313,  ..., -0.0105, -0.0155, -0.0093]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0033, -0.0340,  0.0082,  ..., -0.0173,  0.0344,  0.0237],\n",
      "        [ 0.0181,  0.0151, -0.0202,  ..., -0.0068,  0.0197,  0.0260],\n",
      "        [ 0.0214,  0.0274, -0.0113,  ..., -0.0313, -0.0011, -0.0014],\n",
      "        ...,\n",
      "        [-0.0306, -0.0021,  0.0100,  ...,  0.0027,  0.0346,  0.0122],\n",
      "        [ 0.0038, -0.0057, -0.0311,  ...,  0.0237, -0.0116, -0.0252],\n",
      "        [-0.0309,  0.0040, -0.0204,  ...,  0.0053, -0.0109, -0.0350]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0159, -0.0228,  0.0114,  ...,  0.0277, -0.0017,  0.0192],\n",
      "        [-0.0252,  0.0179, -0.0030,  ..., -0.0236,  0.0088,  0.0267],\n",
      "        [-0.0359, -0.0337,  0.0062,  ..., -0.0358, -0.0073,  0.0054],\n",
      "        ...,\n",
      "        [ 0.0328,  0.0333,  0.0250,  ..., -0.0325, -0.0030,  0.0082],\n",
      "        [ 0.0045,  0.0086, -0.0351,  ...,  0.0306,  0.0137,  0.0110],\n",
      "        [-0.0301, -0.0192,  0.0042,  ...,  0.0277, -0.0067, -0.0361]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0074, -0.0011, -0.0329,  0.0089,  0.0216, -0.0320,  0.0005,  0.0272,\n",
      "        -0.0175,  0.0124, -0.0058,  0.0336, -0.0229, -0.0279, -0.0183,  0.0252,\n",
      "        -0.0212,  0.0140,  0.0329, -0.0157, -0.0018, -0.0312, -0.0098, -0.0074,\n",
      "         0.0331,  0.0068,  0.0056, -0.0105,  0.0075, -0.0068, -0.0345, -0.0221,\n",
      "         0.0232, -0.0071, -0.0078,  0.0307,  0.0312, -0.0207,  0.0346, -0.0196,\n",
      "         0.0121,  0.0312,  0.0264, -0.0340,  0.0093,  0.0334,  0.0061,  0.0079,\n",
      "        -0.0176,  0.0278,  0.0019, -0.0115,  0.0358, -0.0088, -0.0336, -0.0275,\n",
      "         0.0179, -0.0276,  0.0262,  0.0322, -0.0205,  0.0348, -0.0312,  0.0149,\n",
      "         0.0317,  0.0186, -0.0024, -0.0015,  0.0109, -0.0328, -0.0153, -0.0241,\n",
      "         0.0233,  0.0264,  0.0257, -0.0041,  0.0257,  0.0176, -0.0351, -0.0232,\n",
      "         0.0151,  0.0068,  0.0237, -0.0132,  0.0171, -0.0222, -0.0163, -0.0073,\n",
      "        -0.0308,  0.0132, -0.0295, -0.0023, -0.0261, -0.0005,  0.0010, -0.0255,\n",
      "        -0.0202,  0.0251, -0.0348, -0.0027, -0.0232, -0.0206,  0.0231,  0.0110,\n",
      "         0.0221,  0.0248, -0.0080,  0.0185,  0.0256, -0.0179,  0.0201, -0.0343,\n",
      "        -0.0259, -0.0145, -0.0321,  0.0047,  0.0353, -0.0289,  0.0255,  0.0093,\n",
      "        -0.0286,  0.0005, -0.0206,  0.0106,  0.0191, -0.0309,  0.0332,  0.0299,\n",
      "         0.0146, -0.0026, -0.0154, -0.0037, -0.0359, -0.0205, -0.0017, -0.0279,\n",
      "        -0.0026, -0.0265, -0.0051,  0.0237, -0.0091,  0.0294,  0.0307, -0.0090,\n",
      "         0.0345, -0.0303,  0.0227, -0.0230, -0.0176,  0.0044,  0.0142, -0.0103,\n",
      "         0.0298, -0.0340, -0.0197,  0.0300,  0.0309, -0.0357, -0.0202, -0.0311,\n",
      "         0.0344, -0.0175, -0.0341, -0.0092,  0.0192,  0.0224, -0.0173,  0.0323,\n",
      "         0.0069, -0.0268, -0.0111, -0.0044,  0.0039,  0.0260, -0.0063,  0.0257,\n",
      "         0.0102,  0.0095, -0.0002, -0.0323, -0.0182,  0.0070,  0.0234, -0.0063,\n",
      "         0.0185,  0.0235, -0.0263,  0.0268,  0.0116, -0.0223, -0.0039, -0.0350,\n",
      "         0.0193, -0.0161,  0.0104,  0.0157, -0.0109, -0.0325, -0.0255,  0.0086,\n",
      "         0.0033,  0.0278,  0.0178, -0.0227, -0.0142,  0.0312,  0.0275,  0.0202,\n",
      "        -0.0062, -0.0101,  0.0270,  0.0254, -0.0289,  0.0152, -0.0337,  0.0015,\n",
      "        -0.0208,  0.0288,  0.0234,  0.0203,  0.0161,  0.0261, -0.0139, -0.0056,\n",
      "         0.0246, -0.0010, -0.0161, -0.0061, -0.0102,  0.0091,  0.0068, -0.0171,\n",
      "        -0.0138,  0.0050,  0.0278,  0.0007, -0.0327, -0.0143, -0.0026, -0.0106,\n",
      "         0.0091, -0.0039, -0.0104,  0.0209,  0.0186,  0.0015,  0.0192, -0.0289,\n",
      "         0.0210, -0.0311,  0.0348, -0.0264, -0.0294, -0.0037, -0.0277, -0.0234,\n",
      "        -0.0013, -0.0257,  0.0319, -0.0061,  0.0138,  0.0296, -0.0004,  0.0021,\n",
      "         0.0096,  0.0354,  0.0015, -0.0121, -0.0067,  0.0005,  0.0271, -0.0085,\n",
      "        -0.0322,  0.0214, -0.0316,  0.0178,  0.0111,  0.0266,  0.0040,  0.0053,\n",
      "         0.0101, -0.0331, -0.0022, -0.0200,  0.0034,  0.0110, -0.0175, -0.0262,\n",
      "         0.0183, -0.0142, -0.0295, -0.0008, -0.0142,  0.0171, -0.0359, -0.0188,\n",
      "        -0.0297, -0.0327, -0.0351,  0.0279, -0.0358,  0.0122, -0.0059,  0.0212,\n",
      "         0.0117, -0.0227,  0.0167, -0.0104, -0.0264,  0.0081, -0.0160, -0.0354,\n",
      "         0.0283,  0.0126,  0.0029,  0.0282,  0.0067, -0.0194,  0.0243,  0.0219,\n",
      "        -0.0038,  0.0056, -0.0029, -0.0032, -0.0173, -0.0207, -0.0311, -0.0202,\n",
      "        -0.0040,  0.0347,  0.0321,  0.0351,  0.0007, -0.0118, -0.0244, -0.0192,\n",
      "         0.0097, -0.0142, -0.0143,  0.0228,  0.0267, -0.0226,  0.0112, -0.0315,\n",
      "         0.0305,  0.0018,  0.0140, -0.0121, -0.0032,  0.0310, -0.0275,  0.0057,\n",
      "         0.0192,  0.0190, -0.0258,  0.0245, -0.0322,  0.0062,  0.0357, -0.0161,\n",
      "        -0.0161,  0.0029,  0.0028,  0.0087,  0.0049, -0.0002, -0.0060, -0.0184,\n",
      "        -0.0205, -0.0199, -0.0022, -0.0176, -0.0050,  0.0044,  0.0070,  0.0329,\n",
      "        -0.0310,  0.0190,  0.0283, -0.0120, -0.0113,  0.0198, -0.0160,  0.0023,\n",
      "        -0.0249, -0.0249, -0.0293, -0.0001, -0.0137,  0.0228, -0.0301,  0.0232,\n",
      "        -0.0349, -0.0094, -0.0030, -0.0264,  0.0043,  0.0267,  0.0267, -0.0301,\n",
      "        -0.0358,  0.0103,  0.0304, -0.0078, -0.0143, -0.0266,  0.0213,  0.0026,\n",
      "        -0.0181,  0.0292, -0.0089,  0.0223, -0.0132, -0.0238,  0.0331, -0.0085,\n",
      "         0.0013, -0.0254, -0.0202, -0.0194, -0.0239, -0.0049,  0.0022, -0.0099,\n",
      "         0.0220,  0.0219,  0.0127,  0.0012,  0.0359, -0.0054, -0.0274, -0.0201,\n",
      "        -0.0004,  0.0154,  0.0243,  0.0168, -0.0294,  0.0303,  0.0041, -0.0210,\n",
      "         0.0217,  0.0236,  0.0026, -0.0273,  0.0193, -0.0131,  0.0059, -0.0298,\n",
      "        -0.0187,  0.0036,  0.0302, -0.0360,  0.0247,  0.0037,  0.0327,  0.0115,\n",
      "        -0.0147, -0.0220, -0.0036,  0.0055, -0.0255, -0.0066,  0.0125, -0.0112,\n",
      "         0.0013, -0.0096,  0.0181, -0.0004,  0.0006, -0.0280, -0.0191, -0.0145,\n",
      "        -0.0165,  0.0101, -0.0197, -0.0118,  0.0118, -0.0223,  0.0231, -0.0150,\n",
      "        -0.0296,  0.0135, -0.0094,  0.0098, -0.0233,  0.0312,  0.0223, -0.0129,\n",
      "        -0.0249, -0.0265, -0.0151,  0.0118, -0.0056,  0.0183,  0.0039,  0.0229,\n",
      "         0.0269, -0.0345, -0.0010,  0.0358,  0.0277,  0.0300,  0.0020, -0.0098,\n",
      "         0.0290,  0.0253,  0.0221, -0.0278, -0.0337, -0.0210,  0.0268, -0.0353,\n",
      "         0.0196,  0.0063, -0.0125,  0.0347,  0.0022, -0.0046,  0.0304,  0.0068,\n",
      "         0.0215, -0.0139, -0.0107, -0.0092,  0.0358, -0.0335,  0.0193,  0.0171,\n",
      "         0.0106, -0.0190, -0.0136, -0.0271, -0.0354, -0.0185,  0.0173, -0.0065,\n",
      "        -0.0332,  0.0273,  0.0055, -0.0004, -0.0124, -0.0228, -0.0312,  0.0184,\n",
      "         0.0295, -0.0270, -0.0218,  0.0253, -0.0281,  0.0025, -0.0046,  0.0247,\n",
      "        -0.0133, -0.0064,  0.0181, -0.0319, -0.0047,  0.0055,  0.0173,  0.0139,\n",
      "         0.0088, -0.0085, -0.0112,  0.0270, -0.0196,  0.0238, -0.0338,  0.0097,\n",
      "        -0.0222,  0.0269,  0.0140,  0.0208, -0.0326,  0.0122, -0.0177,  0.0065,\n",
      "         0.0331, -0.0287, -0.0328,  0.0184, -0.0181,  0.0058, -0.0012, -0.0212,\n",
      "         0.0292, -0.0319, -0.0352,  0.0074, -0.0110, -0.0250,  0.0168,  0.0256,\n",
      "        -0.0325, -0.0147, -0.0263, -0.0043,  0.0118,  0.0074, -0.0144, -0.0150,\n",
      "         0.0157,  0.0252,  0.0103,  0.0135,  0.0314,  0.0193,  0.0127, -0.0003,\n",
      "         0.0319,  0.0336,  0.0004,  0.0194, -0.0336, -0.0048,  0.0352, -0.0185,\n",
      "         0.0012,  0.0084,  0.0293, -0.0056, -0.0028,  0.0205,  0.0249,  0.0336,\n",
      "         0.0359, -0.0253, -0.0058,  0.0066, -0.0031, -0.0239, -0.0031,  0.0353,\n",
      "        -0.0257,  0.0212, -0.0104, -0.0273, -0.0133, -0.0265, -0.0104,  0.0076,\n",
      "        -0.0228,  0.0233, -0.0142,  0.0023, -0.0167,  0.0207, -0.0330, -0.0159,\n",
      "         0.0011, -0.0085, -0.0280,  0.0122, -0.0007, -0.0277, -0.0290,  0.0356,\n",
      "        -0.0128, -0.0173, -0.0072,  0.0309, -0.0313, -0.0357, -0.0032,  0.0129,\n",
      "         0.0093, -0.0272,  0.0358, -0.0327, -0.0298, -0.0157, -0.0072, -0.0041,\n",
      "         0.0084,  0.0010, -0.0145,  0.0094,  0.0101, -0.0320, -0.0358, -0.0303,\n",
      "         0.0115, -0.0057,  0.0117,  0.0127, -0.0155, -0.0146, -0.0079,  0.0203,\n",
      "        -0.0268, -0.0354, -0.0306,  0.0120,  0.0106,  0.0181,  0.0047, -0.0040,\n",
      "         0.0060, -0.0115, -0.0186, -0.0239,  0.0130, -0.0298, -0.0320, -0.0013,\n",
      "         0.0236, -0.0266,  0.0289,  0.0355, -0.0100, -0.0312, -0.0248,  0.0025,\n",
      "         0.0273, -0.0150,  0.0136,  0.0049, -0.0106, -0.0080,  0.0106,  0.0251,\n",
      "        -0.0161,  0.0240,  0.0210, -0.0283,  0.0113, -0.0236, -0.0307, -0.0027,\n",
      "        -0.0280,  0.0052,  0.0201, -0.0258,  0.0040,  0.0265,  0.0185,  0.0081,\n",
      "        -0.0233,  0.0155, -0.0056, -0.0237, -0.0116,  0.0018,  0.0341,  0.0296,\n",
      "         0.0068,  0.0067,  0.0200, -0.0035, -0.0333,  0.0190, -0.0217,  0.0311,\n",
      "         0.0017,  0.0076, -0.0168,  0.0350, -0.0286,  0.0278,  0.0226,  0.0228,\n",
      "        -0.0050, -0.0016,  0.0310, -0.0066,  0.0223, -0.0311, -0.0188, -0.0204],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0199, -0.0027, -0.0025,  ..., -0.0221, -0.0094, -0.0104],\n",
      "        [ 0.0068, -0.0313, -0.0132,  ..., -0.0304,  0.0314,  0.0091],\n",
      "        [-0.0090, -0.0323,  0.0330,  ...,  0.0258,  0.0164, -0.0025],\n",
      "        ...,\n",
      "        [-0.0333, -0.0195, -0.0058,  ...,  0.0114, -0.0063,  0.0201],\n",
      "        [ 0.0318, -0.0162,  0.0090,  ...,  0.0196, -0.0295,  0.0139],\n",
      "        [ 0.0043,  0.0344, -0.0260,  ...,  0.0154, -0.0252,  0.0187]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0199,  0.0227,  0.0176,  ...,  0.0049, -0.0205, -0.0119],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0176, -0.0101, -0.0100,  ..., -0.0102,  0.0113,  0.0178],\n",
      "        [ 0.0016, -0.0162,  0.0112,  ...,  0.0071, -0.0009, -0.0135],\n",
      "        [ 0.0102, -0.0115, -0.0160,  ..., -0.0037, -0.0108, -0.0023],\n",
      "        ...,\n",
      "        [ 0.0069, -0.0013,  0.0010,  ..., -0.0082, -0.0028, -0.0067],\n",
      "        [-0.0178, -0.0106, -0.0039,  ...,  0.0126, -0.0172,  0.0114],\n",
      "        [ 0.0095, -0.0141, -0.0047,  ...,  0.0160,  0.0043,  0.0007]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([    -0.0077,     -0.0104,     -0.0029,      0.0008,     -0.0094,\n",
      "            -0.0034,      0.0166,     -0.0102,     -0.0049,      0.0056,\n",
      "             0.0124,     -0.0022,      0.0144,      0.0019,      0.0104,\n",
      "             0.0099,     -0.0034,     -0.0005,     -0.0138,     -0.0058,\n",
      "             0.0063,      0.0024,     -0.0023,      0.0100,      0.0100,\n",
      "            -0.0053,      0.0082,     -0.0176,     -0.0068,      0.0130,\n",
      "             0.0160,      0.0039,      0.0177,      0.0127,      0.0140,\n",
      "            -0.0037,      0.0032,      0.0060,      0.0180,      0.0131,\n",
      "            -0.0081,     -0.0086,      0.0146,     -0.0060,      0.0051,\n",
      "             0.0147,      0.0179,     -0.0059,     -0.0063,      0.0131,\n",
      "            -0.0085,     -0.0101,      0.0029,     -0.0032,     -0.0079,\n",
      "             0.0022,     -0.0126,      0.0095,      0.0173,      0.0042,\n",
      "             0.0063,      0.0177,     -0.0128,      0.0163,     -0.0161,\n",
      "             0.0018,      0.0092,     -0.0154,      0.0143,     -0.0029,\n",
      "            -0.0087,     -0.0011,      0.0031,      0.0075,     -0.0169,\n",
      "            -0.0147,      0.0003,      0.0093,     -0.0133,      0.0013,\n",
      "             0.0089,      0.0168,     -0.0108,      0.0125,      0.0126,\n",
      "            -0.0003,      0.0064,     -0.0019,     -0.0029,     -0.0009,\n",
      "             0.0055,     -0.0135,      0.0062,      0.0075,     -0.0028,\n",
      "             0.0133,      0.0049,     -0.0118,     -0.0034,     -0.0097,\n",
      "            -0.0020,      0.0133,     -0.0168,     -0.0127,     -0.0059,\n",
      "             0.0015,     -0.0004,      0.0139,     -0.0114,     -0.0014,\n",
      "            -0.0139,     -0.0097,     -0.0148,      0.0013,      0.0144,\n",
      "            -0.0020,      0.0161,      0.0091,     -0.0005,      0.0075,\n",
      "             0.0052,      0.0048,      0.0090,      0.0110,     -0.0056,\n",
      "            -0.0049,     -0.0057,      0.0126,     -0.0053,     -0.0003,\n",
      "            -0.0164,     -0.0154,      0.0149,     -0.0062,     -0.0145,\n",
      "            -0.0076,      0.0007,     -0.0114,     -0.0113,      0.0025,\n",
      "            -0.0044,      0.0158,      0.0151,      0.0139,      0.0159,\n",
      "             0.0140,      0.0117,      0.0138,      0.0073,     -0.0119,\n",
      "            -0.0005,      0.0020,     -0.0159,      0.0124,     -0.0051,\n",
      "            -0.0180,     -0.0150,     -0.0045,     -0.0002,      0.0040,\n",
      "            -0.0038,     -0.0006,     -0.0168,      0.0111,      0.0007,\n",
      "             0.0057,      0.0040,      0.0065,     -0.0165,     -0.0037,\n",
      "             0.0159,      0.0101,      0.0076,     -0.0122,     -0.0145,\n",
      "             0.0147,      0.0150,     -0.0178,     -0.0165,      0.0106,\n",
      "             0.0143,      0.0096,      0.0075,      0.0141,     -0.0140,\n",
      "            -0.0114,     -0.0046,      0.0173,     -0.0054,     -0.0098,\n",
      "             0.0136,      0.0043,     -0.0036,      0.0153,     -0.0046,\n",
      "            -0.0163,      0.0086,     -0.0095,      0.0124,     -0.0061,\n",
      "             0.0036,     -0.0003,     -0.0150,      0.0150,      0.0091,\n",
      "             0.0123,     -0.0091,      0.0039,     -0.0014,      0.0087,\n",
      "            -0.0009,     -0.0054,      0.0088,     -0.0081,     -0.0039,\n",
      "             0.0091,     -0.0011,     -0.0043,     -0.0086,      0.0117,\n",
      "             0.0108,      0.0114,      0.0064,     -0.0146,      0.0019,\n",
      "            -0.0071,      0.0105,     -0.0047,     -0.0172,      0.0031,\n",
      "             0.0079,     -0.0093,      0.0178,      0.0177,      0.0052,\n",
      "             0.0166,      0.0027,     -0.0037,      0.0074,     -0.0033,\n",
      "            -0.0128,     -0.0174,     -0.0171,     -0.0110,     -0.0076,\n",
      "            -0.0137,     -0.0061,     -0.0157,      0.0012,      0.0130,\n",
      "             0.0004,     -0.0119,     -0.0031,      0.0035,     -0.0028,\n",
      "            -0.0148,      0.0176,     -0.0119,      0.0065,      0.0117,\n",
      "            -0.0060,     -0.0128,     -0.0000,     -0.0137,      0.0170,\n",
      "            -0.0104,      0.0041,      0.0046,      0.0110,     -0.0039,\n",
      "            -0.0127,      0.0061,      0.0158,     -0.0125,     -0.0144,\n",
      "            -0.0129,      0.0168,     -0.0150,      0.0084,     -0.0149,\n",
      "             0.0033,      0.0102,      0.0135,      0.0070,     -0.0079,\n",
      "            -0.0050,     -0.0149,      0.0141,     -0.0053,      0.0110,\n",
      "            -0.0107,     -0.0024,     -0.0021,     -0.0169,      0.0004,\n",
      "             0.0019,      0.0067,     -0.0177,     -0.0097,      0.0051,\n",
      "            -0.0127,      0.0144,     -0.0015,      0.0172,      0.0118,\n",
      "             0.0061,      0.0154,      0.0031,      0.0093,      0.0122,\n",
      "             0.0018,      0.0064,      0.0060,     -0.0155,     -0.0099,\n",
      "             0.0136,      0.0100,      0.0006,      0.0046,     -0.0059,\n",
      "            -0.0160,     -0.0121,     -0.0094,     -0.0083,     -0.0102,\n",
      "            -0.0068,     -0.0081,     -0.0025,      0.0152,     -0.0061,\n",
      "            -0.0080,      0.0034,      0.0035,      0.0011,      0.0097,\n",
      "             0.0043,      0.0107,      0.0105,      0.0110,     -0.0040,\n",
      "             0.0145,     -0.0143,      0.0159,     -0.0150,      0.0082,\n",
      "             0.0015,      0.0167,      0.0093,      0.0153,     -0.0038,\n",
      "            -0.0076,      0.0015,     -0.0102,     -0.0147,     -0.0177,\n",
      "            -0.0135,     -0.0082,      0.0159,     -0.0036,      0.0154,\n",
      "            -0.0045,     -0.0049,      0.0114,     -0.0157,     -0.0088,\n",
      "            -0.0056,      0.0168,     -0.0150,     -0.0161,     -0.0077,\n",
      "             0.0079,     -0.0037,     -0.0126,     -0.0051,      0.0034,\n",
      "             0.0105,     -0.0039,     -0.0113,      0.0086,      0.0018,\n",
      "            -0.0041,     -0.0020,      0.0099,      0.0043,     -0.0105,\n",
      "             0.0082,     -0.0080,      0.0159,      0.0037,     -0.0041,\n",
      "             0.0020,      0.0057,      0.0047,      0.0125,     -0.0094,\n",
      "            -0.0021,      0.0164,     -0.0142,      0.0092,      0.0083,\n",
      "            -0.0072,      0.0158,     -0.0140,     -0.0167,     -0.0126,\n",
      "             0.0180,     -0.0038,     -0.0159,     -0.0013,     -0.0069,\n",
      "             0.0150,      0.0070,      0.0036,      0.0144,      0.0089,\n",
      "            -0.0091,     -0.0088,      0.0017,      0.0005,      0.0105,\n",
      "            -0.0070,      0.0049,      0.0037,     -0.0130,      0.0099,\n",
      "             0.0005,     -0.0093,      0.0004,     -0.0083,      0.0119,\n",
      "            -0.0067,      0.0171,     -0.0049,     -0.0126,      0.0137,\n",
      "             0.0074,      0.0148,      0.0051,      0.0128,     -0.0054,\n",
      "             0.0033,      0.0042,      0.0043,      0.0121,     -0.0174,\n",
      "            -0.0005,     -0.0020,     -0.0026,     -0.0014,     -0.0168,\n",
      "            -0.0034,     -0.0126,      0.0031,     -0.0094,      0.0070,\n",
      "            -0.0024,     -0.0092,     -0.0170,     -0.0027,     -0.0077,\n",
      "            -0.0071,     -0.0064,     -0.0016,      0.0070,     -0.0107,\n",
      "            -0.0131,      0.0052,      0.0094,     -0.0133,      0.0042,\n",
      "            -0.0171,      0.0031,     -0.0110,      0.0047,     -0.0126,\n",
      "            -0.0072,     -0.0107,      0.0136,      0.0060,     -0.0087,\n",
      "             0.0068,     -0.0101,     -0.0146,     -0.0154,      0.0079,\n",
      "             0.0006,     -0.0030,      0.0068,     -0.0044,     -0.0063,\n",
      "             0.0072,      0.0105,      0.0084,      0.0142,     -0.0045,\n",
      "            -0.0024,      0.0009,      0.0172,     -0.0025,     -0.0053,\n",
      "            -0.0012,     -0.0046,      0.0118,      0.0000,     -0.0065,\n",
      "             0.0104,     -0.0068,     -0.0106,     -0.0109,      0.0110,\n",
      "            -0.0046,     -0.0158,      0.0071,     -0.0133,     -0.0171,\n",
      "            -0.0046,      0.0155,     -0.0051,      0.0063,      0.0008,\n",
      "             0.0176,      0.0135,      0.0003,     -0.0120,      0.0156,\n",
      "             0.0072,      0.0148,      0.0021,      0.0065,      0.0101,\n",
      "             0.0169,     -0.0020,      0.0089,     -0.0058,     -0.0100,\n",
      "             0.0143,     -0.0154,     -0.0128,      0.0154,     -0.0149,\n",
      "             0.0018,      0.0101,      0.0078,      0.0137,     -0.0068,\n",
      "             0.0172,      0.0136,     -0.0137,      0.0078,     -0.0024,\n",
      "             0.0086,     -0.0025,     -0.0164,     -0.0089,     -0.0047,\n",
      "             0.0076,      0.0107,      0.0154,      0.0025,      0.0119,\n",
      "             0.0126,     -0.0169,     -0.0053,     -0.0061,      0.0069,\n",
      "             0.0161,      0.0176,     -0.0020,      0.0007,     -0.0145,\n",
      "            -0.0134,      0.0179,      0.0115,     -0.0084,     -0.0135,\n",
      "            -0.0019,      0.0144,      0.0021,     -0.0075,     -0.0144,\n",
      "            -0.0068,      0.0026,      0.0039,     -0.0103,     -0.0136,\n",
      "             0.0034,      0.0022,     -0.0056,      0.0158,      0.0020,\n",
      "            -0.0059,      0.0017,     -0.0151,      0.0028,      0.0133,\n",
      "             0.0030,      0.0165,     -0.0121,      0.0171,      0.0152,\n",
      "             0.0152,     -0.0001,      0.0149,     -0.0085,      0.0091,\n",
      "            -0.0025,      0.0092,      0.0075,     -0.0033,     -0.0150,\n",
      "            -0.0026,     -0.0106,      0.0137,     -0.0126,     -0.0116,\n",
      "            -0.0150,      0.0054,      0.0038,     -0.0042,      0.0147,\n",
      "            -0.0139,     -0.0081,     -0.0055,      0.0126,     -0.0011,\n",
      "            -0.0012,     -0.0035,     -0.0015,      0.0017,      0.0103,\n",
      "            -0.0028,      0.0131,      0.0059,     -0.0110,     -0.0096,\n",
      "            -0.0177,      0.0175,      0.0176,     -0.0093,     -0.0173,\n",
      "            -0.0167,     -0.0116,     -0.0149,     -0.0008,     -0.0087,\n",
      "            -0.0177,     -0.0052,     -0.0146,     -0.0172,     -0.0115,\n",
      "            -0.0123,      0.0133,      0.0175,     -0.0163,     -0.0089,\n",
      "            -0.0107,     -0.0116,     -0.0108,     -0.0075,      0.0117,\n",
      "            -0.0109,     -0.0063,      0.0053,      0.0057,      0.0118,\n",
      "            -0.0158,     -0.0112,      0.0142,      0.0104,     -0.0112,\n",
      "             0.0089,     -0.0041,     -0.0178,      0.0010,      0.0179,\n",
      "            -0.0050,     -0.0079,     -0.0051,     -0.0111,     -0.0054,\n",
      "             0.0133,      0.0167,      0.0053,     -0.0085,     -0.0007,\n",
      "            -0.0109,      0.0081,     -0.0169,      0.0128,     -0.0104,\n",
      "             0.0177,      0.0034,      0.0066,     -0.0136,      0.0170,\n",
      "             0.0034,      0.0045,     -0.0117,      0.0034,      0.0166,\n",
      "             0.0147,     -0.0096,     -0.0125,      0.0122,     -0.0056,\n",
      "            -0.0107,     -0.0130,      0.0040,     -0.0103,     -0.0163,\n",
      "             0.0045,      0.0174,     -0.0079,      0.0154,     -0.0134,\n",
      "             0.0105,     -0.0055,     -0.0083,      0.0077,     -0.0091,\n",
      "             0.0024,      0.0017,     -0.0005,     -0.0036,      0.0012,\n",
      "             0.0172,      0.0176,     -0.0163,      0.0062,     -0.0061,\n",
      "            -0.0150,     -0.0061,     -0.0014,     -0.0145,     -0.0051,\n",
      "             0.0020,      0.0018,      0.0149,      0.0136,     -0.0084,\n",
      "            -0.0028,      0.0136,      0.0001,      0.0167,     -0.0006,\n",
      "             0.0180,     -0.0099,      0.0041,      0.0072,     -0.0066,\n",
      "             0.0048,     -0.0137,      0.0113,     -0.0061,      0.0008,\n",
      "             0.0089,     -0.0165,      0.0043,     -0.0180,     -0.0175,\n",
      "             0.0075,      0.0113,     -0.0021,      0.0092,      0.0077,\n",
      "            -0.0143,     -0.0166,     -0.0163], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0318, -0.0360,  0.0020,  ..., -0.0179, -0.0236, -0.0007],\n",
      "        [-0.0314,  0.0324,  0.0184,  ..., -0.0294,  0.0080,  0.0275],\n",
      "        [ 0.0159,  0.0108, -0.0222,  ..., -0.0333, -0.0229, -0.0081],\n",
      "        ...,\n",
      "        [ 0.0250, -0.0020,  0.0126,  ...,  0.0099, -0.0288,  0.0060],\n",
      "        [-0.0218, -0.0048, -0.0208,  ..., -0.0045,  0.0266,  0.0293],\n",
      "        [ 0.0008, -0.0229,  0.0094,  ..., -0.0355,  0.0149, -0.0192]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0346,  0.0253, -0.0056,  ...,  0.0084, -0.0346, -0.0319],\n",
      "        [ 0.0311,  0.0109,  0.0081,  ..., -0.0276, -0.0269,  0.0244],\n",
      "        [-0.0347,  0.0266,  0.0223,  ...,  0.0005,  0.0310, -0.0236],\n",
      "        ...,\n",
      "        [-0.0275,  0.0096,  0.0169,  ..., -0.0354,  0.0091, -0.0316],\n",
      "        [-0.0346,  0.0233, -0.0132,  ..., -0.0160, -0.0359,  0.0149],\n",
      "        [-0.0147,  0.0121, -0.0346,  ...,  0.0226, -0.0152, -0.0358]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0142,  0.0096, -0.0290,  ..., -0.0131, -0.0235,  0.0133],\n",
      "        [ 0.0135, -0.0167, -0.0347,  ...,  0.0005,  0.0301, -0.0335],\n",
      "        [ 0.0339,  0.0040, -0.0228,  ...,  0.0255, -0.0032, -0.0199],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0222, -0.0342,  ..., -0.0193, -0.0161,  0.0183],\n",
      "        [-0.0079, -0.0198, -0.0243,  ...,  0.0118,  0.0032, -0.0105],\n",
      "        [ 0.0285, -0.0048,  0.0303,  ..., -0.0187, -0.0326,  0.0280]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0095,  0.0250,  0.0091,  ..., -0.0101, -0.0047, -0.0075],\n",
      "        [ 0.0204,  0.0088,  0.0360,  ...,  0.0338, -0.0221, -0.0105],\n",
      "        [ 0.0350,  0.0162,  0.0077,  ..., -0.0237,  0.0133, -0.0238],\n",
      "        ...,\n",
      "        [-0.0194, -0.0019, -0.0125,  ...,  0.0318,  0.0120,  0.0308],\n",
      "        [ 0.0037, -0.0058, -0.0021,  ..., -0.0273,  0.0116,  0.0055],\n",
      "        [-0.0142, -0.0267, -0.0324,  ...,  0.0268,  0.0009,  0.0216]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([    -0.0061,     -0.0199,      0.0160,     -0.0322,     -0.0172,\n",
      "            -0.0127,     -0.0000,      0.0077,     -0.0273,      0.0088,\n",
      "             0.0250,     -0.0277,      0.0178,      0.0298,     -0.0019,\n",
      "             0.0102,      0.0148,     -0.0141,     -0.0160,     -0.0268,\n",
      "             0.0114,     -0.0141,      0.0009,     -0.0144,      0.0202,\n",
      "            -0.0284,      0.0224,     -0.0166,      0.0030,      0.0240,\n",
      "            -0.0170,      0.0296,      0.0103,     -0.0062,     -0.0277,\n",
      "            -0.0035,      0.0079,     -0.0151,     -0.0125,      0.0023,\n",
      "             0.0221,     -0.0201,     -0.0263,      0.0126,     -0.0056,\n",
      "             0.0264,     -0.0020,     -0.0310,     -0.0277,     -0.0258,\n",
      "             0.0163,      0.0355,     -0.0184,      0.0293,     -0.0019,\n",
      "            -0.0106,      0.0138,     -0.0344,     -0.0132,     -0.0106,\n",
      "            -0.0121,     -0.0048,      0.0354,     -0.0039,      0.0336,\n",
      "            -0.0073,      0.0349,     -0.0076,      0.0248,     -0.0030,\n",
      "            -0.0318,     -0.0249,      0.0081,      0.0157,     -0.0073,\n",
      "             0.0304,     -0.0147,      0.0045,      0.0319,      0.0358,\n",
      "            -0.0200,      0.0217,      0.0344,     -0.0242,      0.0346,\n",
      "             0.0040,     -0.0276,      0.0124,      0.0239,     -0.0186,\n",
      "             0.0223,     -0.0079,      0.0302,     -0.0009,      0.0020,\n",
      "            -0.0358,     -0.0248,      0.0115,     -0.0275,      0.0144,\n",
      "            -0.0023,      0.0061,     -0.0257,      0.0278,     -0.0271,\n",
      "            -0.0066,     -0.0331,     -0.0172,     -0.0064,     -0.0028,\n",
      "            -0.0288,     -0.0088,      0.0298,     -0.0344,      0.0073,\n",
      "            -0.0350,     -0.0163,      0.0206,      0.0176,     -0.0087,\n",
      "            -0.0281,     -0.0294,      0.0344,     -0.0071,     -0.0335,\n",
      "             0.0011,      0.0128,      0.0326,     -0.0311,      0.0301,\n",
      "             0.0125,      0.0262,      0.0345,     -0.0020,     -0.0152,\n",
      "             0.0124,      0.0149,     -0.0273,      0.0241,      0.0051,\n",
      "            -0.0103,     -0.0268,     -0.0254,      0.0234,     -0.0262,\n",
      "             0.0044,     -0.0301,      0.0197,     -0.0241,     -0.0167,\n",
      "            -0.0093,      0.0265,      0.0254,     -0.0269,      0.0049,\n",
      "            -0.0034,      0.0280,      0.0024,     -0.0077,      0.0224,\n",
      "            -0.0328,      0.0305,      0.0275,      0.0341,     -0.0293,\n",
      "            -0.0241,     -0.0118,     -0.0112,     -0.0283,     -0.0118,\n",
      "            -0.0065,     -0.0036,     -0.0051,     -0.0316,     -0.0028,\n",
      "             0.0152,      0.0203,      0.0236,     -0.0176,      0.0161,\n",
      "            -0.0159,     -0.0294,      0.0356,     -0.0038,     -0.0156,\n",
      "            -0.0340,      0.0161,      0.0029,     -0.0261,      0.0332,\n",
      "             0.0022,     -0.0193,      0.0137,     -0.0155,      0.0169,\n",
      "            -0.0030,     -0.0327,      0.0217,      0.0209,     -0.0331,\n",
      "            -0.0068,      0.0247,     -0.0009,      0.0330,      0.0148,\n",
      "             0.0287,      0.0042,      0.0241,      0.0233,     -0.0204,\n",
      "             0.0057,      0.0320,      0.0323,      0.0272,      0.0048,\n",
      "             0.0234,      0.0064,     -0.0052,     -0.0204,      0.0143,\n",
      "             0.0107,      0.0157,      0.0194,     -0.0002,      0.0297,\n",
      "            -0.0143,     -0.0261,     -0.0238,     -0.0199,     -0.0151,\n",
      "            -0.0082,      0.0050,      0.0241,      0.0003,     -0.0214,\n",
      "            -0.0142,      0.0281,     -0.0001,     -0.0120,     -0.0237,\n",
      "             0.0167,     -0.0005,     -0.0034,     -0.0019,     -0.0116,\n",
      "            -0.0290,      0.0297,     -0.0027,     -0.0084,      0.0022,\n",
      "            -0.0353,     -0.0049,      0.0285,     -0.0250,      0.0279,\n",
      "            -0.0097,     -0.0182,      0.0292,     -0.0148,     -0.0295,\n",
      "            -0.0005,      0.0068,     -0.0346,      0.0117,      0.0200,\n",
      "             0.0295,      0.0305,     -0.0076,      0.0258,      0.0225,\n",
      "             0.0077,      0.0136,     -0.0270,     -0.0295,      0.0358,\n",
      "            -0.0356,     -0.0326,      0.0022,     -0.0180,      0.0007,\n",
      "            -0.0190,     -0.0198,     -0.0051,     -0.0298,      0.0273,\n",
      "             0.0062,     -0.0105,      0.0173,      0.0336,     -0.0144,\n",
      "            -0.0059,      0.0281,      0.0214,      0.0230,      0.0208,\n",
      "             0.0016,      0.0262,      0.0229,      0.0220,     -0.0202,\n",
      "            -0.0076,      0.0065,      0.0077,      0.0209,     -0.0039,\n",
      "             0.0361,      0.0075,     -0.0062,      0.0309,     -0.0253,\n",
      "             0.0185,      0.0141,      0.0049,      0.0210,     -0.0354,\n",
      "             0.0238,     -0.0116,      0.0334,     -0.0065,     -0.0257,\n",
      "            -0.0182,      0.0105,      0.0154,     -0.0008,     -0.0233,\n",
      "            -0.0284,     -0.0269,      0.0208,      0.0004,     -0.0271,\n",
      "             0.0115,     -0.0035,     -0.0116,     -0.0232,      0.0132,\n",
      "             0.0267,     -0.0027,     -0.0240,      0.0044,      0.0234,\n",
      "            -0.0172,     -0.0027,     -0.0206,      0.0233,     -0.0353,\n",
      "            -0.0182,     -0.0338,      0.0242,     -0.0245,      0.0100,\n",
      "             0.0178,     -0.0060,      0.0038,      0.0288,     -0.0054,\n",
      "            -0.0191,      0.0020,      0.0290,     -0.0327,     -0.0072,\n",
      "            -0.0155,      0.0284,      0.0322,     -0.0065,      0.0282,\n",
      "            -0.0128,      0.0181,      0.0073,      0.0163,     -0.0218,\n",
      "             0.0100,     -0.0093,     -0.0149,      0.0252,      0.0087,\n",
      "             0.0085,     -0.0251,      0.0142,      0.0130,     -0.0295,\n",
      "             0.0308,      0.0113,      0.0233,      0.0330,     -0.0087,\n",
      "            -0.0277,     -0.0230,     -0.0255,      0.0334,     -0.0199,\n",
      "             0.0103,      0.0233,      0.0160,     -0.0357,     -0.0265,\n",
      "             0.0014,      0.0327,      0.0234,      0.0162,     -0.0101,\n",
      "             0.0009,     -0.0108,      0.0177,      0.0059,      0.0242,\n",
      "             0.0101,     -0.0185,      0.0050,      0.0249,     -0.0121,\n",
      "            -0.0240,     -0.0325,      0.0041,     -0.0181,      0.0123,\n",
      "            -0.0198,      0.0067,      0.0278,     -0.0356,      0.0184,\n",
      "            -0.0127,      0.0003,     -0.0284,     -0.0226,     -0.0300,\n",
      "             0.0036,     -0.0300,      0.0300,      0.0006,     -0.0258,\n",
      "             0.0195,     -0.0268,     -0.0336,     -0.0125,      0.0155,\n",
      "             0.0031,     -0.0001,      0.0022,     -0.0135,     -0.0123,\n",
      "             0.0174,     -0.0273,      0.0049,      0.0302,     -0.0355,\n",
      "            -0.0061,      0.0250,      0.0295,     -0.0334,     -0.0261,\n",
      "             0.0235,     -0.0088,     -0.0295,      0.0209,      0.0335,\n",
      "             0.0087,      0.0001,     -0.0173,     -0.0357,     -0.0314,\n",
      "             0.0306,     -0.0034,     -0.0248,     -0.0064,      0.0221,\n",
      "             0.0342,     -0.0186,     -0.0067,     -0.0258,      0.0339,\n",
      "            -0.0145,      0.0328,     -0.0141,      0.0022,     -0.0139,\n",
      "             0.0089,     -0.0284,      0.0284,     -0.0007,      0.0236,\n",
      "             0.0080,      0.0218,      0.0334,      0.0140,      0.0285,\n",
      "            -0.0195,      0.0064,      0.0355,      0.0357,      0.0240,\n",
      "            -0.0340,      0.0207,      0.0226,     -0.0204,     -0.0083,\n",
      "             0.0097,      0.0325,      0.0163,     -0.0281,     -0.0349,\n",
      "            -0.0171,      0.0252,     -0.0269,      0.0332,      0.0188,\n",
      "            -0.0279,     -0.0140,      0.0096,     -0.0161,      0.0169,\n",
      "            -0.0344,     -0.0313,      0.0293,     -0.0174,      0.0180,\n",
      "            -0.0267,     -0.0209,      0.0272,      0.0336,     -0.0279,\n",
      "             0.0321,      0.0311,      0.0087,     -0.0007,      0.0313,\n",
      "             0.0134,     -0.0119,      0.0249,      0.0226,      0.0349,\n",
      "            -0.0355,     -0.0112,      0.0208,     -0.0299,     -0.0308,\n",
      "             0.0150,     -0.0112,      0.0354,     -0.0097,      0.0012,\n",
      "            -0.0156,     -0.0002,     -0.0070,      0.0092,     -0.0155,\n",
      "            -0.0204,      0.0341,     -0.0074,     -0.0307,     -0.0002,\n",
      "             0.0135,     -0.0065,     -0.0149,     -0.0264,     -0.0248,\n",
      "            -0.0052,     -0.0195,     -0.0289,     -0.0233,     -0.0266,\n",
      "            -0.0110,      0.0287,     -0.0092,      0.0347,      0.0329,\n",
      "            -0.0089,      0.0166,     -0.0072,     -0.0066,      0.0151,\n",
      "             0.0199,     -0.0346,      0.0145,     -0.0038,      0.0001,\n",
      "             0.0326,      0.0102,      0.0260,     -0.0073,     -0.0234,\n",
      "            -0.0306,     -0.0251,     -0.0169,     -0.0015,      0.0152,\n",
      "             0.0246,      0.0115,      0.0352,      0.0149,      0.0269,\n",
      "            -0.0193,     -0.0067,      0.0216,      0.0013,      0.0221,\n",
      "            -0.0320,      0.0253,      0.0241,     -0.0113,      0.0331,\n",
      "            -0.0296,      0.0287,     -0.0215,      0.0358,     -0.0266,\n",
      "            -0.0303,     -0.0167,      0.0203,     -0.0220,     -0.0179,\n",
      "            -0.0181,     -0.0011,     -0.0021,      0.0148,      0.0133,\n",
      "            -0.0256,     -0.0151,     -0.0141,      0.0271,     -0.0114,\n",
      "            -0.0101,      0.0134,     -0.0277,     -0.0010,     -0.0111,\n",
      "             0.0050,     -0.0039,     -0.0070,     -0.0224,      0.0093,\n",
      "            -0.0143,     -0.0355,     -0.0100,      0.0275,     -0.0097,\n",
      "             0.0349,     -0.0009,      0.0004,     -0.0089,      0.0359,\n",
      "             0.0316,     -0.0337,     -0.0287,      0.0119,     -0.0188,\n",
      "            -0.0049,      0.0136,      0.0053,      0.0340,      0.0127,\n",
      "             0.0133,      0.0066,      0.0197,      0.0076,      0.0021,\n",
      "             0.0348,     -0.0343,     -0.0307,      0.0216,     -0.0110,\n",
      "            -0.0147,      0.0062,     -0.0042,      0.0263,     -0.0195,\n",
      "             0.0185,      0.0323,     -0.0158,     -0.0096,     -0.0341,\n",
      "            -0.0314,      0.0034,      0.0328,     -0.0184,      0.0088,\n",
      "            -0.0255,     -0.0272,      0.0206,      0.0142,      0.0148,\n",
      "            -0.0108,      0.0014,     -0.0242,     -0.0080,     -0.0241,\n",
      "             0.0317,      0.0075,      0.0243,      0.0167,     -0.0170,\n",
      "            -0.0190,     -0.0341,      0.0288,      0.0232,      0.0263,\n",
      "            -0.0242,     -0.0158,      0.0045,     -0.0210,      0.0109,\n",
      "             0.0132,      0.0039,      0.0043,      0.0026,     -0.0212,\n",
      "             0.0056,     -0.0208,      0.0058,      0.0346,     -0.0321,\n",
      "            -0.0286,      0.0289,      0.0237,      0.0269,      0.0168,\n",
      "            -0.0204,      0.0228,     -0.0145,     -0.0199,     -0.0021,\n",
      "             0.0228,     -0.0328,     -0.0290,      0.0248,     -0.0331,\n",
      "             0.0184,     -0.0328,      0.0178,     -0.0246,     -0.0344,\n",
      "             0.0231,      0.0204,      0.0027,     -0.0151,     -0.0314,\n",
      "             0.0346,     -0.0298,     -0.0153,      0.0158,     -0.0045,\n",
      "             0.0087,      0.0070,     -0.0312,      0.0066,      0.0338,\n",
      "             0.0001,     -0.0138,      0.0029,     -0.0199,      0.0295,\n",
      "            -0.0054,      0.0069,      0.0136,      0.0039,      0.0048,\n",
      "            -0.0141,      0.0244,     -0.0300,     -0.0116,     -0.0067,\n",
      "             0.0321,      0.0277,      0.0155,      0.0055,      0.0329,\n",
      "            -0.0286,     -0.0234,     -0.0203], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0001,  0.0220, -0.0243,  ..., -0.0200,  0.0341,  0.0035],\n",
      "        [-0.0248, -0.0206,  0.0106,  ..., -0.0289,  0.0077,  0.0238],\n",
      "        [-0.0283,  0.0302, -0.0076,  ...,  0.0275,  0.0087,  0.0319],\n",
      "        ...,\n",
      "        [ 0.0130, -0.0357,  0.0189,  ..., -0.0339, -0.0217, -0.0200],\n",
      "        [-0.0086, -0.0047, -0.0333,  ...,  0.0141, -0.0209, -0.0149],\n",
      "        [-0.0343, -0.0340, -0.0069,  ..., -0.0112, -0.0006,  0.0087]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0202, -0.0298, -0.0217,  ...,  0.0082,  0.0255, -0.0197],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0014, -0.0175, -0.0011,  ..., -0.0106,  0.0156, -0.0059],\n",
      "        [-0.0166, -0.0157,  0.0110,  ..., -0.0051,  0.0030, -0.0142],\n",
      "        [-0.0023,  0.0043,  0.0088,  ...,  0.0033, -0.0108, -0.0003],\n",
      "        ...,\n",
      "        [-0.0116,  0.0129, -0.0147,  ..., -0.0002, -0.0136,  0.0006],\n",
      "        [ 0.0093,  0.0174,  0.0133,  ...,  0.0017,  0.0013,  0.0078],\n",
      "        [ 0.0025, -0.0006,  0.0080,  ..., -0.0093, -0.0074,  0.0170]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([    -0.0156,      0.0118,     -0.0120,      0.0126,     -0.0029,\n",
      "             0.0093,      0.0093,      0.0121,      0.0180,      0.0005,\n",
      "            -0.0052,     -0.0133,     -0.0105,     -0.0153,     -0.0159,\n",
      "             0.0142,     -0.0085,      0.0111,     -0.0143,     -0.0062,\n",
      "            -0.0111,     -0.0081,     -0.0089,      0.0169,      0.0099,\n",
      "             0.0070,     -0.0121,      0.0051,      0.0029,      0.0124,\n",
      "             0.0144,     -0.0000,      0.0013,     -0.0055,      0.0136,\n",
      "            -0.0004,      0.0033,     -0.0054,      0.0086,     -0.0084,\n",
      "            -0.0055,      0.0111,      0.0015,     -0.0138,      0.0005,\n",
      "            -0.0115,     -0.0175,      0.0135,     -0.0076,     -0.0099,\n",
      "            -0.0101,      0.0151,      0.0093,      0.0028,      0.0045,\n",
      "            -0.0123,     -0.0009,     -0.0159,      0.0119,      0.0066,\n",
      "             0.0077,      0.0143,      0.0003,     -0.0036,      0.0096,\n",
      "            -0.0030,     -0.0002,     -0.0167,     -0.0032,      0.0005,\n",
      "            -0.0112,      0.0069,     -0.0051,      0.0055,     -0.0108,\n",
      "            -0.0026,      0.0154,      0.0069,     -0.0112,     -0.0142,\n",
      "             0.0099,      0.0063,      0.0066,      0.0172,      0.0168,\n",
      "            -0.0154,      0.0174,     -0.0113,      0.0049,      0.0168,\n",
      "            -0.0043,     -0.0147,      0.0135,     -0.0100,     -0.0074,\n",
      "            -0.0093,      0.0002,     -0.0032,     -0.0125,     -0.0153,\n",
      "             0.0137,     -0.0089,     -0.0084,      0.0133,      0.0152,\n",
      "             0.0179,      0.0034,      0.0172,      0.0118,      0.0180,\n",
      "            -0.0106,      0.0053,      0.0027,     -0.0053,      0.0107,\n",
      "             0.0117,      0.0018,      0.0082,      0.0108,      0.0120,\n",
      "            -0.0168,     -0.0158,      0.0085,      0.0101,     -0.0037,\n",
      "             0.0144,      0.0093,     -0.0101,      0.0109,      0.0038,\n",
      "             0.0017,      0.0123,      0.0127,      0.0151,      0.0093,\n",
      "             0.0114,     -0.0109,      0.0095,     -0.0065,     -0.0002,\n",
      "            -0.0062,      0.0043,      0.0053,      0.0162,     -0.0169,\n",
      "            -0.0051,      0.0125,     -0.0156,     -0.0117,      0.0101,\n",
      "             0.0046,      0.0152,      0.0015,     -0.0121,     -0.0069,\n",
      "             0.0164,     -0.0018,     -0.0082,     -0.0152,      0.0008,\n",
      "            -0.0066,      0.0101,     -0.0020,     -0.0067,     -0.0075,\n",
      "            -0.0171,     -0.0083,     -0.0132,     -0.0162,     -0.0133,\n",
      "             0.0071,      0.0130,     -0.0097,      0.0155,     -0.0171,\n",
      "            -0.0095,      0.0036,     -0.0005,      0.0054,     -0.0069,\n",
      "            -0.0017,      0.0116,      0.0093,      0.0054,     -0.0070,\n",
      "             0.0004,     -0.0106,      0.0056,     -0.0106,      0.0160,\n",
      "             0.0151,      0.0116,     -0.0097,      0.0004,     -0.0145,\n",
      "             0.0018,     -0.0083,     -0.0063,      0.0167,      0.0072,\n",
      "             0.0129,      0.0016,     -0.0173,     -0.0076,     -0.0088,\n",
      "            -0.0071,      0.0002,     -0.0020,     -0.0135,      0.0130,\n",
      "             0.0045,     -0.0134,      0.0094,      0.0002,      0.0138,\n",
      "             0.0145,      0.0054,      0.0041,     -0.0083,      0.0151,\n",
      "            -0.0135,      0.0080,      0.0005,      0.0064,      0.0015,\n",
      "             0.0005,     -0.0129,     -0.0109,     -0.0146,      0.0048,\n",
      "            -0.0176,     -0.0019,      0.0115,     -0.0002,     -0.0103,\n",
      "            -0.0006,     -0.0151,     -0.0024,     -0.0045,     -0.0156,\n",
      "             0.0087,      0.0091,     -0.0174,     -0.0120,      0.0172,\n",
      "            -0.0093,     -0.0009,     -0.0070,     -0.0113,      0.0105,\n",
      "            -0.0072,     -0.0158,     -0.0133,     -0.0058,      0.0085,\n",
      "             0.0067,      0.0112,      0.0124,     -0.0126,     -0.0171,\n",
      "             0.0118,      0.0128,      0.0056,     -0.0066,     -0.0029,\n",
      "             0.0058,      0.0037,      0.0024,      0.0026,      0.0033,\n",
      "             0.0140,      0.0031,     -0.0044,      0.0122,      0.0064,\n",
      "            -0.0039,      0.0086,      0.0155,     -0.0005,      0.0061,\n",
      "             0.0068,      0.0134,      0.0160,     -0.0034,     -0.0010,\n",
      "            -0.0113,     -0.0124,     -0.0004,      0.0100,      0.0031,\n",
      "             0.0012,      0.0142,      0.0063,     -0.0130,      0.0177,\n",
      "            -0.0065,      0.0118,      0.0173,     -0.0164,     -0.0097,\n",
      "             0.0100,     -0.0002,      0.0016,      0.0002,      0.0165,\n",
      "             0.0178,     -0.0097,      0.0180,     -0.0162,     -0.0024,\n",
      "             0.0098,     -0.0080,     -0.0025,     -0.0037,     -0.0062,\n",
      "             0.0059,     -0.0034,     -0.0151,     -0.0082,     -0.0020,\n",
      "            -0.0033,      0.0053,     -0.0135,      0.0133,     -0.0022,\n",
      "            -0.0121,      0.0071,     -0.0088,     -0.0133,      0.0123,\n",
      "            -0.0136,      0.0145,     -0.0068,     -0.0100,      0.0116,\n",
      "             0.0017,     -0.0048,      0.0062,     -0.0067,     -0.0120,\n",
      "             0.0038,      0.0064,     -0.0106,     -0.0178,      0.0002,\n",
      "             0.0002,      0.0032,     -0.0134,     -0.0063,      0.0118,\n",
      "             0.0056,     -0.0031,      0.0086,      0.0019,     -0.0017,\n",
      "            -0.0028,      0.0165,     -0.0067,     -0.0096,      0.0036,\n",
      "             0.0058,      0.0016,      0.0118,     -0.0000,      0.0027,\n",
      "             0.0027,     -0.0025,      0.0132,     -0.0133,     -0.0120,\n",
      "            -0.0092,     -0.0171,     -0.0048,     -0.0110,     -0.0088,\n",
      "            -0.0102,      0.0112,     -0.0093,     -0.0041,      0.0078,\n",
      "            -0.0177,     -0.0121,     -0.0046,     -0.0014,      0.0119,\n",
      "             0.0156,      0.0048,      0.0086,     -0.0023,      0.0012,\n",
      "             0.0101,      0.0073,      0.0099,      0.0100,      0.0044,\n",
      "            -0.0076,      0.0015,      0.0122,      0.0161,     -0.0045,\n",
      "             0.0062,     -0.0084,     -0.0118,      0.0016,     -0.0096,\n",
      "            -0.0063,      0.0014,     -0.0092,     -0.0081,      0.0070,\n",
      "             0.0104,      0.0061,      0.0008,      0.0096,     -0.0055,\n",
      "             0.0010,      0.0080,     -0.0064,     -0.0056,     -0.0158,\n",
      "             0.0151,      0.0166,     -0.0084,     -0.0121,      0.0048,\n",
      "             0.0146,     -0.0079,      0.0021,      0.0061,      0.0142,\n",
      "            -0.0098,      0.0093,     -0.0003,     -0.0090,     -0.0146,\n",
      "            -0.0168,      0.0099,      0.0176,      0.0144,     -0.0106,\n",
      "             0.0151,      0.0071,     -0.0112,      0.0084,      0.0092,\n",
      "             0.0075,      0.0149,      0.0100,      0.0055,      0.0026,\n",
      "            -0.0164,     -0.0050,      0.0033,      0.0118,      0.0167,\n",
      "             0.0057,      0.0016,     -0.0035,      0.0112,      0.0018,\n",
      "             0.0180,     -0.0138,      0.0001,     -0.0025,     -0.0089,\n",
      "            -0.0014,      0.0175,     -0.0125,     -0.0102,     -0.0175,\n",
      "             0.0115,     -0.0143,     -0.0007,      0.0088,      0.0139,\n",
      "            -0.0158,     -0.0128,     -0.0171,     -0.0071,     -0.0173,\n",
      "            -0.0051,      0.0050,      0.0033,      0.0173,     -0.0141,\n",
      "             0.0043,      0.0072,     -0.0138,     -0.0180,     -0.0096,\n",
      "            -0.0040,     -0.0100,      0.0048,      0.0138,      0.0042,\n",
      "             0.0155,      0.0159,     -0.0164,     -0.0084,     -0.0002,\n",
      "             0.0025,     -0.0048,      0.0128,     -0.0122,     -0.0064,\n",
      "            -0.0123,     -0.0072,     -0.0153,      0.0160,     -0.0136,\n",
      "            -0.0170,     -0.0006,      0.0114,      0.0015,     -0.0056,\n",
      "            -0.0125,     -0.0061,     -0.0079,      0.0162,      0.0160,\n",
      "             0.0129,      0.0028,     -0.0160,     -0.0008,     -0.0112,\n",
      "            -0.0001,     -0.0123,     -0.0013,      0.0091,     -0.0161,\n",
      "            -0.0114,     -0.0048,      0.0136,     -0.0045,      0.0035,\n",
      "             0.0053,      0.0066,     -0.0062,     -0.0009,     -0.0120,\n",
      "            -0.0046,      0.0083,     -0.0175,     -0.0114,      0.0084,\n",
      "            -0.0044,      0.0118,      0.0046,     -0.0090,     -0.0099,\n",
      "            -0.0094,     -0.0075,     -0.0121,      0.0176,      0.0133,\n",
      "             0.0143,      0.0166,      0.0172,      0.0019,      0.0155,\n",
      "             0.0074,     -0.0112,     -0.0111,     -0.0141,     -0.0161,\n",
      "            -0.0017,     -0.0112,     -0.0013,     -0.0088,     -0.0114,\n",
      "            -0.0032,     -0.0123,     -0.0139,      0.0099,     -0.0095,\n",
      "            -0.0023,     -0.0086,      0.0166,     -0.0075,     -0.0097,\n",
      "            -0.0016,      0.0118,     -0.0094,      0.0143,     -0.0075,\n",
      "             0.0076,      0.0171,      0.0149,      0.0123,     -0.0044,\n",
      "             0.0004,     -0.0118,     -0.0012,      0.0168,      0.0175,\n",
      "            -0.0148,      0.0110,     -0.0056,     -0.0049,      0.0007,\n",
      "             0.0110,      0.0011,     -0.0067,      0.0116,      0.0098,\n",
      "            -0.0055,      0.0119,      0.0174,     -0.0133,     -0.0113,\n",
      "             0.0066,     -0.0062,     -0.0078,      0.0124,     -0.0027,\n",
      "            -0.0039,     -0.0073,      0.0010,     -0.0169,     -0.0025,\n",
      "             0.0087,      0.0091,      0.0059,     -0.0152,      0.0014,\n",
      "             0.0164,     -0.0091,      0.0101,      0.0023,     -0.0074,\n",
      "             0.0141,     -0.0017,      0.0137,     -0.0099,     -0.0059,\n",
      "            -0.0169,      0.0092,     -0.0141,      0.0036,      0.0077,\n",
      "             0.0034,      0.0029,     -0.0046,      0.0080,     -0.0023,\n",
      "            -0.0000,      0.0165,      0.0162,     -0.0162,     -0.0014,\n",
      "            -0.0103,      0.0086,      0.0002,     -0.0031,      0.0162,\n",
      "            -0.0017,     -0.0103,     -0.0073,      0.0133,      0.0150,\n",
      "            -0.0137,      0.0127,      0.0013,     -0.0145,      0.0155,\n",
      "             0.0132,     -0.0034,      0.0101,     -0.0090,      0.0114,\n",
      "             0.0140,      0.0109,     -0.0163,     -0.0096,     -0.0003,\n",
      "            -0.0158,      0.0086,      0.0176,     -0.0159,      0.0097,\n",
      "            -0.0091,     -0.0151,     -0.0012,      0.0114,     -0.0079,\n",
      "            -0.0094,      0.0119,     -0.0132,     -0.0160,     -0.0001,\n",
      "             0.0153,     -0.0085,     -0.0088,     -0.0140,      0.0157,\n",
      "            -0.0066,      0.0109,      0.0112,     -0.0017,     -0.0076,\n",
      "            -0.0108,     -0.0168,      0.0084,     -0.0037,     -0.0055,\n",
      "            -0.0137,      0.0119,     -0.0135,      0.0081,     -0.0018,\n",
      "             0.0121,     -0.0100,     -0.0067,     -0.0068,     -0.0068,\n",
      "             0.0141,      0.0051,     -0.0035,     -0.0167,      0.0016,\n",
      "             0.0149,     -0.0016,     -0.0122,     -0.0029,     -0.0108,\n",
      "            -0.0090,     -0.0115,     -0.0034,     -0.0099,     -0.0040,\n",
      "             0.0122,      0.0026,     -0.0006,      0.0157,      0.0136,\n",
      "            -0.0177,      0.0008,      0.0114,      0.0154,      0.0006,\n",
      "            -0.0025,      0.0179,     -0.0119,      0.0088,     -0.0128,\n",
      "             0.0115,     -0.0069,     -0.0003,      0.0064,      0.0050,\n",
      "             0.0019,      0.0126,      0.0066,      0.0088,     -0.0180,\n",
      "             0.0172,      0.0034,     -0.0147,     -0.0117,     -0.0167,\n",
      "             0.0120,      0.0058,     -0.0151,      0.0018,     -0.0020,\n",
      "            -0.0130,      0.0095,      0.0151], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0167,  0.0055, -0.0185,  ..., -0.0169, -0.0036,  0.0051],\n",
      "        [ 0.0332, -0.0052,  0.0015,  ...,  0.0047, -0.0167,  0.0309],\n",
      "        [-0.0125,  0.0251,  0.0331,  ...,  0.0202, -0.0120, -0.0075],\n",
      "        ...,\n",
      "        [ 0.0088,  0.0166, -0.0155,  ...,  0.0127,  0.0149, -0.0241],\n",
      "        [-0.0287,  0.0322,  0.0151,  ...,  0.0170,  0.0355,  0.0040],\n",
      "        [ 0.0119,  0.0333,  0.0323,  ..., -0.0085, -0.0184,  0.0209]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0005,  0.0216,  0.0075,  ...,  0.0268, -0.0348,  0.0038],\n",
      "        [ 0.0195,  0.0053,  0.0269,  ...,  0.0360, -0.0067,  0.0149],\n",
      "        [ 0.0078, -0.0303, -0.0238,  ...,  0.0358, -0.0340,  0.0246],\n",
      "        ...,\n",
      "        [-0.0157,  0.0265, -0.0050,  ...,  0.0005, -0.0051, -0.0268],\n",
      "        [ 0.0013, -0.0032,  0.0328,  ...,  0.0319, -0.0135,  0.0025],\n",
      "        [ 0.0315, -0.0147,  0.0215,  ..., -0.0336, -0.0222, -0.0205]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0156, -0.0104,  0.0039,  ...,  0.0034,  0.0014,  0.0310],\n",
      "        [-0.0258, -0.0180, -0.0124,  ...,  0.0060, -0.0349,  0.0343],\n",
      "        [ 0.0272,  0.0086,  0.0294,  ..., -0.0119,  0.0074, -0.0329],\n",
      "        ...,\n",
      "        [-0.0285,  0.0214, -0.0266,  ..., -0.0050, -0.0219, -0.0248],\n",
      "        [ 0.0194,  0.0277,  0.0077,  ...,  0.0122, -0.0205, -0.0139],\n",
      "        [ 0.0145, -0.0059,  0.0173,  ...,  0.0005,  0.0315, -0.0019]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0120,  0.0098, -0.0210,  ...,  0.0047, -0.0007, -0.0245],\n",
      "        [-0.0196,  0.0249,  0.0223,  ...,  0.0145, -0.0207,  0.0273],\n",
      "        [ 0.0197, -0.0047, -0.0307,  ..., -0.0191,  0.0345, -0.0310],\n",
      "        ...,\n",
      "        [-0.0151, -0.0249, -0.0328,  ..., -0.0287, -0.0315,  0.0243],\n",
      "        [-0.0243, -0.0063, -0.0314,  ..., -0.0330,  0.0112,  0.0318],\n",
      "        [-0.0342, -0.0139,  0.0005,  ...,  0.0040,  0.0008,  0.0138]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([     0.0141,     -0.0259,      0.0272,      0.0302,      0.0154,\n",
      "            -0.0165,     -0.0351,      0.0252,      0.0299,      0.0049,\n",
      "             0.0132,      0.0038,     -0.0219,      0.0276,     -0.0300,\n",
      "            -0.0111,      0.0229,      0.0325,     -0.0160,     -0.0319,\n",
      "            -0.0284,     -0.0123,      0.0154,      0.0230,      0.0240,\n",
      "            -0.0233,      0.0100,      0.0052,      0.0244,      0.0261,\n",
      "             0.0095,     -0.0177,     -0.0316,     -0.0322,      0.0235,\n",
      "             0.0216,      0.0302,      0.0129,     -0.0150,      0.0167,\n",
      "            -0.0107,      0.0048,      0.0297,     -0.0196,      0.0284,\n",
      "             0.0318,      0.0095,     -0.0035,      0.0161,     -0.0108,\n",
      "            -0.0143,      0.0260,     -0.0158,      0.0249,     -0.0347,\n",
      "             0.0336,      0.0229,      0.0204,     -0.0334,      0.0251,\n",
      "            -0.0159,     -0.0262,      0.0095,     -0.0051,     -0.0237,\n",
      "             0.0134,      0.0000,      0.0124,     -0.0348,     -0.0184,\n",
      "             0.0067,     -0.0218,     -0.0101,     -0.0028,     -0.0308,\n",
      "            -0.0151,      0.0278,     -0.0162,     -0.0158,     -0.0264,\n",
      "            -0.0178,     -0.0174,     -0.0046,      0.0083,      0.0256,\n",
      "            -0.0100,      0.0156,     -0.0185,      0.0098,      0.0239,\n",
      "            -0.0040,     -0.0292,      0.0085,      0.0014,     -0.0031,\n",
      "             0.0055,     -0.0266,     -0.0254,      0.0023,      0.0328,\n",
      "             0.0322,     -0.0141,      0.0350,      0.0336,      0.0244,\n",
      "             0.0329,     -0.0093,     -0.0133,     -0.0045,     -0.0109,\n",
      "             0.0103,     -0.0211,     -0.0054,      0.0257,      0.0237,\n",
      "            -0.0059,      0.0083,     -0.0048,      0.0135,     -0.0032,\n",
      "             0.0228,      0.0034,      0.0106,     -0.0164,      0.0247,\n",
      "            -0.0122,      0.0140,      0.0294,     -0.0161,     -0.0315,\n",
      "             0.0349,     -0.0046,     -0.0119,      0.0260,     -0.0209,\n",
      "            -0.0195,      0.0288,      0.0103,      0.0255,      0.0060,\n",
      "             0.0057,      0.0083,     -0.0061,      0.0305,     -0.0355,\n",
      "             0.0120,      0.0044,     -0.0234,      0.0192,     -0.0260,\n",
      "            -0.0290,      0.0201,      0.0249,     -0.0162,      0.0064,\n",
      "             0.0121,      0.0126,     -0.0075,      0.0304,     -0.0118,\n",
      "            -0.0246,      0.0186,     -0.0016,      0.0259,      0.0070,\n",
      "            -0.0211,     -0.0173,      0.0211,      0.0305,     -0.0350,\n",
      "            -0.0096,      0.0326,      0.0094,      0.0152,      0.0279,\n",
      "            -0.0100,     -0.0040,     -0.0208,     -0.0350,      0.0328,\n",
      "            -0.0132,     -0.0271,      0.0064,      0.0303,     -0.0060,\n",
      "             0.0038,      0.0171,     -0.0292,     -0.0024,      0.0320,\n",
      "             0.0057,      0.0089,     -0.0320,     -0.0280,     -0.0178,\n",
      "             0.0205,     -0.0123,     -0.0091,      0.0080,      0.0050,\n",
      "            -0.0185,     -0.0104,     -0.0334,     -0.0040,     -0.0109,\n",
      "            -0.0352,     -0.0273,      0.0349,     -0.0127,     -0.0347,\n",
      "             0.0102,      0.0263,     -0.0076,      0.0202,      0.0204,\n",
      "            -0.0164,      0.0037,      0.0104,      0.0352,      0.0111,\n",
      "            -0.0104,      0.0360,      0.0001,      0.0214,     -0.0179,\n",
      "             0.0315,      0.0262,      0.0048,     -0.0225,      0.0021,\n",
      "            -0.0289,     -0.0085,      0.0201,     -0.0305,      0.0138,\n",
      "            -0.0142,      0.0236,      0.0347,      0.0168,     -0.0350,\n",
      "             0.0110,      0.0256,     -0.0227,     -0.0184,     -0.0331,\n",
      "            -0.0045,      0.0161,     -0.0103,      0.0187,     -0.0321,\n",
      "            -0.0347,     -0.0055,      0.0309,     -0.0124,     -0.0305,\n",
      "             0.0197,     -0.0254,     -0.0302,      0.0116,     -0.0289,\n",
      "             0.0039,     -0.0191,     -0.0064,      0.0119,     -0.0092,\n",
      "            -0.0317,     -0.0024,      0.0270,     -0.0339,     -0.0163,\n",
      "            -0.0216,      0.0151,      0.0148,      0.0105,      0.0162,\n",
      "            -0.0348,      0.0039,      0.0190,     -0.0135,     -0.0028,\n",
      "            -0.0089,     -0.0281,      0.0060,     -0.0350,     -0.0179,\n",
      "            -0.0102,      0.0185,      0.0313,     -0.0216,     -0.0056,\n",
      "             0.0100,      0.0253,      0.0127,      0.0031,     -0.0234,\n",
      "            -0.0114,     -0.0040,      0.0023,      0.0006,      0.0341,\n",
      "            -0.0279,     -0.0190,     -0.0330,      0.0187,      0.0319,\n",
      "            -0.0272,      0.0038,     -0.0336,     -0.0251,      0.0360,\n",
      "             0.0088,     -0.0240,      0.0067,     -0.0177,      0.0057,\n",
      "             0.0205,      0.0099,      0.0214,     -0.0224,     -0.0043,\n",
      "            -0.0186,     -0.0145,      0.0060,     -0.0161,     -0.0063,\n",
      "             0.0152,     -0.0184,     -0.0027,     -0.0111,      0.0040,\n",
      "             0.0356,      0.0020,      0.0040,      0.0283,     -0.0122,\n",
      "             0.0126,     -0.0126,      0.0347,      0.0328,     -0.0018,\n",
      "             0.0080,     -0.0256,      0.0271,      0.0187,      0.0271,\n",
      "            -0.0250,     -0.0196,     -0.0172,     -0.0082,      0.0195,\n",
      "             0.0144,     -0.0196,      0.0347,      0.0017,      0.0315,\n",
      "            -0.0172,     -0.0305,      0.0133,     -0.0164,      0.0085,\n",
      "             0.0233,     -0.0106,     -0.0202,     -0.0069,     -0.0053,\n",
      "             0.0284,      0.0134,      0.0018,      0.0246,      0.0084,\n",
      "             0.0074,     -0.0132,     -0.0236,      0.0312,     -0.0193,\n",
      "             0.0140,      0.0322,     -0.0123,     -0.0180,     -0.0222,\n",
      "             0.0138,     -0.0007,     -0.0102,     -0.0294,     -0.0269,\n",
      "            -0.0220,      0.0040,     -0.0116,      0.0020,      0.0119,\n",
      "             0.0079,      0.0166,     -0.0238,     -0.0336,      0.0110,\n",
      "             0.0196,      0.0273,     -0.0284,      0.0140,      0.0317,\n",
      "            -0.0031,     -0.0209,      0.0114,      0.0074,      0.0176,\n",
      "            -0.0233,      0.0293,      0.0273,     -0.0136,     -0.0263,\n",
      "            -0.0243,     -0.0069,      0.0326,      0.0295,     -0.0231,\n",
      "             0.0092,      0.0128,      0.0314,     -0.0336,     -0.0186,\n",
      "             0.0257,     -0.0207,     -0.0209,     -0.0313,     -0.0354,\n",
      "            -0.0117,     -0.0298,      0.0082,      0.0143,      0.0261,\n",
      "            -0.0332,     -0.0299,      0.0252,     -0.0077,      0.0226,\n",
      "            -0.0103,      0.0006,      0.0148,      0.0170,     -0.0198,\n",
      "             0.0253,     -0.0352,     -0.0192,      0.0056,     -0.0134,\n",
      "            -0.0084,      0.0332,     -0.0176,     -0.0331,     -0.0078,\n",
      "             0.0004,     -0.0078,      0.0126,     -0.0311,      0.0198,\n",
      "            -0.0293,     -0.0013,     -0.0312,      0.0144,      0.0123,\n",
      "            -0.0078,     -0.0242,      0.0239,      0.0298,     -0.0110,\n",
      "             0.0047,      0.0356,      0.0051,      0.0113,     -0.0157,\n",
      "             0.0007,     -0.0071,      0.0016,      0.0244,      0.0058,\n",
      "             0.0166,     -0.0112,     -0.0337,     -0.0320,     -0.0275,\n",
      "             0.0294,      0.0277,      0.0179,     -0.0080,      0.0041,\n",
      "             0.0158,      0.0215,     -0.0090,     -0.0095,      0.0110,\n",
      "             0.0129,      0.0295,      0.0132,     -0.0182,     -0.0206,\n",
      "             0.0353,      0.0246,      0.0228,     -0.0023,      0.0108,\n",
      "             0.0296,      0.0125,      0.0244,      0.0250,      0.0241,\n",
      "            -0.0344,     -0.0023,     -0.0297,     -0.0350,      0.0333,\n",
      "             0.0162,      0.0059,     -0.0116,      0.0064,     -0.0237,\n",
      "            -0.0135,     -0.0295,     -0.0235,      0.0189,      0.0151,\n",
      "             0.0231,      0.0330,     -0.0211,      0.0166,     -0.0346,\n",
      "             0.0038,     -0.0080,     -0.0190,     -0.0080,      0.0085,\n",
      "            -0.0240,      0.0108,      0.0292,      0.0001,      0.0037,\n",
      "            -0.0208,      0.0128,      0.0348,      0.0228,      0.0181,\n",
      "             0.0156,      0.0327,     -0.0137,     -0.0302,      0.0353,\n",
      "             0.0070,     -0.0093,      0.0098,      0.0064,      0.0153,\n",
      "             0.0100,      0.0282,     -0.0177,      0.0359,     -0.0137,\n",
      "            -0.0107,      0.0009,      0.0264,     -0.0242,      0.0009,\n",
      "            -0.0031,     -0.0017,     -0.0225,      0.0293,      0.0140,\n",
      "            -0.0244,     -0.0176,      0.0282,     -0.0235,      0.0252,\n",
      "            -0.0185,     -0.0150,      0.0267,      0.0304,      0.0092,\n",
      "             0.0266,     -0.0302,     -0.0148,      0.0274,     -0.0250,\n",
      "            -0.0352,      0.0072,     -0.0198,      0.0330,      0.0357,\n",
      "            -0.0096,     -0.0040,     -0.0170,     -0.0136,     -0.0098,\n",
      "            -0.0101,      0.0187,     -0.0304,      0.0197,     -0.0166,\n",
      "             0.0079,     -0.0095,     -0.0225,      0.0294,     -0.0157,\n",
      "             0.0201,      0.0150,      0.0128,     -0.0333,     -0.0091,\n",
      "             0.0092,     -0.0165,     -0.0088,      0.0343,      0.0134,\n",
      "            -0.0041,     -0.0335,      0.0127,     -0.0222,     -0.0257,\n",
      "             0.0018,      0.0085,      0.0262,      0.0182,      0.0299,\n",
      "            -0.0147,      0.0054,     -0.0121,     -0.0093,      0.0013,\n",
      "             0.0277,     -0.0139,      0.0245,     -0.0060,      0.0053,\n",
      "            -0.0168,     -0.0048,     -0.0328,      0.0198,     -0.0133,\n",
      "             0.0352,      0.0114,      0.0071,      0.0017,      0.0050,\n",
      "            -0.0318,     -0.0083,     -0.0194,      0.0005,     -0.0092,\n",
      "             0.0137,      0.0181,     -0.0061,     -0.0250,      0.0288,\n",
      "            -0.0003,     -0.0077,      0.0093,     -0.0266,     -0.0162,\n",
      "            -0.0333,      0.0016,      0.0304,      0.0021,      0.0029,\n",
      "             0.0016,     -0.0165,     -0.0207,      0.0246,     -0.0195,\n",
      "             0.0031,      0.0222,     -0.0214,      0.0210,     -0.0345,\n",
      "             0.0287,      0.0306,      0.0324,      0.0051,     -0.0096,\n",
      "            -0.0024,     -0.0111,     -0.0100,     -0.0128,      0.0262,\n",
      "             0.0329,     -0.0177,     -0.0059,      0.0149,     -0.0322,\n",
      "            -0.0062,     -0.0063,      0.0248,     -0.0130,     -0.0064,\n",
      "            -0.0076,     -0.0341,     -0.0349,     -0.0292,     -0.0318,\n",
      "             0.0207,     -0.0211,      0.0358,      0.0036,     -0.0160,\n",
      "             0.0226,      0.0312,      0.0299,      0.0241,      0.0145,\n",
      "            -0.0255,      0.0360,      0.0068,     -0.0240,     -0.0002,\n",
      "            -0.0268,     -0.0071,      0.0247,     -0.0209,      0.0095,\n",
      "            -0.0313,     -0.0054,      0.0262,     -0.0235,      0.0289,\n",
      "            -0.0338,      0.0139,     -0.0231,     -0.0324,      0.0251,\n",
      "             0.0281,     -0.0021,     -0.0231,     -0.0222,      0.0302,\n",
      "            -0.0108,     -0.0241,     -0.0016,     -0.0266,      0.0112,\n",
      "             0.0344,      0.0178,      0.0146,     -0.0035,     -0.0170,\n",
      "             0.0117,      0.0263,      0.0353,     -0.0298,      0.0163,\n",
      "            -0.0068,      0.0237,      0.0260,     -0.0264,     -0.0047,\n",
      "            -0.0172,      0.0148,      0.0349,     -0.0170,      0.0085,\n",
      "            -0.0295,      0.0042,     -0.0290,     -0.0127,     -0.0038,\n",
      "            -0.0250,     -0.0073,      0.0338,     -0.0330,     -0.0280,\n",
      "             0.0322,     -0.0316,     -0.0020], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0144,  0.0064, -0.0274,  ..., -0.0283, -0.0316,  0.0205],\n",
      "        [ 0.0287, -0.0026, -0.0116,  ..., -0.0344, -0.0125, -0.0185],\n",
      "        [-0.0055, -0.0188,  0.0193,  ...,  0.0293, -0.0247, -0.0076],\n",
      "        ...,\n",
      "        [-0.0061, -0.0032,  0.0285,  ...,  0.0226,  0.0285, -0.0038],\n",
      "        [-0.0061, -0.0190, -0.0160,  ...,  0.0038, -0.0013, -0.0162],\n",
      "        [ 0.0258, -0.0065, -0.0199,  ..., -0.0222, -0.0116, -0.0134]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0360,  0.0234, -0.0037,  ..., -0.0260, -0.0077, -0.0192],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0096,  0.0128, -0.0105,  ..., -0.0125, -0.0156, -0.0055],\n",
      "        [-0.0039, -0.0064,  0.0071,  ...,  0.0152,  0.0091, -0.0038],\n",
      "        [ 0.0176,  0.0042, -0.0014,  ...,  0.0110,  0.0047, -0.0144],\n",
      "        ...,\n",
      "        [-0.0141, -0.0076, -0.0175,  ...,  0.0172, -0.0014, -0.0162],\n",
      "        [ 0.0139, -0.0080,  0.0012,  ..., -0.0145,  0.0119,  0.0093],\n",
      "        [-0.0079, -0.0028, -0.0119,  ...,  0.0118, -0.0123,  0.0131]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([     0.0009,      0.0084,     -0.0133,      0.0080,      0.0043,\n",
      "            -0.0107,      0.0010,      0.0006,      0.0089,      0.0068,\n",
      "             0.0046,     -0.0014,     -0.0132,     -0.0150,      0.0006,\n",
      "             0.0137,     -0.0079,      0.0042,     -0.0120,      0.0049,\n",
      "            -0.0073,     -0.0125,     -0.0115,     -0.0119,      0.0102,\n",
      "             0.0112,      0.0037,     -0.0112,      0.0174,      0.0001,\n",
      "             0.0138,      0.0037,      0.0004,     -0.0087,      0.0008,\n",
      "            -0.0066,      0.0115,     -0.0023,      0.0003,      0.0008,\n",
      "             0.0136,     -0.0062,     -0.0108,     -0.0145,     -0.0092,\n",
      "             0.0069,      0.0059,     -0.0159,      0.0072,     -0.0004,\n",
      "            -0.0067,      0.0046,     -0.0180,     -0.0009,     -0.0138,\n",
      "            -0.0020,     -0.0158,      0.0031,     -0.0119,     -0.0119,\n",
      "             0.0075,      0.0119,      0.0152,     -0.0093,     -0.0082,\n",
      "            -0.0087,     -0.0162,      0.0144,      0.0023,      0.0178,\n",
      "             0.0086,      0.0149,     -0.0084,     -0.0173,     -0.0169,\n",
      "             0.0100,      0.0011,      0.0168,     -0.0012,      0.0029,\n",
      "             0.0159,     -0.0075,     -0.0159,      0.0111,      0.0016,\n",
      "             0.0001,     -0.0134,      0.0165,     -0.0075,      0.0007,\n",
      "            -0.0150,      0.0058,     -0.0008,     -0.0083,      0.0082,\n",
      "             0.0093,     -0.0053,      0.0109,      0.0171,     -0.0169,\n",
      "            -0.0108,      0.0016,      0.0035,     -0.0142,     -0.0031,\n",
      "            -0.0111,     -0.0027,     -0.0082,     -0.0114,     -0.0152,\n",
      "            -0.0075,     -0.0082,     -0.0046,      0.0161,     -0.0017,\n",
      "             0.0083,     -0.0119,      0.0013,      0.0149,      0.0000,\n",
      "            -0.0024,      0.0025,      0.0147,      0.0065,      0.0088,\n",
      "            -0.0008,      0.0001,     -0.0015,     -0.0017,     -0.0036,\n",
      "            -0.0058,     -0.0065,     -0.0175,      0.0080,      0.0056,\n",
      "             0.0094,     -0.0054,      0.0122,     -0.0178,      0.0125,\n",
      "             0.0138,     -0.0179,      0.0099,     -0.0126,      0.0015,\n",
      "             0.0025,      0.0063,     -0.0049,      0.0175,      0.0064,\n",
      "            -0.0032,      0.0158,     -0.0109,      0.0044,      0.0040,\n",
      "             0.0034,      0.0158,      0.0177,      0.0018,      0.0012,\n",
      "            -0.0111,     -0.0094,      0.0118,     -0.0111,      0.0016,\n",
      "             0.0165,     -0.0036,     -0.0130,      0.0094,      0.0080,\n",
      "             0.0018,     -0.0166,      0.0070,      0.0079,      0.0158,\n",
      "             0.0025,      0.0016,     -0.0175,      0.0144,     -0.0180,\n",
      "             0.0092,      0.0051,      0.0034,     -0.0046,     -0.0114,\n",
      "             0.0162,     -0.0152,      0.0139,     -0.0018,     -0.0124,\n",
      "            -0.0037,      0.0102,      0.0136,     -0.0161,     -0.0126,\n",
      "            -0.0102,      0.0087,     -0.0064,     -0.0014,      0.0163,\n",
      "            -0.0140,      0.0013,     -0.0077,      0.0068,     -0.0114,\n",
      "            -0.0095,      0.0032,     -0.0023,     -0.0004,     -0.0048,\n",
      "            -0.0058,      0.0159,      0.0144,      0.0115,      0.0176,\n",
      "             0.0015,      0.0102,     -0.0028,     -0.0049,     -0.0131,\n",
      "            -0.0004,     -0.0078,     -0.0008,     -0.0090,      0.0066,\n",
      "             0.0058,     -0.0026,      0.0064,      0.0016,     -0.0049,\n",
      "             0.0175,      0.0102,      0.0112,     -0.0032,     -0.0092,\n",
      "             0.0031,     -0.0029,     -0.0002,      0.0143,      0.0087,\n",
      "            -0.0052,      0.0013,      0.0064,     -0.0051,      0.0043,\n",
      "            -0.0164,     -0.0175,     -0.0157,      0.0110,      0.0113,\n",
      "             0.0174,     -0.0057,      0.0131,     -0.0120,      0.0092,\n",
      "            -0.0082,      0.0060,      0.0018,      0.0164,      0.0099,\n",
      "             0.0015,     -0.0043,      0.0035,     -0.0174,      0.0035,\n",
      "             0.0022,      0.0145,      0.0096,      0.0030,     -0.0001,\n",
      "            -0.0023,      0.0151,     -0.0088,     -0.0062,     -0.0098,\n",
      "             0.0120,      0.0121,      0.0146,      0.0168,      0.0102,\n",
      "            -0.0057,      0.0117,     -0.0117,      0.0171,      0.0141,\n",
      "            -0.0128,      0.0082,      0.0047,      0.0091,     -0.0022,\n",
      "            -0.0173,     -0.0101,      0.0070,      0.0031,     -0.0133,\n",
      "            -0.0059,      0.0082,     -0.0063,      0.0127,     -0.0166,\n",
      "             0.0048,      0.0009,     -0.0117,      0.0113,     -0.0066,\n",
      "             0.0034,      0.0121,     -0.0009,     -0.0024,     -0.0175,\n",
      "             0.0008,     -0.0176,     -0.0141,     -0.0167,     -0.0053,\n",
      "             0.0064,      0.0170,      0.0168,     -0.0122,     -0.0153,\n",
      "            -0.0032,     -0.0165,      0.0146,      0.0057,      0.0176,\n",
      "            -0.0090,      0.0164,      0.0079,      0.0136,      0.0126,\n",
      "            -0.0084,      0.0090,      0.0016,      0.0100,     -0.0138,\n",
      "             0.0101,     -0.0049,      0.0044,      0.0062,     -0.0088,\n",
      "            -0.0176,      0.0071,     -0.0047,      0.0098,      0.0058,\n",
      "            -0.0135,      0.0065,     -0.0108,      0.0064,     -0.0171,\n",
      "             0.0145,      0.0094,     -0.0066,     -0.0139,     -0.0015,\n",
      "             0.0024,     -0.0141,      0.0073,     -0.0132,      0.0025,\n",
      "             0.0136,      0.0060,     -0.0081,     -0.0139,     -0.0083,\n",
      "            -0.0131,     -0.0148,      0.0029,     -0.0080,      0.0030,\n",
      "            -0.0096,      0.0160,     -0.0058,      0.0026,      0.0058,\n",
      "             0.0154,      0.0000,      0.0026,      0.0145,      0.0077,\n",
      "            -0.0017,     -0.0143,      0.0148,     -0.0065,      0.0066,\n",
      "            -0.0078,      0.0069,      0.0165,     -0.0057,      0.0130,\n",
      "            -0.0079,      0.0045,      0.0012,     -0.0111,      0.0069,\n",
      "             0.0136,      0.0111,      0.0023,      0.0174,     -0.0002,\n",
      "            -0.0048,     -0.0041,     -0.0076,      0.0093,      0.0019,\n",
      "             0.0176,      0.0138,      0.0030,      0.0071,     -0.0158,\n",
      "             0.0098,     -0.0112,     -0.0112,     -0.0042,     -0.0002,\n",
      "             0.0034,      0.0147,     -0.0070,      0.0099,      0.0029,\n",
      "            -0.0038,     -0.0121,      0.0105,      0.0082,      0.0007,\n",
      "            -0.0154,     -0.0002,      0.0018,     -0.0141,     -0.0035,\n",
      "            -0.0083,      0.0127,      0.0095,     -0.0172,     -0.0144,\n",
      "             0.0121,      0.0165,     -0.0124,      0.0113,      0.0144,\n",
      "            -0.0020,      0.0075,      0.0155,     -0.0061,      0.0016,\n",
      "             0.0107,     -0.0113,      0.0076,      0.0049,      0.0058,\n",
      "            -0.0087,     -0.0172,      0.0003,      0.0005,      0.0098,\n",
      "             0.0052,      0.0065,     -0.0102,     -0.0128,     -0.0134,\n",
      "            -0.0151,      0.0009,      0.0142,     -0.0002,     -0.0036,\n",
      "            -0.0059,     -0.0173,      0.0103,      0.0143,     -0.0145,\n",
      "            -0.0159,      0.0114,     -0.0101,     -0.0174,     -0.0009,\n",
      "            -0.0001,     -0.0138,     -0.0157,      0.0042,     -0.0180,\n",
      "            -0.0128,      0.0093,      0.0008,     -0.0055,     -0.0005,\n",
      "             0.0047,     -0.0006,     -0.0135,     -0.0115,     -0.0057,\n",
      "            -0.0123,     -0.0148,     -0.0153,     -0.0059,      0.0122,\n",
      "             0.0023,     -0.0090,     -0.0025,      0.0131,      0.0145,\n",
      "             0.0020,      0.0068,      0.0105,     -0.0103,     -0.0033,\n",
      "             0.0149,     -0.0053,      0.0014,     -0.0088,     -0.0134,\n",
      "            -0.0094,      0.0061,     -0.0043,      0.0011,      0.0174,\n",
      "            -0.0019,      0.0082,      0.0063,     -0.0126,     -0.0016,\n",
      "             0.0101,     -0.0145,      0.0105,      0.0161,     -0.0119,\n",
      "            -0.0000,     -0.0034,     -0.0084,     -0.0093,      0.0068,\n",
      "            -0.0145,      0.0087,     -0.0042,      0.0022,     -0.0104,\n",
      "            -0.0100,     -0.0138,     -0.0073,     -0.0046,      0.0169,\n",
      "            -0.0096,      0.0130,      0.0055,     -0.0037,     -0.0174,\n",
      "            -0.0083,     -0.0048,     -0.0179,      0.0005,      0.0043,\n",
      "             0.0118,     -0.0066,     -0.0164,      0.0059,     -0.0074,\n",
      "            -0.0149,     -0.0015,     -0.0089,      0.0164,      0.0104,\n",
      "             0.0147,     -0.0114,     -0.0018,      0.0177,      0.0122,\n",
      "            -0.0159,      0.0140,     -0.0038,      0.0105,     -0.0046,\n",
      "             0.0085,      0.0036,      0.0105,      0.0038,     -0.0151,\n",
      "             0.0003,      0.0111,      0.0093,     -0.0015,      0.0153,\n",
      "            -0.0176,      0.0161,      0.0059,     -0.0049,     -0.0024,\n",
      "            -0.0156,     -0.0128,      0.0144,     -0.0134,     -0.0045,\n",
      "            -0.0037,      0.0125,     -0.0004,      0.0066,      0.0024,\n",
      "            -0.0086,     -0.0124,     -0.0073,     -0.0056,     -0.0087,\n",
      "            -0.0033,     -0.0113,     -0.0146,     -0.0013,     -0.0044,\n",
      "             0.0084,     -0.0160,      0.0161,     -0.0167,      0.0179,\n",
      "             0.0039,      0.0088,      0.0005,     -0.0119,     -0.0120,\n",
      "            -0.0171,     -0.0163,      0.0025,     -0.0039,     -0.0076,\n",
      "             0.0118,      0.0014,      0.0124,      0.0004,     -0.0047,\n",
      "             0.0108,      0.0031,      0.0162,      0.0055,      0.0034,\n",
      "             0.0099,      0.0157,      0.0099,     -0.0171,     -0.0026,\n",
      "             0.0044,      0.0090,     -0.0159,     -0.0046,     -0.0024,\n",
      "            -0.0080,     -0.0072,     -0.0118,     -0.0043,      0.0083,\n",
      "             0.0169,     -0.0009,     -0.0098,     -0.0129,     -0.0052,\n",
      "            -0.0158,      0.0151,     -0.0019,     -0.0110,     -0.0111,\n",
      "             0.0120,      0.0122,     -0.0067,     -0.0115,      0.0107,\n",
      "            -0.0144,     -0.0039,      0.0012,      0.0120,     -0.0075,\n",
      "             0.0011,     -0.0017,      0.0169,      0.0107,     -0.0104,\n",
      "            -0.0063,      0.0010,      0.0046,     -0.0090,      0.0001,\n",
      "            -0.0178,      0.0053,     -0.0041,      0.0030,      0.0044,\n",
      "            -0.0172,     -0.0136,      0.0110,     -0.0029,      0.0042,\n",
      "            -0.0034,      0.0126,     -0.0082,     -0.0022,     -0.0107,\n",
      "            -0.0106,     -0.0145,     -0.0113,      0.0119,     -0.0002,\n",
      "            -0.0175,     -0.0031,     -0.0083,      0.0169,     -0.0142,\n",
      "            -0.0109,      0.0058,      0.0176,     -0.0006,     -0.0116,\n",
      "            -0.0151,      0.0095,      0.0169,     -0.0124,     -0.0076,\n",
      "             0.0045,      0.0119,      0.0153,     -0.0016,      0.0053,\n",
      "             0.0169,      0.0161,      0.0098,     -0.0143,      0.0039,\n",
      "            -0.0164,     -0.0028,     -0.0101,     -0.0105,      0.0034,\n",
      "            -0.0164,      0.0127,      0.0128,      0.0033,      0.0016,\n",
      "            -0.0074,     -0.0067,     -0.0137,     -0.0069,      0.0102,\n",
      "             0.0051,     -0.0176,      0.0012,     -0.0032,      0.0001,\n",
      "            -0.0059,     -0.0064,     -0.0153,      0.0163,      0.0092,\n",
      "             0.0159,     -0.0053,     -0.0131,     -0.0026,      0.0011,\n",
      "             0.0005,     -0.0074,     -0.0133,      0.0178,      0.0136,\n",
      "            -0.0064,      0.0061,      0.0135,     -0.0134,      0.0084,\n",
      "            -0.0052,      0.0059,     -0.0178,      0.0013,      0.0142,\n",
      "            -0.0117,     -0.0047,     -0.0100], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0116, -0.0157, -0.0095,  ..., -0.0280, -0.0025,  0.0183],\n",
      "        [ 0.0212,  0.0013,  0.0327,  ...,  0.0029,  0.0065, -0.0024],\n",
      "        [ 0.0320,  0.0174, -0.0340,  ..., -0.0357,  0.0311, -0.0068],\n",
      "        ...,\n",
      "        [-0.0063, -0.0040,  0.0024,  ..., -0.0034, -0.0159, -0.0242],\n",
      "        [ 0.0334, -0.0177, -0.0217,  ...,  0.0300,  0.0246, -0.0051],\n",
      "        [-0.0011, -0.0162, -0.0300,  ...,  0.0243,  0.0244, -0.0270]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[    -0.0288,     -0.0241,      0.0258,  ...,      0.0114,\n",
      "             -0.0263,     -0.0218],\n",
      "        [    -0.0182,      0.0022,      0.0244,  ...,     -0.0000,\n",
      "             -0.0225,     -0.0132],\n",
      "        [     0.0035,     -0.0003,     -0.0249,  ...,      0.0287,\n",
      "             -0.0292,      0.0133],\n",
      "        ...,\n",
      "        [    -0.0128,     -0.0115,     -0.0055,  ...,     -0.0282,\n",
      "              0.0340,     -0.0034],\n",
      "        [    -0.0105,      0.0206,     -0.0219,  ...,      0.0169,\n",
      "             -0.0128,      0.0079],\n",
      "        [    -0.0230,     -0.0152,     -0.0331,  ...,     -0.0163,\n",
      "              0.0337,      0.0178]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0069,  0.0185, -0.0098,  ..., -0.0338, -0.0125,  0.0194],\n",
      "        [-0.0239,  0.0297,  0.0121,  ...,  0.0124, -0.0269,  0.0093],\n",
      "        [-0.0117, -0.0114, -0.0178,  ..., -0.0314, -0.0129, -0.0256],\n",
      "        ...,\n",
      "        [-0.0052, -0.0310,  0.0321,  ..., -0.0130,  0.0088, -0.0142],\n",
      "        [-0.0160, -0.0002,  0.0204,  ..., -0.0048,  0.0298, -0.0132],\n",
      "        [-0.0293,  0.0145,  0.0075,  ...,  0.0281, -0.0204, -0.0283]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0222, -0.0053,  0.0121,  ...,  0.0265, -0.0291,  0.0282],\n",
      "        [-0.0338,  0.0180,  0.0298,  ...,  0.0085, -0.0220,  0.0060],\n",
      "        [ 0.0103, -0.0150,  0.0290,  ...,  0.0069,  0.0183,  0.0274],\n",
      "        ...,\n",
      "        [-0.0084, -0.0072, -0.0220,  ..., -0.0008, -0.0077,  0.0300],\n",
      "        [ 0.0088, -0.0111, -0.0186,  ...,  0.0152,  0.0291,  0.0343],\n",
      "        [-0.0344, -0.0312,  0.0328,  ..., -0.0164, -0.0269, -0.0010]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([     0.0103,      0.0032,      0.0343,     -0.0252,      0.0047,\n",
      "             0.0328,      0.0155,      0.0113,     -0.0143,      0.0259,\n",
      "            -0.0259,     -0.0353,     -0.0168,      0.0190,     -0.0361,\n",
      "             0.0033,      0.0277,     -0.0183,      0.0301,     -0.0332,\n",
      "            -0.0205,     -0.0251,      0.0088,     -0.0169,     -0.0114,\n",
      "             0.0121,     -0.0073,      0.0344,     -0.0089,     -0.0291,\n",
      "            -0.0182,     -0.0106,      0.0283,      0.0032,     -0.0298,\n",
      "            -0.0237,      0.0202,     -0.0243,     -0.0169,     -0.0294,\n",
      "             0.0043,      0.0045,     -0.0228,     -0.0030,      0.0160,\n",
      "             0.0340,      0.0162,     -0.0186,      0.0251,     -0.0188,\n",
      "             0.0281,     -0.0106,     -0.0122,     -0.0314,      0.0011,\n",
      "             0.0298,      0.0331,      0.0251,     -0.0081,      0.0327,\n",
      "            -0.0288,     -0.0177,     -0.0243,     -0.0200,     -0.0053,\n",
      "             0.0286,      0.0294,      0.0351,     -0.0265,     -0.0161,\n",
      "             0.0073,     -0.0340,     -0.0107,      0.0217,      0.0074,\n",
      "             0.0084,      0.0333,      0.0319,     -0.0261,      0.0306,\n",
      "            -0.0023,      0.0356,      0.0324,      0.0039,     -0.0008,\n",
      "            -0.0084,     -0.0344,      0.0027,     -0.0218,      0.0304,\n",
      "            -0.0043,     -0.0254,     -0.0208,     -0.0224,     -0.0341,\n",
      "             0.0004,      0.0302,      0.0179,      0.0238,      0.0169,\n",
      "            -0.0096,      0.0128,      0.0182,     -0.0320,      0.0326,\n",
      "            -0.0162,      0.0050,     -0.0024,      0.0249,     -0.0328,\n",
      "             0.0119,      0.0333,      0.0180,     -0.0040,     -0.0265,\n",
      "             0.0246,     -0.0136,      0.0191,      0.0040,     -0.0316,\n",
      "            -0.0330,     -0.0084,      0.0119,      0.0010,      0.0354,\n",
      "             0.0074,     -0.0118,     -0.0286,      0.0011,      0.0100,\n",
      "            -0.0248,     -0.0223,      0.0261,      0.0360,     -0.0335,\n",
      "            -0.0303,     -0.0279,      0.0082,      0.0220,     -0.0163,\n",
      "             0.0238,      0.0212,      0.0103,     -0.0347,     -0.0015,\n",
      "            -0.0086,      0.0093,     -0.0289,     -0.0104,     -0.0334,\n",
      "             0.0106,     -0.0355,     -0.0227,     -0.0224,     -0.0242,\n",
      "            -0.0207,     -0.0216,     -0.0091,     -0.0007,      0.0052,\n",
      "            -0.0339,      0.0182,      0.0066,      0.0339,      0.0229,\n",
      "             0.0233,      0.0342,     -0.0282,     -0.0074,      0.0310,\n",
      "             0.0166,      0.0001,     -0.0233,     -0.0189,     -0.0323,\n",
      "            -0.0230,      0.0114,      0.0231,      0.0149,      0.0360,\n",
      "             0.0191,      0.0141,      0.0344,      0.0256,     -0.0277,\n",
      "            -0.0318,      0.0302,     -0.0041,     -0.0251,      0.0341,\n",
      "            -0.0255,     -0.0070,      0.0173,      0.0222,      0.0041,\n",
      "            -0.0165,      0.0135,      0.0272,     -0.0241,     -0.0320,\n",
      "             0.0242,      0.0137,     -0.0227,     -0.0140,      0.0171,\n",
      "             0.0215,     -0.0295,     -0.0086,      0.0063,     -0.0263,\n",
      "             0.0270,     -0.0059,     -0.0047,     -0.0331,      0.0277,\n",
      "            -0.0212,      0.0097,     -0.0311,      0.0115,      0.0226,\n",
      "             0.0087,     -0.0173,      0.0170,     -0.0219,      0.0264,\n",
      "             0.0339,     -0.0029,      0.0174,     -0.0132,      0.0265,\n",
      "             0.0334,      0.0117,      0.0161,      0.0248,     -0.0182,\n",
      "             0.0358,      0.0150,     -0.0064,     -0.0038,      0.0331,\n",
      "            -0.0078,      0.0249,     -0.0268,      0.0255,      0.0084,\n",
      "             0.0175,     -0.0029,      0.0141,      0.0317,      0.0025,\n",
      "            -0.0253,      0.0304,     -0.0129,      0.0189,      0.0202,\n",
      "             0.0090,     -0.0189,      0.0293,     -0.0130,     -0.0130,\n",
      "             0.0249,      0.0230,      0.0236,      0.0220,      0.0126,\n",
      "            -0.0011,      0.0098,     -0.0105,     -0.0017,      0.0355,\n",
      "             0.0181,     -0.0231,     -0.0101,      0.0289,      0.0310,\n",
      "             0.0286,     -0.0066,      0.0137,     -0.0301,      0.0265,\n",
      "             0.0066,     -0.0091,      0.0212,     -0.0354,     -0.0300,\n",
      "            -0.0167,      0.0340,      0.0177,      0.0102,     -0.0354,\n",
      "            -0.0308,      0.0337,      0.0346,     -0.0331,      0.0295,\n",
      "             0.0257,      0.0154,      0.0131,     -0.0110,      0.0163,\n",
      "            -0.0222,     -0.0040,      0.0146,      0.0302,      0.0068,\n",
      "            -0.0279,      0.0325,     -0.0243,     -0.0247,      0.0036,\n",
      "             0.0049,     -0.0213,     -0.0225,     -0.0048,     -0.0309,\n",
      "             0.0189,      0.0359,     -0.0223,      0.0006,      0.0206,\n",
      "             0.0292,     -0.0064,      0.0200,     -0.0093,     -0.0321,\n",
      "             0.0029,     -0.0294,     -0.0102,     -0.0010,     -0.0080,\n",
      "            -0.0207,      0.0253,     -0.0250,      0.0008,     -0.0131,\n",
      "             0.0021,      0.0124,      0.0251,     -0.0254,      0.0280,\n",
      "            -0.0120,     -0.0081,      0.0238,     -0.0223,      0.0353,\n",
      "            -0.0305,      0.0266,      0.0070,     -0.0041,      0.0155,\n",
      "             0.0072,     -0.0049,     -0.0133,     -0.0174,      0.0321,\n",
      "            -0.0094,      0.0337,     -0.0145,      0.0075,     -0.0181,\n",
      "             0.0306,     -0.0024,     -0.0099,     -0.0176,      0.0092,\n",
      "            -0.0214,      0.0223,     -0.0294,     -0.0278,      0.0268,\n",
      "             0.0240,     -0.0307,     -0.0054,     -0.0004,      0.0245,\n",
      "             0.0192,      0.0326,     -0.0121,     -0.0172,      0.0092,\n",
      "            -0.0292,     -0.0046,      0.0166,     -0.0315,      0.0126,\n",
      "            -0.0096,     -0.0033,     -0.0200,      0.0045,     -0.0143,\n",
      "             0.0255,      0.0013,      0.0195,      0.0195,      0.0029,\n",
      "            -0.0179,      0.0275,      0.0293,      0.0040,     -0.0167,\n",
      "            -0.0018,      0.0108,      0.0212,     -0.0240,      0.0196,\n",
      "             0.0200,     -0.0278,     -0.0321,      0.0281,     -0.0159,\n",
      "             0.0291,     -0.0178,     -0.0242,      0.0124,      0.0310,\n",
      "            -0.0157,      0.0115,      0.0319,     -0.0239,     -0.0255,\n",
      "            -0.0196,     -0.0313,      0.0323,      0.0129,     -0.0350,\n",
      "            -0.0173,     -0.0304,      0.0212,      0.0154,      0.0138,\n",
      "            -0.0122,      0.0119,     -0.0003,      0.0219,     -0.0037,\n",
      "            -0.0281,     -0.0290,      0.0192,      0.0311,      0.0356,\n",
      "            -0.0351,      0.0225,      0.0306,      0.0266,      0.0155,\n",
      "            -0.0355,      0.0034,     -0.0283,     -0.0219,      0.0360,\n",
      "            -0.0056,     -0.0140,     -0.0219,      0.0191,     -0.0272,\n",
      "            -0.0306,     -0.0046,     -0.0154,     -0.0149,     -0.0167,\n",
      "            -0.0003,     -0.0100,      0.0014,     -0.0079,     -0.0041,\n",
      "            -0.0037,      0.0100,      0.0291,     -0.0320,     -0.0161,\n",
      "             0.0328,     -0.0115,     -0.0260,      0.0162,     -0.0241,\n",
      "             0.0342,      0.0027,     -0.0285,     -0.0038,     -0.0123,\n",
      "            -0.0030,     -0.0153,     -0.0007,     -0.0076,      0.0245,\n",
      "             0.0159,      0.0259,      0.0057,      0.0215,      0.0219,\n",
      "             0.0310,     -0.0024,      0.0153,      0.0160,      0.0061,\n",
      "             0.0136,     -0.0044,     -0.0046,      0.0275,      0.0336,\n",
      "            -0.0020,      0.0062,     -0.0039,      0.0290,     -0.0187,\n",
      "            -0.0067,     -0.0347,     -0.0116,      0.0042,      0.0296,\n",
      "             0.0036,      0.0082,      0.0131,      0.0180,     -0.0274,\n",
      "            -0.0104,      0.0224,      0.0113,     -0.0006,     -0.0257,\n",
      "             0.0017,     -0.0162,      0.0245,     -0.0261,     -0.0007,\n",
      "             0.0010,     -0.0309,     -0.0316,      0.0164,     -0.0035,\n",
      "            -0.0080,      0.0356,     -0.0341,     -0.0064,     -0.0225,\n",
      "            -0.0073,      0.0336,     -0.0256,     -0.0171,      0.0044,\n",
      "             0.0281,      0.0056,      0.0025,      0.0103,      0.0308,\n",
      "            -0.0071,      0.0252,      0.0091,     -0.0256,     -0.0232,\n",
      "            -0.0346,      0.0020,     -0.0000,      0.0214,     -0.0142,\n",
      "             0.0090,      0.0050,     -0.0261,      0.0076,     -0.0240,\n",
      "             0.0056,     -0.0074,      0.0075,     -0.0151,      0.0118,\n",
      "             0.0158,     -0.0108,     -0.0148,     -0.0254,      0.0175,\n",
      "             0.0097,     -0.0179,      0.0325,      0.0346,      0.0160,\n",
      "            -0.0127,     -0.0334,      0.0058,      0.0225,     -0.0306,\n",
      "             0.0269,     -0.0315,     -0.0012,     -0.0176,      0.0294,\n",
      "             0.0179,     -0.0138,     -0.0308,     -0.0233,      0.0261,\n",
      "            -0.0055,      0.0274,      0.0251,     -0.0280,     -0.0013,\n",
      "            -0.0010,      0.0243,      0.0085,      0.0305,     -0.0160,\n",
      "            -0.0134,      0.0335,     -0.0158,     -0.0284,     -0.0155,\n",
      "             0.0199,      0.0218,      0.0347,      0.0179,     -0.0146,\n",
      "            -0.0321,     -0.0192,     -0.0111,      0.0161,     -0.0051,\n",
      "            -0.0021,     -0.0015,      0.0063,      0.0127,     -0.0200,\n",
      "             0.0158,      0.0176,      0.0118,      0.0093,      0.0116,\n",
      "             0.0148,      0.0209,     -0.0123,     -0.0134,     -0.0288,\n",
      "             0.0250,      0.0065,      0.0219,     -0.0254,      0.0074,\n",
      "             0.0244,      0.0015,      0.0092,      0.0174,      0.0150,\n",
      "             0.0028,     -0.0098,      0.0156,      0.0159,      0.0337,\n",
      "             0.0056,     -0.0049,      0.0014,      0.0001,     -0.0281,\n",
      "             0.0079,     -0.0135,      0.0276,     -0.0230,      0.0186,\n",
      "             0.0122,      0.0144,     -0.0280,      0.0238,     -0.0232,\n",
      "            -0.0194,      0.0352,     -0.0290,      0.0106,      0.0064,\n",
      "            -0.0327,     -0.0124,      0.0226,     -0.0245,      0.0062,\n",
      "             0.0253,     -0.0305,      0.0319,     -0.0203,      0.0023,\n",
      "            -0.0080,     -0.0029,      0.0173,     -0.0058,      0.0236,\n",
      "             0.0242,      0.0082,     -0.0099,     -0.0129,      0.0249,\n",
      "             0.0149,     -0.0178,      0.0298,      0.0129,      0.0132,\n",
      "            -0.0302,      0.0294,     -0.0340,      0.0078,      0.0080,\n",
      "             0.0015,      0.0116,     -0.0350,      0.0335,     -0.0222,\n",
      "             0.0137,     -0.0103,     -0.0098,     -0.0229,      0.0258,\n",
      "             0.0353,     -0.0277,      0.0079,     -0.0041,      0.0181,\n",
      "             0.0183,     -0.0166,      0.0285,      0.0197,      0.0180,\n",
      "             0.0171,     -0.0334,      0.0287,     -0.0071,      0.0258,\n",
      "             0.0120,     -0.0354,      0.0094,     -0.0021,     -0.0343,\n",
      "             0.0247,      0.0190,     -0.0271,     -0.0359,     -0.0181,\n",
      "            -0.0137,     -0.0041,     -0.0077,      0.0110,     -0.0102,\n",
      "            -0.0314,     -0.0239,     -0.0296,     -0.0323,      0.0028,\n",
      "            -0.0231,     -0.0004,      0.0022,     -0.0047,      0.0148,\n",
      "             0.0019,      0.0107,     -0.0115,      0.0108,     -0.0319,\n",
      "             0.0267,      0.0059,      0.0138,     -0.0291,      0.0203,\n",
      "            -0.0273,     -0.0318,      0.0233,     -0.0265,      0.0326,\n",
      "            -0.0031,      0.0159,     -0.0216,      0.0359,     -0.0022,\n",
      "             0.0277,      0.0145,      0.0356], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0263, -0.0085,  0.0156,  ..., -0.0102,  0.0098,  0.0053],\n",
      "        [-0.0331, -0.0311, -0.0302,  ...,  0.0282, -0.0352, -0.0304],\n",
      "        [-0.0309, -0.0252, -0.0187,  ..., -0.0050,  0.0203,  0.0302],\n",
      "        ...,\n",
      "        [-0.0118,  0.0278, -0.0050,  ...,  0.0131,  0.0238,  0.0254],\n",
      "        [-0.0358, -0.0178,  0.0227,  ...,  0.0122,  0.0353,  0.0335],\n",
      "        [-0.0094, -0.0200, -0.0057,  ...,  0.0249,  0.0136,  0.0250]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0134, -0.0050,  0.0184,  ...,  0.0262,  0.0082, -0.0232],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0159,  0.0147,  0.0165,  ..., -0.0133, -0.0051,  0.0016],\n",
      "        [ 0.0150, -0.0113,  0.0153,  ...,  0.0161,  0.0108,  0.0079],\n",
      "        [-0.0134, -0.0036,  0.0033,  ...,  0.0097,  0.0169, -0.0057],\n",
      "        ...,\n",
      "        [-0.0177,  0.0007, -0.0178,  ..., -0.0040,  0.0030, -0.0156],\n",
      "        [-0.0026, -0.0098,  0.0027,  ..., -0.0051, -0.0070, -0.0147],\n",
      "        [-0.0102, -0.0044,  0.0093,  ...,  0.0076,  0.0115,  0.0051]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([     0.0040,     -0.0018,      0.0062,      0.0004,      0.0039,\n",
      "             0.0179,     -0.0069,      0.0093,     -0.0133,      0.0080,\n",
      "             0.0088,      0.0147,      0.0007,      0.0116,      0.0112,\n",
      "            -0.0026,     -0.0072,      0.0005,      0.0107,     -0.0025,\n",
      "            -0.0061,     -0.0057,     -0.0139,      0.0147,      0.0026,\n",
      "             0.0170,     -0.0125,      0.0067,     -0.0092,     -0.0016,\n",
      "            -0.0092,     -0.0001,      0.0051,      0.0075,      0.0090,\n",
      "            -0.0083,      0.0068,     -0.0107,     -0.0039,      0.0137,\n",
      "            -0.0090,     -0.0079,      0.0050,      0.0076,     -0.0020,\n",
      "            -0.0073,      0.0084,     -0.0060,      0.0074,     -0.0024,\n",
      "            -0.0098,      0.0164,     -0.0000,      0.0124,     -0.0155,\n",
      "             0.0062,     -0.0169,      0.0118,     -0.0128,      0.0006,\n",
      "             0.0080,     -0.0147,     -0.0061,      0.0129,      0.0052,\n",
      "             0.0115,     -0.0124,     -0.0067,     -0.0098,     -0.0110,\n",
      "            -0.0150,      0.0161,      0.0102,      0.0177,      0.0044,\n",
      "            -0.0069,     -0.0161,      0.0125,      0.0077,      0.0013,\n",
      "            -0.0134,     -0.0083,      0.0167,      0.0005,     -0.0013,\n",
      "            -0.0068,      0.0081,      0.0122,      0.0129,      0.0003,\n",
      "            -0.0047,      0.0130,      0.0068,      0.0118,      0.0065,\n",
      "             0.0089,      0.0161,      0.0152,     -0.0163,      0.0049,\n",
      "             0.0179,      0.0171,     -0.0088,     -0.0081,      0.0041,\n",
      "            -0.0058,     -0.0010,     -0.0126,     -0.0133,     -0.0001,\n",
      "            -0.0131,      0.0060,      0.0131,     -0.0024,      0.0176,\n",
      "             0.0075,     -0.0108,     -0.0057,     -0.0146,      0.0064,\n",
      "             0.0089,     -0.0049,     -0.0158,      0.0012,      0.0105,\n",
      "            -0.0089,     -0.0101,     -0.0167,      0.0142,     -0.0145,\n",
      "            -0.0148,     -0.0016,      0.0112,      0.0133,     -0.0000,\n",
      "             0.0160,      0.0141,      0.0167,      0.0069,      0.0013,\n",
      "            -0.0064,     -0.0101,     -0.0049,     -0.0143,      0.0131,\n",
      "             0.0068,     -0.0119,     -0.0083,      0.0105,      0.0163,\n",
      "             0.0165,     -0.0098,      0.0011,      0.0038,     -0.0087,\n",
      "             0.0024,      0.0024,      0.0005,     -0.0038,     -0.0043,\n",
      "             0.0051,     -0.0164,     -0.0010,     -0.0179,      0.0087,\n",
      "             0.0158,     -0.0162,     -0.0091,     -0.0074,     -0.0112,\n",
      "            -0.0154,     -0.0154,     -0.0139,     -0.0093,      0.0034,\n",
      "             0.0121,     -0.0106,      0.0149,      0.0010,     -0.0067,\n",
      "            -0.0099,      0.0039,      0.0171,     -0.0120,     -0.0149,\n",
      "             0.0021,     -0.0101,      0.0039,      0.0003,      0.0150,\n",
      "            -0.0112,     -0.0112,      0.0101,      0.0035,      0.0002,\n",
      "             0.0085,      0.0104,      0.0116,      0.0097,     -0.0045,\n",
      "             0.0025,     -0.0084,      0.0143,      0.0125,     -0.0142,\n",
      "            -0.0176,      0.0129,     -0.0126,      0.0131,      0.0050,\n",
      "             0.0101,     -0.0017,      0.0074,     -0.0153,     -0.0087,\n",
      "             0.0047,      0.0163,      0.0109,     -0.0146,     -0.0112,\n",
      "             0.0054,     -0.0163,     -0.0073,     -0.0074,     -0.0092,\n",
      "            -0.0073,      0.0044,     -0.0118,     -0.0019,     -0.0120,\n",
      "             0.0145,      0.0034,      0.0037,      0.0175,      0.0080,\n",
      "            -0.0111,     -0.0166,      0.0033,     -0.0158,      0.0175,\n",
      "            -0.0051,     -0.0055,     -0.0174,      0.0058,     -0.0164,\n",
      "             0.0152,     -0.0144,     -0.0168,     -0.0138,     -0.0112,\n",
      "             0.0085,      0.0105,     -0.0036,     -0.0083,     -0.0172,\n",
      "             0.0164,      0.0016,      0.0119,     -0.0158,      0.0112,\n",
      "            -0.0170,     -0.0124,      0.0097,      0.0022,     -0.0097,\n",
      "            -0.0035,      0.0179,     -0.0113,      0.0075,     -0.0152,\n",
      "             0.0180,     -0.0130,      0.0072,      0.0130,     -0.0177,\n",
      "             0.0137,      0.0130,     -0.0176,      0.0086,      0.0080,\n",
      "             0.0172,     -0.0125,     -0.0013,      0.0128,     -0.0145,\n",
      "             0.0165,     -0.0115,     -0.0165,      0.0006,      0.0180,\n",
      "             0.0036,     -0.0080,     -0.0026,      0.0133,      0.0026,\n",
      "             0.0088,      0.0151,      0.0131,      0.0040,     -0.0100,\n",
      "            -0.0130,      0.0154,     -0.0152,      0.0100,      0.0122,\n",
      "             0.0079,      0.0134,      0.0141,      0.0116,      0.0134,\n",
      "            -0.0146,      0.0135,     -0.0143,     -0.0098,     -0.0177,\n",
      "             0.0171,     -0.0083,     -0.0099,      0.0178,     -0.0093,\n",
      "            -0.0105,      0.0019,     -0.0001,      0.0128,      0.0179,\n",
      "            -0.0105,     -0.0047,     -0.0175,     -0.0008,     -0.0085,\n",
      "            -0.0038,     -0.0027,      0.0076,      0.0028,      0.0138,\n",
      "             0.0063,     -0.0100,      0.0005,      0.0050,     -0.0179,\n",
      "            -0.0161,     -0.0165,     -0.0014,     -0.0029,      0.0078,\n",
      "            -0.0146,      0.0058,     -0.0039,     -0.0080,     -0.0130,\n",
      "             0.0093,     -0.0062,      0.0072,      0.0169,     -0.0077,\n",
      "             0.0127,     -0.0009,     -0.0166,      0.0056,      0.0018,\n",
      "            -0.0019,     -0.0032,     -0.0153,      0.0053,      0.0087,\n",
      "            -0.0013,      0.0057,      0.0155,     -0.0041,      0.0046,\n",
      "            -0.0100,      0.0017,     -0.0055,     -0.0146,     -0.0105,\n",
      "            -0.0067,      0.0026,     -0.0150,     -0.0088,     -0.0175,\n",
      "             0.0022,      0.0044,     -0.0147,      0.0074,     -0.0010,\n",
      "             0.0039,     -0.0090,      0.0137,      0.0028,     -0.0139,\n",
      "            -0.0149,      0.0180,     -0.0032,     -0.0078,     -0.0002,\n",
      "            -0.0098,      0.0055,      0.0057,     -0.0039,     -0.0055,\n",
      "            -0.0009,     -0.0157,     -0.0057,     -0.0001,     -0.0149,\n",
      "             0.0171,      0.0080,      0.0007,      0.0032,      0.0142,\n",
      "             0.0012,      0.0008,      0.0152,      0.0072,      0.0064,\n",
      "             0.0131,      0.0034,      0.0165,      0.0133,      0.0155,\n",
      "            -0.0079,      0.0084,     -0.0038,      0.0156,     -0.0114,\n",
      "             0.0160,     -0.0097,      0.0060,     -0.0094,     -0.0036,\n",
      "             0.0122,     -0.0173,     -0.0112,      0.0127,     -0.0061,\n",
      "            -0.0126,     -0.0024,     -0.0018,      0.0111,      0.0104,\n",
      "             0.0109,      0.0031,      0.0056,      0.0149,      0.0095,\n",
      "             0.0163,     -0.0036,     -0.0104,     -0.0007,      0.0075,\n",
      "             0.0180,     -0.0120,     -0.0101,      0.0161,      0.0045,\n",
      "             0.0035,     -0.0068,     -0.0161,      0.0079,      0.0091,\n",
      "            -0.0008,     -0.0138,     -0.0145,     -0.0029,     -0.0172,\n",
      "            -0.0137,     -0.0144,     -0.0003,      0.0105,     -0.0149,\n",
      "            -0.0179,     -0.0094,     -0.0101,      0.0099,     -0.0094,\n",
      "             0.0089,     -0.0162,      0.0037,     -0.0158,     -0.0024,\n",
      "             0.0067,      0.0153,      0.0180,      0.0091,      0.0062,\n",
      "            -0.0092,      0.0062,     -0.0174,     -0.0043,     -0.0004,\n",
      "             0.0175,      0.0120,     -0.0068,      0.0140,      0.0002,\n",
      "             0.0050,     -0.0071,     -0.0116,      0.0044,     -0.0029,\n",
      "             0.0112,     -0.0097,      0.0078,      0.0063,     -0.0151,\n",
      "            -0.0004,     -0.0100,      0.0093,     -0.0029,      0.0047,\n",
      "             0.0174,      0.0083,      0.0094,     -0.0167,     -0.0050,\n",
      "            -0.0084,     -0.0041,     -0.0004,     -0.0147,     -0.0066,\n",
      "            -0.0063,      0.0141,     -0.0053,      0.0170,     -0.0120,\n",
      "            -0.0056,     -0.0130,     -0.0044,     -0.0161,      0.0138,\n",
      "            -0.0070,      0.0040,      0.0040,      0.0099,      0.0069,\n",
      "             0.0136,      0.0050,     -0.0002,     -0.0119,     -0.0010,\n",
      "             0.0146,     -0.0051,     -0.0172,     -0.0009,     -0.0059,\n",
      "            -0.0032,     -0.0055,     -0.0060,     -0.0057,     -0.0027,\n",
      "             0.0149,     -0.0020,     -0.0009,      0.0055,      0.0047,\n",
      "             0.0024,      0.0041,     -0.0152,      0.0032,      0.0028,\n",
      "             0.0147,      0.0172,      0.0164,     -0.0166,      0.0144,\n",
      "             0.0163,     -0.0070,      0.0070,      0.0080,      0.0168,\n",
      "             0.0082,      0.0095,     -0.0133,     -0.0099,      0.0036,\n",
      "            -0.0170,      0.0047,      0.0127,      0.0153,      0.0017,\n",
      "             0.0033,     -0.0071,      0.0109,      0.0066,     -0.0151,\n",
      "             0.0053,      0.0180,      0.0075,      0.0174,     -0.0140,\n",
      "            -0.0136,      0.0161,      0.0001,     -0.0151,     -0.0010,\n",
      "            -0.0086,     -0.0109,      0.0056,     -0.0010,      0.0164,\n",
      "             0.0087,      0.0073,      0.0160,     -0.0123,     -0.0085,\n",
      "             0.0051,      0.0037,      0.0084,      0.0081,     -0.0037,\n",
      "            -0.0086,      0.0094,      0.0011,      0.0111,      0.0145,\n",
      "             0.0098,      0.0036,     -0.0129,     -0.0024,      0.0121,\n",
      "            -0.0028,     -0.0157,      0.0079,      0.0051,      0.0097,\n",
      "             0.0069,     -0.0013,     -0.0024,      0.0136,     -0.0046,\n",
      "             0.0019,      0.0074,      0.0158,     -0.0121,     -0.0080,\n",
      "             0.0083,      0.0080,      0.0035,     -0.0049,     -0.0100,\n",
      "            -0.0151,      0.0144,     -0.0111,      0.0000,     -0.0048,\n",
      "            -0.0108,     -0.0157,      0.0133,     -0.0087,      0.0055,\n",
      "             0.0092,      0.0162,     -0.0048,     -0.0143,      0.0000,\n",
      "            -0.0000,      0.0073,     -0.0061,      0.0095,     -0.0050,\n",
      "             0.0177,      0.0044,     -0.0007,      0.0160,      0.0006,\n",
      "            -0.0138,      0.0033,      0.0113,     -0.0078,     -0.0020,\n",
      "            -0.0000,      0.0046,     -0.0064,      0.0028,     -0.0137,\n",
      "            -0.0144,     -0.0155,      0.0131,     -0.0132,     -0.0102,\n",
      "             0.0069,      0.0172,      0.0036,     -0.0118,     -0.0155,\n",
      "            -0.0125,     -0.0106,      0.0056,      0.0085,     -0.0089,\n",
      "            -0.0058,      0.0029,     -0.0047,      0.0049,      0.0140,\n",
      "             0.0084,     -0.0064,      0.0040,     -0.0051,      0.0165,\n",
      "            -0.0079,     -0.0145,     -0.0152,      0.0082,     -0.0147,\n",
      "             0.0062,      0.0104,      0.0095,     -0.0024,     -0.0057,\n",
      "             0.0116,     -0.0016,     -0.0172,      0.0001,      0.0096,\n",
      "             0.0008,      0.0038,      0.0038,     -0.0118,      0.0158,\n",
      "            -0.0032,      0.0165,      0.0018,      0.0161,      0.0082,\n",
      "             0.0014,      0.0003,     -0.0072,     -0.0026,     -0.0113,\n",
      "             0.0150,     -0.0066,     -0.0011,     -0.0079,      0.0001,\n",
      "             0.0032,     -0.0045,      0.0074,     -0.0140,     -0.0113,\n",
      "            -0.0071,     -0.0132,     -0.0041,      0.0016,      0.0118,\n",
      "             0.0103,      0.0019,     -0.0024,     -0.0098,     -0.0168,\n",
      "             0.0136,     -0.0011,     -0.0009,      0.0134,      0.0009,\n",
      "             0.0052,     -0.0152,      0.0077,      0.0153,     -0.0084,\n",
      "             0.0151,     -0.0123,      0.0026,     -0.0114,     -0.0092,\n",
      "             0.0175,     -0.0024,     -0.0019], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0267, -0.0241, -0.0047,  ...,  0.0353,  0.0001, -0.0324],\n",
      "        [ 0.0244,  0.0179, -0.0080,  ...,  0.0357, -0.0134, -0.0182],\n",
      "        [-0.0348, -0.0255,  0.0295,  ...,  0.0307, -0.0291, -0.0337],\n",
      "        ...,\n",
      "        [-0.0060,  0.0057,  0.0321,  ...,  0.0144,  0.0184,  0.0345],\n",
      "        [-0.0305, -0.0261, -0.0274,  ...,  0.0226, -0.0161, -0.0217],\n",
      "        [ 0.0106,  0.0008,  0.0081,  ..., -0.0345, -0.0007,  0.0313]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0091, -0.0291, -0.0291,  ..., -0.0319,  0.0028, -0.0041],\n",
      "        [ 0.0341,  0.0066, -0.0184,  ...,  0.0033,  0.0324,  0.0202],\n",
      "        [-0.0153,  0.0086,  0.0200,  ..., -0.0089, -0.0207, -0.0193],\n",
      "        ...,\n",
      "        [ 0.0264, -0.0083,  0.0298,  ..., -0.0010, -0.0352,  0.0061],\n",
      "        [-0.0309,  0.0348, -0.0241,  ...,  0.0180,  0.0342, -0.0249],\n",
      "        [ 0.0211, -0.0018,  0.0169,  ..., -0.0175, -0.0210, -0.0135]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0135, -0.0099,  0.0116,  ...,  0.0176,  0.0195,  0.0209],\n",
      "        [-0.0123, -0.0190, -0.0011,  ..., -0.0018,  0.0128,  0.0140],\n",
      "        [-0.0054, -0.0165, -0.0340,  ..., -0.0048, -0.0305,  0.0310],\n",
      "        ...,\n",
      "        [-0.0265, -0.0210,  0.0150,  ..., -0.0166,  0.0277, -0.0233],\n",
      "        [-0.0118, -0.0217,  0.0245,  ...,  0.0225, -0.0325,  0.0343],\n",
      "        [-0.0253, -0.0156, -0.0124,  ...,  0.0104, -0.0250,  0.0313]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0057, -0.0111, -0.0034,  ...,  0.0313, -0.0079,  0.0130],\n",
      "        [ 0.0230, -0.0054,  0.0059,  ...,  0.0126, -0.0104,  0.0294],\n",
      "        [-0.0120,  0.0288,  0.0287,  ..., -0.0297, -0.0199,  0.0004],\n",
      "        ...,\n",
      "        [ 0.0209,  0.0216,  0.0117,  ..., -0.0160, -0.0330, -0.0244],\n",
      "        [-0.0142, -0.0260,  0.0244,  ..., -0.0011,  0.0302,  0.0045],\n",
      "        [ 0.0221, -0.0339, -0.0285,  ...,  0.0339,  0.0280,  0.0264]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([    -0.0334,      0.0206,     -0.0180,      0.0151,     -0.0049,\n",
      "             0.0112,     -0.0173,     -0.0258,     -0.0109,     -0.0241,\n",
      "            -0.0141,     -0.0177,      0.0084,      0.0184,     -0.0104,\n",
      "            -0.0132,     -0.0160,      0.0018,      0.0087,      0.0312,\n",
      "            -0.0285,     -0.0254,     -0.0291,     -0.0199,     -0.0228,\n",
      "             0.0260,     -0.0246,      0.0220,      0.0288,     -0.0092,\n",
      "            -0.0187,     -0.0254,      0.0271,     -0.0273,      0.0152,\n",
      "             0.0307,     -0.0226,      0.0037,     -0.0296,     -0.0195,\n",
      "            -0.0283,     -0.0337,      0.0292,     -0.0347,     -0.0076,\n",
      "            -0.0147,     -0.0299,      0.0167,     -0.0196,     -0.0256,\n",
      "            -0.0075,     -0.0040,      0.0069,     -0.0067,      0.0151,\n",
      "            -0.0261,      0.0239,      0.0039,      0.0301,     -0.0134,\n",
      "             0.0221,      0.0324,      0.0130,      0.0274,     -0.0335,\n",
      "            -0.0251,     -0.0267,     -0.0020,      0.0246,     -0.0149,\n",
      "             0.0135,      0.0242,      0.0066,      0.0248,     -0.0193,\n",
      "            -0.0063,      0.0163,      0.0090,      0.0206,     -0.0226,\n",
      "            -0.0027,      0.0124,     -0.0309,     -0.0290,     -0.0032,\n",
      "             0.0191,     -0.0284,      0.0214,      0.0163,      0.0251,\n",
      "            -0.0261,      0.0126,     -0.0146,      0.0220,     -0.0356,\n",
      "             0.0037,      0.0082,     -0.0331,      0.0070,      0.0358,\n",
      "            -0.0189,      0.0281,      0.0028,      0.0256,      0.0263,\n",
      "            -0.0127,     -0.0278,      0.0333,     -0.0070,     -0.0284,\n",
      "            -0.0024,     -0.0327,     -0.0209,      0.0353,     -0.0299,\n",
      "             0.0239,      0.0030,     -0.0155,     -0.0191,      0.0333,\n",
      "            -0.0080,     -0.0168,     -0.0102,      0.0154,     -0.0053,\n",
      "            -0.0090,      0.0307,      0.0352,     -0.0232,     -0.0063,\n",
      "             0.0296,      0.0174,     -0.0219,      0.0247,     -0.0283,\n",
      "            -0.0184,     -0.0249,     -0.0052,      0.0167,      0.0087,\n",
      "            -0.0002,     -0.0075,     -0.0157,     -0.0153,     -0.0106,\n",
      "            -0.0002,      0.0108,      0.0147,     -0.0101,      0.0066,\n",
      "            -0.0156,      0.0021,      0.0136,      0.0160,     -0.0020,\n",
      "            -0.0077,     -0.0056,     -0.0006,      0.0093,      0.0296,\n",
      "            -0.0154,      0.0143,      0.0196,     -0.0127,      0.0162,\n",
      "             0.0210,      0.0215,      0.0258,     -0.0342,      0.0155,\n",
      "            -0.0007,      0.0260,     -0.0068,      0.0079,      0.0077,\n",
      "            -0.0159,     -0.0250,     -0.0114,     -0.0260,      0.0271,\n",
      "             0.0173,     -0.0123,      0.0308,      0.0297,      0.0286,\n",
      "             0.0322,      0.0223,     -0.0296,      0.0036,      0.0275,\n",
      "            -0.0311,      0.0260,     -0.0205,     -0.0200,     -0.0142,\n",
      "             0.0314,     -0.0074,     -0.0018,     -0.0268,     -0.0129,\n",
      "            -0.0154,     -0.0151,     -0.0246,     -0.0010,     -0.0095,\n",
      "            -0.0056,      0.0133,      0.0058,     -0.0342,     -0.0155,\n",
      "            -0.0296,     -0.0072,      0.0310,     -0.0070,     -0.0196,\n",
      "            -0.0318,      0.0048,      0.0327,     -0.0306,      0.0293,\n",
      "            -0.0094,     -0.0100,     -0.0138,      0.0083,      0.0040,\n",
      "             0.0233,      0.0316,      0.0282,     -0.0352,      0.0276,\n",
      "            -0.0349,     -0.0128,     -0.0294,      0.0266,      0.0255,\n",
      "             0.0146,     -0.0020,     -0.0046,      0.0237,      0.0164,\n",
      "             0.0157,      0.0313,      0.0235,     -0.0171,      0.0329,\n",
      "            -0.0048,      0.0016,     -0.0177,     -0.0301,     -0.0077,\n",
      "             0.0310,      0.0223,     -0.0273,     -0.0313,     -0.0028,\n",
      "            -0.0088,      0.0126,      0.0100,     -0.0316,      0.0140,\n",
      "            -0.0249,      0.0008,      0.0221,      0.0299,     -0.0055,\n",
      "            -0.0270,     -0.0083,      0.0127,      0.0111,     -0.0139,\n",
      "            -0.0339,      0.0312,     -0.0112,      0.0169,      0.0090,\n",
      "            -0.0164,      0.0209,     -0.0247,     -0.0155,      0.0174,\n",
      "            -0.0323,      0.0030,     -0.0350,      0.0079,     -0.0084,\n",
      "            -0.0209,      0.0044,     -0.0280,     -0.0037,      0.0292,\n",
      "             0.0258,      0.0331,      0.0298,     -0.0066,     -0.0222,\n",
      "            -0.0351,      0.0286,      0.0108,     -0.0220,     -0.0224,\n",
      "             0.0274,      0.0190,      0.0054,      0.0192,      0.0172,\n",
      "            -0.0020,     -0.0350,     -0.0319,     -0.0299,     -0.0108,\n",
      "            -0.0247,     -0.0308,      0.0211,     -0.0336,     -0.0074,\n",
      "            -0.0238,     -0.0026,     -0.0306,      0.0046,     -0.0234,\n",
      "            -0.0249,     -0.0031,      0.0214,      0.0111,     -0.0115,\n",
      "            -0.0352,      0.0002,      0.0161,     -0.0321,      0.0129,\n",
      "            -0.0076,      0.0303,     -0.0149,     -0.0037,      0.0035,\n",
      "             0.0099,     -0.0057,      0.0273,      0.0035,     -0.0235,\n",
      "            -0.0358,     -0.0248,      0.0006,      0.0199,      0.0251,\n",
      "            -0.0151,     -0.0068,      0.0227,      0.0328,     -0.0310,\n",
      "            -0.0353,      0.0089,     -0.0124,      0.0319,      0.0218,\n",
      "            -0.0214,     -0.0096,      0.0044,     -0.0051,     -0.0190,\n",
      "             0.0212,      0.0068,     -0.0139,      0.0038,      0.0108,\n",
      "            -0.0062,     -0.0034,      0.0180,      0.0059,      0.0257,\n",
      "            -0.0326,      0.0161,      0.0120,     -0.0239,     -0.0285,\n",
      "            -0.0088,     -0.0135,      0.0307,      0.0029,     -0.0031,\n",
      "             0.0236,     -0.0183,      0.0094,      0.0188,     -0.0072,\n",
      "             0.0047,     -0.0309,     -0.0354,      0.0063,     -0.0039,\n",
      "            -0.0360,     -0.0243,     -0.0098,     -0.0142,      0.0250,\n",
      "            -0.0159,      0.0000,     -0.0054,     -0.0280,      0.0085,\n",
      "             0.0185,      0.0283,      0.0063,     -0.0248,      0.0258,\n",
      "             0.0165,      0.0134,     -0.0040,     -0.0171,      0.0259,\n",
      "             0.0170,      0.0276,      0.0021,     -0.0081,      0.0114,\n",
      "            -0.0167,      0.0089,      0.0297,     -0.0146,     -0.0209,\n",
      "            -0.0001,      0.0218,     -0.0051,     -0.0288,     -0.0090,\n",
      "             0.0160,     -0.0340,      0.0085,     -0.0231,     -0.0238,\n",
      "            -0.0276,      0.0337,      0.0126,      0.0089,     -0.0061,\n",
      "             0.0155,     -0.0037,     -0.0041,      0.0339,      0.0287,\n",
      "            -0.0306,      0.0012,      0.0253,      0.0304,      0.0301,\n",
      "            -0.0124,      0.0038,     -0.0244,     -0.0118,      0.0165,\n",
      "             0.0055,      0.0274,     -0.0273,     -0.0090,      0.0334,\n",
      "            -0.0326,     -0.0299,     -0.0014,      0.0209,     -0.0294,\n",
      "            -0.0222,      0.0092,     -0.0076,     -0.0175,      0.0306,\n",
      "             0.0106,      0.0041,      0.0107,      0.0264,      0.0078,\n",
      "             0.0215,      0.0300,     -0.0211,     -0.0347,     -0.0221,\n",
      "            -0.0324,      0.0217,     -0.0194,      0.0285,      0.0272,\n",
      "             0.0219,      0.0298,     -0.0348,     -0.0085,     -0.0279,\n",
      "             0.0071,     -0.0271,      0.0113,     -0.0162,     -0.0087,\n",
      "             0.0199,     -0.0316,     -0.0144,      0.0326,      0.0314,\n",
      "             0.0306,      0.0154,     -0.0204,      0.0322,     -0.0047,\n",
      "            -0.0309,     -0.0180,     -0.0155,     -0.0198,     -0.0164,\n",
      "            -0.0315,     -0.0273,     -0.0358,      0.0107,      0.0210,\n",
      "             0.0190,      0.0353,      0.0149,      0.0235,     -0.0039,\n",
      "            -0.0140,     -0.0086,     -0.0029,     -0.0182,     -0.0328,\n",
      "            -0.0346,     -0.0013,     -0.0344,      0.0086,     -0.0136,\n",
      "            -0.0233,     -0.0001,     -0.0140,      0.0195,      0.0125,\n",
      "            -0.0062,     -0.0308,     -0.0012,      0.0320,     -0.0235,\n",
      "            -0.0215,     -0.0210,      0.0262,      0.0096,     -0.0137,\n",
      "            -0.0170,      0.0316,      0.0107,     -0.0323,      0.0019,\n",
      "            -0.0212,      0.0180,      0.0208,      0.0338,      0.0345,\n",
      "             0.0343,     -0.0090,      0.0093,     -0.0257,     -0.0171,\n",
      "            -0.0210,      0.0075,     -0.0266,      0.0083,     -0.0029,\n",
      "            -0.0102,     -0.0186,     -0.0206,     -0.0302,     -0.0300,\n",
      "             0.0341,      0.0006,     -0.0178,      0.0076,     -0.0108,\n",
      "             0.0327,     -0.0118,     -0.0298,     -0.0223,      0.0219,\n",
      "            -0.0334,     -0.0356,      0.0270,      0.0197,      0.0166,\n",
      "             0.0334,      0.0153,     -0.0121,      0.0142,      0.0290,\n",
      "            -0.0097,     -0.0155,      0.0334,      0.0018,     -0.0214,\n",
      "             0.0234,      0.0085,     -0.0296,      0.0305,      0.0136,\n",
      "             0.0190,     -0.0011,     -0.0081,     -0.0038,     -0.0324,\n",
      "            -0.0271,     -0.0066,     -0.0227,     -0.0344,      0.0250,\n",
      "            -0.0324,     -0.0252,      0.0220,     -0.0319,     -0.0176,\n",
      "             0.0216,      0.0099,     -0.0245,      0.0148,      0.0203,\n",
      "            -0.0151,     -0.0038,      0.0060,     -0.0168,     -0.0165,\n",
      "            -0.0041,      0.0138,     -0.0252,     -0.0315,      0.0198,\n",
      "             0.0099,      0.0077,     -0.0289,     -0.0101,     -0.0314,\n",
      "            -0.0064,      0.0188,     -0.0033,     -0.0185,     -0.0241,\n",
      "            -0.0221,     -0.0223,      0.0216,      0.0134,      0.0224,\n",
      "            -0.0261,     -0.0141,     -0.0158,      0.0194,     -0.0210,\n",
      "            -0.0128,     -0.0344,     -0.0088,     -0.0061,      0.0011,\n",
      "            -0.0157,      0.0219,      0.0199,      0.0142,     -0.0046,\n",
      "            -0.0065,     -0.0272,     -0.0280,      0.0045,     -0.0098,\n",
      "             0.0198,     -0.0287,      0.0282,      0.0266,      0.0050,\n",
      "            -0.0067,     -0.0080,     -0.0280,     -0.0356,     -0.0088,\n",
      "            -0.0038,     -0.0201,     -0.0055,     -0.0285,      0.0106,\n",
      "             0.0021,     -0.0274,      0.0225,     -0.0340,      0.0065,\n",
      "             0.0087,     -0.0071,     -0.0160,      0.0032,      0.0141,\n",
      "            -0.0294,     -0.0128,      0.0066,      0.0296,      0.0049,\n",
      "            -0.0229,      0.0048,      0.0016,      0.0038,     -0.0136,\n",
      "            -0.0081,      0.0119,      0.0300,      0.0356,      0.0198,\n",
      "             0.0098,      0.0215,     -0.0238,      0.0089,      0.0212,\n",
      "             0.0109,      0.0217,     -0.0019,      0.0350,     -0.0118,\n",
      "             0.0260,      0.0134,      0.0068,      0.0114,      0.0154,\n",
      "            -0.0054,      0.0148,     -0.0240,     -0.0013,      0.0045,\n",
      "            -0.0306,     -0.0117,      0.0030,     -0.0149,     -0.0267,\n",
      "            -0.0016,      0.0057,     -0.0075,     -0.0018,     -0.0019,\n",
      "             0.0271,      0.0096,      0.0082,     -0.0006,     -0.0330,\n",
      "            -0.0218,      0.0200,     -0.0351,     -0.0091,      0.0315,\n",
      "            -0.0071,      0.0260,     -0.0157,     -0.0165,     -0.0177,\n",
      "            -0.0024,      0.0265,     -0.0199,      0.0122,     -0.0084,\n",
      "            -0.0277,     -0.0153,      0.0025,     -0.0060,      0.0000,\n",
      "            -0.0319,     -0.0083,      0.0011,      0.0155,     -0.0260,\n",
      "            -0.0114,      0.0310,      0.0071,      0.0334,     -0.0194,\n",
      "             0.0229,      0.0100,      0.0202], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0285, -0.0039,  0.0050,  ..., -0.0018,  0.0194,  0.0350],\n",
      "        [ 0.0298,  0.0020,  0.0075,  ...,  0.0126,  0.0287, -0.0051],\n",
      "        [-0.0247, -0.0033, -0.0356,  ..., -0.0017, -0.0261,  0.0342],\n",
      "        ...,\n",
      "        [ 0.0352, -0.0341, -0.0306,  ...,  0.0176,  0.0065, -0.0023],\n",
      "        [ 0.0171, -0.0291, -0.0094,  ...,  0.0072,  0.0271, -0.0135],\n",
      "        [-0.0224, -0.0081,  0.0150,  ...,  0.0009, -0.0121,  0.0258]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0211, -0.0315, -0.0354,  ...,  0.0121,  0.0119,  0.0035],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0120, -0.0017,  0.0146,  ..., -0.0113, -0.0042,  0.0144],\n",
      "        [-0.0180, -0.0088, -0.0120,  ...,  0.0041,  0.0089, -0.0136],\n",
      "        [ 0.0135,  0.0133, -0.0013,  ...,  0.0078,  0.0106,  0.0155],\n",
      "        ...,\n",
      "        [-0.0070, -0.0075, -0.0056,  ..., -0.0062,  0.0016, -0.0100],\n",
      "        [-0.0098,  0.0012, -0.0122,  ...,  0.0170, -0.0092,  0.0004],\n",
      "        [-0.0158,  0.0120,  0.0106,  ...,  0.0079, -0.0010, -0.0050]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([     0.0170,     -0.0034,      0.0103,      0.0023,     -0.0007,\n",
      "             0.0017,     -0.0065,     -0.0150,      0.0054,     -0.0123,\n",
      "             0.0173,     -0.0014,      0.0119,     -0.0160,      0.0126,\n",
      "            -0.0123,     -0.0179,      0.0081,      0.0179,     -0.0082,\n",
      "            -0.0068,     -0.0098,      0.0047,     -0.0157,      0.0025,\n",
      "            -0.0144,     -0.0016,     -0.0148,      0.0074,      0.0150,\n",
      "            -0.0091,     -0.0038,      0.0056,     -0.0021,      0.0102,\n",
      "             0.0066,     -0.0097,     -0.0076,      0.0165,     -0.0131,\n",
      "             0.0060,      0.0075,      0.0100,     -0.0172,     -0.0003,\n",
      "            -0.0069,     -0.0019,      0.0138,      0.0030,      0.0090,\n",
      "             0.0158,     -0.0102,     -0.0004,      0.0138,      0.0056,\n",
      "            -0.0053,     -0.0158,      0.0126,     -0.0135,      0.0175,\n",
      "            -0.0098,      0.0025,      0.0151,     -0.0005,      0.0021,\n",
      "             0.0117,      0.0179,      0.0079,     -0.0038,     -0.0125,\n",
      "             0.0119,      0.0035,      0.0047,     -0.0163,     -0.0152,\n",
      "             0.0103,     -0.0023,      0.0169,      0.0110,      0.0118,\n",
      "             0.0045,     -0.0018,     -0.0064,     -0.0100,      0.0028,\n",
      "             0.0164,      0.0147,     -0.0099,      0.0157,      0.0003,\n",
      "            -0.0161,      0.0113,     -0.0046,      0.0048,      0.0125,\n",
      "            -0.0062,     -0.0022,      0.0020,     -0.0132,      0.0121,\n",
      "            -0.0081,     -0.0152,      0.0045,     -0.0054,      0.0136,\n",
      "             0.0153,      0.0171,     -0.0126,     -0.0052,     -0.0082,\n",
      "             0.0046,     -0.0080,      0.0069,     -0.0058,      0.0005,\n",
      "            -0.0099,      0.0175,      0.0082,      0.0022,     -0.0114,\n",
      "             0.0079,     -0.0108,      0.0007,     -0.0162,      0.0017,\n",
      "            -0.0097,     -0.0064,     -0.0109,     -0.0166,     -0.0071,\n",
      "             0.0059,     -0.0051,     -0.0168,     -0.0162,     -0.0091,\n",
      "             0.0066,     -0.0094,      0.0041,      0.0171,     -0.0106,\n",
      "             0.0085,     -0.0029,      0.0041,     -0.0149,     -0.0056,\n",
      "            -0.0053,      0.0159,      0.0025,     -0.0090,     -0.0038,\n",
      "            -0.0120,     -0.0175,      0.0148,      0.0060,     -0.0129,\n",
      "             0.0123,      0.0140,     -0.0151,     -0.0022,     -0.0085,\n",
      "            -0.0074,      0.0099,      0.0101,     -0.0027,      0.0117,\n",
      "            -0.0065,     -0.0139,     -0.0063,     -0.0084,     -0.0149,\n",
      "             0.0043,      0.0173,      0.0090,      0.0142,     -0.0109,\n",
      "             0.0147,     -0.0066,     -0.0136,      0.0015,      0.0099,\n",
      "            -0.0018,     -0.0067,      0.0147,      0.0036,      0.0133,\n",
      "            -0.0079,     -0.0120,     -0.0104,      0.0087,      0.0022,\n",
      "             0.0103,      0.0170,     -0.0129,     -0.0026,      0.0150,\n",
      "            -0.0055,      0.0127,      0.0048,     -0.0051,      0.0023,\n",
      "            -0.0171,     -0.0007,      0.0155,     -0.0071,      0.0150,\n",
      "             0.0125,      0.0106,      0.0162,      0.0018,      0.0065,\n",
      "            -0.0148,     -0.0149,     -0.0152,      0.0073,     -0.0005,\n",
      "             0.0114,      0.0066,     -0.0096,     -0.0148,     -0.0010,\n",
      "             0.0108,      0.0122,     -0.0146,      0.0027,      0.0063,\n",
      "             0.0106,     -0.0132,      0.0056,      0.0132,      0.0086,\n",
      "             0.0102,     -0.0125,      0.0071,      0.0130,      0.0011,\n",
      "             0.0093,     -0.0041,      0.0154,     -0.0008,      0.0105,\n",
      "            -0.0057,     -0.0146,      0.0130,     -0.0090,     -0.0014,\n",
      "            -0.0153,      0.0124,      0.0087,      0.0024,      0.0036,\n",
      "             0.0016,     -0.0150,     -0.0047,     -0.0052,     -0.0136,\n",
      "            -0.0080,     -0.0082,     -0.0060,      0.0125,     -0.0051,\n",
      "            -0.0131,     -0.0016,      0.0066,     -0.0131,      0.0139,\n",
      "            -0.0050,      0.0171,     -0.0171,     -0.0041,      0.0107,\n",
      "             0.0030,      0.0165,      0.0027,      0.0030,      0.0067,\n",
      "            -0.0036,     -0.0116,      0.0168,     -0.0173,      0.0125,\n",
      "             0.0029,     -0.0069,      0.0136,      0.0108,      0.0052,\n",
      "             0.0010,      0.0115,     -0.0069,      0.0111,     -0.0129,\n",
      "            -0.0050,     -0.0052,     -0.0155,     -0.0127,      0.0153,\n",
      "             0.0173,     -0.0179,      0.0124,     -0.0147,     -0.0033,\n",
      "            -0.0017,      0.0109,      0.0005,     -0.0152,     -0.0030,\n",
      "             0.0030,      0.0141,      0.0007,     -0.0125,      0.0161,\n",
      "             0.0010,     -0.0078,     -0.0065,     -0.0075,      0.0126,\n",
      "             0.0093,     -0.0045,      0.0105,      0.0152,     -0.0079,\n",
      "            -0.0135,      0.0101,      0.0173,     -0.0169,      0.0165,\n",
      "             0.0130,     -0.0169,      0.0059,     -0.0094,     -0.0063,\n",
      "             0.0001,     -0.0089,     -0.0119,      0.0019,     -0.0126,\n",
      "            -0.0133,     -0.0059,     -0.0071,      0.0132,      0.0125,\n",
      "            -0.0096,     -0.0053,      0.0055,     -0.0168,     -0.0118,\n",
      "            -0.0062,      0.0092,      0.0104,      0.0166,      0.0022,\n",
      "            -0.0131,     -0.0014,      0.0104,     -0.0120,     -0.0153,\n",
      "             0.0169,      0.0054,     -0.0056,     -0.0012,      0.0054,\n",
      "             0.0040,      0.0094,      0.0017,      0.0016,      0.0024,\n",
      "             0.0122,     -0.0136,     -0.0152,     -0.0061,      0.0078,\n",
      "            -0.0112,     -0.0130,     -0.0016,     -0.0001,     -0.0026,\n",
      "            -0.0069,      0.0127,      0.0048,      0.0158,      0.0127,\n",
      "             0.0031,      0.0034,      0.0069,      0.0127,     -0.0175,\n",
      "            -0.0009,      0.0086,      0.0100,     -0.0119,      0.0037,\n",
      "            -0.0035,      0.0055,     -0.0039,     -0.0125,      0.0043,\n",
      "            -0.0084,     -0.0040,     -0.0022,      0.0177,      0.0123,\n",
      "             0.0062,     -0.0152,     -0.0064,     -0.0074,      0.0140,\n",
      "             0.0112,      0.0026,      0.0012,      0.0168,     -0.0173,\n",
      "            -0.0156,     -0.0024,      0.0170,     -0.0008,     -0.0035,\n",
      "             0.0051,     -0.0007,     -0.0088,     -0.0022,     -0.0177,\n",
      "            -0.0158,      0.0048,      0.0149,     -0.0008,      0.0053,\n",
      "             0.0060,      0.0118,      0.0016,     -0.0044,     -0.0046,\n",
      "             0.0165,      0.0034,      0.0069,     -0.0114,     -0.0148,\n",
      "            -0.0007,      0.0088,     -0.0010,     -0.0053,     -0.0158,\n",
      "             0.0027,     -0.0159,     -0.0001,     -0.0070,     -0.0065,\n",
      "            -0.0018,     -0.0002,     -0.0015,      0.0027,      0.0059,\n",
      "             0.0123,     -0.0112,     -0.0067,      0.0090,      0.0048,\n",
      "             0.0021,     -0.0019,     -0.0013,     -0.0172,     -0.0170,\n",
      "             0.0046,      0.0058,     -0.0042,      0.0135,      0.0053,\n",
      "            -0.0055,      0.0133,      0.0047,      0.0074,     -0.0157,\n",
      "             0.0047,      0.0094,      0.0169,      0.0086,      0.0019,\n",
      "             0.0101,     -0.0175,     -0.0066,      0.0036,     -0.0068,\n",
      "             0.0074,     -0.0118,     -0.0176,     -0.0145,      0.0094,\n",
      "            -0.0010,      0.0053,     -0.0113,      0.0165,     -0.0069,\n",
      "            -0.0030,      0.0034,      0.0027,      0.0061,      0.0160,\n",
      "             0.0180,     -0.0046,     -0.0079,      0.0014,      0.0100,\n",
      "            -0.0032,      0.0171,     -0.0004,     -0.0069,      0.0042,\n",
      "            -0.0141,      0.0062,     -0.0103,      0.0025,      0.0063,\n",
      "             0.0046,      0.0132,     -0.0110,      0.0072,      0.0069,\n",
      "             0.0017,     -0.0035,      0.0034,     -0.0124,     -0.0050,\n",
      "            -0.0048,      0.0126,     -0.0027,      0.0172,      0.0169,\n",
      "            -0.0173,      0.0035,     -0.0168,     -0.0065,      0.0117,\n",
      "            -0.0105,     -0.0014,      0.0002,     -0.0008,     -0.0048,\n",
      "             0.0177,     -0.0076,     -0.0111,     -0.0156,     -0.0096,\n",
      "             0.0112,      0.0030,      0.0035,      0.0174,      0.0089,\n",
      "            -0.0095,     -0.0115,      0.0114,     -0.0048,      0.0002,\n",
      "            -0.0083,      0.0119,      0.0148,      0.0085,      0.0009,\n",
      "            -0.0154,      0.0072,      0.0028,      0.0035,     -0.0012,\n",
      "             0.0169,      0.0023,     -0.0166,      0.0103,      0.0177,\n",
      "             0.0040,     -0.0139,     -0.0171,      0.0039,     -0.0115,\n",
      "            -0.0092,      0.0168,     -0.0043,      0.0047,      0.0120,\n",
      "            -0.0112,      0.0128,      0.0058,      0.0014,     -0.0153,\n",
      "            -0.0168,      0.0112,      0.0149,      0.0172,     -0.0174,\n",
      "             0.0059,      0.0144,      0.0171,      0.0053,      0.0151,\n",
      "            -0.0130,     -0.0115,      0.0164,     -0.0018,     -0.0015,\n",
      "            -0.0042,      0.0104,     -0.0151,      0.0127,     -0.0061,\n",
      "             0.0164,     -0.0017,     -0.0128,      0.0124,      0.0152,\n",
      "            -0.0162,      0.0098,     -0.0121,     -0.0040,      0.0127,\n",
      "            -0.0111,     -0.0030,     -0.0031,      0.0031,      0.0054,\n",
      "             0.0100,      0.0035,     -0.0047,     -0.0103,      0.0067,\n",
      "            -0.0076,     -0.0032,     -0.0060,     -0.0104,      0.0016,\n",
      "            -0.0168,     -0.0132,      0.0059,      0.0052,      0.0179,\n",
      "            -0.0161,     -0.0055,     -0.0167,      0.0097,     -0.0137,\n",
      "             0.0006,      0.0121,     -0.0109,     -0.0133,      0.0122,\n",
      "             0.0052,      0.0128,      0.0056,      0.0138,     -0.0147,\n",
      "             0.0033,      0.0144,     -0.0179,      0.0084,      0.0116,\n",
      "             0.0044,     -0.0029,     -0.0013,     -0.0112,     -0.0051,\n",
      "             0.0040,      0.0045,      0.0061,     -0.0033,     -0.0177,\n",
      "             0.0101,     -0.0131,      0.0139,      0.0123,      0.0179,\n",
      "             0.0117,      0.0144,     -0.0116,     -0.0020,     -0.0178,\n",
      "             0.0055,     -0.0141,      0.0098,     -0.0083,     -0.0091,\n",
      "             0.0025,     -0.0161,     -0.0018,      0.0173,      0.0066,\n",
      "            -0.0123,      0.0116,     -0.0123,     -0.0150,     -0.0022,\n",
      "            -0.0053,      0.0130,     -0.0125,     -0.0046,     -0.0174,\n",
      "             0.0107,     -0.0038,     -0.0075,     -0.0147,      0.0079,\n",
      "             0.0049,     -0.0055,     -0.0069,     -0.0158,     -0.0037,\n",
      "             0.0065,      0.0171,     -0.0097,      0.0061,      0.0060,\n",
      "            -0.0039,      0.0136,     -0.0051,      0.0028,     -0.0133,\n",
      "             0.0101,      0.0169,     -0.0169,      0.0087,      0.0021,\n",
      "            -0.0009,      0.0116,     -0.0130,      0.0046,      0.0098,\n",
      "             0.0083,     -0.0165,     -0.0136,     -0.0065,     -0.0047,\n",
      "             0.0022,      0.0093,     -0.0179,     -0.0083,      0.0005,\n",
      "            -0.0142,     -0.0143,     -0.0112,      0.0071,      0.0049,\n",
      "            -0.0077,      0.0124,     -0.0032,     -0.0079,     -0.0157,\n",
      "             0.0155,     -0.0141,     -0.0057,      0.0118,      0.0127,\n",
      "             0.0121,     -0.0086,      0.0137,      0.0109,      0.0175,\n",
      "             0.0028,     -0.0046,     -0.0129,      0.0133,     -0.0081,\n",
      "             0.0003,      0.0090,     -0.0005,     -0.0000,      0.0059,\n",
      "            -0.0090,      0.0050,     -0.0074,      0.0159,     -0.0144,\n",
      "             0.0106,      0.0011,      0.0043], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0285, -0.0213, -0.0034,  ..., -0.0159, -0.0043,  0.0227],\n",
      "        [-0.0090,  0.0048,  0.0121,  ..., -0.0220,  0.0038, -0.0318],\n",
      "        [-0.0103,  0.0039, -0.0092,  ..., -0.0114,  0.0248, -0.0098],\n",
      "        ...,\n",
      "        [ 0.0215,  0.0308,  0.0179,  ..., -0.0082,  0.0008,  0.0009],\n",
      "        [-0.0086, -0.0013, -0.0033,  ...,  0.0252, -0.0020, -0.0306],\n",
      "        [-0.0196, -0.0231, -0.0189,  ...,  0.0063, -0.0185,  0.0124]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "aad3f48c-32f0-40f4-985c-7c3e71df700f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.GPTModel'>\n",
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(256, 768)\n",
      "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n",
      "[Parameter containing:\n",
      "tensor([[     0.3374,     -0.1778,     -0.3035,  ...,     -0.3181,\n",
      "             -1.3936,      0.5226],\n",
      "        [     0.2579,      0.3420,     -0.8168,  ...,     -0.4098,\n",
      "              0.4978,     -0.3721],\n",
      "        [     0.7957,      0.5350,      0.9427,  ...,     -1.0749,\n",
      "              0.0955,     -1.4138],\n",
      "        ...,\n",
      "        [    -0.7128,     -0.5019,      1.4119,  ...,     -0.1498,\n",
      "             -0.4898,     -1.0620],\n",
      "        [     2.0646,      1.1190,      0.3849,  ...,     -0.7202,\n",
      "             -0.5570,      0.9864],\n",
      "        [     0.0011,     -0.7532,     -0.1792,  ...,     -0.3244,\n",
      "              0.2606,      0.5889]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.8769,  0.2550,  0.8441,  ..., -1.0354,  1.3085,  1.7957],\n",
      "        [-1.0029,  0.0995,  1.2459,  ...,  1.5453, -0.1126, -1.5197],\n",
      "        [ 1.3317,  0.7561,  0.9077,  ...,  0.0830,  1.8336, -2.2225],\n",
      "        ...,\n",
      "        [ 1.1003, -0.5333,  0.5827,  ...,  0.7884,  1.1323, -0.3501],\n",
      "        [ 1.0171,  0.3694, -1.3678,  ..., -0.6988, -0.9380, -1.0564],\n",
      "        [-0.5017,  0.7875,  1.0353,  ...,  1.8956, -0.9677, -0.1236]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[     0.0283,     -0.0332,      0.0125,  ...,      0.0348,\n",
      "              0.0103,      0.0164],\n",
      "        [    -0.0212,     -0.0001,     -0.0106,  ...,     -0.0059,\n",
      "              0.0134,     -0.0315],\n",
      "        [     0.0190,     -0.0124,     -0.0083,  ...,     -0.0237,\n",
      "              0.0043,      0.0235],\n",
      "        ...,\n",
      "        [     0.0133,      0.0099,      0.0012,  ...,      0.0215,\n",
      "             -0.0251,      0.0123],\n",
      "        [    -0.0120,     -0.0322,      0.0083,  ...,      0.0032,\n",
      "              0.0013,     -0.0242],\n",
      "        [    -0.0021,     -0.0241,      0.0218,  ...,      0.0221,\n",
      "             -0.0203,     -0.0166]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0266,  0.0049, -0.0182,  ...,  0.0070, -0.0124, -0.0275],\n",
      "        [ 0.0156, -0.0022, -0.0125,  ..., -0.0274,  0.0311,  0.0285],\n",
      "        [ 0.0044, -0.0063, -0.0033,  ..., -0.0279, -0.0054, -0.0342],\n",
      "        ...,\n",
      "        [ 0.0150, -0.0191,  0.0103,  ..., -0.0287,  0.0078,  0.0257],\n",
      "        [ 0.0301, -0.0164,  0.0020,  ...,  0.0142, -0.0351,  0.0306],\n",
      "        [-0.0109, -0.0126, -0.0245,  ...,  0.0004,  0.0029,  0.0042]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0115, -0.0161,  0.0170,  ..., -0.0193, -0.0269,  0.0054],\n",
      "        [ 0.0125, -0.0345, -0.0224,  ..., -0.0216,  0.0346,  0.0022],\n",
      "        [-0.0311, -0.0035, -0.0185,  ...,  0.0320,  0.0299, -0.0143],\n",
      "        ...,\n",
      "        [-0.0225, -0.0181,  0.0014,  ..., -0.0070,  0.0272,  0.0243],\n",
      "        [ 0.0238, -0.0182, -0.0289,  ...,  0.0255, -0.0353,  0.0074],\n",
      "        [-0.0251, -0.0006,  0.0302,  ..., -0.0309,  0.0350,  0.0207]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0301,  0.0241,  0.0034,  ..., -0.0299, -0.0174,  0.0045],\n",
      "        [ 0.0273,  0.0173, -0.0071,  ...,  0.0114,  0.0329,  0.0273],\n",
      "        [-0.0012,  0.0062,  0.0189,  ..., -0.0198,  0.0092, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0180, -0.0353, -0.0344,  ..., -0.0247,  0.0071,  0.0232],\n",
      "        [ 0.0301,  0.0354,  0.0320,  ...,  0.0084,  0.0132,  0.0334],\n",
      "        [-0.0122, -0.0111, -0.0168,  ..., -0.0063,  0.0201,  0.0099]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([     0.0200,     -0.0237,     -0.0298,     -0.0212,      0.0042,\n",
      "            -0.0132,     -0.0251,     -0.0235,     -0.0212,     -0.0134,\n",
      "            -0.0342,      0.0042,     -0.0310,      0.0277,     -0.0026,\n",
      "            -0.0287,      0.0333,      0.0232,      0.0226,     -0.0360,\n",
      "             0.0084,     -0.0193,     -0.0211,     -0.0332,     -0.0339,\n",
      "             0.0205,     -0.0315,      0.0016,      0.0082,     -0.0242,\n",
      "            -0.0137,      0.0227,     -0.0209,      0.0264,     -0.0261,\n",
      "             0.0160,     -0.0290,     -0.0159,      0.0210,      0.0000,\n",
      "             0.0213,      0.0155,      0.0209,     -0.0279,      0.0155,\n",
      "            -0.0232,      0.0223,      0.0347,      0.0093,     -0.0116,\n",
      "            -0.0223,      0.0158,     -0.0280,      0.0252,      0.0058,\n",
      "             0.0277,      0.0314,     -0.0122,      0.0258,     -0.0285,\n",
      "            -0.0193,     -0.0110,      0.0314,      0.0253,      0.0026,\n",
      "             0.0205,     -0.0013,     -0.0173,      0.0277,     -0.0181,\n",
      "            -0.0310,      0.0343,      0.0167,     -0.0324,     -0.0361,\n",
      "             0.0200,     -0.0245,     -0.0124,     -0.0188,     -0.0161,\n",
      "             0.0224,     -0.0031,     -0.0038,      0.0235,     -0.0014,\n",
      "            -0.0140,     -0.0175,     -0.0006,     -0.0330,     -0.0347,\n",
      "            -0.0152,      0.0194,      0.0338,     -0.0040,      0.0239,\n",
      "             0.0163,      0.0189,      0.0205,     -0.0066,      0.0135,\n",
      "             0.0136,      0.0226,     -0.0150,      0.0006,     -0.0313,\n",
      "             0.0165,     -0.0355,      0.0075,      0.0041,     -0.0358,\n",
      "            -0.0295,      0.0214,     -0.0146,      0.0038,     -0.0102,\n",
      "             0.0167,     -0.0144,      0.0065,      0.0325,      0.0343,\n",
      "            -0.0282,     -0.0332,     -0.0062,     -0.0028,     -0.0211,\n",
      "             0.0296,      0.0329,      0.0094,     -0.0038,     -0.0016,\n",
      "            -0.0348,     -0.0135,     -0.0271,     -0.0326,     -0.0352,\n",
      "             0.0191,     -0.0296,      0.0127,      0.0270,     -0.0045,\n",
      "            -0.0153,      0.0274,     -0.0195,      0.0296,     -0.0327,\n",
      "            -0.0029,      0.0117,      0.0272,      0.0210,     -0.0310,\n",
      "             0.0074,      0.0312,     -0.0044,     -0.0027,      0.0280,\n",
      "             0.0092,      0.0064,      0.0331,     -0.0328,      0.0268,\n",
      "            -0.0285,      0.0179,      0.0162,      0.0220,     -0.0052,\n",
      "             0.0353,     -0.0109,     -0.0112,      0.0351,     -0.0041,\n",
      "             0.0157,      0.0178,     -0.0064,      0.0251,     -0.0135,\n",
      "             0.0251,      0.0206,      0.0034,      0.0109,      0.0038,\n",
      "             0.0338,      0.0128,      0.0299,      0.0138,     -0.0175,\n",
      "             0.0126,     -0.0218,     -0.0332,      0.0288,     -0.0344,\n",
      "            -0.0176,      0.0349,     -0.0249,     -0.0173,      0.0253,\n",
      "            -0.0129,     -0.0259,      0.0275,     -0.0151,      0.0156,\n",
      "            -0.0052,     -0.0265,     -0.0235,      0.0296,      0.0007,\n",
      "            -0.0193,      0.0296,      0.0007,     -0.0032,      0.0233,\n",
      "             0.0309,      0.0051,      0.0015,     -0.0258,     -0.0163,\n",
      "             0.0116,      0.0256,     -0.0317,     -0.0165,      0.0183,\n",
      "             0.0345,     -0.0244,     -0.0009,     -0.0132,      0.0283,\n",
      "             0.0178,      0.0123,     -0.0359,     -0.0001,      0.0266,\n",
      "            -0.0118,      0.0209,     -0.0321,      0.0180,      0.0100,\n",
      "            -0.0194,     -0.0046,      0.0037,     -0.0167,      0.0307,\n",
      "             0.0327,      0.0209,     -0.0323,      0.0190,     -0.0122,\n",
      "            -0.0126,      0.0254,      0.0077,      0.0191,      0.0342,\n",
      "             0.0258,      0.0319,      0.0148,      0.0031,      0.0334,\n",
      "            -0.0098,      0.0023,      0.0196,     -0.0009,      0.0044,\n",
      "             0.0311,      0.0041,     -0.0311,      0.0353,     -0.0039,\n",
      "             0.0177,     -0.0242,      0.0351,      0.0331,      0.0202,\n",
      "            -0.0124,     -0.0267,      0.0077,      0.0225,     -0.0100,\n",
      "             0.0214,     -0.0160,      0.0356,     -0.0104,     -0.0219,\n",
      "            -0.0144,     -0.0170,     -0.0243,     -0.0097,      0.0076,\n",
      "            -0.0306,     -0.0207,      0.0046,     -0.0001,      0.0093,\n",
      "            -0.0085,     -0.0133,     -0.0004,     -0.0311,      0.0282,\n",
      "            -0.0341,      0.0079,     -0.0202,      0.0357,      0.0300,\n",
      "             0.0246,     -0.0231,     -0.0214,      0.0264,     -0.0077,\n",
      "             0.0351,      0.0117,      0.0101,     -0.0055,      0.0208,\n",
      "            -0.0236,      0.0361,      0.0237,     -0.0210,      0.0094,\n",
      "            -0.0069,      0.0100,      0.0011,      0.0302,      0.0257,\n",
      "             0.0163,     -0.0288,     -0.0140,      0.0309,     -0.0160,\n",
      "             0.0290,     -0.0355,     -0.0006,      0.0098,      0.0046,\n",
      "             0.0154,      0.0025,     -0.0187,      0.0218,      0.0203,\n",
      "             0.0238,      0.0220,      0.0018,      0.0171,     -0.0061,\n",
      "            -0.0016,      0.0334,      0.0100,     -0.0175,      0.0356,\n",
      "            -0.0080,      0.0215,      0.0035,     -0.0268,     -0.0020,\n",
      "            -0.0137,     -0.0023,      0.0143,     -0.0026,      0.0073,\n",
      "             0.0099,      0.0014,      0.0124,     -0.0209,      0.0019,\n",
      "            -0.0314,     -0.0002,      0.0021,     -0.0269,     -0.0131,\n",
      "             0.0043,     -0.0110,      0.0119,      0.0114,      0.0059,\n",
      "            -0.0267,     -0.0073,      0.0200,      0.0034,     -0.0060,\n",
      "            -0.0011,      0.0068,      0.0180,      0.0224,     -0.0022,\n",
      "             0.0092,     -0.0173,      0.0120,     -0.0273,     -0.0119,\n",
      "            -0.0116,      0.0113,      0.0280,      0.0095,     -0.0290,\n",
      "            -0.0316,      0.0136,      0.0284,     -0.0316,      0.0150,\n",
      "            -0.0241,      0.0237,     -0.0008,      0.0309,      0.0028,\n",
      "            -0.0175,      0.0193,     -0.0206,      0.0022,     -0.0189,\n",
      "             0.0039,      0.0067,     -0.0058,     -0.0058,      0.0114,\n",
      "            -0.0039,     -0.0061,     -0.0305,      0.0038,     -0.0239,\n",
      "             0.0196,     -0.0304,      0.0119,     -0.0014,      0.0253,\n",
      "            -0.0173,      0.0230,     -0.0274,      0.0192,      0.0170,\n",
      "             0.0223,     -0.0284,      0.0190,      0.0340,     -0.0015,\n",
      "             0.0299,     -0.0278,      0.0324,      0.0300,     -0.0345,\n",
      "            -0.0054,     -0.0129,      0.0115,     -0.0249,      0.0207,\n",
      "            -0.0046,     -0.0195,      0.0257,      0.0109,      0.0330,\n",
      "             0.0257,     -0.0115,      0.0004,      0.0239,     -0.0048,\n",
      "            -0.0357,      0.0033,      0.0349,      0.0136,     -0.0288,\n",
      "             0.0011,     -0.0028,      0.0132,     -0.0153,      0.0173,\n",
      "             0.0002,     -0.0325,     -0.0320,     -0.0172,     -0.0099,\n",
      "             0.0320,     -0.0274,      0.0095,      0.0013,      0.0081,\n",
      "             0.0286,     -0.0353,     -0.0341,      0.0124,      0.0250,\n",
      "             0.0349,      0.0322,     -0.0199,      0.0356,     -0.0210,\n",
      "            -0.0352,     -0.0356,     -0.0322,     -0.0253,      0.0127,\n",
      "            -0.0203,      0.0327,     -0.0314,      0.0254,     -0.0292,\n",
      "            -0.0035,     -0.0031,     -0.0281,     -0.0275,      0.0086,\n",
      "             0.0055,      0.0046,     -0.0212,     -0.0197,     -0.0095,\n",
      "             0.0234,     -0.0349,      0.0286,      0.0126,     -0.0348,\n",
      "             0.0183,      0.0309,      0.0318,      0.0264,      0.0186,\n",
      "             0.0005,     -0.0295,      0.0083,     -0.0065,      0.0121,\n",
      "             0.0045,      0.0331,      0.0066,     -0.0200,      0.0093,\n",
      "             0.0060,      0.0093,     -0.0090,     -0.0105,      0.0189,\n",
      "             0.0150,     -0.0305,      0.0063,      0.0279,      0.0264,\n",
      "             0.0215,      0.0305,     -0.0133,      0.0249,     -0.0314,\n",
      "             0.0099,      0.0162,     -0.0308,     -0.0261,     -0.0338,\n",
      "             0.0019,      0.0083,      0.0126,     -0.0155,      0.0009,\n",
      "            -0.0010,      0.0069,      0.0289,     -0.0102,     -0.0354,\n",
      "            -0.0022,     -0.0080,     -0.0353,      0.0011,     -0.0240,\n",
      "            -0.0076,      0.0037,      0.0104,     -0.0019,     -0.0120,\n",
      "            -0.0165,     -0.0221,      0.0346,     -0.0074,     -0.0290,\n",
      "            -0.0043,     -0.0250,      0.0010,     -0.0004,      0.0026,\n",
      "             0.0023,      0.0222,      0.0360,     -0.0154,     -0.0205,\n",
      "             0.0178,     -0.0306,     -0.0035,     -0.0006,     -0.0199,\n",
      "             0.0040,      0.0056,     -0.0241,     -0.0245,     -0.0091,\n",
      "             0.0229,     -0.0042,     -0.0076,     -0.0149,      0.0249,\n",
      "             0.0212,      0.0166,     -0.0093,      0.0151,      0.0256,\n",
      "            -0.0177,     -0.0235,      0.0114,     -0.0195,      0.0256,\n",
      "            -0.0213,     -0.0142,     -0.0220,     -0.0011,      0.0297,\n",
      "            -0.0082,      0.0143,      0.0348,     -0.0009,      0.0229,\n",
      "            -0.0183,      0.0023,      0.0092,      0.0274,     -0.0032,\n",
      "            -0.0050,     -0.0175,     -0.0236,      0.0000,      0.0124,\n",
      "             0.0162,     -0.0040,      0.0076,     -0.0128,     -0.0111,\n",
      "            -0.0316,     -0.0057,      0.0328,      0.0204,      0.0090,\n",
      "            -0.0197,      0.0176,      0.0044,     -0.0006,      0.0079,\n",
      "             0.0253,      0.0292,     -0.0019,      0.0092,     -0.0060,\n",
      "             0.0228,     -0.0139,     -0.0035,      0.0334,      0.0077,\n",
      "             0.0077,      0.0330,     -0.0217,     -0.0278,     -0.0189,\n",
      "             0.0162,      0.0295,      0.0218,      0.0250,      0.0045,\n",
      "             0.0204,     -0.0262,     -0.0137,      0.0179,      0.0202,\n",
      "            -0.0236,      0.0334,     -0.0037,      0.0093,     -0.0208,\n",
      "             0.0110,      0.0254,      0.0147,      0.0223,      0.0348,\n",
      "            -0.0003,      0.0109,     -0.0255,      0.0098,     -0.0267,\n",
      "            -0.0150,     -0.0023,     -0.0188,      0.0040,      0.0303,\n",
      "            -0.0154,     -0.0232,     -0.0048,     -0.0237,      0.0254,\n",
      "             0.0085,     -0.0183,      0.0219,      0.0052,      0.0347,\n",
      "            -0.0103,     -0.0207,      0.0095,     -0.0264,      0.0203,\n",
      "            -0.0049,     -0.0303,      0.0199,     -0.0004,      0.0192,\n",
      "            -0.0091,      0.0259,      0.0244,     -0.0179,     -0.0264,\n",
      "             0.0293,     -0.0258,      0.0246,     -0.0196,      0.0293,\n",
      "             0.0324,      0.0299,      0.0043,      0.0258,      0.0056,\n",
      "            -0.0112,      0.0008,      0.0072,      0.0221,      0.0009,\n",
      "             0.0181,     -0.0319,     -0.0348,      0.0168,     -0.0305,\n",
      "             0.0360,     -0.0235,     -0.0339,     -0.0309,     -0.0130,\n",
      "            -0.0034,     -0.0298,      0.0204,     -0.0350,     -0.0006,\n",
      "            -0.0200,     -0.0285,     -0.0120,     -0.0049,      0.0098,\n",
      "            -0.0163,     -0.0254,     -0.0032,      0.0185,      0.0183,\n",
      "             0.0097,      0.0158,      0.0047,      0.0101,     -0.0195,\n",
      "             0.0188,      0.0305,      0.0274,      0.0154,      0.0080,\n",
      "            -0.0136,      0.0093,     -0.0169,     -0.0186,     -0.0136,\n",
      "             0.0341,     -0.0295,      0.0229,     -0.0314,      0.0129,\n",
      "            -0.0132,     -0.0345,      0.0227], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0090, -0.0287, -0.0344,  ..., -0.0360,  0.0031, -0.0080],\n",
      "        [-0.0122, -0.0287, -0.0022,  ...,  0.0148, -0.0062,  0.0047],\n",
      "        [-0.0023,  0.0247,  0.0178,  ...,  0.0313, -0.0130, -0.0243],\n",
      "        ...,\n",
      "        [-0.0128,  0.0130,  0.0253,  ...,  0.0313, -0.0141,  0.0171],\n",
      "        [-0.0223, -0.0013, -0.0113,  ...,  0.0085, -0.0196,  0.0128],\n",
      "        [ 0.0264, -0.0036,  0.0240,  ...,  0.0245, -0.0034,  0.0032]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([0.0176, 0.0330, 0.0337,  ..., 0.0245, 0.0124, 0.0359],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0090, -0.0067, -0.0003,  ...,  0.0145, -0.0069,  0.0099],\n",
      "        [ 0.0019,  0.0042,  0.0157,  ..., -0.0068,  0.0090, -0.0055],\n",
      "        [ 0.0106, -0.0105, -0.0093,  ...,  0.0171, -0.0160, -0.0025],\n",
      "        ...,\n",
      "        [ 0.0071,  0.0033,  0.0014,  ...,  0.0045,  0.0111,  0.0140],\n",
      "        [-0.0011, -0.0174, -0.0087,  ...,  0.0107, -0.0042,  0.0132],\n",
      "        [-0.0014,  0.0087,  0.0174,  ..., -0.0074, -0.0014,  0.0013]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([     0.0143,     -0.0178,     -0.0005,     -0.0156,      0.0076,\n",
      "            -0.0005,     -0.0152,      0.0003,     -0.0064,     -0.0124,\n",
      "            -0.0060,     -0.0133,      0.0129,     -0.0121,     -0.0058,\n",
      "            -0.0137,      0.0178,      0.0117,     -0.0016,     -0.0143,\n",
      "            -0.0097,     -0.0080,     -0.0049,     -0.0141,      0.0029,\n",
      "            -0.0068,      0.0101,     -0.0109,      0.0014,      0.0020,\n",
      "             0.0061,     -0.0032,     -0.0139,      0.0154,      0.0141,\n",
      "             0.0081,      0.0068,      0.0126,     -0.0141,      0.0132,\n",
      "             0.0066,     -0.0124,      0.0177,      0.0158,     -0.0176,\n",
      "             0.0075,     -0.0044,     -0.0148,      0.0159,      0.0136,\n",
      "             0.0048,     -0.0130,     -0.0066,      0.0144,      0.0134,\n",
      "            -0.0034,      0.0044,      0.0127,      0.0163,     -0.0172,\n",
      "            -0.0136,      0.0159,     -0.0163,     -0.0026,     -0.0018,\n",
      "            -0.0034,     -0.0147,      0.0063,      0.0129,      0.0060,\n",
      "            -0.0025,      0.0106,      0.0101,      0.0026,     -0.0059,\n",
      "            -0.0126,      0.0077,      0.0079,     -0.0173,     -0.0011,\n",
      "            -0.0066,     -0.0114,      0.0113,     -0.0002,     -0.0023,\n",
      "            -0.0012,     -0.0003,     -0.0179,      0.0158,     -0.0135,\n",
      "             0.0154,     -0.0145,      0.0136,      0.0100,      0.0150,\n",
      "             0.0145,      0.0139,      0.0121,      0.0028,     -0.0090,\n",
      "             0.0010,     -0.0062,      0.0049,     -0.0055,     -0.0135,\n",
      "             0.0025,      0.0097,      0.0070,     -0.0078,     -0.0141,\n",
      "            -0.0025,      0.0167,      0.0093,      0.0051,      0.0126,\n",
      "             0.0058,      0.0042,      0.0048,      0.0179,     -0.0127,\n",
      "             0.0140,     -0.0017,     -0.0159,     -0.0137,      0.0007,\n",
      "             0.0174,      0.0164,     -0.0084,     -0.0102,     -0.0034,\n",
      "             0.0028,     -0.0084,     -0.0058,      0.0061,      0.0158,\n",
      "             0.0001,     -0.0048,      0.0160,     -0.0153,      0.0131,\n",
      "            -0.0166,      0.0168,      0.0101,      0.0122,      0.0176,\n",
      "            -0.0080,     -0.0008,      0.0090,     -0.0065,     -0.0171,\n",
      "            -0.0111,     -0.0009,      0.0039,      0.0107,      0.0054,\n",
      "            -0.0106,      0.0075,      0.0097,      0.0177,     -0.0072,\n",
      "            -0.0114,      0.0092,      0.0085,     -0.0022,      0.0037,\n",
      "             0.0074,     -0.0100,     -0.0085,     -0.0110,     -0.0132,\n",
      "             0.0099,      0.0069,      0.0046,      0.0073,      0.0155,\n",
      "             0.0100,      0.0132,      0.0108,      0.0126,     -0.0145,\n",
      "            -0.0033,     -0.0170,      0.0180,      0.0069,      0.0063,\n",
      "            -0.0122,     -0.0087,     -0.0069,     -0.0009,      0.0026,\n",
      "             0.0107,      0.0052,      0.0044,     -0.0020,     -0.0124,\n",
      "            -0.0102,     -0.0018,     -0.0114,     -0.0015,     -0.0035,\n",
      "             0.0019,      0.0093,     -0.0021,      0.0113,     -0.0031,\n",
      "             0.0109,     -0.0163,     -0.0130,      0.0158,     -0.0170,\n",
      "             0.0160,     -0.0047,     -0.0170,     -0.0018,     -0.0160,\n",
      "            -0.0123,     -0.0101,      0.0082,     -0.0036,      0.0135,\n",
      "             0.0083,      0.0172,      0.0006,      0.0151,      0.0111,\n",
      "            -0.0154,      0.0025,     -0.0115,      0.0092,     -0.0138,\n",
      "            -0.0019,      0.0159,     -0.0155,      0.0140,     -0.0141,\n",
      "            -0.0014,      0.0144,      0.0010,     -0.0127,      0.0007,\n",
      "            -0.0113,     -0.0125,      0.0178,     -0.0070,      0.0096,\n",
      "             0.0018,      0.0110,      0.0156,     -0.0011,     -0.0162,\n",
      "            -0.0049,      0.0031,      0.0008,      0.0074,     -0.0115,\n",
      "             0.0065,      0.0161,      0.0042,      0.0159,     -0.0114,\n",
      "             0.0094,      0.0066,     -0.0178,      0.0006,      0.0068,\n",
      "            -0.0060,     -0.0170,      0.0114,     -0.0135,      0.0168,\n",
      "            -0.0137,     -0.0100,     -0.0179,     -0.0003,      0.0128,\n",
      "             0.0083,      0.0051,     -0.0119,      0.0060,      0.0043,\n",
      "             0.0159,      0.0052,     -0.0023,      0.0089,     -0.0075,\n",
      "             0.0160,     -0.0142,     -0.0178,     -0.0036,     -0.0021,\n",
      "            -0.0060,      0.0126,     -0.0008,      0.0008,     -0.0077,\n",
      "             0.0059,      0.0108,     -0.0055,      0.0055,      0.0082,\n",
      "            -0.0111,      0.0109,      0.0135,      0.0151,      0.0136,\n",
      "             0.0154,     -0.0092,      0.0052,      0.0015,     -0.0153,\n",
      "            -0.0011,     -0.0107,      0.0174,     -0.0047,      0.0038,\n",
      "             0.0177,     -0.0156,     -0.0150,      0.0022,     -0.0130,\n",
      "             0.0026,      0.0122,      0.0118,      0.0062,     -0.0036,\n",
      "             0.0057,      0.0122,      0.0023,      0.0018,     -0.0148,\n",
      "             0.0124,      0.0093,      0.0021,     -0.0044,     -0.0010,\n",
      "             0.0134,     -0.0035,      0.0101,     -0.0055,     -0.0012,\n",
      "             0.0050,      0.0072,     -0.0144,     -0.0146,     -0.0153,\n",
      "            -0.0129,     -0.0180,      0.0028,      0.0092,     -0.0177,\n",
      "            -0.0010,     -0.0060,      0.0024,      0.0007,      0.0065,\n",
      "             0.0020,      0.0045,      0.0048,      0.0136,      0.0178,\n",
      "            -0.0029,      0.0083,      0.0100,      0.0111,     -0.0079,\n",
      "            -0.0090,     -0.0040,      0.0037,      0.0091,     -0.0141,\n",
      "            -0.0177,     -0.0118,     -0.0081,     -0.0141,      0.0025,\n",
      "             0.0152,     -0.0119,     -0.0017,     -0.0004,      0.0023,\n",
      "             0.0035,      0.0056,      0.0126,      0.0061,     -0.0071,\n",
      "             0.0139,     -0.0039,      0.0116,      0.0019,     -0.0102,\n",
      "            -0.0038,     -0.0031,     -0.0123,      0.0111,     -0.0075,\n",
      "             0.0174,      0.0001,     -0.0110,      0.0170,     -0.0010,\n",
      "             0.0042,     -0.0028,      0.0045,     -0.0106,     -0.0153,\n",
      "            -0.0120,      0.0158,      0.0054,     -0.0050,      0.0134,\n",
      "            -0.0020,     -0.0044,      0.0045,     -0.0061,      0.0135,\n",
      "            -0.0109,      0.0159,      0.0048,     -0.0018,      0.0142,\n",
      "             0.0127,      0.0096,      0.0004,     -0.0121,     -0.0058,\n",
      "             0.0173,      0.0087,      0.0061,     -0.0080,     -0.0024,\n",
      "             0.0164,      0.0137,      0.0056,     -0.0170,     -0.0134,\n",
      "             0.0135,      0.0028,     -0.0075,     -0.0102,     -0.0142,\n",
      "            -0.0081,      0.0096,     -0.0124,     -0.0006,     -0.0124,\n",
      "             0.0004,      0.0089,     -0.0065,     -0.0135,     -0.0114,\n",
      "             0.0018,     -0.0117,     -0.0021,      0.0148,      0.0143,\n",
      "             0.0069,     -0.0083,      0.0118,      0.0111,      0.0155,\n",
      "             0.0071,      0.0123,      0.0046,     -0.0109,      0.0027,\n",
      "            -0.0053,      0.0100,     -0.0107,      0.0120,     -0.0151,\n",
      "             0.0054,     -0.0017,      0.0002,     -0.0123,     -0.0121,\n",
      "             0.0115,      0.0109,     -0.0078,      0.0098,     -0.0049,\n",
      "             0.0109,      0.0082,      0.0110,     -0.0114,      0.0150,\n",
      "            -0.0100,      0.0141,     -0.0091,     -0.0115,      0.0100,\n",
      "             0.0071,      0.0051,      0.0032,      0.0086,      0.0101,\n",
      "            -0.0065,      0.0079,      0.0109,      0.0008,     -0.0140,\n",
      "            -0.0124,      0.0091,      0.0101,      0.0090,      0.0162,\n",
      "             0.0013,     -0.0076,     -0.0118,      0.0026,      0.0064,\n",
      "            -0.0005,     -0.0094,      0.0151,     -0.0078,      0.0056,\n",
      "             0.0033,     -0.0004,     -0.0073,      0.0054,     -0.0094,\n",
      "            -0.0107,      0.0157,     -0.0118,      0.0085,     -0.0005,\n",
      "            -0.0110,      0.0089,     -0.0175,     -0.0121,     -0.0167,\n",
      "             0.0059,     -0.0024,     -0.0003,     -0.0087,     -0.0093,\n",
      "             0.0155,     -0.0059,      0.0167,      0.0091,     -0.0117,\n",
      "            -0.0026,      0.0009,      0.0124,      0.0056,      0.0064,\n",
      "             0.0067,     -0.0118,     -0.0132,      0.0001,     -0.0178,\n",
      "            -0.0174,      0.0175,     -0.0048,      0.0013,     -0.0045,\n",
      "            -0.0066,     -0.0086,      0.0051,      0.0132,     -0.0025,\n",
      "             0.0055,      0.0032,      0.0128,     -0.0085,     -0.0058,\n",
      "            -0.0020,     -0.0028,     -0.0021,     -0.0103,      0.0028,\n",
      "             0.0037,      0.0160,      0.0020,     -0.0046,     -0.0074,\n",
      "             0.0030,      0.0158,     -0.0079,     -0.0153,      0.0139,\n",
      "            -0.0116,      0.0076,      0.0129,      0.0087,     -0.0014,\n",
      "             0.0158,     -0.0141,      0.0152,      0.0016,     -0.0163,\n",
      "            -0.0053,      0.0059,     -0.0103,      0.0021,     -0.0141,\n",
      "            -0.0065,      0.0103,      0.0008,     -0.0168,     -0.0175,\n",
      "             0.0037,     -0.0119,      0.0096,     -0.0112,     -0.0137,\n",
      "            -0.0053,      0.0178,     -0.0005,      0.0064,     -0.0104,\n",
      "            -0.0143,      0.0002,      0.0061,      0.0056,     -0.0072,\n",
      "            -0.0164,      0.0141,     -0.0002,     -0.0100,      0.0158,\n",
      "             0.0073,     -0.0060,      0.0142,      0.0031,      0.0071,\n",
      "            -0.0065,      0.0021,     -0.0124,     -0.0033,      0.0093,\n",
      "            -0.0078,      0.0170,     -0.0122,     -0.0000,      0.0087,\n",
      "             0.0102,     -0.0126,     -0.0096,      0.0017,      0.0067,\n",
      "             0.0136,     -0.0120,     -0.0090,      0.0021,      0.0060,\n",
      "             0.0124,     -0.0045,     -0.0152,     -0.0167,     -0.0112,\n",
      "             0.0080,     -0.0051,     -0.0164,      0.0101,      0.0120,\n",
      "             0.0176,     -0.0166,      0.0097,     -0.0076,     -0.0115,\n",
      "             0.0022,      0.0140,      0.0142,      0.0085,     -0.0042,\n",
      "            -0.0156,      0.0046,      0.0170,      0.0060,     -0.0040,\n",
      "            -0.0042,      0.0156,      0.0084,     -0.0093,     -0.0133,\n",
      "            -0.0064,      0.0088,     -0.0000,     -0.0164,      0.0015,\n",
      "             0.0168,     -0.0011,     -0.0041,      0.0078,      0.0096,\n",
      "            -0.0146,     -0.0036,     -0.0025,     -0.0007,     -0.0136,\n",
      "             0.0070,      0.0145,     -0.0043,     -0.0156,     -0.0127,\n",
      "             0.0061,     -0.0039,      0.0102,     -0.0095,      0.0097,\n",
      "             0.0050,      0.0105,     -0.0108,     -0.0043,     -0.0063,\n",
      "            -0.0145,     -0.0159,     -0.0148,      0.0070,      0.0033,\n",
      "            -0.0059,      0.0166,      0.0046,     -0.0098,     -0.0094,\n",
      "            -0.0165,      0.0047,     -0.0105,     -0.0124,     -0.0062,\n",
      "             0.0097,      0.0052,     -0.0100,     -0.0127,      0.0030,\n",
      "            -0.0009,     -0.0116,     -0.0179,      0.0170,     -0.0057,\n",
      "            -0.0005,      0.0073,     -0.0005,     -0.0030,      0.0083,\n",
      "             0.0039,     -0.0053,     -0.0103,      0.0110,     -0.0159,\n",
      "            -0.0169,     -0.0069,      0.0154,      0.0151,     -0.0025,\n",
      "            -0.0070,     -0.0095,     -0.0138,      0.0140,     -0.0100,\n",
      "             0.0052,     -0.0047,      0.0076,      0.0103,      0.0141,\n",
      "             0.0064,      0.0002,     -0.0140,      0.0013,     -0.0110,\n",
      "            -0.0141,      0.0072,     -0.0122,     -0.0120,     -0.0041,\n",
      "            -0.0152,     -0.0100,     -0.0004], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0014, -0.0185, -0.0274,  ..., -0.0335, -0.0231,  0.0215],\n",
      "        [ 0.0051,  0.0113,  0.0072,  ..., -0.0049, -0.0191, -0.0080],\n",
      "        [-0.0184,  0.0212,  0.0305,  ...,  0.0035,  0.0297,  0.0088],\n",
      "        ...,\n",
      "        [ 0.0313,  0.0330, -0.0181,  ...,  0.0297,  0.0001, -0.0250],\n",
      "        [-0.0058, -0.0040, -0.0252,  ..., -0.0290, -0.0078, -0.0297],\n",
      "        [ 0.0005,  0.0100, -0.0057,  ..., -0.0335,  0.0334,  0.0015]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0151, -0.0277, -0.0339,  ..., -0.0276,  0.0181, -0.0308],\n",
      "        [ 0.0359, -0.0352,  0.0189,  ..., -0.0292, -0.0157, -0.0196],\n",
      "        [ 0.0010,  0.0265, -0.0135,  ...,  0.0311, -0.0235,  0.0288],\n",
      "        ...,\n",
      "        [ 0.0023,  0.0113,  0.0009,  ...,  0.0310, -0.0093,  0.0282],\n",
      "        [-0.0004, -0.0021,  0.0163,  ...,  0.0002,  0.0226,  0.0039],\n",
      "        [-0.0049, -0.0300, -0.0137,  ..., -0.0193, -0.0361, -0.0099]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0154, -0.0066,  0.0188,  ...,  0.0124,  0.0092,  0.0001],\n",
      "        [ 0.0101,  0.0074, -0.0322,  ..., -0.0106, -0.0124,  0.0085],\n",
      "        [-0.0242, -0.0106,  0.0334,  ...,  0.0266, -0.0147, -0.0014],\n",
      "        ...,\n",
      "        [ 0.0088,  0.0354, -0.0253,  ...,  0.0290,  0.0173, -0.0311],\n",
      "        [-0.0076,  0.0197, -0.0273,  ..., -0.0123,  0.0277,  0.0246],\n",
      "        [ 0.0264,  0.0199,  0.0315,  ..., -0.0125,  0.0351,  0.0149]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[     0.0353,     -0.0359,     -0.0191,  ...,     -0.0357,\n",
      "             -0.0298,     -0.0010],\n",
      "        [     0.0057,     -0.0275,     -0.0326,  ...,      0.0133,\n",
      "              0.0303,     -0.0294],\n",
      "        [     0.0130,      0.0341,      0.0076,  ...,     -0.0134,\n",
      "             -0.0085,      0.0018],\n",
      "        ...,\n",
      "        [     0.0086,     -0.0220,     -0.0317,  ...,     -0.0049,\n",
      "              0.0055,     -0.0186],\n",
      "        [     0.0337,      0.0058,     -0.0231,  ...,      0.0228,\n",
      "              0.0066,     -0.0034],\n",
      "        [     0.0000,      0.0144,      0.0061,  ...,     -0.0309,\n",
      "              0.0199,     -0.0000]], requires_grad=True), Parameter containing:\n",
      "tensor([     0.0218,     -0.0206,     -0.0117,     -0.0233,     -0.0279,\n",
      "             0.0168,     -0.0062,      0.0144,     -0.0135,     -0.0192,\n",
      "             0.0285,      0.0015,      0.0025,      0.0116,     -0.0102,\n",
      "             0.0260,      0.0059,     -0.0098,     -0.0021,     -0.0173,\n",
      "            -0.0177,     -0.0156,      0.0018,      0.0209,     -0.0337,\n",
      "            -0.0036,      0.0271,     -0.0035,     -0.0153,     -0.0188,\n",
      "             0.0197,      0.0113,      0.0017,     -0.0207,     -0.0028,\n",
      "             0.0256,     -0.0336,      0.0211,     -0.0003,      0.0026,\n",
      "             0.0324,      0.0212,      0.0141,     -0.0350,     -0.0134,\n",
      "            -0.0280,     -0.0103,      0.0196,     -0.0174,     -0.0354,\n",
      "             0.0221,     -0.0182,     -0.0336,     -0.0168,      0.0242,\n",
      "            -0.0136,      0.0134,      0.0266,     -0.0133,      0.0259,\n",
      "             0.0168,     -0.0076,      0.0339,     -0.0215,      0.0177,\n",
      "            -0.0064,     -0.0020,     -0.0250,     -0.0110,     -0.0010,\n",
      "            -0.0129,      0.0130,      0.0033,      0.0330,     -0.0205,\n",
      "             0.0031,     -0.0209,      0.0316,      0.0355,     -0.0116,\n",
      "            -0.0050,      0.0263,     -0.0069,     -0.0041,     -0.0020,\n",
      "            -0.0325,     -0.0350,     -0.0217,     -0.0190,      0.0040,\n",
      "            -0.0100,     -0.0139,     -0.0069,     -0.0353,      0.0064,\n",
      "             0.0072,     -0.0213,      0.0357,     -0.0325,     -0.0317,\n",
      "             0.0262,     -0.0153,     -0.0112,     -0.0313,      0.0297,\n",
      "            -0.0259,      0.0238,      0.0218,      0.0215,      0.0030,\n",
      "            -0.0270,      0.0009,      0.0131,      0.0123,     -0.0137,\n",
      "             0.0322,      0.0256,      0.0294,      0.0360,     -0.0149,\n",
      "            -0.0232,     -0.0018,      0.0023,      0.0195,      0.0353,\n",
      "             0.0073,      0.0103,      0.0250,      0.0302,     -0.0042,\n",
      "            -0.0211,     -0.0327,     -0.0338,     -0.0239,      0.0299,\n",
      "             0.0314,     -0.0306,      0.0068,     -0.0289,      0.0066,\n",
      "            -0.0042,     -0.0133,      0.0333,     -0.0031,      0.0200,\n",
      "             0.0198,      0.0110,      0.0123,     -0.0234,      0.0270,\n",
      "             0.0073,     -0.0325,     -0.0166,     -0.0318,     -0.0274,\n",
      "            -0.0163,     -0.0322,     -0.0151,      0.0253,      0.0010,\n",
      "             0.0286,     -0.0210,     -0.0032,     -0.0062,     -0.0068,\n",
      "             0.0316,      0.0190,     -0.0211,     -0.0157,     -0.0174,\n",
      "            -0.0240,     -0.0314,      0.0281,      0.0011,      0.0261,\n",
      "             0.0315,      0.0084,     -0.0234,     -0.0098,      0.0183,\n",
      "            -0.0003,     -0.0244,     -0.0178,     -0.0043,      0.0237,\n",
      "             0.0239,     -0.0199,     -0.0349,     -0.0043,     -0.0182,\n",
      "             0.0045,      0.0050,      0.0295,     -0.0358,      0.0179,\n",
      "             0.0015,      0.0355,     -0.0324,     -0.0188,     -0.0160,\n",
      "            -0.0165,     -0.0265,      0.0330,      0.0162,     -0.0156,\n",
      "             0.0124,     -0.0115,     -0.0187,     -0.0090,      0.0274,\n",
      "             0.0207,     -0.0210,     -0.0301,      0.0285,     -0.0134,\n",
      "             0.0111,      0.0028,      0.0203,      0.0244,      0.0195,\n",
      "            -0.0067,      0.0084,     -0.0197,     -0.0177,      0.0175,\n",
      "            -0.0078,     -0.0118,     -0.0014,      0.0136,     -0.0128,\n",
      "             0.0277,     -0.0171,     -0.0070,      0.0224,     -0.0152,\n",
      "            -0.0120,      0.0058,      0.0033,      0.0074,      0.0325,\n",
      "             0.0068,     -0.0288,     -0.0146,      0.0300,     -0.0273,\n",
      "             0.0319,      0.0315,     -0.0160,     -0.0356,     -0.0143,\n",
      "             0.0288,     -0.0255,      0.0112,     -0.0057,      0.0067,\n",
      "             0.0279,      0.0173,     -0.0224,     -0.0151,     -0.0301,\n",
      "             0.0183,      0.0102,     -0.0268,      0.0119,      0.0170,\n",
      "            -0.0024,     -0.0009,      0.0334,      0.0196,     -0.0310,\n",
      "            -0.0118,      0.0276,      0.0360,      0.0216,     -0.0285,\n",
      "            -0.0292,      0.0133,      0.0011,      0.0079,     -0.0253,\n",
      "            -0.0211,      0.0333,     -0.0194,     -0.0304,      0.0358,\n",
      "            -0.0108,     -0.0288,     -0.0349,      0.0222,     -0.0120,\n",
      "             0.0249,     -0.0299,      0.0216,      0.0172,      0.0356,\n",
      "            -0.0206,     -0.0271,      0.0228,      0.0127,     -0.0011,\n",
      "             0.0157,      0.0098,     -0.0313,     -0.0082,     -0.0042,\n",
      "             0.0231,      0.0044,     -0.0357,     -0.0222,     -0.0254,\n",
      "            -0.0092,      0.0096,     -0.0197,      0.0072,      0.0034,\n",
      "            -0.0015,      0.0252,      0.0102,      0.0251,      0.0339,\n",
      "             0.0181,     -0.0057,      0.0063,      0.0306,     -0.0150,\n",
      "            -0.0118,     -0.0248,     -0.0207,     -0.0177,     -0.0235,\n",
      "            -0.0083,     -0.0308,     -0.0359,     -0.0341,     -0.0218,\n",
      "             0.0353,      0.0138,     -0.0173,      0.0179,      0.0052,\n",
      "             0.0214,      0.0314,      0.0303,      0.0120,      0.0039,\n",
      "             0.0086,      0.0346,     -0.0228,     -0.0149,     -0.0288,\n",
      "             0.0087,      0.0171,      0.0233,      0.0293,      0.0314,\n",
      "             0.0039,      0.0222,     -0.0030,     -0.0112,     -0.0054,\n",
      "            -0.0354,     -0.0233,     -0.0234,      0.0249,     -0.0185,\n",
      "             0.0136,     -0.0249,      0.0271,     -0.0317,     -0.0336,\n",
      "             0.0255,      0.0355,     -0.0321,      0.0105,     -0.0220,\n",
      "             0.0351,     -0.0114,     -0.0230,     -0.0182,     -0.0351,\n",
      "             0.0061,      0.0100,     -0.0327,      0.0241,      0.0055,\n",
      "            -0.0212,      0.0187,     -0.0197,      0.0036,      0.0085,\n",
      "             0.0151,      0.0134,     -0.0289,      0.0270,      0.0047,\n",
      "             0.0078,     -0.0136,      0.0223,      0.0144,     -0.0213,\n",
      "             0.0247,     -0.0130,     -0.0341,     -0.0031,     -0.0143,\n",
      "             0.0187,     -0.0349,      0.0183,      0.0101,      0.0237,\n",
      "            -0.0095,     -0.0126,     -0.0145,     -0.0067,      0.0165,\n",
      "             0.0099,     -0.0088,     -0.0311,     -0.0184,     -0.0359,\n",
      "             0.0110,     -0.0139,      0.0290,     -0.0272,     -0.0274,\n",
      "            -0.0346,     -0.0071,     -0.0208,      0.0223,      0.0210,\n",
      "             0.0208,     -0.0013,     -0.0196,      0.0013,     -0.0147,\n",
      "            -0.0313,      0.0157,     -0.0200,      0.0310,      0.0139,\n",
      "            -0.0115,      0.0127,      0.0174,     -0.0013,     -0.0087,\n",
      "             0.0100,     -0.0013,     -0.0159,     -0.0308,      0.0096,\n",
      "             0.0226,     -0.0043,      0.0333,      0.0344,     -0.0110,\n",
      "             0.0072,     -0.0171,     -0.0084,     -0.0056,      0.0343,\n",
      "            -0.0343,     -0.0096,      0.0125,      0.0253,      0.0002,\n",
      "             0.0252,      0.0210,     -0.0334,      0.0229,      0.0172,\n",
      "            -0.0024,      0.0019,      0.0108,      0.0062,      0.0102,\n",
      "            -0.0357,     -0.0027,      0.0097,     -0.0144,      0.0000,\n",
      "            -0.0018,      0.0193,     -0.0105,      0.0319,     -0.0315,\n",
      "            -0.0234,      0.0080,     -0.0313,      0.0333,      0.0114,\n",
      "             0.0258,      0.0095,     -0.0326,      0.0304,      0.0045,\n",
      "             0.0088,     -0.0044,      0.0359,      0.0302,     -0.0205,\n",
      "             0.0356,     -0.0285,     -0.0248,      0.0286,      0.0067,\n",
      "            -0.0236,      0.0194,      0.0129,     -0.0221,     -0.0173,\n",
      "            -0.0035,     -0.0349,     -0.0089,      0.0300,      0.0075,\n",
      "            -0.0265,     -0.0203,     -0.0049,     -0.0253,     -0.0240,\n",
      "            -0.0235,     -0.0104,      0.0113,      0.0235,     -0.0018,\n",
      "             0.0222,     -0.0184,      0.0323,     -0.0122,      0.0337,\n",
      "             0.0125,      0.0254,     -0.0032,     -0.0210,     -0.0063,\n",
      "             0.0091,      0.0223,     -0.0254,     -0.0298,     -0.0193,\n",
      "            -0.0218,      0.0067,      0.0219,      0.0333,      0.0338,\n",
      "             0.0187,      0.0023,      0.0168,     -0.0295,     -0.0261,\n",
      "             0.0041,      0.0034,      0.0269,      0.0191,      0.0220,\n",
      "            -0.0134,     -0.0261,      0.0280,     -0.0344,      0.0127,\n",
      "             0.0205,     -0.0080,      0.0206,     -0.0074,      0.0262,\n",
      "            -0.0190,      0.0073,      0.0051,     -0.0032,     -0.0216,\n",
      "             0.0083,      0.0256,      0.0279,     -0.0047,      0.0005,\n",
      "            -0.0231,      0.0029,     -0.0077,     -0.0229,      0.0052,\n",
      "            -0.0123,      0.0146,     -0.0351,      0.0244,     -0.0285,\n",
      "             0.0179,      0.0033,      0.0022,     -0.0285,     -0.0126,\n",
      "             0.0003,     -0.0207,     -0.0175,     -0.0252,     -0.0072,\n",
      "             0.0283,      0.0316,     -0.0192,      0.0176,      0.0338,\n",
      "             0.0253,      0.0227,      0.0165,      0.0185,     -0.0264,\n",
      "             0.0274,     -0.0357,      0.0265,     -0.0277,      0.0110,\n",
      "            -0.0059,      0.0150,      0.0099,      0.0358,      0.0056,\n",
      "             0.0331,     -0.0295,     -0.0003,     -0.0088,      0.0040,\n",
      "             0.0136,      0.0105,      0.0352,     -0.0254,     -0.0308,\n",
      "            -0.0128,      0.0322,     -0.0297,     -0.0136,     -0.0048,\n",
      "            -0.0192,      0.0240,     -0.0346,     -0.0056,     -0.0280,\n",
      "             0.0106,      0.0060,      0.0209,     -0.0063,      0.0287,\n",
      "            -0.0172,     -0.0165,      0.0264,      0.0198,      0.0129,\n",
      "             0.0306,      0.0328,      0.0024,      0.0289,      0.0077,\n",
      "            -0.0075,      0.0025,      0.0123,     -0.0056,      0.0328,\n",
      "            -0.0011,      0.0012,     -0.0031,     -0.0022,     -0.0154,\n",
      "            -0.0050,      0.0084,      0.0085,     -0.0006,     -0.0101,\n",
      "             0.0081,     -0.0134,     -0.0241,      0.0109,      0.0194,\n",
      "             0.0195,     -0.0066,      0.0102,     -0.0032,      0.0085,\n",
      "            -0.0273,     -0.0251,     -0.0242,      0.0216,     -0.0287,\n",
      "            -0.0199,      0.0188,     -0.0172,     -0.0255,     -0.0007,\n",
      "             0.0140,     -0.0231,      0.0352,      0.0022,      0.0185,\n",
      "             0.0091,      0.0357,     -0.0259,     -0.0155,     -0.0312,\n",
      "             0.0024,      0.0332,      0.0031,     -0.0195,      0.0323,\n",
      "            -0.0122,     -0.0160,      0.0071,     -0.0331,     -0.0255,\n",
      "             0.0272,      0.0106,     -0.0171,      0.0345,      0.0210,\n",
      "             0.0298,     -0.0221,      0.0156,      0.0072,     -0.0019,\n",
      "             0.0313,      0.0091,     -0.0128,      0.0144,      0.0196,\n",
      "            -0.0092,      0.0039,      0.0275,     -0.0096,     -0.0023,\n",
      "             0.0108,      0.0097,      0.0217,     -0.0042,      0.0160,\n",
      "             0.0125,      0.0188,     -0.0026,      0.0119,     -0.0135,\n",
      "            -0.0202,     -0.0014,      0.0177,      0.0253,     -0.0065,\n",
      "            -0.0243,     -0.0149,      0.0057,      0.0191,     -0.0144,\n",
      "            -0.0098,      0.0326,     -0.0152,     -0.0145,     -0.0293,\n",
      "             0.0008,      0.0110,      0.0297,     -0.0205,     -0.0151,\n",
      "            -0.0299,     -0.0228,      0.0051,     -0.0351,      0.0089,\n",
      "            -0.0109,     -0.0227,     -0.0102,     -0.0138,     -0.0308,\n",
      "            -0.0315,     -0.0066,     -0.0159], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0325,  0.0296,  0.0218,  ..., -0.0352,  0.0202, -0.0197],\n",
      "        [-0.0185,  0.0096,  0.0291,  ...,  0.0355, -0.0157,  0.0173],\n",
      "        [ 0.0201,  0.0265, -0.0092,  ...,  0.0267, -0.0339,  0.0283],\n",
      "        ...,\n",
      "        [-0.0187,  0.0135,  0.0178,  ...,  0.0119, -0.0206, -0.0047],\n",
      "        [ 0.0306,  0.0217, -0.0068,  ...,  0.0355,  0.0052,  0.0159],\n",
      "        [ 0.0346, -0.0163, -0.0118,  ..., -0.0217, -0.0356,  0.0189]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0226,  0.0064, -0.0112,  ...,  0.0065, -0.0293,  0.0102],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0146,  0.0016, -0.0081,  ..., -0.0112,  0.0026,  0.0111],\n",
      "        [-0.0139,  0.0019,  0.0157,  ...,  0.0027,  0.0129, -0.0093],\n",
      "        [ 0.0161, -0.0070,  0.0006,  ..., -0.0088,  0.0092,  0.0141],\n",
      "        ...,\n",
      "        [-0.0024,  0.0033, -0.0114,  ..., -0.0026,  0.0168,  0.0042],\n",
      "        [-0.0060,  0.0032,  0.0127,  ...,  0.0125, -0.0086, -0.0016],\n",
      "        [ 0.0148,  0.0173,  0.0152,  ...,  0.0163,  0.0179, -0.0070]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([     0.0007,     -0.0160,     -0.0093,     -0.0045,     -0.0099,\n",
      "            -0.0114,      0.0042,     -0.0039,     -0.0176,     -0.0042,\n",
      "             0.0112,     -0.0020,      0.0067,     -0.0023,      0.0078,\n",
      "            -0.0141,     -0.0162,     -0.0098,     -0.0009,      0.0067,\n",
      "            -0.0033,      0.0019,     -0.0003,      0.0128,      0.0100,\n",
      "            -0.0116,      0.0079,     -0.0010,      0.0089,     -0.0163,\n",
      "            -0.0050,      0.0081,      0.0084,      0.0085,     -0.0143,\n",
      "             0.0169,     -0.0023,     -0.0133,      0.0083,      0.0118,\n",
      "            -0.0076,     -0.0017,      0.0143,      0.0028,      0.0015,\n",
      "            -0.0155,      0.0024,     -0.0014,     -0.0127,     -0.0022,\n",
      "             0.0099,      0.0138,     -0.0056,     -0.0008,      0.0092,\n",
      "             0.0163,      0.0130,     -0.0101,     -0.0173,      0.0166,\n",
      "             0.0173,      0.0045,      0.0085,     -0.0132,     -0.0044,\n",
      "             0.0036,     -0.0136,      0.0015,      0.0004,      0.0179,\n",
      "            -0.0175,      0.0163,     -0.0000,     -0.0101,      0.0080,\n",
      "            -0.0008,     -0.0001,     -0.0096,     -0.0062,     -0.0141,\n",
      "             0.0179,      0.0019,     -0.0160,     -0.0119,     -0.0103,\n",
      "            -0.0041,     -0.0017,      0.0068,      0.0162,      0.0092,\n",
      "             0.0057,      0.0050,     -0.0171,     -0.0051,     -0.0012,\n",
      "             0.0114,      0.0131,      0.0092,      0.0141,     -0.0029,\n",
      "             0.0065,     -0.0118,     -0.0023,      0.0063,      0.0147,\n",
      "             0.0039,      0.0048,      0.0040,     -0.0178,      0.0131,\n",
      "            -0.0150,      0.0095,     -0.0109,     -0.0002,     -0.0118,\n",
      "             0.0048,      0.0023,      0.0180,     -0.0116,      0.0060,\n",
      "             0.0061,      0.0085,     -0.0040,      0.0017,      0.0060,\n",
      "            -0.0107,      0.0036,      0.0070,     -0.0090,      0.0062,\n",
      "             0.0095,      0.0097,     -0.0126,      0.0071,      0.0089,\n",
      "             0.0056,      0.0024,      0.0055,      0.0011,      0.0087,\n",
      "            -0.0012,     -0.0097,      0.0139,      0.0020,     -0.0091,\n",
      "             0.0171,     -0.0053,      0.0147,      0.0013,     -0.0131,\n",
      "            -0.0088,      0.0117,     -0.0166,      0.0127,      0.0045,\n",
      "             0.0167,      0.0083,      0.0174,     -0.0002,      0.0018,\n",
      "             0.0069,     -0.0107,     -0.0091,     -0.0055,      0.0137,\n",
      "             0.0125,     -0.0035,      0.0090,     -0.0018,      0.0086,\n",
      "             0.0124,     -0.0064,      0.0162,     -0.0045,     -0.0077,\n",
      "             0.0037,     -0.0099,      0.0131,      0.0072,      0.0074,\n",
      "            -0.0164,      0.0059,     -0.0145,     -0.0079,     -0.0122,\n",
      "            -0.0168,      0.0134,      0.0138,     -0.0156,      0.0146,\n",
      "             0.0109,     -0.0140,      0.0011,     -0.0087,     -0.0157,\n",
      "            -0.0157,      0.0077,      0.0020,     -0.0096,     -0.0043,\n",
      "             0.0163,      0.0168,      0.0048,     -0.0143,      0.0146,\n",
      "             0.0068,      0.0158,      0.0138,     -0.0077,      0.0028,\n",
      "             0.0152,      0.0035,      0.0069,      0.0128,     -0.0053,\n",
      "            -0.0141,     -0.0160,      0.0074,      0.0052,     -0.0018,\n",
      "            -0.0159,      0.0006,     -0.0119,      0.0135,      0.0093,\n",
      "            -0.0086,      0.0129,     -0.0177,      0.0173,     -0.0163,\n",
      "            -0.0057,      0.0049,     -0.0167,     -0.0021,      0.0045,\n",
      "            -0.0049,      0.0076,     -0.0119,      0.0033,     -0.0024,\n",
      "             0.0035,      0.0011,     -0.0088,      0.0171,     -0.0008,\n",
      "             0.0156,     -0.0155,      0.0116,     -0.0107,      0.0143,\n",
      "            -0.0039,     -0.0012,     -0.0039,      0.0136,      0.0068,\n",
      "             0.0024,     -0.0033,     -0.0078,      0.0164,     -0.0020,\n",
      "             0.0083,     -0.0159,      0.0124,      0.0046,     -0.0029,\n",
      "            -0.0174,      0.0166,     -0.0135,     -0.0161,     -0.0073,\n",
      "             0.0167,     -0.0093,      0.0180,      0.0177,     -0.0057,\n",
      "            -0.0111,      0.0114,     -0.0178,      0.0076,     -0.0111,\n",
      "            -0.0067,      0.0045,     -0.0136,      0.0023,      0.0072,\n",
      "             0.0094,     -0.0161,      0.0021,     -0.0034,      0.0015,\n",
      "            -0.0155,      0.0120,     -0.0147,      0.0119,     -0.0056,\n",
      "            -0.0100,      0.0169,      0.0005,      0.0037,      0.0095,\n",
      "             0.0122,      0.0016,     -0.0127,      0.0019,      0.0007,\n",
      "             0.0178,      0.0086,     -0.0066,     -0.0172,      0.0062,\n",
      "            -0.0153,     -0.0108,     -0.0077,      0.0015,     -0.0085,\n",
      "            -0.0065,     -0.0089,     -0.0036,      0.0040,     -0.0062,\n",
      "             0.0090,     -0.0106,      0.0045,     -0.0089,     -0.0013,\n",
      "            -0.0049,      0.0013,      0.0004,      0.0112,     -0.0023,\n",
      "             0.0113,      0.0017,      0.0155,     -0.0171,     -0.0170,\n",
      "            -0.0143,     -0.0063,      0.0171,     -0.0066,      0.0079,\n",
      "            -0.0111,     -0.0155,      0.0031,      0.0071,     -0.0153,\n",
      "             0.0108,     -0.0085,     -0.0121,      0.0087,     -0.0037,\n",
      "            -0.0045,     -0.0104,     -0.0019,     -0.0107,      0.0020,\n",
      "             0.0145,      0.0154,      0.0053,     -0.0015,     -0.0066,\n",
      "             0.0078,      0.0031,      0.0000,      0.0121,     -0.0073,\n",
      "             0.0084,     -0.0040,     -0.0136,     -0.0010,     -0.0083,\n",
      "             0.0136,     -0.0155,      0.0172,     -0.0088,     -0.0178,\n",
      "            -0.0079,      0.0121,     -0.0139,     -0.0026,     -0.0118,\n",
      "            -0.0123,      0.0012,     -0.0068,     -0.0101,      0.0038,\n",
      "            -0.0097,      0.0064,      0.0039,     -0.0163,      0.0178,\n",
      "            -0.0169,      0.0002,      0.0165,     -0.0179,      0.0124,\n",
      "             0.0163,     -0.0151,     -0.0043,     -0.0131,     -0.0010,\n",
      "            -0.0016,      0.0052,     -0.0158,     -0.0058,     -0.0094,\n",
      "             0.0098,      0.0128,      0.0151,     -0.0132,     -0.0031,\n",
      "            -0.0074,      0.0178,     -0.0093,     -0.0052,      0.0115,\n",
      "            -0.0160,     -0.0148,      0.0146,     -0.0163,     -0.0093,\n",
      "            -0.0016,     -0.0168,      0.0065,      0.0061,     -0.0012,\n",
      "            -0.0072,      0.0169,      0.0121,      0.0043,     -0.0125,\n",
      "            -0.0017,     -0.0040,     -0.0163,     -0.0057,      0.0009,\n",
      "             0.0152,      0.0132,      0.0144,     -0.0003,      0.0063,\n",
      "             0.0143,      0.0139,     -0.0149,      0.0008,     -0.0106,\n",
      "             0.0128,     -0.0118,      0.0039,     -0.0123,     -0.0022,\n",
      "            -0.0075,     -0.0116,      0.0097,      0.0087,     -0.0169,\n",
      "            -0.0124,      0.0136,     -0.0069,      0.0084,      0.0031,\n",
      "             0.0068,      0.0088,     -0.0010,      0.0154,      0.0079,\n",
      "            -0.0032,      0.0005,     -0.0003,      0.0058,     -0.0071,\n",
      "             0.0015,      0.0048,      0.0017,      0.0004,      0.0144,\n",
      "             0.0119,     -0.0090,     -0.0011,     -0.0067,      0.0149,\n",
      "             0.0041,      0.0089,     -0.0035,     -0.0178,     -0.0117,\n",
      "             0.0175,     -0.0004,      0.0052,     -0.0136,     -0.0093,\n",
      "            -0.0180,     -0.0035,     -0.0053,      0.0011,      0.0031,\n",
      "            -0.0032,     -0.0138,     -0.0130,      0.0162,      0.0069,\n",
      "             0.0060,      0.0179,     -0.0146,      0.0116,     -0.0040,\n",
      "             0.0011,      0.0121,     -0.0007,     -0.0097,     -0.0074,\n",
      "             0.0022,     -0.0031,      0.0152,     -0.0085,     -0.0089,\n",
      "             0.0170,     -0.0022,      0.0002,      0.0020,     -0.0146,\n",
      "            -0.0151,     -0.0096,      0.0084,     -0.0049,     -0.0061,\n",
      "            -0.0148,     -0.0005,      0.0026,      0.0121,     -0.0141,\n",
      "            -0.0154,      0.0052,      0.0113,      0.0000,     -0.0073,\n",
      "            -0.0152,     -0.0040,     -0.0069,      0.0107,      0.0131,\n",
      "             0.0134,      0.0024,      0.0071,     -0.0070,      0.0141,\n",
      "            -0.0070,     -0.0129,      0.0162,      0.0118,     -0.0163,\n",
      "             0.0011,      0.0050,     -0.0088,      0.0088,      0.0117,\n",
      "             0.0016,     -0.0127,      0.0141,     -0.0173,      0.0153,\n",
      "             0.0009,      0.0119,     -0.0067,      0.0177,      0.0065,\n",
      "            -0.0054,     -0.0137,     -0.0046,     -0.0103,     -0.0017,\n",
      "             0.0024,     -0.0009,      0.0125,     -0.0067,     -0.0080,\n",
      "            -0.0157,     -0.0084,     -0.0083,      0.0097,      0.0001,\n",
      "            -0.0025,      0.0116,     -0.0141,     -0.0130,      0.0118,\n",
      "             0.0144,     -0.0053,      0.0071,      0.0021,     -0.0131,\n",
      "             0.0006,      0.0136,      0.0163,     -0.0086,      0.0077,\n",
      "             0.0118,     -0.0110,      0.0118,     -0.0037,     -0.0053,\n",
      "             0.0061,      0.0124,      0.0045,     -0.0076,     -0.0166,\n",
      "             0.0152,     -0.0140,      0.0025,     -0.0164,      0.0064,\n",
      "             0.0095,      0.0179,      0.0067,      0.0050,     -0.0021,\n",
      "             0.0089,     -0.0038,     -0.0073,      0.0043,     -0.0150,\n",
      "             0.0089,      0.0012,     -0.0152,     -0.0020,     -0.0131,\n",
      "            -0.0058,     -0.0099,     -0.0103,     -0.0030,      0.0057,\n",
      "             0.0098,      0.0028,      0.0068,     -0.0082,      0.0004,\n",
      "             0.0022,      0.0114,     -0.0044,     -0.0079,     -0.0085,\n",
      "            -0.0065,     -0.0143,     -0.0044,     -0.0105,     -0.0126,\n",
      "             0.0056,     -0.0170,     -0.0127,     -0.0078,      0.0025,\n",
      "             0.0008,      0.0010,     -0.0020,      0.0047,     -0.0030,\n",
      "             0.0075,     -0.0104,      0.0152,      0.0048,     -0.0148,\n",
      "            -0.0013,     -0.0020,     -0.0143,      0.0156,     -0.0131,\n",
      "            -0.0125,     -0.0096,      0.0024,     -0.0111,     -0.0137,\n",
      "             0.0097,     -0.0056,     -0.0131,     -0.0110,      0.0054,\n",
      "            -0.0148,     -0.0096,      0.0083,      0.0165,      0.0068,\n",
      "             0.0033,     -0.0045,      0.0064,      0.0028,     -0.0148,\n",
      "             0.0050,      0.0023,     -0.0120,      0.0047,     -0.0030,\n",
      "             0.0176,      0.0154,     -0.0009,      0.0153,     -0.0135,\n",
      "            -0.0011,      0.0073,     -0.0129,      0.0170,      0.0113,\n",
      "            -0.0084,      0.0168,      0.0064,     -0.0153,     -0.0091,\n",
      "            -0.0069,      0.0003,      0.0030,     -0.0161,     -0.0049,\n",
      "             0.0131,      0.0123,     -0.0146,     -0.0066,      0.0157,\n",
      "             0.0067,      0.0142,      0.0035,      0.0180,      0.0048,\n",
      "            -0.0017,     -0.0044,      0.0031,     -0.0069,      0.0057,\n",
      "             0.0036,      0.0144,      0.0043,     -0.0030,     -0.0138,\n",
      "            -0.0153,      0.0051,     -0.0145,     -0.0136,      0.0121,\n",
      "            -0.0102,     -0.0008,      0.0173,      0.0158,      0.0023,\n",
      "             0.0077,      0.0087,      0.0160,      0.0124,     -0.0071,\n",
      "             0.0097,      0.0102,      0.0167,     -0.0047,      0.0002,\n",
      "             0.0121,     -0.0180,      0.0066,     -0.0162,      0.0051,\n",
      "            -0.0038,     -0.0004,     -0.0055,      0.0036,     -0.0123,\n",
      "            -0.0048,     -0.0144,      0.0101,      0.0121,     -0.0094,\n",
      "            -0.0149,     -0.0080,     -0.0102], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0181, -0.0075,  0.0042,  ...,  0.0008, -0.0227, -0.0305],\n",
      "        [-0.0147, -0.0307,  0.0298,  ...,  0.0245, -0.0252,  0.0177],\n",
      "        [-0.0208, -0.0050,  0.0131,  ...,  0.0204,  0.0151, -0.0300],\n",
      "        ...,\n",
      "        [ 0.0174, -0.0227,  0.0089,  ...,  0.0358,  0.0205, -0.0272],\n",
      "        [-0.0062,  0.0120, -0.0050,  ...,  0.0166, -0.0232,  0.0141],\n",
      "        [ 0.0155, -0.0161, -0.0205,  ..., -0.0192, -0.0043,  0.0078]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0264, -0.0033,  0.0135,  ...,  0.0151,  0.0345, -0.0213],\n",
      "        [ 0.0135, -0.0188,  0.0294,  ..., -0.0137,  0.0251,  0.0035],\n",
      "        [-0.0151, -0.0184,  0.0031,  ...,  0.0267, -0.0170,  0.0258],\n",
      "        ...,\n",
      "        [ 0.0171, -0.0292,  0.0325,  ...,  0.0132, -0.0274, -0.0211],\n",
      "        [-0.0045, -0.0263, -0.0312,  ...,  0.0308,  0.0007,  0.0283],\n",
      "        [ 0.0024, -0.0169,  0.0084,  ...,  0.0035,  0.0142,  0.0311]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0143, -0.0205, -0.0265,  ...,  0.0211,  0.0167,  0.0293],\n",
      "        [ 0.0227, -0.0118,  0.0084,  ..., -0.0328,  0.0327,  0.0219],\n",
      "        [-0.0035,  0.0122, -0.0246,  ...,  0.0011,  0.0237,  0.0025],\n",
      "        ...,\n",
      "        [ 0.0073,  0.0269, -0.0235,  ...,  0.0020, -0.0297,  0.0027],\n",
      "        [-0.0129, -0.0207, -0.0085,  ...,  0.0305,  0.0102,  0.0002],\n",
      "        [ 0.0001,  0.0177,  0.0044,  ..., -0.0075,  0.0215, -0.0291]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0009,  0.0263, -0.0240,  ...,  0.0241,  0.0313,  0.0291],\n",
      "        [-0.0069,  0.0137, -0.0211,  ...,  0.0041, -0.0099, -0.0298],\n",
      "        [ 0.0161, -0.0221, -0.0058,  ..., -0.0228, -0.0086, -0.0320],\n",
      "        ...,\n",
      "        [ 0.0353, -0.0318, -0.0093,  ...,  0.0338, -0.0090,  0.0298],\n",
      "        [ 0.0074, -0.0332, -0.0271,  ..., -0.0024,  0.0064, -0.0200],\n",
      "        [ 0.0191, -0.0309, -0.0353,  ...,  0.0233, -0.0058, -0.0180]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([    -0.0084,      0.0134,      0.0149,     -0.0296,      0.0262,\n",
      "            -0.0229,     -0.0107,     -0.0005,      0.0307,     -0.0061,\n",
      "            -0.0018,      0.0134,     -0.0280,      0.0304,      0.0076,\n",
      "            -0.0357,      0.0179,     -0.0195,     -0.0130,      0.0241,\n",
      "             0.0100,      0.0174,      0.0021,     -0.0287,     -0.0032,\n",
      "            -0.0193,      0.0341,      0.0171,     -0.0291,     -0.0205,\n",
      "             0.0180,     -0.0323,     -0.0014,      0.0096,      0.0361,\n",
      "             0.0002,      0.0153,      0.0017,     -0.0009,      0.0235,\n",
      "            -0.0276,      0.0110,      0.0030,      0.0191,     -0.0068,\n",
      "             0.0026,      0.0189,      0.0340,     -0.0065,      0.0158,\n",
      "            -0.0051,      0.0055,     -0.0255,     -0.0145,     -0.0039,\n",
      "             0.0345,      0.0046,     -0.0139,     -0.0205,     -0.0177,\n",
      "             0.0188,      0.0283,     -0.0273,     -0.0032,      0.0164,\n",
      "             0.0078,      0.0285,     -0.0310,     -0.0198,      0.0218,\n",
      "            -0.0359,      0.0124,      0.0256,      0.0133,      0.0336,\n",
      "             0.0211,     -0.0357,     -0.0284,     -0.0015,     -0.0294,\n",
      "            -0.0100,      0.0050,     -0.0335,      0.0118,      0.0158,\n",
      "            -0.0265,     -0.0205,      0.0359,      0.0172,     -0.0219,\n",
      "            -0.0192,     -0.0262,      0.0243,     -0.0017,     -0.0018,\n",
      "            -0.0324,      0.0222,     -0.0113,     -0.0192,      0.0193,\n",
      "            -0.0189,     -0.0233,      0.0252,     -0.0069,     -0.0324,\n",
      "            -0.0321,     -0.0002,      0.0356,      0.0084,      0.0316,\n",
      "            -0.0256,     -0.0031,      0.0121,     -0.0109,      0.0141,\n",
      "            -0.0338,     -0.0200,      0.0088,     -0.0024,     -0.0068,\n",
      "            -0.0196,      0.0314,     -0.0051,     -0.0007,      0.0041,\n",
      "            -0.0057,     -0.0125,     -0.0227,      0.0188,     -0.0135,\n",
      "            -0.0304,     -0.0095,     -0.0245,     -0.0196,     -0.0081,\n",
      "             0.0217,      0.0329,      0.0234,      0.0271,      0.0268,\n",
      "            -0.0289,     -0.0018,     -0.0239,     -0.0070,      0.0270,\n",
      "            -0.0080,     -0.0303,     -0.0006,      0.0238,     -0.0226,\n",
      "             0.0116,     -0.0258,     -0.0210,      0.0010,      0.0317,\n",
      "            -0.0253,     -0.0257,      0.0074,      0.0037,      0.0070,\n",
      "             0.0117,      0.0130,     -0.0163,     -0.0308,      0.0025,\n",
      "            -0.0355,     -0.0120,      0.0134,     -0.0068,     -0.0345,\n",
      "            -0.0300,      0.0125,     -0.0340,     -0.0090,     -0.0040,\n",
      "             0.0308,      0.0135,      0.0351,     -0.0111,     -0.0320,\n",
      "             0.0006,     -0.0015,      0.0022,     -0.0333,     -0.0031,\n",
      "             0.0010,     -0.0076,     -0.0123,      0.0001,     -0.0192,\n",
      "             0.0107,      0.0138,      0.0304,      0.0338,      0.0155,\n",
      "            -0.0282,      0.0061,     -0.0231,     -0.0214,      0.0225,\n",
      "             0.0152,      0.0097,     -0.0006,     -0.0160,     -0.0095,\n",
      "             0.0283,      0.0299,      0.0011,      0.0194,      0.0288,\n",
      "            -0.0102,     -0.0298,      0.0286,      0.0274,      0.0108,\n",
      "            -0.0135,     -0.0080,      0.0230,      0.0016,      0.0243,\n",
      "            -0.0293,     -0.0118,      0.0265,      0.0198,     -0.0140,\n",
      "            -0.0189,      0.0043,      0.0206,     -0.0200,     -0.0188,\n",
      "            -0.0177,     -0.0097,     -0.0243,      0.0190,      0.0194,\n",
      "            -0.0208,     -0.0024,      0.0277,      0.0154,     -0.0331,\n",
      "            -0.0184,      0.0311,     -0.0064,     -0.0129,     -0.0289,\n",
      "            -0.0173,     -0.0331,     -0.0214,      0.0248,     -0.0090,\n",
      "            -0.0159,     -0.0280,      0.0341,      0.0150,      0.0250,\n",
      "            -0.0312,      0.0258,      0.0157,     -0.0159,     -0.0104,\n",
      "            -0.0204,     -0.0254,      0.0347,     -0.0029,     -0.0195,\n",
      "             0.0140,     -0.0277,     -0.0285,      0.0224,      0.0238,\n",
      "             0.0121,     -0.0185,     -0.0079,      0.0027,     -0.0155,\n",
      "            -0.0113,      0.0041,      0.0218,     -0.0122,     -0.0182,\n",
      "            -0.0172,      0.0107,      0.0358,     -0.0351,     -0.0150,\n",
      "             0.0196,      0.0327,      0.0347,     -0.0033,      0.0304,\n",
      "            -0.0178,     -0.0290,     -0.0204,     -0.0289,     -0.0220,\n",
      "             0.0064,      0.0014,     -0.0039,      0.0094,      0.0300,\n",
      "             0.0077,     -0.0354,      0.0318,      0.0319,      0.0226,\n",
      "             0.0289,     -0.0144,      0.0279,      0.0065,      0.0345,\n",
      "             0.0114,      0.0035,      0.0200,      0.0180,      0.0233,\n",
      "             0.0108,     -0.0346,      0.0075,     -0.0125,      0.0341,\n",
      "             0.0076,     -0.0159,     -0.0177,     -0.0234,      0.0184,\n",
      "            -0.0015,     -0.0248,      0.0082,      0.0128,     -0.0265,\n",
      "             0.0268,      0.0037,      0.0018,     -0.0132,      0.0206,\n",
      "             0.0350,      0.0055,      0.0032,      0.0078,      0.0177,\n",
      "             0.0121,      0.0172,     -0.0019,      0.0007,      0.0266,\n",
      "            -0.0239,      0.0170,     -0.0035,      0.0242,     -0.0105,\n",
      "            -0.0120,     -0.0137,     -0.0178,     -0.0074,      0.0041,\n",
      "             0.0193,     -0.0103,     -0.0148,     -0.0315,      0.0150,\n",
      "            -0.0082,      0.0197,     -0.0009,      0.0125,     -0.0075,\n",
      "             0.0293,      0.0310,     -0.0141,      0.0015,     -0.0144,\n",
      "            -0.0247,      0.0186,      0.0285,      0.0196,     -0.0083,\n",
      "            -0.0154,      0.0302,      0.0149,      0.0137,     -0.0041,\n",
      "            -0.0359,      0.0184,     -0.0305,      0.0214,     -0.0087,\n",
      "             0.0208,      0.0344,      0.0342,     -0.0216,      0.0067,\n",
      "             0.0083,     -0.0151,     -0.0027,     -0.0129,     -0.0162,\n",
      "             0.0129,      0.0160,      0.0340,     -0.0132,      0.0232,\n",
      "            -0.0094,      0.0265,      0.0005,     -0.0042,     -0.0359,\n",
      "             0.0080,     -0.0296,      0.0228,     -0.0327,      0.0105,\n",
      "             0.0230,     -0.0290,     -0.0270,      0.0124,      0.0341,\n",
      "            -0.0096,     -0.0154,      0.0104,      0.0063,     -0.0229,\n",
      "             0.0020,      0.0312,      0.0352,     -0.0319,     -0.0355,\n",
      "            -0.0121,      0.0040,      0.0183,      0.0343,      0.0027,\n",
      "             0.0000,      0.0155,     -0.0214,      0.0216,     -0.0234,\n",
      "            -0.0165,     -0.0033,      0.0146,     -0.0165,     -0.0329,\n",
      "            -0.0002,     -0.0084,      0.0152,      0.0333,     -0.0334,\n",
      "            -0.0128,     -0.0132,     -0.0298,      0.0207,     -0.0141,\n",
      "            -0.0266,      0.0127,      0.0093,      0.0291,      0.0133,\n",
      "            -0.0073,     -0.0333,      0.0237,      0.0170,     -0.0201,\n",
      "            -0.0310,     -0.0200,      0.0200,      0.0046,      0.0088,\n",
      "            -0.0123,     -0.0037,      0.0140,      0.0053,      0.0095,\n",
      "             0.0130,      0.0211,      0.0358,      0.0245,     -0.0009,\n",
      "            -0.0209,     -0.0143,      0.0348,      0.0280,      0.0283,\n",
      "            -0.0346,      0.0059,      0.0148,      0.0283,      0.0292,\n",
      "             0.0325,     -0.0111,      0.0057,      0.0264,      0.0283,\n",
      "            -0.0145,     -0.0031,     -0.0105,     -0.0026,      0.0206,\n",
      "            -0.0038,      0.0177,     -0.0300,     -0.0296,     -0.0181,\n",
      "             0.0006,      0.0218,     -0.0339,     -0.0270,      0.0001,\n",
      "            -0.0251,      0.0221,     -0.0149,     -0.0215,     -0.0176,\n",
      "             0.0076,      0.0268,      0.0070,      0.0251,      0.0259,\n",
      "             0.0121,     -0.0137,      0.0099,     -0.0308,     -0.0146,\n",
      "            -0.0357,      0.0345,     -0.0325,     -0.0103,      0.0038,\n",
      "             0.0198,     -0.0242,     -0.0169,      0.0323,      0.0014,\n",
      "            -0.0097,      0.0244,     -0.0202,      0.0067,     -0.0026,\n",
      "             0.0280,      0.0343,     -0.0242,     -0.0314,     -0.0214,\n",
      "             0.0125,      0.0230,     -0.0239,      0.0332,      0.0129,\n",
      "             0.0342,      0.0092,      0.0207,     -0.0107,      0.0356,\n",
      "             0.0310,      0.0010,      0.0231,      0.0227,     -0.0078,\n",
      "             0.0297,     -0.0128,      0.0218,     -0.0172,     -0.0220,\n",
      "             0.0194,     -0.0175,      0.0101,     -0.0142,     -0.0120,\n",
      "            -0.0250,      0.0216,      0.0259,      0.0166,     -0.0192,\n",
      "             0.0151,     -0.0194,     -0.0240,     -0.0160,     -0.0144,\n",
      "            -0.0304,     -0.0160,     -0.0035,      0.0002,      0.0168,\n",
      "            -0.0035,      0.0070,      0.0123,     -0.0314,     -0.0115,\n",
      "             0.0241,      0.0031,     -0.0353,      0.0089,     -0.0248,\n",
      "             0.0003,     -0.0317,      0.0079,      0.0007,     -0.0283,\n",
      "             0.0010,      0.0191,      0.0230,     -0.0011,     -0.0281,\n",
      "            -0.0341,     -0.0144,      0.0080,      0.0018,      0.0260,\n",
      "            -0.0093,      0.0072,     -0.0092,     -0.0082,      0.0314,\n",
      "             0.0005,     -0.0319,     -0.0109,     -0.0140,      0.0226,\n",
      "             0.0263,     -0.0068,      0.0201,     -0.0012,     -0.0149,\n",
      "             0.0350,      0.0235,     -0.0147,      0.0151,      0.0281,\n",
      "            -0.0186,     -0.0341,      0.0132,     -0.0132,     -0.0057,\n",
      "            -0.0021,      0.0119,     -0.0157,      0.0123,     -0.0065,\n",
      "             0.0244,     -0.0305,     -0.0171,     -0.0029,     -0.0238,\n",
      "             0.0291,     -0.0254,     -0.0271,     -0.0324,      0.0099,\n",
      "             0.0346,     -0.0291,     -0.0162,      0.0273,      0.0307,\n",
      "             0.0098,     -0.0322,     -0.0048,      0.0024,     -0.0118,\n",
      "             0.0186,     -0.0277,     -0.0098,      0.0148,      0.0224,\n",
      "            -0.0127,     -0.0170,     -0.0288,      0.0112,     -0.0095,\n",
      "             0.0093,     -0.0032,     -0.0264,      0.0142,     -0.0249,\n",
      "             0.0334,      0.0215,      0.0330,      0.0102,      0.0118,\n",
      "            -0.0028,     -0.0199,      0.0191,      0.0155,     -0.0046,\n",
      "            -0.0051,      0.0274,     -0.0303,      0.0244,     -0.0294,\n",
      "             0.0191,     -0.0063,      0.0089,      0.0204,     -0.0205,\n",
      "             0.0147,     -0.0250,      0.0170,      0.0111,     -0.0159,\n",
      "            -0.0359,      0.0343,     -0.0345,      0.0005,     -0.0043,\n",
      "            -0.0241,      0.0034,      0.0355,     -0.0179,     -0.0117,\n",
      "             0.0202,      0.0291,     -0.0045,      0.0080,      0.0040,\n",
      "             0.0065,     -0.0003,     -0.0258,      0.0187,      0.0196,\n",
      "             0.0359,     -0.0242,     -0.0287,     -0.0215,      0.0235,\n",
      "            -0.0177,      0.0170,     -0.0358,      0.0207,      0.0355,\n",
      "             0.0196,     -0.0329,     -0.0242,      0.0158,      0.0263,\n",
      "            -0.0099,      0.0183,     -0.0020,      0.0116,     -0.0050,\n",
      "            -0.0203,      0.0258,     -0.0216,     -0.0203,      0.0301,\n",
      "             0.0188,     -0.0185,      0.0285,      0.0293,     -0.0058,\n",
      "            -0.0247,     -0.0266,     -0.0355,      0.0245,     -0.0084,\n",
      "            -0.0115,      0.0297,      0.0094,     -0.0103,     -0.0029,\n",
      "             0.0302,      0.0297,     -0.0092,      0.0230,     -0.0297,\n",
      "             0.0296,     -0.0226,      0.0334,     -0.0183,      0.0224,\n",
      "             0.0320,      0.0002,     -0.0150], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0142, -0.0260,  0.0183,  ..., -0.0064, -0.0190,  0.0081],\n",
      "        [ 0.0138, -0.0269, -0.0218,  ...,  0.0071,  0.0143, -0.0340],\n",
      "        [-0.0328,  0.0211, -0.0270,  ...,  0.0318,  0.0113, -0.0008],\n",
      "        ...,\n",
      "        [ 0.0223, -0.0130, -0.0195,  ..., -0.0010, -0.0010,  0.0139],\n",
      "        [ 0.0292,  0.0182,  0.0146,  ...,  0.0109, -0.0037,  0.0152],\n",
      "        [ 0.0171,  0.0146,  0.0257,  ..., -0.0261,  0.0206,  0.0278]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0357, -0.0162, -0.0006,  ..., -0.0282,  0.0233,  0.0282],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0014, -0.0167,  0.0170,  ..., -0.0134, -0.0061,  0.0110],\n",
      "        [ 0.0016,  0.0103, -0.0100,  ...,  0.0043,  0.0077, -0.0169],\n",
      "        [-0.0022, -0.0123,  0.0033,  ..., -0.0141, -0.0079, -0.0064],\n",
      "        ...,\n",
      "        [ 0.0054,  0.0084,  0.0045,  ...,  0.0168, -0.0122,  0.0054],\n",
      "        [ 0.0104,  0.0074,  0.0130,  ..., -0.0026, -0.0151, -0.0144],\n",
      "        [ 0.0011, -0.0080,  0.0054,  ...,  0.0049, -0.0107, -0.0018]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([    -0.0087,      0.0179,     -0.0165,      0.0085,      0.0089,\n",
      "            -0.0170,      0.0075,     -0.0079,      0.0119,     -0.0049,\n",
      "             0.0052,      0.0092,     -0.0080,     -0.0016,      0.0081,\n",
      "            -0.0124,      0.0108,      0.0170,     -0.0152,     -0.0016,\n",
      "             0.0048,     -0.0008,      0.0129,     -0.0062,      0.0051,\n",
      "             0.0084,      0.0156,      0.0118,      0.0102,      0.0125,\n",
      "            -0.0126,      0.0120,     -0.0125,     -0.0153,      0.0172,\n",
      "             0.0028,      0.0035,     -0.0018,      0.0056,     -0.0072,\n",
      "            -0.0135,     -0.0020,      0.0002,     -0.0157,      0.0012,\n",
      "            -0.0123,      0.0103,     -0.0034,     -0.0078,     -0.0083,\n",
      "            -0.0144,     -0.0087,     -0.0177,     -0.0059,      0.0083,\n",
      "            -0.0028,      0.0144,      0.0012,     -0.0054,     -0.0045,\n",
      "            -0.0036,      0.0019,      0.0053,      0.0100,      0.0175,\n",
      "            -0.0058,     -0.0095,     -0.0150,      0.0126,      0.0147,\n",
      "             0.0122,      0.0075,     -0.0079,      0.0044,      0.0083,\n",
      "            -0.0176,      0.0043,     -0.0142,      0.0120,      0.0088,\n",
      "             0.0074,     -0.0170,      0.0152,      0.0021,     -0.0160,\n",
      "            -0.0057,      0.0177,      0.0094,     -0.0052,     -0.0175,\n",
      "             0.0000,     -0.0002,      0.0089,      0.0170,      0.0037,\n",
      "             0.0023,      0.0150,     -0.0061,      0.0172,     -0.0080,\n",
      "            -0.0066,      0.0016,     -0.0006,     -0.0054,     -0.0067,\n",
      "            -0.0027,     -0.0126,     -0.0150,     -0.0152,      0.0100,\n",
      "            -0.0002,      0.0163,     -0.0175,      0.0084,      0.0028,\n",
      "            -0.0093,      0.0033,     -0.0095,      0.0021,     -0.0131,\n",
      "            -0.0036,     -0.0028,      0.0055,     -0.0115,      0.0094,\n",
      "            -0.0077,      0.0174,      0.0102,      0.0150,      0.0072,\n",
      "            -0.0046,     -0.0143,      0.0089,     -0.0116,      0.0070,\n",
      "            -0.0145,      0.0055,     -0.0129,     -0.0071,      0.0115,\n",
      "             0.0132,      0.0141,      0.0095,      0.0178,      0.0146,\n",
      "            -0.0061,      0.0112,     -0.0054,      0.0134,      0.0028,\n",
      "            -0.0153,     -0.0020,      0.0112,     -0.0048,      0.0018,\n",
      "            -0.0066,     -0.0156,      0.0096,      0.0094,      0.0030,\n",
      "            -0.0039,     -0.0110,     -0.0099,      0.0123,     -0.0115,\n",
      "            -0.0145,      0.0060,     -0.0171,      0.0139,     -0.0144,\n",
      "            -0.0074,      0.0015,     -0.0054,      0.0037,     -0.0117,\n",
      "            -0.0153,     -0.0046,      0.0167,     -0.0125,     -0.0160,\n",
      "            -0.0010,     -0.0067,     -0.0098,      0.0168,      0.0003,\n",
      "             0.0029,     -0.0122,     -0.0022,      0.0051,     -0.0069,\n",
      "            -0.0039,     -0.0044,     -0.0045,     -0.0005,      0.0126,\n",
      "            -0.0041,      0.0137,     -0.0117,      0.0073,     -0.0087,\n",
      "            -0.0019,      0.0131,     -0.0080,     -0.0082,      0.0060,\n",
      "             0.0021,     -0.0081,      0.0065,      0.0167,      0.0039,\n",
      "             0.0091,      0.0020,     -0.0166,      0.0030,      0.0115,\n",
      "            -0.0083,     -0.0111,     -0.0110,      0.0144,     -0.0090,\n",
      "            -0.0047,      0.0113,      0.0054,     -0.0042,     -0.0019,\n",
      "            -0.0028,      0.0108,      0.0099,      0.0068,     -0.0014,\n",
      "            -0.0174,     -0.0160,     -0.0074,      0.0127,     -0.0152,\n",
      "            -0.0037,      0.0023,     -0.0133,     -0.0140,     -0.0013,\n",
      "            -0.0066,      0.0024,      0.0111,     -0.0097,     -0.0060,\n",
      "             0.0180,      0.0007,      0.0084,     -0.0068,     -0.0002,\n",
      "            -0.0174,      0.0155,      0.0125,      0.0040,     -0.0098,\n",
      "             0.0129,     -0.0170,     -0.0147,      0.0036,      0.0132,\n",
      "             0.0013,     -0.0138,      0.0145,     -0.0054,     -0.0069,\n",
      "             0.0048,     -0.0065,     -0.0137,     -0.0109,      0.0137,\n",
      "             0.0107,      0.0081,     -0.0086,      0.0168,      0.0025,\n",
      "            -0.0014,     -0.0080,     -0.0031,      0.0086,     -0.0030,\n",
      "             0.0127,     -0.0133,     -0.0102,     -0.0059,      0.0004,\n",
      "             0.0024,     -0.0055,     -0.0025,      0.0066,     -0.0155,\n",
      "             0.0162,      0.0029,     -0.0125,     -0.0176,      0.0004,\n",
      "             0.0159,     -0.0146,      0.0060,     -0.0095,      0.0093,\n",
      "             0.0007,      0.0117,      0.0139,     -0.0069,      0.0025,\n",
      "            -0.0121,     -0.0166,      0.0096,      0.0098,      0.0103,\n",
      "            -0.0111,      0.0102,     -0.0168,      0.0079,     -0.0012,\n",
      "             0.0048,     -0.0114,     -0.0171,      0.0018,      0.0083,\n",
      "            -0.0015,     -0.0014,     -0.0178,      0.0141,     -0.0109,\n",
      "             0.0055,     -0.0007,     -0.0173,      0.0103,     -0.0093,\n",
      "             0.0020,      0.0072,     -0.0072,     -0.0136,     -0.0132,\n",
      "             0.0007,      0.0129,     -0.0052,      0.0047,     -0.0137,\n",
      "            -0.0163,     -0.0086,      0.0004,      0.0102,      0.0015,\n",
      "            -0.0035,     -0.0124,      0.0148,     -0.0021,     -0.0110,\n",
      "            -0.0081,      0.0056,     -0.0139,      0.0115,      0.0036,\n",
      "            -0.0019,     -0.0017,      0.0007,     -0.0026,     -0.0086,\n",
      "             0.0103,     -0.0034,      0.0140,     -0.0161,      0.0003,\n",
      "            -0.0144,      0.0116,      0.0030,      0.0137,      0.0051,\n",
      "             0.0012,      0.0169,     -0.0177,      0.0175,      0.0047,\n",
      "             0.0020,     -0.0077,      0.0113,      0.0113,     -0.0024,\n",
      "            -0.0115,      0.0060,      0.0056,      0.0050,     -0.0107,\n",
      "            -0.0085,     -0.0032,     -0.0080,      0.0116,      0.0161,\n",
      "             0.0165,     -0.0158,     -0.0081,      0.0164,      0.0150,\n",
      "             0.0106,     -0.0045,      0.0017,      0.0021,     -0.0158,\n",
      "             0.0072,      0.0161,      0.0031,      0.0029,      0.0072,\n",
      "            -0.0059,      0.0043,     -0.0146,     -0.0048,      0.0170,\n",
      "            -0.0053,      0.0030,      0.0153,      0.0034,      0.0113,\n",
      "            -0.0172,     -0.0150,      0.0174,     -0.0097,     -0.0155,\n",
      "            -0.0178,     -0.0038,      0.0030,     -0.0083,     -0.0032,\n",
      "            -0.0047,     -0.0173,     -0.0070,     -0.0119,     -0.0106,\n",
      "             0.0172,      0.0063,     -0.0164,      0.0097,     -0.0170,\n",
      "             0.0063,     -0.0054,     -0.0025,     -0.0128,     -0.0112,\n",
      "             0.0112,      0.0116,      0.0070,      0.0035,      0.0167,\n",
      "             0.0123,     -0.0173,      0.0111,     -0.0091,      0.0122,\n",
      "             0.0003,      0.0001,      0.0105,      0.0095,     -0.0132,\n",
      "             0.0076,     -0.0122,     -0.0108,      0.0139,      0.0169,\n",
      "             0.0006,     -0.0100,     -0.0180,      0.0107,     -0.0003,\n",
      "             0.0012,     -0.0157,      0.0117,      0.0026,     -0.0140,\n",
      "            -0.0121,      0.0066,      0.0066,      0.0009,      0.0023,\n",
      "             0.0101,      0.0164,     -0.0119,     -0.0033,     -0.0005,\n",
      "             0.0076,     -0.0069,      0.0128,      0.0044,      0.0174,\n",
      "            -0.0044,      0.0149,      0.0028,     -0.0137,      0.0033,\n",
      "             0.0137,     -0.0165,     -0.0163,      0.0125,     -0.0053,\n",
      "            -0.0073,     -0.0046,      0.0140,     -0.0007,     -0.0096,\n",
      "            -0.0013,     -0.0060,      0.0084,      0.0160,     -0.0145,\n",
      "            -0.0049,     -0.0081,      0.0059,     -0.0001,      0.0156,\n",
      "             0.0099,     -0.0115,     -0.0018,     -0.0115,     -0.0168,\n",
      "            -0.0088,      0.0087,     -0.0029,     -0.0144,      0.0015,\n",
      "            -0.0103,     -0.0173,     -0.0098,      0.0148,     -0.0146,\n",
      "             0.0038,     -0.0175,      0.0028,     -0.0057,      0.0138,\n",
      "            -0.0171,      0.0066,      0.0176,      0.0157,     -0.0052,\n",
      "             0.0068,     -0.0109,     -0.0060,      0.0028,      0.0147,\n",
      "            -0.0156,      0.0140,     -0.0172,     -0.0154,      0.0105,\n",
      "            -0.0084,     -0.0098,      0.0069,      0.0084,     -0.0115,\n",
      "            -0.0146,     -0.0092,     -0.0085,     -0.0058,      0.0136,\n",
      "             0.0067,      0.0057,     -0.0056,      0.0025,     -0.0097,\n",
      "            -0.0176,      0.0104,     -0.0018,      0.0145,     -0.0143,\n",
      "            -0.0022,      0.0170,     -0.0012,      0.0045,      0.0113,\n",
      "             0.0070,      0.0159,     -0.0170,     -0.0050,      0.0009,\n",
      "            -0.0118,      0.0013,      0.0132,      0.0004,     -0.0163,\n",
      "             0.0138,      0.0117,     -0.0091,      0.0076,      0.0101,\n",
      "            -0.0051,      0.0033,      0.0037,      0.0164,      0.0007,\n",
      "            -0.0158,     -0.0051,      0.0037,      0.0071,      0.0120,\n",
      "            -0.0090,     -0.0129,      0.0105,      0.0139,     -0.0015,\n",
      "             0.0085,     -0.0040,      0.0039,      0.0087,     -0.0046,\n",
      "            -0.0018,     -0.0068,      0.0164,     -0.0145,      0.0025,\n",
      "             0.0001,      0.0078,     -0.0154,     -0.0176,      0.0155,\n",
      "             0.0051,      0.0161,     -0.0145,      0.0110,      0.0178,\n",
      "            -0.0175,      0.0162,     -0.0006,     -0.0143,      0.0049,\n",
      "            -0.0087,     -0.0118,      0.0121,      0.0026,     -0.0141,\n",
      "             0.0073,     -0.0098,     -0.0156,      0.0170,      0.0038,\n",
      "            -0.0165,     -0.0081,     -0.0117,      0.0092,      0.0165,\n",
      "            -0.0163,     -0.0155,      0.0158,     -0.0058,     -0.0170,\n",
      "            -0.0047,     -0.0161,      0.0043,     -0.0079,     -0.0097,\n",
      "             0.0131,      0.0118,     -0.0067,     -0.0084,     -0.0081,\n",
      "             0.0072,     -0.0029,      0.0005,     -0.0108,     -0.0109,\n",
      "            -0.0149,      0.0101,     -0.0091,      0.0024,     -0.0170,\n",
      "            -0.0131,      0.0087,      0.0163,      0.0007,      0.0029,\n",
      "             0.0159,     -0.0031,      0.0010,     -0.0041,     -0.0120,\n",
      "            -0.0077,     -0.0175,      0.0154,      0.0101,      0.0148,\n",
      "             0.0025,     -0.0176,     -0.0003,      0.0008,     -0.0126,\n",
      "            -0.0179,      0.0048,     -0.0098,     -0.0013,      0.0072,\n",
      "            -0.0041,     -0.0115,     -0.0074,      0.0081,      0.0093,\n",
      "             0.0110,      0.0098,     -0.0009,     -0.0064,      0.0137,\n",
      "            -0.0114,     -0.0151,     -0.0015,      0.0065,     -0.0082,\n",
      "             0.0112,     -0.0178,      0.0081,      0.0005,     -0.0122,\n",
      "            -0.0069,     -0.0128,      0.0095,     -0.0023,     -0.0083,\n",
      "             0.0104,      0.0050,     -0.0090,     -0.0108,      0.0161,\n",
      "             0.0122,     -0.0178,     -0.0092,      0.0022,      0.0130,\n",
      "            -0.0133,     -0.0134,     -0.0059,     -0.0046,      0.0180,\n",
      "            -0.0001,      0.0131,     -0.0124,      0.0119,      0.0084,\n",
      "             0.0090,      0.0145,     -0.0062,      0.0158,     -0.0148,\n",
      "            -0.0144,     -0.0004,     -0.0128,      0.0160,      0.0020,\n",
      "            -0.0069,     -0.0022,     -0.0088,      0.0085,      0.0062,\n",
      "             0.0039,      0.0096,      0.0138,     -0.0047,     -0.0038,\n",
      "            -0.0128,      0.0052,     -0.0092,      0.0148,      0.0138,\n",
      "            -0.0087,      0.0163,     -0.0115,      0.0138,      0.0036,\n",
      "            -0.0074,     -0.0077,      0.0064], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0102, -0.0322,  0.0283,  ...,  0.0240, -0.0230,  0.0346],\n",
      "        [ 0.0117,  0.0167,  0.0180,  ..., -0.0216, -0.0080, -0.0186],\n",
      "        [ 0.0359,  0.0041, -0.0322,  ..., -0.0334, -0.0257,  0.0205],\n",
      "        ...,\n",
      "        [ 0.0177,  0.0170,  0.0213,  ...,  0.0359, -0.0011, -0.0209],\n",
      "        [-0.0164, -0.0013,  0.0015,  ..., -0.0234, -0.0100,  0.0008],\n",
      "        [-0.0296,  0.0317,  0.0119,  ..., -0.0034, -0.0071, -0.0253]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0044, -0.0314,  0.0292,  ..., -0.0063, -0.0111, -0.0145],\n",
      "        [ 0.0242,  0.0219,  0.0168,  ...,  0.0037, -0.0240, -0.0287],\n",
      "        [ 0.0357, -0.0302,  0.0177,  ...,  0.0089, -0.0107, -0.0244],\n",
      "        ...,\n",
      "        [ 0.0281,  0.0338,  0.0307,  ..., -0.0213,  0.0273,  0.0057],\n",
      "        [ 0.0329, -0.0282, -0.0177,  ..., -0.0041,  0.0294, -0.0121],\n",
      "        [ 0.0220, -0.0095,  0.0359,  ...,  0.0172,  0.0178, -0.0108]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0173,  0.0241,  0.0262,  ...,  0.0306,  0.0186,  0.0309],\n",
      "        [ 0.0283, -0.0234,  0.0063,  ..., -0.0345, -0.0200,  0.0111],\n",
      "        [-0.0153,  0.0078, -0.0298,  ..., -0.0094,  0.0249, -0.0025],\n",
      "        ...,\n",
      "        [-0.0015,  0.0205, -0.0077,  ...,  0.0327, -0.0243, -0.0235],\n",
      "        [-0.0013,  0.0282, -0.0335,  ..., -0.0295,  0.0190, -0.0300],\n",
      "        [-0.0334, -0.0347,  0.0321,  ..., -0.0024, -0.0325,  0.0321]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0178,  0.0136, -0.0270,  ...,  0.0209, -0.0082,  0.0216],\n",
      "        [ 0.0218, -0.0172,  0.0330,  ...,  0.0281,  0.0224, -0.0286],\n",
      "        [ 0.0092,  0.0069, -0.0326,  ...,  0.0301, -0.0019, -0.0243],\n",
      "        ...,\n",
      "        [-0.0205,  0.0133, -0.0130,  ...,  0.0034,  0.0223,  0.0086],\n",
      "        [ 0.0222,  0.0214,  0.0308,  ..., -0.0229, -0.0119,  0.0265],\n",
      "        [ 0.0188, -0.0309, -0.0154,  ...,  0.0179,  0.0256, -0.0023]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([     0.0055,      0.0117,     -0.0259,     -0.0221,     -0.0082,\n",
      "             0.0249,     -0.0309,      0.0003,     -0.0236,     -0.0231,\n",
      "            -0.0276,     -0.0212,     -0.0192,      0.0155,     -0.0082,\n",
      "             0.0220,      0.0314,      0.0104,     -0.0081,      0.0268,\n",
      "            -0.0285,      0.0151,     -0.0138,     -0.0073,     -0.0287,\n",
      "             0.0109,      0.0202,     -0.0286,     -0.0306,     -0.0148,\n",
      "             0.0291,     -0.0161,      0.0199,      0.0006,     -0.0137,\n",
      "            -0.0307,      0.0239,      0.0320,      0.0077,     -0.0286,\n",
      "            -0.0053,      0.0296,     -0.0152,      0.0146,     -0.0138,\n",
      "            -0.0167,      0.0315,     -0.0291,     -0.0360,      0.0122,\n",
      "             0.0223,      0.0250,      0.0307,     -0.0126,      0.0046,\n",
      "             0.0055,     -0.0339,     -0.0350,      0.0293,      0.0009,\n",
      "             0.0100,      0.0286,     -0.0323,      0.0154,      0.0081,\n",
      "            -0.0226,     -0.0178,     -0.0093,      0.0218,     -0.0070,\n",
      "            -0.0174,      0.0150,      0.0281,     -0.0324,      0.0204,\n",
      "             0.0197,      0.0145,     -0.0101,     -0.0356,     -0.0351,\n",
      "             0.0263,      0.0115,     -0.0181,     -0.0275,      0.0178,\n",
      "             0.0342,      0.0125,     -0.0043,     -0.0331,     -0.0155,\n",
      "             0.0321,     -0.0105,      0.0252,     -0.0106,     -0.0336,\n",
      "            -0.0036,     -0.0214,      0.0277,     -0.0342,     -0.0047,\n",
      "             0.0104,     -0.0011,     -0.0321,     -0.0077,      0.0321,\n",
      "            -0.0133,     -0.0274,     -0.0167,     -0.0192,     -0.0151,\n",
      "             0.0130,      0.0281,      0.0054,      0.0107,      0.0059,\n",
      "            -0.0103,     -0.0102,     -0.0051,     -0.0233,     -0.0055,\n",
      "            -0.0081,      0.0141,      0.0340,     -0.0358,      0.0222,\n",
      "             0.0328,     -0.0011,      0.0011,     -0.0175,     -0.0095,\n",
      "             0.0346,      0.0163,      0.0283,     -0.0005,      0.0192,\n",
      "             0.0213,      0.0135,      0.0032,     -0.0136,     -0.0104,\n",
      "            -0.0287,      0.0291,     -0.0353,     -0.0080,     -0.0289,\n",
      "             0.0204,     -0.0308,      0.0115,     -0.0005,     -0.0126,\n",
      "            -0.0172,     -0.0326,      0.0287,      0.0252,      0.0112,\n",
      "             0.0233,      0.0071,     -0.0065,      0.0135,     -0.0292,\n",
      "             0.0229,     -0.0191,     -0.0164,     -0.0272,      0.0322,\n",
      "            -0.0062,      0.0346,      0.0016,      0.0274,     -0.0259,\n",
      "             0.0168,     -0.0265,     -0.0202,      0.0242,      0.0263,\n",
      "            -0.0093,     -0.0230,     -0.0179,     -0.0308,     -0.0254,\n",
      "            -0.0345,     -0.0234,      0.0181,     -0.0046,      0.0208,\n",
      "             0.0162,     -0.0093,     -0.0292,      0.0224,      0.0125,\n",
      "             0.0282,     -0.0194,      0.0091,     -0.0004,     -0.0015,\n",
      "            -0.0010,     -0.0089,      0.0263,      0.0130,      0.0017,\n",
      "             0.0319,      0.0006,      0.0305,      0.0046,      0.0169,\n",
      "             0.0003,     -0.0095,     -0.0266,     -0.0061,     -0.0345,\n",
      "             0.0163,      0.0201,      0.0295,      0.0269,     -0.0213,\n",
      "             0.0156,     -0.0191,     -0.0025,      0.0350,     -0.0341,\n",
      "            -0.0190,     -0.0221,      0.0065,     -0.0073,     -0.0006,\n",
      "            -0.0342,      0.0048,      0.0276,      0.0256,      0.0298,\n",
      "             0.0269,      0.0037,      0.0256,     -0.0075,      0.0047,\n",
      "            -0.0286,      0.0166,     -0.0028,      0.0315,      0.0133,\n",
      "            -0.0213,      0.0242,      0.0319,     -0.0331,      0.0134,\n",
      "            -0.0061,      0.0171,      0.0161,     -0.0263,      0.0132,\n",
      "            -0.0336,     -0.0161,      0.0180,     -0.0233,     -0.0199,\n",
      "            -0.0079,     -0.0205,     -0.0197,     -0.0022,     -0.0239,\n",
      "            -0.0147,      0.0041,      0.0339,      0.0005,      0.0000,\n",
      "            -0.0286,     -0.0343,     -0.0121,     -0.0095,     -0.0030,\n",
      "            -0.0035,     -0.0140,     -0.0195,     -0.0275,      0.0137,\n",
      "            -0.0176,     -0.0240,      0.0358,      0.0303,     -0.0268,\n",
      "            -0.0037,     -0.0236,      0.0225,      0.0189,     -0.0067,\n",
      "            -0.0178,     -0.0262,      0.0207,      0.0074,     -0.0111,\n",
      "            -0.0235,      0.0042,     -0.0198,      0.0138,      0.0224,\n",
      "             0.0021,      0.0076,     -0.0103,      0.0224,     -0.0076,\n",
      "            -0.0104,      0.0334,      0.0188,      0.0258,     -0.0085,\n",
      "            -0.0339,      0.0172,     -0.0202,     -0.0207,     -0.0032,\n",
      "             0.0221,      0.0179,     -0.0128,      0.0011,      0.0092,\n",
      "             0.0020,      0.0337,     -0.0235,      0.0235,      0.0343,\n",
      "             0.0243,      0.0223,      0.0161,     -0.0169,     -0.0256,\n",
      "            -0.0316,     -0.0312,     -0.0226,      0.0160,     -0.0067,\n",
      "             0.0053,     -0.0260,      0.0254,      0.0138,      0.0036,\n",
      "             0.0338,     -0.0226,      0.0272,      0.0303,      0.0192,\n",
      "             0.0161,      0.0125,      0.0083,     -0.0239,      0.0259,\n",
      "            -0.0331,      0.0003,      0.0054,      0.0269,      0.0244,\n",
      "            -0.0281,      0.0295,     -0.0140,      0.0195,      0.0135,\n",
      "            -0.0265,     -0.0134,     -0.0206,     -0.0281,     -0.0012,\n",
      "            -0.0020,      0.0333,      0.0318,      0.0014,     -0.0184,\n",
      "             0.0166,     -0.0206,      0.0162,      0.0043,     -0.0075,\n",
      "             0.0224,      0.0298,      0.0047,     -0.0225,     -0.0269,\n",
      "             0.0284,     -0.0273,      0.0236,      0.0154,      0.0349,\n",
      "             0.0256,     -0.0285,      0.0117,     -0.0326,      0.0095,\n",
      "            -0.0296,      0.0299,      0.0141,     -0.0025,      0.0268,\n",
      "            -0.0149,     -0.0197,     -0.0324,      0.0307,      0.0149,\n",
      "             0.0304,     -0.0332,      0.0127,     -0.0162,      0.0225,\n",
      "             0.0347,      0.0233,     -0.0056,     -0.0259,      0.0013,\n",
      "             0.0069,     -0.0197,     -0.0353,     -0.0099,     -0.0087,\n",
      "            -0.0313,      0.0166,     -0.0031,      0.0141,      0.0073,\n",
      "            -0.0177,      0.0342,      0.0245,      0.0126,     -0.0124,\n",
      "             0.0090,      0.0302,     -0.0051,      0.0216,      0.0305,\n",
      "            -0.0036,     -0.0198,     -0.0220,     -0.0356,     -0.0071,\n",
      "            -0.0102,     -0.0189,      0.0261,     -0.0099,     -0.0151,\n",
      "             0.0270,      0.0203,     -0.0074,     -0.0339,      0.0325,\n",
      "            -0.0130,      0.0229,      0.0116,      0.0318,      0.0246,\n",
      "             0.0232,      0.0060,     -0.0003,      0.0021,     -0.0298,\n",
      "            -0.0028,     -0.0130,      0.0265,     -0.0219,      0.0234,\n",
      "             0.0221,      0.0134,     -0.0204,     -0.0134,     -0.0301,\n",
      "             0.0068,      0.0213,     -0.0000,     -0.0199,     -0.0060,\n",
      "             0.0153,     -0.0344,     -0.0262,      0.0275,     -0.0258,\n",
      "            -0.0298,     -0.0083,     -0.0300,      0.0090,      0.0226,\n",
      "             0.0306,      0.0098,     -0.0177,      0.0261,      0.0267,\n",
      "            -0.0017,     -0.0238,      0.0018,      0.0232,     -0.0301,\n",
      "             0.0150,     -0.0290,     -0.0054,      0.0351,      0.0291,\n",
      "             0.0316,     -0.0304,     -0.0202,     -0.0258,     -0.0046,\n",
      "             0.0351,      0.0181,      0.0082,      0.0110,      0.0295,\n",
      "             0.0140,     -0.0167,      0.0259,     -0.0212,     -0.0110,\n",
      "             0.0322,      0.0330,      0.0149,     -0.0235,      0.0037,\n",
      "            -0.0265,     -0.0027,     -0.0323,      0.0210,      0.0355,\n",
      "            -0.0056,     -0.0242,      0.0352,     -0.0037,     -0.0095,\n",
      "            -0.0159,      0.0301,     -0.0105,      0.0118,     -0.0231,\n",
      "            -0.0306,      0.0087,      0.0194,     -0.0297,     -0.0147,\n",
      "            -0.0246,     -0.0324,      0.0181,      0.0337,      0.0107,\n",
      "             0.0285,      0.0122,     -0.0318,     -0.0281,      0.0227,\n",
      "            -0.0023,     -0.0134,     -0.0047,      0.0233,     -0.0037,\n",
      "             0.0317,     -0.0138,     -0.0278,      0.0122,     -0.0050,\n",
      "             0.0047,     -0.0117,      0.0222,      0.0313,     -0.0245,\n",
      "             0.0200,     -0.0325,      0.0055,     -0.0025,     -0.0200,\n",
      "             0.0019,      0.0234,      0.0059,     -0.0259,      0.0013,\n",
      "            -0.0351,     -0.0085,     -0.0209,     -0.0201,     -0.0109,\n",
      "            -0.0263,      0.0241,     -0.0202,      0.0082,      0.0096,\n",
      "             0.0049,     -0.0334,      0.0342,     -0.0194,      0.0307,\n",
      "            -0.0197,      0.0087,     -0.0316,     -0.0341,     -0.0096,\n",
      "             0.0176,     -0.0291,      0.0328,     -0.0040,      0.0105,\n",
      "             0.0287,     -0.0284,     -0.0299,      0.0102,     -0.0141,\n",
      "            -0.0269,      0.0196,      0.0200,      0.0339,     -0.0164,\n",
      "            -0.0214,      0.0287,     -0.0017,      0.0129,      0.0221,\n",
      "             0.0261,     -0.0074,      0.0106,      0.0332,     -0.0061,\n",
      "             0.0026,      0.0344,     -0.0268,      0.0334,     -0.0172,\n",
      "             0.0015,     -0.0025,      0.0009,     -0.0361,      0.0294,\n",
      "            -0.0268,     -0.0060,      0.0002,      0.0123,      0.0345,\n",
      "             0.0335,      0.0352,      0.0224,     -0.0089,      0.0074,\n",
      "            -0.0333,     -0.0203,     -0.0344,      0.0357,      0.0145,\n",
      "             0.0243,      0.0233,     -0.0243,      0.0169,      0.0201,\n",
      "            -0.0293,      0.0279,     -0.0163,      0.0081,      0.0276,\n",
      "             0.0021,      0.0259,      0.0262,      0.0294,      0.0164,\n",
      "            -0.0052,      0.0015,     -0.0029,     -0.0066,      0.0117,\n",
      "             0.0212,     -0.0223,      0.0313,     -0.0138,      0.0107,\n",
      "            -0.0016,     -0.0163,     -0.0069,     -0.0034,      0.0121,\n",
      "             0.0005,      0.0108,     -0.0065,     -0.0348,     -0.0154,\n",
      "            -0.0288,     -0.0157,     -0.0219,     -0.0024,      0.0322,\n",
      "            -0.0316,     -0.0335,      0.0309,      0.0110,     -0.0035,\n",
      "             0.0212,      0.0128,     -0.0314,     -0.0332,      0.0072,\n",
      "             0.0085,     -0.0267,     -0.0025,      0.0073,     -0.0160,\n",
      "             0.0151,     -0.0082,     -0.0061,     -0.0292,      0.0171,\n",
      "             0.0186,     -0.0110,     -0.0260,      0.0095,     -0.0342,\n",
      "            -0.0181,      0.0066,      0.0173,     -0.0103,     -0.0011,\n",
      "             0.0152,      0.0315,      0.0173,     -0.0330,      0.0164,\n",
      "            -0.0334,     -0.0059,     -0.0092,     -0.0281,      0.0344,\n",
      "             0.0126,      0.0355,     -0.0041,      0.0103,      0.0184,\n",
      "            -0.0320,     -0.0012,      0.0118,     -0.0164,      0.0078,\n",
      "            -0.0166,     -0.0288,     -0.0344,     -0.0286,     -0.0221,\n",
      "            -0.0325,      0.0027,      0.0259,      0.0180,     -0.0098,\n",
      "            -0.0147,      0.0343,      0.0245,     -0.0058,     -0.0099,\n",
      "             0.0332,     -0.0118,     -0.0338,      0.0223,      0.0213,\n",
      "             0.0259,      0.0146,     -0.0072,     -0.0095,     -0.0122,\n",
      "             0.0226,      0.0330,      0.0247,      0.0097,      0.0165,\n",
      "             0.0133,     -0.0114,     -0.0051,     -0.0235,      0.0179,\n",
      "             0.0232,      0.0257,      0.0119,      0.0006,      0.0225,\n",
      "            -0.0130,     -0.0220,     -0.0102], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0340,  0.0185,  0.0150,  ..., -0.0357, -0.0038, -0.0032],\n",
      "        [-0.0050, -0.0349,  0.0025,  ..., -0.0175, -0.0331, -0.0230],\n",
      "        [-0.0317,  0.0138,  0.0015,  ...,  0.0258,  0.0358, -0.0170],\n",
      "        ...,\n",
      "        [ 0.0119,  0.0287, -0.0293,  ...,  0.0214,  0.0078, -0.0030],\n",
      "        [-0.0051,  0.0157, -0.0243,  ...,  0.0346, -0.0166,  0.0227],\n",
      "        [ 0.0130, -0.0061, -0.0322,  ...,  0.0134,  0.0097,  0.0325]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0027, -0.0286, -0.0152,  ...,  0.0302, -0.0172, -0.0354],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0038, -0.0036,  0.0172,  ..., -0.0154, -0.0012, -0.0097],\n",
      "        [-0.0123, -0.0036,  0.0149,  ..., -0.0003,  0.0040,  0.0146],\n",
      "        [-0.0164, -0.0038, -0.0130,  ...,  0.0159, -0.0041,  0.0007],\n",
      "        ...,\n",
      "        [ 0.0118,  0.0032,  0.0070,  ...,  0.0047,  0.0019,  0.0135],\n",
      "        [ 0.0136, -0.0043,  0.0128,  ...,  0.0018, -0.0085,  0.0098],\n",
      "        [ 0.0096, -0.0092, -0.0055,  ...,  0.0166,  0.0122, -0.0144]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([     0.0135,      0.0013,     -0.0004,      0.0131,      0.0038,\n",
      "             0.0152,     -0.0116,     -0.0133,      0.0128,      0.0030,\n",
      "            -0.0071,     -0.0067,     -0.0011,     -0.0173,     -0.0131,\n",
      "            -0.0063,     -0.0064,      0.0165,     -0.0046,     -0.0050,\n",
      "            -0.0002,     -0.0080,     -0.0113,     -0.0081,      0.0162,\n",
      "            -0.0076,     -0.0126,     -0.0007,      0.0048,     -0.0036,\n",
      "             0.0141,     -0.0177,      0.0060,      0.0026,      0.0116,\n",
      "             0.0027,      0.0140,      0.0110,      0.0096,      0.0074,\n",
      "             0.0152,     -0.0061,      0.0136,      0.0046,      0.0057,\n",
      "             0.0056,     -0.0052,      0.0033,     -0.0146,     -0.0028,\n",
      "             0.0164,     -0.0119,     -0.0005,     -0.0028,     -0.0020,\n",
      "            -0.0011,     -0.0036,     -0.0033,      0.0062,     -0.0139,\n",
      "            -0.0173,     -0.0099,     -0.0042,     -0.0179,     -0.0149,\n",
      "             0.0030,      0.0136,     -0.0136,      0.0149,      0.0177,\n",
      "            -0.0121,      0.0050,      0.0062,      0.0017,      0.0139,\n",
      "             0.0041,      0.0157,      0.0145,     -0.0031,      0.0022,\n",
      "             0.0130,     -0.0074,     -0.0014,      0.0070,      0.0144,\n",
      "            -0.0145,     -0.0154,     -0.0005,     -0.0007,     -0.0063,\n",
      "            -0.0124,      0.0007,     -0.0155,     -0.0084,     -0.0074,\n",
      "             0.0071,      0.0092,      0.0104,     -0.0125,      0.0015,\n",
      "            -0.0147,     -0.0063,      0.0105,     -0.0006,      0.0116,\n",
      "            -0.0020,     -0.0160,     -0.0062,     -0.0019,      0.0117,\n",
      "            -0.0049,     -0.0106,      0.0034,      0.0019,     -0.0143,\n",
      "             0.0094,      0.0101,     -0.0116,      0.0081,     -0.0048,\n",
      "             0.0088,      0.0104,     -0.0065,     -0.0179,     -0.0057,\n",
      "            -0.0128,      0.0156,     -0.0137,      0.0165,      0.0137,\n",
      "             0.0096,     -0.0134,     -0.0176,      0.0006,      0.0110,\n",
      "            -0.0125,     -0.0091,     -0.0132,     -0.0102,     -0.0137,\n",
      "             0.0037,      0.0113,     -0.0052,      0.0014,     -0.0168,\n",
      "             0.0142,     -0.0117,      0.0110,     -0.0084,      0.0006,\n",
      "             0.0142,     -0.0162,     -0.0115,     -0.0125,     -0.0055,\n",
      "             0.0055,     -0.0168,     -0.0050,     -0.0057,     -0.0096,\n",
      "            -0.0087,      0.0063,     -0.0045,      0.0056,      0.0044,\n",
      "             0.0017,      0.0027,     -0.0152,     -0.0132,     -0.0069,\n",
      "            -0.0054,     -0.0088,     -0.0001,     -0.0011,      0.0025,\n",
      "            -0.0064,      0.0086,     -0.0119,     -0.0029,      0.0056,\n",
      "             0.0142,      0.0029,      0.0022,      0.0172,      0.0003,\n",
      "             0.0119,     -0.0180,      0.0023,      0.0139,     -0.0101,\n",
      "             0.0118,      0.0180,      0.0095,      0.0179,      0.0039,\n",
      "            -0.0018,      0.0160,     -0.0172,      0.0128,     -0.0114,\n",
      "            -0.0095,     -0.0005,      0.0164,     -0.0002,      0.0104,\n",
      "             0.0055,     -0.0031,     -0.0119,     -0.0091,      0.0180,\n",
      "             0.0130,      0.0042,      0.0120,      0.0113,      0.0170,\n",
      "            -0.0105,      0.0129,      0.0159,      0.0115,      0.0068,\n",
      "            -0.0093,     -0.0003,      0.0061,      0.0076,     -0.0086,\n",
      "             0.0011,      0.0125,     -0.0011,      0.0033,     -0.0066,\n",
      "             0.0135,     -0.0083,     -0.0048,      0.0158,      0.0160,\n",
      "             0.0033,      0.0155,      0.0117,      0.0072,     -0.0114,\n",
      "            -0.0124,     -0.0041,     -0.0125,      0.0069,      0.0012,\n",
      "             0.0065,      0.0037,      0.0116,      0.0072,     -0.0146,\n",
      "             0.0061,     -0.0155,      0.0146,     -0.0091,      0.0049,\n",
      "            -0.0171,      0.0125,      0.0092,     -0.0030,     -0.0112,\n",
      "            -0.0158,     -0.0127,     -0.0075,     -0.0165,     -0.0179,\n",
      "             0.0083,     -0.0021,     -0.0176,      0.0046,     -0.0153,\n",
      "             0.0051,     -0.0176,     -0.0154,      0.0145,      0.0167,\n",
      "             0.0086,      0.0029,     -0.0072,     -0.0157,     -0.0048,\n",
      "            -0.0074,     -0.0046,     -0.0126,      0.0029,      0.0001,\n",
      "            -0.0120,      0.0107,     -0.0079,     -0.0129,     -0.0013,\n",
      "            -0.0129,     -0.0148,     -0.0175,     -0.0012,     -0.0108,\n",
      "             0.0077,     -0.0036,      0.0165,      0.0030,     -0.0168,\n",
      "             0.0146,     -0.0038,      0.0118,      0.0133,      0.0126,\n",
      "            -0.0063,     -0.0176,      0.0051,      0.0042,      0.0043,\n",
      "             0.0088,     -0.0136,      0.0086,     -0.0138,     -0.0079,\n",
      "             0.0128,      0.0067,      0.0130,      0.0004,     -0.0160,\n",
      "             0.0017,     -0.0082,     -0.0147,      0.0061,     -0.0178,\n",
      "            -0.0110,     -0.0036,      0.0111,      0.0039,     -0.0060,\n",
      "            -0.0014,      0.0163,      0.0168,      0.0180,      0.0003,\n",
      "            -0.0104,     -0.0057,     -0.0122,      0.0092,     -0.0019,\n",
      "            -0.0177,      0.0064,      0.0094,      0.0142,     -0.0023,\n",
      "             0.0178,     -0.0145,     -0.0065,     -0.0060,      0.0083,\n",
      "            -0.0138,      0.0143,     -0.0022,     -0.0077,     -0.0049,\n",
      "             0.0133,     -0.0121,     -0.0117,      0.0091,      0.0162,\n",
      "            -0.0134,      0.0098,     -0.0007,     -0.0158,      0.0083,\n",
      "            -0.0046,      0.0099,      0.0058,     -0.0113,      0.0037,\n",
      "            -0.0108,     -0.0149,     -0.0108,     -0.0027,      0.0158,\n",
      "            -0.0170,      0.0175,     -0.0036,     -0.0135,      0.0014,\n",
      "            -0.0087,     -0.0130,      0.0066,     -0.0098,     -0.0178,\n",
      "             0.0178,      0.0070,     -0.0074,      0.0174,      0.0154,\n",
      "             0.0075,      0.0158,     -0.0035,     -0.0137,     -0.0076,\n",
      "             0.0126,     -0.0128,     -0.0062,     -0.0127,     -0.0126,\n",
      "             0.0058,     -0.0065,      0.0072,     -0.0061,     -0.0045,\n",
      "            -0.0095,     -0.0002,      0.0048,     -0.0057,     -0.0004,\n",
      "             0.0034,      0.0029,     -0.0060,     -0.0157,      0.0086,\n",
      "             0.0076,      0.0070,     -0.0023,      0.0132,     -0.0082,\n",
      "            -0.0060,     -0.0074,      0.0149,     -0.0020,      0.0042,\n",
      "            -0.0009,      0.0122,     -0.0057,     -0.0078,      0.0150,\n",
      "             0.0039,     -0.0125,      0.0164,      0.0096,     -0.0164,\n",
      "             0.0175,      0.0111,      0.0146,     -0.0029,      0.0152,\n",
      "            -0.0177,      0.0107,      0.0081,     -0.0099,     -0.0045,\n",
      "             0.0035,     -0.0006,     -0.0012,     -0.0115,      0.0035,\n",
      "             0.0080,      0.0020,      0.0135,      0.0177,     -0.0101,\n",
      "             0.0146,      0.0006,      0.0051,      0.0094,     -0.0017,\n",
      "             0.0041,      0.0156,     -0.0130,      0.0062,     -0.0127,\n",
      "             0.0016,     -0.0055,     -0.0075,      0.0066,     -0.0012,\n",
      "            -0.0143,     -0.0111,     -0.0089,      0.0147,      0.0145,\n",
      "             0.0088,     -0.0023,      0.0126,     -0.0027,     -0.0030,\n",
      "            -0.0074,      0.0039,      0.0029,      0.0027,      0.0101,\n",
      "             0.0134,     -0.0111,     -0.0162,     -0.0014,      0.0140,\n",
      "            -0.0165,      0.0176,     -0.0179,     -0.0049,      0.0004,\n",
      "             0.0045,     -0.0007,     -0.0115,     -0.0057,     -0.0107,\n",
      "            -0.0048,     -0.0004,     -0.0136,     -0.0002,      0.0086,\n",
      "             0.0073,      0.0066,      0.0132,      0.0052,      0.0095,\n",
      "            -0.0143,      0.0071,      0.0015,      0.0076,      0.0038,\n",
      "             0.0043,     -0.0094,     -0.0021,      0.0023,     -0.0077,\n",
      "             0.0151,     -0.0039,     -0.0004,      0.0162,     -0.0048,\n",
      "             0.0109,     -0.0057,      0.0063,      0.0038,      0.0126,\n",
      "             0.0080,     -0.0098,      0.0108,     -0.0093,      0.0077,\n",
      "            -0.0180,     -0.0104,      0.0135,     -0.0136,     -0.0000,\n",
      "            -0.0118,      0.0126,      0.0036,      0.0002,     -0.0076,\n",
      "             0.0119,     -0.0127,      0.0140,      0.0028,     -0.0137,\n",
      "            -0.0139,      0.0049,      0.0171,     -0.0077,      0.0134,\n",
      "             0.0158,      0.0140,     -0.0069,     -0.0176,      0.0061,\n",
      "            -0.0003,      0.0056,      0.0138,     -0.0177,      0.0180,\n",
      "            -0.0059,     -0.0067,     -0.0085,      0.0032,      0.0085,\n",
      "            -0.0065,     -0.0168,     -0.0070,     -0.0088,     -0.0108,\n",
      "             0.0015,     -0.0071,      0.0079,      0.0086,     -0.0079,\n",
      "            -0.0177,      0.0011,     -0.0022,     -0.0036,     -0.0072,\n",
      "            -0.0035,      0.0090,     -0.0109,      0.0072,      0.0099,\n",
      "             0.0180,      0.0125,      0.0076,      0.0142,     -0.0082,\n",
      "             0.0110,      0.0099,      0.0059,     -0.0152,     -0.0070,\n",
      "            -0.0019,      0.0089,      0.0092,      0.0006,     -0.0031,\n",
      "            -0.0098,     -0.0059,     -0.0075,     -0.0144,     -0.0015,\n",
      "            -0.0091,     -0.0106,      0.0054,      0.0149,      0.0139,\n",
      "             0.0065,     -0.0111,     -0.0134,     -0.0163,     -0.0179,\n",
      "            -0.0054,      0.0084,      0.0072,     -0.0133,      0.0136,\n",
      "            -0.0152,      0.0033,     -0.0109,     -0.0084,     -0.0052,\n",
      "            -0.0021,      0.0157,      0.0072,     -0.0083,     -0.0110,\n",
      "             0.0052,     -0.0145,      0.0011,     -0.0089,      0.0164,\n",
      "             0.0020,     -0.0169,      0.0091,      0.0179,      0.0147,\n",
      "            -0.0160,     -0.0015,      0.0127,      0.0178,     -0.0034,\n",
      "             0.0045,     -0.0118,      0.0119,      0.0034,     -0.0053,\n",
      "            -0.0097,      0.0090,      0.0017,      0.0106,      0.0049,\n",
      "             0.0098,     -0.0094,     -0.0104,      0.0132,     -0.0019,\n",
      "             0.0018,     -0.0128,      0.0053,      0.0036,     -0.0100,\n",
      "             0.0129,     -0.0145,      0.0133,     -0.0111,     -0.0176,\n",
      "             0.0133,     -0.0073,      0.0108,      0.0143,      0.0010,\n",
      "            -0.0059,      0.0159,     -0.0127,      0.0098,      0.0027,\n",
      "            -0.0103,      0.0078,     -0.0135,     -0.0179,      0.0069,\n",
      "            -0.0179,      0.0116,      0.0158,      0.0086,      0.0086,\n",
      "            -0.0043,      0.0158,     -0.0154,      0.0101,      0.0007,\n",
      "            -0.0025,     -0.0161,     -0.0075,     -0.0058,      0.0139,\n",
      "            -0.0090,      0.0052,      0.0150,      0.0010,      0.0024,\n",
      "             0.0102,     -0.0126,      0.0109,     -0.0038,      0.0152,\n",
      "            -0.0009,      0.0056,      0.0012,     -0.0165,      0.0027,\n",
      "             0.0092,     -0.0174,      0.0122,      0.0090,     -0.0074,\n",
      "            -0.0152,      0.0096,     -0.0048,     -0.0009,     -0.0172,\n",
      "             0.0026,      0.0119,      0.0073,     -0.0112,     -0.0037,\n",
      "             0.0114,      0.0044,      0.0116,     -0.0020,      0.0067,\n",
      "             0.0009,      0.0115,      0.0084,     -0.0118,     -0.0026,\n",
      "            -0.0033,     -0.0173,      0.0071,     -0.0092,      0.0116,\n",
      "             0.0129,     -0.0090,      0.0042,     -0.0170,     -0.0053,\n",
      "            -0.0068,     -0.0166,     -0.0130,     -0.0032,      0.0177,\n",
      "             0.0042,      0.0097,      0.0117,     -0.0073,      0.0014,\n",
      "             0.0109,      0.0114,     -0.0178], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0011,  0.0042, -0.0308,  ..., -0.0151,  0.0022,  0.0039],\n",
      "        [ 0.0031, -0.0102, -0.0051,  ...,  0.0218, -0.0080, -0.0349],\n",
      "        [-0.0061,  0.0236, -0.0198,  ...,  0.0136, -0.0067, -0.0006],\n",
      "        ...,\n",
      "        [ 0.0019, -0.0222,  0.0185,  ..., -0.0143,  0.0026,  0.0264],\n",
      "        [-0.0043,  0.0035, -0.0030,  ..., -0.0006, -0.0126, -0.0261],\n",
      "        [ 0.0120,  0.0045,  0.0150,  ..., -0.0296, -0.0117, -0.0356]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0213,  0.0027,  0.0172,  ...,  0.0014, -0.0066,  0.0109],\n",
      "        [ 0.0081,  0.0340, -0.0361,  ...,  0.0279,  0.0065, -0.0247],\n",
      "        [-0.0271,  0.0315,  0.0349,  ..., -0.0207, -0.0067, -0.0296],\n",
      "        ...,\n",
      "        [-0.0264, -0.0256,  0.0302,  ..., -0.0252, -0.0011,  0.0333],\n",
      "        [-0.0122, -0.0239,  0.0169,  ...,  0.0251, -0.0029,  0.0355],\n",
      "        [-0.0003, -0.0270, -0.0290,  ..., -0.0308, -0.0188, -0.0052]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0325,  0.0330,  0.0041,  ..., -0.0066, -0.0020, -0.0258],\n",
      "        [-0.0232, -0.0032,  0.0340,  ...,  0.0127,  0.0109, -0.0010],\n",
      "        [ 0.0008,  0.0049, -0.0192,  ..., -0.0187,  0.0321, -0.0335],\n",
      "        ...,\n",
      "        [ 0.0355, -0.0141, -0.0288,  ...,  0.0162, -0.0104,  0.0008],\n",
      "        [ 0.0134,  0.0264,  0.0326,  ..., -0.0338, -0.0252,  0.0339],\n",
      "        [ 0.0254,  0.0200,  0.0316,  ..., -0.0011,  0.0264, -0.0136]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0207, -0.0129,  0.0185,  ..., -0.0328, -0.0153, -0.0070],\n",
      "        [-0.0215,  0.0010, -0.0284,  ..., -0.0277, -0.0094, -0.0026],\n",
      "        [-0.0223, -0.0333, -0.0243,  ...,  0.0141,  0.0289,  0.0163],\n",
      "        ...,\n",
      "        [-0.0144,  0.0097, -0.0038,  ..., -0.0083, -0.0139,  0.0299],\n",
      "        [-0.0188, -0.0092,  0.0335,  ..., -0.0305,  0.0108,  0.0261],\n",
      "        [ 0.0353,  0.0178, -0.0082,  ...,  0.0151,  0.0115, -0.0162]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([    -0.0010,     -0.0057,      0.0169,     -0.0267,     -0.0312,\n",
      "             0.0333,      0.0167,      0.0183,      0.0261,     -0.0019,\n",
      "            -0.0148,     -0.0240,      0.0050,     -0.0090,      0.0272,\n",
      "            -0.0171,      0.0124,     -0.0168,      0.0158,     -0.0041,\n",
      "            -0.0082,      0.0324,      0.0288,      0.0147,      0.0067,\n",
      "            -0.0348,      0.0012,     -0.0199,     -0.0255,     -0.0116,\n",
      "            -0.0221,     -0.0022,      0.0025,     -0.0104,      0.0139,\n",
      "            -0.0295,     -0.0016,      0.0116,     -0.0046,      0.0016,\n",
      "            -0.0047,      0.0033,     -0.0235,     -0.0341,     -0.0323,\n",
      "            -0.0320,     -0.0326,      0.0038,     -0.0264,      0.0121,\n",
      "            -0.0042,      0.0084,      0.0199,      0.0338,      0.0247,\n",
      "            -0.0319,     -0.0237,     -0.0280,     -0.0044,      0.0273,\n",
      "            -0.0275,     -0.0162,      0.0007,     -0.0353,     -0.0286,\n",
      "             0.0144,      0.0264,      0.0037,     -0.0242,      0.0028,\n",
      "             0.0195,     -0.0286,     -0.0323,     -0.0153,      0.0227,\n",
      "            -0.0357,      0.0195,      0.0139,      0.0349,      0.0343,\n",
      "             0.0195,      0.0056,     -0.0024,      0.0070,     -0.0220,\n",
      "             0.0042,     -0.0030,     -0.0057,     -0.0336,     -0.0236,\n",
      "             0.0034,     -0.0001,      0.0033,     -0.0310,     -0.0139,\n",
      "             0.0297,      0.0339,      0.0090,     -0.0252,     -0.0014,\n",
      "            -0.0084,      0.0039,     -0.0249,      0.0017,     -0.0266,\n",
      "            -0.0315,      0.0228,      0.0160,     -0.0313,     -0.0329,\n",
      "            -0.0290,      0.0141,      0.0097,      0.0178,     -0.0103,\n",
      "             0.0077,     -0.0320,     -0.0229,     -0.0117,     -0.0235,\n",
      "            -0.0076,      0.0077,      0.0216,     -0.0192,     -0.0321,\n",
      "            -0.0231,     -0.0161,     -0.0096,     -0.0138,     -0.0260,\n",
      "             0.0315,     -0.0189,      0.0353,      0.0084,     -0.0295,\n",
      "             0.0033,      0.0172,      0.0217,     -0.0320,      0.0220,\n",
      "            -0.0258,      0.0155,     -0.0251,     -0.0292,      0.0347,\n",
      "            -0.0017,     -0.0219,     -0.0109,      0.0044,     -0.0182,\n",
      "             0.0104,     -0.0177,     -0.0333,     -0.0313,      0.0272,\n",
      "             0.0203,     -0.0346,     -0.0267,      0.0272,      0.0270,\n",
      "             0.0002,      0.0102,     -0.0138,     -0.0049,     -0.0286,\n",
      "            -0.0078,      0.0197,      0.0039,     -0.0149,      0.0333,\n",
      "            -0.0050,      0.0255,      0.0298,     -0.0305,     -0.0121,\n",
      "             0.0233,     -0.0014,      0.0255,     -0.0204,     -0.0218,\n",
      "            -0.0009,      0.0041,      0.0331,      0.0085,      0.0080,\n",
      "            -0.0353,      0.0209,     -0.0076,      0.0307,     -0.0182,\n",
      "             0.0206,     -0.0256,      0.0338,      0.0016,      0.0157,\n",
      "             0.0257,      0.0139,      0.0007,      0.0162,      0.0060,\n",
      "            -0.0159,      0.0214,      0.0151,      0.0029,      0.0088,\n",
      "             0.0261,     -0.0092,     -0.0067,      0.0163,      0.0269,\n",
      "            -0.0085,      0.0332,      0.0256,      0.0052,     -0.0107,\n",
      "            -0.0296,     -0.0295,      0.0337,      0.0264,     -0.0174,\n",
      "             0.0032,     -0.0246,      0.0359,      0.0353,     -0.0120,\n",
      "             0.0247,     -0.0209,      0.0276,      0.0339,     -0.0020,\n",
      "             0.0117,     -0.0157,     -0.0196,      0.0081,      0.0330,\n",
      "             0.0185,      0.0250,      0.0271,      0.0043,      0.0111,\n",
      "             0.0106,      0.0030,     -0.0199,      0.0140,      0.0266,\n",
      "             0.0130,      0.0068,      0.0003,     -0.0059,     -0.0341,\n",
      "             0.0124,      0.0339,     -0.0283,     -0.0028,     -0.0049,\n",
      "             0.0071,      0.0289,     -0.0099,      0.0087,      0.0133,\n",
      "             0.0184,      0.0301,      0.0167,     -0.0281,     -0.0177,\n",
      "            -0.0083,     -0.0236,      0.0311,      0.0089,      0.0135,\n",
      "            -0.0015,      0.0125,      0.0192,      0.0204,     -0.0034,\n",
      "             0.0319,     -0.0101,      0.0182,     -0.0252,     -0.0280,\n",
      "             0.0014,     -0.0058,     -0.0154,     -0.0058,     -0.0273,\n",
      "             0.0114,     -0.0170,      0.0026,      0.0359,      0.0191,\n",
      "            -0.0298,     -0.0206,     -0.0330,      0.0127,      0.0080,\n",
      "            -0.0162,      0.0251,      0.0329,      0.0218,     -0.0161,\n",
      "             0.0357,     -0.0360,     -0.0132,      0.0253,     -0.0133,\n",
      "            -0.0114,      0.0029,     -0.0057,     -0.0210,      0.0064,\n",
      "             0.0139,     -0.0284,      0.0236,     -0.0105,     -0.0209,\n",
      "            -0.0089,      0.0072,      0.0300,      0.0316,     -0.0249,\n",
      "             0.0026,     -0.0328,      0.0228,     -0.0054,      0.0294,\n",
      "            -0.0154,      0.0146,      0.0056,      0.0203,     -0.0271,\n",
      "            -0.0131,      0.0300,     -0.0117,      0.0127,      0.0146,\n",
      "            -0.0115,     -0.0262,      0.0095,     -0.0180,     -0.0017,\n",
      "             0.0218,     -0.0330,      0.0338,      0.0359,      0.0250,\n",
      "            -0.0339,      0.0001,      0.0270,     -0.0164,     -0.0140,\n",
      "             0.0268,      0.0126,      0.0267,     -0.0077,      0.0031,\n",
      "            -0.0305,     -0.0104,     -0.0072,     -0.0260,     -0.0140,\n",
      "            -0.0251,      0.0181,     -0.0129,     -0.0126,      0.0111,\n",
      "             0.0213,     -0.0319,      0.0007,      0.0020,     -0.0249,\n",
      "            -0.0277,      0.0320,     -0.0277,     -0.0335,      0.0145,\n",
      "             0.0037,      0.0165,      0.0108,     -0.0341,     -0.0130,\n",
      "            -0.0114,      0.0178,      0.0240,      0.0323,      0.0344,\n",
      "            -0.0353,     -0.0025,     -0.0112,      0.0138,      0.0256,\n",
      "            -0.0044,     -0.0045,     -0.0301,     -0.0082,      0.0201,\n",
      "             0.0359,     -0.0307,     -0.0096,      0.0057,     -0.0264,\n",
      "            -0.0267,     -0.0250,      0.0267,     -0.0087,     -0.0293,\n",
      "             0.0013,     -0.0296,      0.0035,     -0.0113,     -0.0246,\n",
      "             0.0012,      0.0154,     -0.0069,     -0.0206,      0.0064,\n",
      "             0.0150,     -0.0359,     -0.0133,      0.0094,     -0.0103,\n",
      "             0.0339,      0.0150,      0.0036,      0.0256,      0.0313,\n",
      "            -0.0334,     -0.0075,      0.0234,     -0.0353,      0.0322,\n",
      "            -0.0254,     -0.0184,      0.0181,      0.0270,      0.0207,\n",
      "             0.0200,      0.0211,     -0.0260,      0.0036,     -0.0242,\n",
      "             0.0200,      0.0299,      0.0292,     -0.0043,      0.0024,\n",
      "             0.0040,     -0.0150,     -0.0193,      0.0350,      0.0000,\n",
      "            -0.0111,     -0.0021,     -0.0156,      0.0115,     -0.0019,\n",
      "             0.0029,      0.0344,     -0.0054,     -0.0326,     -0.0059,\n",
      "             0.0174,      0.0190,      0.0197,     -0.0044,     -0.0212,\n",
      "            -0.0154,      0.0131,      0.0075,      0.0164,      0.0319,\n",
      "            -0.0001,      0.0195,     -0.0005,      0.0341,     -0.0292,\n",
      "            -0.0287,     -0.0261,     -0.0020,      0.0143,     -0.0185,\n",
      "            -0.0285,      0.0188,      0.0154,     -0.0261,     -0.0255,\n",
      "             0.0021,      0.0288,      0.0322,      0.0195,      0.0253,\n",
      "             0.0240,      0.0010,     -0.0336,     -0.0253,     -0.0141,\n",
      "            -0.0049,      0.0093,     -0.0356,      0.0282,     -0.0268,\n",
      "             0.0012,      0.0131,     -0.0001,      0.0120,      0.0271,\n",
      "             0.0229,      0.0346,     -0.0065,      0.0111,      0.0072,\n",
      "            -0.0032,     -0.0203,      0.0303,      0.0359,      0.0351,\n",
      "             0.0204,      0.0094,      0.0126,     -0.0275,     -0.0009,\n",
      "             0.0133,      0.0330,      0.0327,      0.0277,     -0.0076,\n",
      "            -0.0360,      0.0071,     -0.0325,     -0.0187,      0.0303,\n",
      "             0.0296,      0.0095,     -0.0355,      0.0340,      0.0245,\n",
      "             0.0201,      0.0043,     -0.0269,     -0.0091,      0.0222,\n",
      "             0.0251,      0.0036,      0.0074,      0.0187,     -0.0038,\n",
      "            -0.0165,      0.0329,     -0.0078,      0.0317,      0.0035,\n",
      "            -0.0334,      0.0087,     -0.0296,     -0.0198,     -0.0057,\n",
      "            -0.0127,      0.0325,     -0.0202,      0.0003,     -0.0081,\n",
      "            -0.0067,      0.0107,      0.0121,     -0.0153,      0.0146,\n",
      "            -0.0099,     -0.0003,      0.0010,      0.0187,     -0.0252,\n",
      "             0.0138,     -0.0324,      0.0250,     -0.0097,      0.0289,\n",
      "             0.0317,     -0.0296,      0.0101,     -0.0178,     -0.0035,\n",
      "            -0.0245,     -0.0242,     -0.0016,     -0.0316,      0.0203,\n",
      "             0.0050,      0.0153,      0.0026,     -0.0314,     -0.0317,\n",
      "             0.0230,     -0.0008,      0.0164,      0.0135,      0.0170,\n",
      "             0.0028,      0.0179,     -0.0030,     -0.0156,     -0.0237,\n",
      "             0.0352,     -0.0003,      0.0182,      0.0137,     -0.0009,\n",
      "             0.0283,     -0.0115,     -0.0182,      0.0197,     -0.0027,\n",
      "            -0.0324,      0.0031,      0.0001,      0.0217,     -0.0109,\n",
      "            -0.0118,     -0.0141,     -0.0069,      0.0041,     -0.0179,\n",
      "            -0.0123,     -0.0318,      0.0138,      0.0147,      0.0324,\n",
      "            -0.0353,      0.0299,      0.0156,      0.0271,      0.0072,\n",
      "             0.0211,      0.0115,      0.0335,     -0.0104,     -0.0111,\n",
      "             0.0358,     -0.0225,      0.0110,     -0.0187,      0.0084,\n",
      "             0.0227,     -0.0145,     -0.0233,      0.0294,     -0.0359,\n",
      "             0.0048,     -0.0152,      0.0086,      0.0310,     -0.0077,\n",
      "             0.0330,     -0.0138,      0.0251,     -0.0351,     -0.0150,\n",
      "            -0.0027,      0.0148,     -0.0038,      0.0212,     -0.0019,\n",
      "             0.0166,      0.0098,      0.0047,     -0.0134,     -0.0290,\n",
      "            -0.0275,     -0.0125,     -0.0177,      0.0270,     -0.0357,\n",
      "            -0.0233,      0.0248,      0.0043,     -0.0301,      0.0142,\n",
      "             0.0176,      0.0133,     -0.0206,      0.0271,      0.0329,\n",
      "            -0.0286,     -0.0275,      0.0138,     -0.0270,      0.0095,\n",
      "             0.0274,     -0.0288,     -0.0194,     -0.0253,      0.0188,\n",
      "            -0.0177,     -0.0303,      0.0258,     -0.0245,     -0.0296,\n",
      "            -0.0298,     -0.0193,     -0.0217,     -0.0112,      0.0180,\n",
      "            -0.0195,     -0.0168,     -0.0055,      0.0097,     -0.0300,\n",
      "            -0.0281,     -0.0017,      0.0268,      0.0019,     -0.0147,\n",
      "            -0.0342,      0.0173,      0.0246,     -0.0220,     -0.0327,\n",
      "            -0.0105,     -0.0280,      0.0213,      0.0036,      0.0101,\n",
      "             0.0329,     -0.0293,     -0.0253,     -0.0085,      0.0071,\n",
      "            -0.0332,      0.0243,     -0.0138,     -0.0318,     -0.0097,\n",
      "             0.0323,      0.0334,      0.0156,      0.0292,     -0.0215,\n",
      "             0.0165,     -0.0045,      0.0349,      0.0268,      0.0223,\n",
      "            -0.0200,     -0.0141,      0.0206,     -0.0317,      0.0300,\n",
      "            -0.0324,     -0.0109,      0.0069,     -0.0072,     -0.0103,\n",
      "            -0.0195,     -0.0287,     -0.0193,     -0.0317,     -0.0323,\n",
      "            -0.0030,      0.0295,      0.0155,     -0.0201,      0.0286,\n",
      "            -0.0244,     -0.0294,     -0.0304,      0.0037,      0.0112,\n",
      "            -0.0299,      0.0297,     -0.0210], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0032, -0.0109,  0.0035,  ...,  0.0075,  0.0216,  0.0146],\n",
      "        [ 0.0312, -0.0219, -0.0158,  ...,  0.0359, -0.0185, -0.0101],\n",
      "        [ 0.0046, -0.0198, -0.0341,  ...,  0.0112, -0.0112,  0.0285],\n",
      "        ...,\n",
      "        [ 0.0209, -0.0332,  0.0323,  ..., -0.0280,  0.0070,  0.0182],\n",
      "        [-0.0276,  0.0227, -0.0068,  ..., -0.0349,  0.0236,  0.0123],\n",
      "        [-0.0203,  0.0294, -0.0119,  ..., -0.0176, -0.0003,  0.0010]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0227, -0.0213, -0.0055,  ...,  0.0119,  0.0337, -0.0036],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0098, -0.0132,  0.0138,  ...,  0.0138, -0.0015, -0.0051],\n",
      "        [-0.0080,  0.0066,  0.0109,  ..., -0.0164,  0.0119, -0.0073],\n",
      "        [ 0.0106,  0.0165, -0.0160,  ...,  0.0158,  0.0046, -0.0127],\n",
      "        ...,\n",
      "        [ 0.0066, -0.0094,  0.0041,  ..., -0.0121, -0.0120, -0.0104],\n",
      "        [-0.0065,  0.0067, -0.0022,  ...,  0.0004, -0.0134,  0.0075],\n",
      "        [-0.0115,  0.0171,  0.0111,  ..., -0.0079, -0.0085,  0.0029]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([     0.0029,      0.0072,     -0.0099,     -0.0153,      0.0157,\n",
      "             0.0116,     -0.0173,      0.0041,      0.0122,     -0.0156,\n",
      "             0.0074,     -0.0016,     -0.0018,     -0.0076,     -0.0122,\n",
      "             0.0160,      0.0121,     -0.0091,     -0.0116,      0.0076,\n",
      "             0.0000,      0.0106,     -0.0022,     -0.0163,      0.0143,\n",
      "            -0.0087,      0.0022,     -0.0096,      0.0059,      0.0045,\n",
      "             0.0073,      0.0133,     -0.0155,      0.0060,     -0.0123,\n",
      "            -0.0164,      0.0124,      0.0002,     -0.0140,     -0.0017,\n",
      "             0.0176,      0.0033,     -0.0087,     -0.0034,      0.0007,\n",
      "            -0.0066,     -0.0057,     -0.0156,      0.0176,     -0.0065,\n",
      "            -0.0091,     -0.0108,      0.0111,     -0.0044,     -0.0156,\n",
      "            -0.0163,     -0.0123,      0.0175,      0.0063,      0.0164,\n",
      "             0.0092,      0.0097,     -0.0132,     -0.0163,     -0.0125,\n",
      "             0.0148,      0.0001,     -0.0103,     -0.0074,     -0.0068,\n",
      "             0.0069,     -0.0075,     -0.0017,     -0.0032,      0.0163,\n",
      "            -0.0122,      0.0012,      0.0095,      0.0070,     -0.0042,\n",
      "            -0.0052,     -0.0173,     -0.0094,     -0.0114,     -0.0077,\n",
      "             0.0069,      0.0083,     -0.0024,     -0.0178,      0.0016,\n",
      "            -0.0143,      0.0175,     -0.0042,      0.0039,     -0.0025,\n",
      "             0.0158,      0.0030,      0.0054,      0.0168,      0.0005,\n",
      "            -0.0035,      0.0014,      0.0074,      0.0032,     -0.0005,\n",
      "            -0.0126,     -0.0177,     -0.0124,     -0.0020,     -0.0052,\n",
      "             0.0047,     -0.0043,      0.0077,      0.0106,      0.0105,\n",
      "             0.0097,     -0.0126,     -0.0101,     -0.0125,      0.0178,\n",
      "             0.0048,      0.0010,      0.0065,      0.0140,     -0.0079,\n",
      "            -0.0063,      0.0016,      0.0096,     -0.0045,      0.0140,\n",
      "             0.0033,     -0.0128,      0.0113,     -0.0140,      0.0056,\n",
      "             0.0127,      0.0159,     -0.0090,      0.0073,     -0.0004,\n",
      "            -0.0059,     -0.0156,      0.0097,      0.0029,     -0.0080,\n",
      "             0.0046,      0.0091,     -0.0003,      0.0023,     -0.0078,\n",
      "            -0.0100,      0.0159,      0.0057,      0.0078,      0.0044,\n",
      "             0.0003,      0.0011,     -0.0154,     -0.0104,     -0.0017,\n",
      "            -0.0173,      0.0176,      0.0167,      0.0037,     -0.0132,\n",
      "            -0.0083,      0.0158,     -0.0152,      0.0134,     -0.0038,\n",
      "             0.0100,      0.0116,      0.0137,     -0.0131,     -0.0058,\n",
      "             0.0090,     -0.0026,      0.0032,     -0.0131,      0.0171,\n",
      "             0.0174,      0.0042,     -0.0137,      0.0068,      0.0013,\n",
      "             0.0127,     -0.0129,     -0.0138,     -0.0075,      0.0131,\n",
      "            -0.0136,     -0.0155,      0.0038,      0.0120,      0.0090,\n",
      "             0.0156,      0.0149,      0.0012,      0.0106,      0.0168,\n",
      "             0.0110,     -0.0113,     -0.0161,     -0.0122,      0.0126,\n",
      "            -0.0140,      0.0119,      0.0102,      0.0088,     -0.0136,\n",
      "             0.0078,      0.0077,      0.0059,      0.0114,     -0.0173,\n",
      "             0.0014,     -0.0005,      0.0097,     -0.0143,      0.0090,\n",
      "             0.0023,      0.0155,      0.0085,      0.0179,     -0.0114,\n",
      "            -0.0081,      0.0045,      0.0001,     -0.0163,      0.0085,\n",
      "            -0.0109,      0.0007,     -0.0086,     -0.0043,      0.0111,\n",
      "            -0.0038,     -0.0106,      0.0171,      0.0112,     -0.0068,\n",
      "             0.0133,     -0.0141,      0.0144,     -0.0167,      0.0048,\n",
      "             0.0082,      0.0029,      0.0065,     -0.0123,      0.0013,\n",
      "             0.0176,     -0.0040,      0.0152,     -0.0154,     -0.0174,\n",
      "            -0.0021,     -0.0133,     -0.0073,     -0.0025,     -0.0108,\n",
      "             0.0121,      0.0056,     -0.0128,      0.0068,      0.0028,\n",
      "             0.0116,      0.0066,      0.0167,      0.0135,      0.0066,\n",
      "             0.0091,     -0.0067,     -0.0049,      0.0129,     -0.0178,\n",
      "            -0.0132,      0.0108,      0.0134,     -0.0029,      0.0023,\n",
      "             0.0028,     -0.0147,      0.0060,      0.0156,     -0.0012,\n",
      "            -0.0180,      0.0154,     -0.0146,      0.0103,      0.0135,\n",
      "             0.0037,      0.0084,      0.0050,     -0.0029,      0.0134,\n",
      "             0.0138,     -0.0059,      0.0045,      0.0007,      0.0016,\n",
      "            -0.0040,      0.0030,     -0.0081,     -0.0072,      0.0173,\n",
      "            -0.0105,      0.0069,     -0.0005,      0.0029,      0.0109,\n",
      "            -0.0126,     -0.0097,     -0.0047,     -0.0092,      0.0037,\n",
      "             0.0021,      0.0013,     -0.0158,      0.0150,      0.0043,\n",
      "             0.0036,     -0.0034,     -0.0091,     -0.0049,     -0.0138,\n",
      "            -0.0143,      0.0134,     -0.0104,     -0.0158,      0.0068,\n",
      "            -0.0111,      0.0011,      0.0029,      0.0022,      0.0056,\n",
      "            -0.0088,      0.0041,      0.0071,     -0.0116,     -0.0074,\n",
      "             0.0074,     -0.0154,      0.0131,      0.0161,     -0.0009,\n",
      "            -0.0014,      0.0057,     -0.0144,      0.0108,      0.0158,\n",
      "             0.0142,      0.0060,      0.0110,     -0.0043,      0.0100,\n",
      "             0.0158,      0.0009,     -0.0002,     -0.0162,      0.0016,\n",
      "             0.0028,      0.0152,     -0.0009,     -0.0025,      0.0151,\n",
      "            -0.0134,     -0.0009,     -0.0167,     -0.0166,      0.0119,\n",
      "             0.0135,      0.0146,     -0.0086,     -0.0080,     -0.0065,\n",
      "             0.0106,     -0.0061,      0.0148,     -0.0004,      0.0055,\n",
      "            -0.0086,     -0.0056,      0.0166,      0.0008,      0.0145,\n",
      "            -0.0163,      0.0013,     -0.0034,      0.0101,     -0.0123,\n",
      "            -0.0140,     -0.0083,      0.0145,     -0.0102,      0.0007,\n",
      "            -0.0030,     -0.0178,     -0.0179,     -0.0140,      0.0036,\n",
      "            -0.0080,     -0.0019,     -0.0142,      0.0133,     -0.0055,\n",
      "            -0.0130,     -0.0170,     -0.0005,      0.0107,     -0.0160,\n",
      "             0.0052,      0.0151,      0.0034,     -0.0146,      0.0064,\n",
      "             0.0179,     -0.0008,      0.0107,      0.0077,      0.0085,\n",
      "             0.0108,     -0.0038,      0.0156,     -0.0157,     -0.0023,\n",
      "            -0.0049,      0.0057,     -0.0157,      0.0078,      0.0059,\n",
      "            -0.0137,     -0.0084,      0.0097,     -0.0126,     -0.0130,\n",
      "             0.0013,      0.0044,      0.0172,      0.0078,     -0.0035,\n",
      "            -0.0168,     -0.0036,      0.0073,      0.0176,      0.0164,\n",
      "             0.0091,      0.0040,     -0.0149,      0.0075,      0.0102,\n",
      "            -0.0078,     -0.0086,     -0.0073,      0.0082,     -0.0110,\n",
      "            -0.0073,      0.0074,     -0.0007,     -0.0162,     -0.0076,\n",
      "             0.0078,     -0.0066,     -0.0097,      0.0013,     -0.0110,\n",
      "            -0.0026,      0.0142,     -0.0018,     -0.0160,      0.0044,\n",
      "             0.0143,     -0.0018,     -0.0117,     -0.0045,      0.0041,\n",
      "             0.0159,     -0.0180,      0.0080,      0.0116,      0.0046,\n",
      "             0.0010,     -0.0008,     -0.0172,      0.0112,      0.0034,\n",
      "             0.0138,     -0.0106,     -0.0052,      0.0019,     -0.0066,\n",
      "             0.0018,      0.0047,      0.0104,     -0.0092,     -0.0018,\n",
      "             0.0004,      0.0057,     -0.0119,     -0.0138,     -0.0131,\n",
      "            -0.0044,     -0.0113,     -0.0103,     -0.0058,     -0.0106,\n",
      "            -0.0083,     -0.0131,     -0.0120,     -0.0025,     -0.0119,\n",
      "             0.0090,      0.0072,      0.0103,      0.0177,      0.0046,\n",
      "             0.0140,     -0.0082,     -0.0135,     -0.0003,      0.0171,\n",
      "            -0.0035,      0.0029,     -0.0044,     -0.0067,      0.0075,\n",
      "            -0.0078,     -0.0028,     -0.0036,      0.0160,      0.0025,\n",
      "            -0.0078,     -0.0140,      0.0018,      0.0101,     -0.0048,\n",
      "             0.0100,      0.0071,     -0.0004,     -0.0078,      0.0036,\n",
      "            -0.0153,      0.0006,     -0.0154,      0.0116,      0.0074,\n",
      "             0.0158,     -0.0100,     -0.0143,     -0.0006,      0.0133,\n",
      "             0.0014,     -0.0029,      0.0144,      0.0110,     -0.0103,\n",
      "             0.0103,      0.0043,     -0.0032,     -0.0111,      0.0118,\n",
      "             0.0066,     -0.0068,     -0.0012,      0.0035,      0.0034,\n",
      "            -0.0052,     -0.0078,      0.0141,      0.0169,      0.0038,\n",
      "             0.0104,      0.0078,      0.0172,     -0.0096,     -0.0045,\n",
      "             0.0088,     -0.0171,      0.0014,     -0.0037,     -0.0151,\n",
      "             0.0028,      0.0145,      0.0083,      0.0076,     -0.0150,\n",
      "            -0.0135,      0.0064,      0.0086,     -0.0023,      0.0079,\n",
      "            -0.0002,     -0.0026,      0.0151,      0.0015,      0.0161,\n",
      "            -0.0154,     -0.0039,      0.0015,     -0.0023,     -0.0070,\n",
      "            -0.0169,     -0.0036,      0.0011,      0.0011,      0.0023,\n",
      "            -0.0007,     -0.0178,      0.0020,      0.0115,     -0.0010,\n",
      "            -0.0134,     -0.0115,      0.0068,      0.0178,      0.0036,\n",
      "            -0.0115,     -0.0012,     -0.0090,     -0.0064,      0.0135,\n",
      "            -0.0006,      0.0147,     -0.0005,      0.0125,     -0.0176,\n",
      "             0.0110,     -0.0177,      0.0006,     -0.0174,     -0.0042,\n",
      "            -0.0071,     -0.0137,     -0.0087,      0.0095,      0.0101,\n",
      "             0.0074,      0.0003,     -0.0077,      0.0142,      0.0063,\n",
      "             0.0120,      0.0163,      0.0139,      0.0173,     -0.0131,\n",
      "            -0.0131,      0.0062,     -0.0129,     -0.0054,     -0.0005,\n",
      "             0.0053,      0.0119,     -0.0148,      0.0088,     -0.0163,\n",
      "             0.0091,     -0.0044,      0.0028,     -0.0131,     -0.0150,\n",
      "             0.0116,      0.0047,      0.0077,      0.0014,      0.0117,\n",
      "             0.0099,      0.0131,      0.0031,     -0.0107,     -0.0178,\n",
      "             0.0178,     -0.0160,      0.0135,     -0.0096,     -0.0087,\n",
      "             0.0123,      0.0153,      0.0091,      0.0107,      0.0082,\n",
      "             0.0069,     -0.0170,      0.0134,      0.0100,      0.0051,\n",
      "             0.0006,      0.0177,      0.0169,     -0.0039,      0.0128,\n",
      "            -0.0151,     -0.0020,     -0.0131,      0.0110,      0.0136,\n",
      "             0.0037,     -0.0017,     -0.0088,      0.0019,      0.0139,\n",
      "            -0.0030,     -0.0178,      0.0154,      0.0013,     -0.0023,\n",
      "            -0.0073,      0.0087,     -0.0140,      0.0176,      0.0031,\n",
      "            -0.0113,     -0.0177,     -0.0134,     -0.0094,      0.0071,\n",
      "            -0.0051,      0.0147,      0.0115,      0.0121,     -0.0127,\n",
      "            -0.0047,      0.0031,     -0.0022,      0.0012,     -0.0043,\n",
      "            -0.0047,      0.0135,      0.0121,     -0.0126,      0.0081,\n",
      "            -0.0092,     -0.0074,     -0.0055,     -0.0125,      0.0174,\n",
      "            -0.0069,      0.0075,      0.0001,     -0.0130,      0.0099,\n",
      "             0.0040,      0.0022,     -0.0010,      0.0084,      0.0058,\n",
      "             0.0027,     -0.0110,      0.0027,     -0.0121,     -0.0099,\n",
      "             0.0041,      0.0155,      0.0117,      0.0039,      0.0133,\n",
      "             0.0154,      0.0175,     -0.0060,     -0.0007,      0.0097,\n",
      "            -0.0065,      0.0175,     -0.0177,      0.0056,     -0.0171,\n",
      "             0.0079,     -0.0001,     -0.0011], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0218, -0.0057,  0.0185,  ...,  0.0114, -0.0089,  0.0233],\n",
      "        [-0.0336,  0.0022,  0.0058,  ...,  0.0343, -0.0210,  0.0360],\n",
      "        [ 0.0220,  0.0132,  0.0198,  ...,  0.0174,  0.0340, -0.0035],\n",
      "        ...,\n",
      "        [-0.0315,  0.0139,  0.0009,  ..., -0.0351, -0.0008,  0.0221],\n",
      "        [-0.0260,  0.0289,  0.0320,  ...,  0.0213,  0.0303, -0.0319],\n",
      "        [ 0.0071, -0.0281, -0.0268,  ..., -0.0260, -0.0227, -0.0272]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0190, -0.0193, -0.0233,  ...,  0.0253,  0.0098, -0.0309],\n",
      "        [-0.0252,  0.0194, -0.0096,  ...,  0.0095,  0.0345, -0.0299],\n",
      "        [-0.0291,  0.0097,  0.0154,  ...,  0.0138,  0.0003, -0.0248],\n",
      "        ...,\n",
      "        [ 0.0222,  0.0164, -0.0010,  ..., -0.0102, -0.0110,  0.0323],\n",
      "        [-0.0170,  0.0222, -0.0201,  ...,  0.0042,  0.0037, -0.0028],\n",
      "        [-0.0015, -0.0276, -0.0253,  ...,  0.0151,  0.0032, -0.0002]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0296,  0.0335, -0.0281,  ..., -0.0228,  0.0355, -0.0332],\n",
      "        [-0.0250, -0.0164, -0.0123,  ...,  0.0192,  0.0241, -0.0191],\n",
      "        [ 0.0146,  0.0319,  0.0089,  ..., -0.0091,  0.0321,  0.0150],\n",
      "        ...,\n",
      "        [-0.0237,  0.0295,  0.0036,  ...,  0.0104, -0.0277, -0.0122],\n",
      "        [-0.0278, -0.0081,  0.0326,  ...,  0.0319, -0.0008, -0.0055],\n",
      "        [-0.0104, -0.0319,  0.0327,  ...,  0.0220,  0.0036,  0.0009]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0011, -0.0254,  0.0096,  ..., -0.0057,  0.0033, -0.0025],\n",
      "        [ 0.0136, -0.0162, -0.0133,  ...,  0.0213, -0.0019,  0.0080],\n",
      "        [-0.0192, -0.0134,  0.0069,  ...,  0.0020, -0.0263,  0.0114],\n",
      "        ...,\n",
      "        [-0.0359, -0.0139, -0.0262,  ..., -0.0284, -0.0178, -0.0296],\n",
      "        [-0.0288,  0.0111, -0.0151,  ...,  0.0076, -0.0158, -0.0034],\n",
      "        [-0.0271, -0.0255, -0.0182,  ...,  0.0087,  0.0207,  0.0213]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([    -0.0343,     -0.0092,     -0.0183,     -0.0359,     -0.0063,\n",
      "             0.0163,      0.0150,     -0.0080,     -0.0025,      0.0094,\n",
      "            -0.0280,      0.0018,      0.0136,      0.0247,      0.0241,\n",
      "            -0.0234,      0.0237,     -0.0329,      0.0043,     -0.0221,\n",
      "             0.0316,     -0.0074,      0.0043,     -0.0213,     -0.0235,\n",
      "            -0.0192,      0.0320,     -0.0124,      0.0148,     -0.0219,\n",
      "            -0.0331,     -0.0327,     -0.0111,      0.0347,      0.0162,\n",
      "            -0.0346,      0.0148,     -0.0208,     -0.0101,      0.0029,\n",
      "            -0.0094,     -0.0253,      0.0123,      0.0100,     -0.0084,\n",
      "             0.0156,      0.0209,     -0.0191,      0.0244,      0.0307,\n",
      "            -0.0345,      0.0290,     -0.0108,      0.0285,      0.0302,\n",
      "            -0.0321,      0.0170,     -0.0075,     -0.0170,      0.0240,\n",
      "            -0.0099,     -0.0355,      0.0237,     -0.0028,     -0.0095,\n",
      "             0.0345,     -0.0076,      0.0332,      0.0094,     -0.0003,\n",
      "            -0.0021,     -0.0213,      0.0269,     -0.0164,     -0.0082,\n",
      "            -0.0174,      0.0153,     -0.0276,     -0.0179,      0.0163,\n",
      "             0.0010,      0.0124,     -0.0199,     -0.0242,      0.0153,\n",
      "             0.0231,      0.0328,     -0.0194,     -0.0097,      0.0179,\n",
      "            -0.0014,     -0.0032,     -0.0032,     -0.0048,     -0.0098,\n",
      "            -0.0043,      0.0257,     -0.0118,     -0.0108,     -0.0340,\n",
      "             0.0097,      0.0284,      0.0162,      0.0359,     -0.0037,\n",
      "            -0.0126,     -0.0166,      0.0070,      0.0018,     -0.0300,\n",
      "             0.0147,      0.0157,      0.0075,      0.0140,      0.0182,\n",
      "            -0.0227,     -0.0061,      0.0140,     -0.0135,      0.0108,\n",
      "             0.0257,      0.0077,     -0.0358,     -0.0246,     -0.0120,\n",
      "             0.0188,      0.0348,     -0.0345,      0.0172,     -0.0185,\n",
      "            -0.0250,      0.0001,      0.0359,      0.0349,      0.0183,\n",
      "             0.0202,     -0.0112,     -0.0125,      0.0263,      0.0266,\n",
      "            -0.0238,     -0.0024,      0.0238,     -0.0088,      0.0267,\n",
      "            -0.0148,     -0.0212,     -0.0347,     -0.0206,     -0.0149,\n",
      "            -0.0022,      0.0276,      0.0326,      0.0339,      0.0160,\n",
      "            -0.0178,     -0.0039,     -0.0188,      0.0081,      0.0333,\n",
      "            -0.0280,     -0.0033,     -0.0319,     -0.0315,     -0.0192,\n",
      "            -0.0097,      0.0255,     -0.0147,     -0.0089,      0.0203,\n",
      "             0.0270,     -0.0167,     -0.0116,      0.0135,      0.0154,\n",
      "             0.0130,      0.0287,     -0.0196,     -0.0242,      0.0084,\n",
      "             0.0348,      0.0084,      0.0009,      0.0007,      0.0294,\n",
      "             0.0172,      0.0008,     -0.0237,      0.0191,      0.0179,\n",
      "             0.0145,      0.0198,     -0.0247,     -0.0182,     -0.0130,\n",
      "             0.0121,     -0.0303,     -0.0027,     -0.0328,     -0.0197,\n",
      "             0.0222,     -0.0106,      0.0070,      0.0037,      0.0083,\n",
      "             0.0022,      0.0296,     -0.0327,      0.0034,     -0.0249,\n",
      "            -0.0030,     -0.0040,      0.0262,      0.0308,     -0.0236,\n",
      "             0.0349,     -0.0318,      0.0197,     -0.0205,     -0.0289,\n",
      "            -0.0331,     -0.0180,     -0.0193,      0.0099,      0.0355,\n",
      "             0.0002,      0.0263,      0.0097,      0.0316,     -0.0181,\n",
      "             0.0201,     -0.0341,      0.0124,     -0.0038,     -0.0181,\n",
      "             0.0354,     -0.0031,     -0.0090,     -0.0018,     -0.0173,\n",
      "            -0.0327,      0.0052,      0.0217,     -0.0062,      0.0218,\n",
      "            -0.0359,     -0.0024,     -0.0275,     -0.0100,     -0.0092,\n",
      "            -0.0049,      0.0277,      0.0089,     -0.0091,      0.0292,\n",
      "            -0.0189,     -0.0026,      0.0236,      0.0239,     -0.0066,\n",
      "             0.0047,      0.0207,     -0.0028,     -0.0301,     -0.0268,\n",
      "            -0.0281,     -0.0034,     -0.0319,     -0.0040,     -0.0099,\n",
      "            -0.0128,      0.0302,     -0.0315,     -0.0172,     -0.0356,\n",
      "             0.0030,      0.0230,     -0.0175,     -0.0019,      0.0004,\n",
      "            -0.0278,      0.0183,     -0.0306,      0.0314,     -0.0341,\n",
      "             0.0256,     -0.0310,      0.0185,      0.0296,     -0.0217,\n",
      "             0.0224,      0.0086,     -0.0057,      0.0215,     -0.0164,\n",
      "            -0.0057,     -0.0334,      0.0324,      0.0101,     -0.0149,\n",
      "            -0.0166,      0.0106,      0.0129,      0.0163,      0.0069,\n",
      "             0.0245,      0.0062,      0.0216,      0.0315,     -0.0022,\n",
      "            -0.0229,     -0.0247,      0.0178,     -0.0347,      0.0044,\n",
      "            -0.0350,      0.0193,      0.0296,     -0.0129,      0.0345,\n",
      "            -0.0042,     -0.0291,     -0.0087,     -0.0048,      0.0046,\n",
      "             0.0097,     -0.0240,      0.0146,      0.0062,      0.0196,\n",
      "            -0.0086,     -0.0330,      0.0329,     -0.0039,      0.0269,\n",
      "             0.0142,     -0.0192,      0.0206,      0.0061,     -0.0237,\n",
      "             0.0337,      0.0051,     -0.0086,      0.0205,     -0.0103,\n",
      "             0.0343,     -0.0050,      0.0247,     -0.0236,      0.0131,\n",
      "            -0.0349,      0.0148,      0.0101,      0.0139,     -0.0069,\n",
      "            -0.0074,     -0.0098,     -0.0189,      0.0011,     -0.0327,\n",
      "             0.0215,     -0.0180,     -0.0190,      0.0012,      0.0146,\n",
      "            -0.0358,     -0.0147,      0.0254,      0.0087,      0.0278,\n",
      "            -0.0167,      0.0310,     -0.0082,     -0.0055,      0.0145,\n",
      "            -0.0184,     -0.0197,     -0.0305,      0.0014,      0.0263,\n",
      "            -0.0146,      0.0164,      0.0159,     -0.0253,      0.0094,\n",
      "            -0.0075,     -0.0109,     -0.0138,     -0.0160,     -0.0287,\n",
      "            -0.0179,      0.0149,     -0.0060,     -0.0302,      0.0207,\n",
      "             0.0037,     -0.0026,     -0.0178,     -0.0203,      0.0000,\n",
      "            -0.0220,      0.0333,      0.0209,      0.0310,      0.0093,\n",
      "             0.0000,      0.0197,      0.0262,      0.0234,     -0.0066,\n",
      "             0.0175,     -0.0073,     -0.0315,      0.0175,      0.0134,\n",
      "            -0.0038,      0.0309,      0.0005,     -0.0207,      0.0143,\n",
      "             0.0272,      0.0264,     -0.0275,     -0.0009,     -0.0014,\n",
      "            -0.0309,     -0.0331,      0.0094,     -0.0185,     -0.0194,\n",
      "            -0.0176,      0.0043,      0.0147,     -0.0301,     -0.0305,\n",
      "            -0.0282,     -0.0106,     -0.0213,     -0.0152,     -0.0047,\n",
      "            -0.0194,      0.0008,     -0.0005,      0.0302,      0.0184,\n",
      "             0.0311,     -0.0098,     -0.0248,      0.0322,      0.0112,\n",
      "             0.0177,     -0.0147,     -0.0060,     -0.0280,      0.0245,\n",
      "             0.0194,      0.0331,     -0.0059,     -0.0063,     -0.0185,\n",
      "            -0.0325,      0.0209,      0.0240,     -0.0148,      0.0329,\n",
      "             0.0323,     -0.0166,      0.0264,     -0.0337,     -0.0124,\n",
      "            -0.0012,     -0.0066,      0.0020,     -0.0180,      0.0054,\n",
      "             0.0133,     -0.0143,      0.0313,     -0.0281,      0.0241,\n",
      "             0.0073,     -0.0106,      0.0183,     -0.0048,     -0.0080,\n",
      "            -0.0181,     -0.0007,     -0.0359,     -0.0185,      0.0165,\n",
      "             0.0194,      0.0109,     -0.0223,      0.0338,     -0.0241,\n",
      "             0.0352,      0.0105,      0.0037,      0.0335,     -0.0145,\n",
      "            -0.0034,      0.0064,      0.0221,     -0.0331,      0.0070,\n",
      "             0.0018,     -0.0254,     -0.0150,      0.0063,      0.0305,\n",
      "             0.0281,     -0.0328,     -0.0087,      0.0299,     -0.0145,\n",
      "            -0.0179,      0.0166,      0.0121,     -0.0075,     -0.0164,\n",
      "             0.0176,     -0.0292,      0.0041,     -0.0269,     -0.0309,\n",
      "             0.0226,     -0.0251,      0.0283,     -0.0221,     -0.0327,\n",
      "            -0.0179,      0.0024,     -0.0284,      0.0052,     -0.0144,\n",
      "            -0.0165,      0.0049,      0.0227,     -0.0306,      0.0157,\n",
      "            -0.0337,     -0.0286,     -0.0017,     -0.0215,     -0.0191,\n",
      "             0.0244,      0.0067,      0.0275,     -0.0220,     -0.0184,\n",
      "            -0.0142,      0.0233,     -0.0076,      0.0322,      0.0194,\n",
      "             0.0242,      0.0156,     -0.0260,      0.0261,      0.0168,\n",
      "             0.0020,      0.0335,     -0.0289,      0.0024,     -0.0186,\n",
      "             0.0245,     -0.0124,      0.0246,      0.0253,     -0.0205,\n",
      "            -0.0147,     -0.0085,     -0.0307,      0.0084,     -0.0337,\n",
      "            -0.0275,     -0.0334,      0.0048,      0.0026,     -0.0139,\n",
      "            -0.0224,      0.0065,     -0.0056,     -0.0197,     -0.0074,\n",
      "             0.0015,      0.0224,     -0.0221,      0.0028,     -0.0186,\n",
      "            -0.0186,      0.0163,     -0.0026,      0.0343,     -0.0040,\n",
      "             0.0183,     -0.0135,     -0.0071,      0.0149,      0.0306,\n",
      "            -0.0071,      0.0175,     -0.0196,     -0.0259,     -0.0049,\n",
      "            -0.0082,     -0.0103,     -0.0068,      0.0192,     -0.0049,\n",
      "             0.0029,      0.0153,     -0.0076,      0.0351,     -0.0207,\n",
      "            -0.0044,      0.0310,     -0.0325,      0.0317,     -0.0317,\n",
      "            -0.0185,     -0.0352,      0.0061,      0.0126,     -0.0055,\n",
      "             0.0022,     -0.0256,      0.0249,     -0.0013,      0.0336,\n",
      "            -0.0012,      0.0165,      0.0177,      0.0109,      0.0255,\n",
      "             0.0357,     -0.0348,     -0.0211,     -0.0040,     -0.0334,\n",
      "            -0.0333,     -0.0143,      0.0295,      0.0157,     -0.0237,\n",
      "             0.0038,      0.0329,      0.0340,      0.0350,      0.0303,\n",
      "            -0.0036,      0.0149,      0.0050,      0.0261,      0.0028,\n",
      "            -0.0098,      0.0247,     -0.0059,      0.0268,      0.0221,\n",
      "             0.0112,      0.0026,     -0.0136,     -0.0115,     -0.0269,\n",
      "            -0.0317,     -0.0342,      0.0010,     -0.0233,     -0.0111,\n",
      "            -0.0178,     -0.0005,      0.0331,     -0.0160,     -0.0158,\n",
      "            -0.0312,     -0.0099,      0.0309,      0.0002,      0.0205,\n",
      "             0.0197,      0.0186,     -0.0350,      0.0342,      0.0076,\n",
      "            -0.0321,      0.0197,     -0.0165,     -0.0123,     -0.0222,\n",
      "             0.0247,     -0.0221,     -0.0026,      0.0078,      0.0325,\n",
      "             0.0108,     -0.0175,     -0.0160,      0.0002,     -0.0009,\n",
      "             0.0324,     -0.0268,      0.0211,      0.0117,      0.0078,\n",
      "             0.0232,     -0.0182,      0.0052,     -0.0171,      0.0169,\n",
      "             0.0340,      0.0241,      0.0219,      0.0126,     -0.0304,\n",
      "            -0.0244,      0.0054,     -0.0010,      0.0165,      0.0253,\n",
      "            -0.0047,     -0.0119,      0.0057,     -0.0120,     -0.0146,\n",
      "             0.0267,     -0.0355,      0.0029,      0.0163,     -0.0176,\n",
      "            -0.0213,     -0.0350,      0.0200,     -0.0185,      0.0277,\n",
      "            -0.0352,     -0.0111,     -0.0008,      0.0294,     -0.0055,\n",
      "             0.0213,     -0.0037,     -0.0057,      0.0344,     -0.0260,\n",
      "            -0.0266,     -0.0237,     -0.0036,      0.0294,     -0.0095,\n",
      "             0.0099,     -0.0018,      0.0024,      0.0296,      0.0057,\n",
      "            -0.0184,     -0.0340,     -0.0076,     -0.0300,      0.0206,\n",
      "            -0.0274,      0.0288,      0.0293,     -0.0055,      0.0296,\n",
      "            -0.0137,     -0.0231,     -0.0046], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0128, -0.0352, -0.0110,  ..., -0.0336, -0.0274, -0.0047],\n",
      "        [ 0.0091, -0.0357, -0.0153,  ..., -0.0161, -0.0177,  0.0179],\n",
      "        [ 0.0306, -0.0278, -0.0188,  ...,  0.0102,  0.0109, -0.0034],\n",
      "        ...,\n",
      "        [-0.0286, -0.0348,  0.0314,  ...,  0.0110,  0.0185, -0.0143],\n",
      "        [ 0.0045, -0.0343,  0.0151,  ..., -0.0071,  0.0263,  0.0044],\n",
      "        [ 0.0174,  0.0191, -0.0092,  ..., -0.0077, -0.0037,  0.0153]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0328,  0.0020,  0.0100,  ...,  0.0082, -0.0233, -0.0013],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0158,  0.0122, -0.0015,  ..., -0.0115,  0.0058,  0.0023],\n",
      "        [-0.0092,  0.0018,  0.0058,  ...,  0.0012,  0.0051,  0.0103],\n",
      "        [-0.0102,  0.0006,  0.0012,  ..., -0.0174,  0.0117,  0.0016],\n",
      "        ...,\n",
      "        [-0.0012, -0.0036, -0.0058,  ...,  0.0176,  0.0088,  0.0132],\n",
      "        [-0.0022,  0.0065, -0.0061,  ..., -0.0179, -0.0111, -0.0022],\n",
      "        [ 0.0039,  0.0114, -0.0132,  ..., -0.0071,  0.0165,  0.0168]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([     0.0003,      0.0067,      0.0072,      0.0039,      0.0102,\n",
      "             0.0072,     -0.0092,      0.0077,      0.0030,     -0.0068,\n",
      "             0.0133,     -0.0038,     -0.0099,     -0.0079,     -0.0157,\n",
      "             0.0027,     -0.0089,      0.0173,      0.0166,      0.0115,\n",
      "            -0.0086,      0.0154,      0.0016,     -0.0068,     -0.0157,\n",
      "             0.0053,     -0.0178,     -0.0076,      0.0068,     -0.0166,\n",
      "            -0.0017,      0.0161,      0.0157,      0.0071,     -0.0103,\n",
      "            -0.0003,     -0.0094,      0.0030,     -0.0020,      0.0153,\n",
      "             0.0125,     -0.0034,      0.0047,     -0.0112,     -0.0040,\n",
      "            -0.0020,     -0.0131,     -0.0173,      0.0072,     -0.0086,\n",
      "            -0.0072,      0.0065,      0.0094,     -0.0047,      0.0017,\n",
      "            -0.0140,      0.0075,     -0.0144,     -0.0008,      0.0052,\n",
      "            -0.0155,     -0.0131,     -0.0034,      0.0136,     -0.0131,\n",
      "            -0.0092,      0.0063,      0.0168,      0.0079,      0.0052,\n",
      "             0.0178,     -0.0172,     -0.0050,      0.0058,      0.0012,\n",
      "             0.0109,     -0.0014,      0.0054,      0.0174,     -0.0095,\n",
      "             0.0093,     -0.0088,      0.0071,     -0.0164,     -0.0108,\n",
      "            -0.0180,     -0.0091,      0.0137,     -0.0134,     -0.0053,\n",
      "             0.0051,     -0.0027,     -0.0144,     -0.0005,     -0.0157,\n",
      "             0.0067,      0.0041,     -0.0134,     -0.0066,      0.0173,\n",
      "            -0.0037,     -0.0041,     -0.0005,     -0.0036,     -0.0085,\n",
      "            -0.0095,     -0.0107,     -0.0017,     -0.0127,      0.0027,\n",
      "             0.0069,     -0.0000,     -0.0008,     -0.0028,      0.0081,\n",
      "            -0.0037,      0.0008,     -0.0038,     -0.0134,      0.0083,\n",
      "            -0.0015,      0.0120,      0.0028,     -0.0148,      0.0058,\n",
      "             0.0112,     -0.0004,     -0.0052,     -0.0170,     -0.0069,\n",
      "             0.0087,      0.0010,      0.0152,     -0.0024,      0.0148,\n",
      "            -0.0030,      0.0128,      0.0119,     -0.0169,      0.0045,\n",
      "             0.0162,     -0.0003,     -0.0131,     -0.0151,     -0.0046,\n",
      "            -0.0030,     -0.0126,      0.0106,     -0.0050,     -0.0049,\n",
      "            -0.0065,      0.0077,      0.0064,     -0.0137,      0.0108,\n",
      "             0.0169,      0.0049,      0.0067,     -0.0135,      0.0085,\n",
      "            -0.0027,      0.0088,     -0.0169,      0.0098,      0.0001,\n",
      "             0.0007,     -0.0126,     -0.0075,     -0.0089,     -0.0158,\n",
      "            -0.0120,      0.0009,      0.0172,      0.0144,      0.0155,\n",
      "            -0.0001,     -0.0162,     -0.0153,     -0.0072,      0.0041,\n",
      "             0.0047,     -0.0087,      0.0157,     -0.0091,      0.0011,\n",
      "             0.0160,     -0.0051,     -0.0111,      0.0081,      0.0176,\n",
      "             0.0028,     -0.0137,      0.0017,     -0.0082,      0.0138,\n",
      "             0.0081,     -0.0164,     -0.0127,      0.0107,      0.0161,\n",
      "            -0.0096,      0.0155,      0.0140,     -0.0170,      0.0114,\n",
      "             0.0020,      0.0047,      0.0083,     -0.0024,      0.0116,\n",
      "            -0.0079,     -0.0075,      0.0179,      0.0147,     -0.0140,\n",
      "             0.0136,     -0.0138,      0.0018,      0.0154,     -0.0048,\n",
      "             0.0093,      0.0179,      0.0151,     -0.0028,     -0.0169,\n",
      "             0.0093,      0.0036,      0.0034,      0.0080,      0.0062,\n",
      "             0.0010,      0.0074,     -0.0119,     -0.0056,      0.0022,\n",
      "            -0.0136,      0.0146,      0.0106,      0.0004,     -0.0097,\n",
      "             0.0139,     -0.0002,     -0.0098,     -0.0010,      0.0073,\n",
      "             0.0161,     -0.0012,      0.0065,     -0.0075,      0.0048,\n",
      "             0.0051,      0.0138,     -0.0044,      0.0099,     -0.0137,\n",
      "            -0.0109,     -0.0129,     -0.0043,      0.0166,     -0.0067,\n",
      "             0.0003,     -0.0132,      0.0063,     -0.0163,     -0.0080,\n",
      "            -0.0132,      0.0162,      0.0031,      0.0004,     -0.0028,\n",
      "            -0.0177,      0.0170,      0.0155,     -0.0051,      0.0076,\n",
      "             0.0028,      0.0176,     -0.0123,     -0.0084,      0.0139,\n",
      "             0.0178,      0.0053,     -0.0072,     -0.0080,      0.0061,\n",
      "             0.0058,      0.0062,      0.0120,      0.0041,     -0.0096,\n",
      "             0.0155,     -0.0143,     -0.0056,      0.0003,     -0.0163,\n",
      "            -0.0180,     -0.0013,     -0.0016,      0.0005,     -0.0107,\n",
      "            -0.0033,      0.0130,     -0.0130,      0.0034,     -0.0094,\n",
      "             0.0152,     -0.0095,     -0.0147,     -0.0155,      0.0013,\n",
      "             0.0013,      0.0119,     -0.0029,     -0.0084,      0.0073,\n",
      "             0.0027,      0.0025,     -0.0103,      0.0070,     -0.0003,\n",
      "             0.0139,      0.0152,     -0.0168,      0.0131,     -0.0087,\n",
      "             0.0012,     -0.0018,      0.0124,     -0.0010,     -0.0000,\n",
      "            -0.0100,      0.0152,      0.0070,     -0.0167,     -0.0118,\n",
      "            -0.0149,     -0.0130,     -0.0050,     -0.0136,     -0.0161,\n",
      "            -0.0147,     -0.0170,      0.0077,      0.0175,     -0.0175,\n",
      "            -0.0140,      0.0018,     -0.0169,      0.0030,     -0.0129,\n",
      "            -0.0151,     -0.0031,     -0.0005,      0.0033,     -0.0167,\n",
      "            -0.0119,     -0.0038,      0.0146,      0.0011,     -0.0072,\n",
      "            -0.0171,     -0.0138,     -0.0134,      0.0163,     -0.0108,\n",
      "             0.0083,     -0.0134,      0.0093,     -0.0094,     -0.0139,\n",
      "             0.0001,     -0.0044,     -0.0065,      0.0141,      0.0118,\n",
      "            -0.0048,     -0.0047,     -0.0165,      0.0175,      0.0061,\n",
      "            -0.0039,     -0.0001,     -0.0178,      0.0076,      0.0143,\n",
      "             0.0157,     -0.0101,      0.0016,     -0.0146,     -0.0171,\n",
      "            -0.0008,      0.0121,      0.0109,     -0.0072,      0.0071,\n",
      "             0.0024,      0.0066,      0.0018,     -0.0093,     -0.0081,\n",
      "             0.0057,      0.0090,      0.0085,      0.0142,     -0.0004,\n",
      "            -0.0133,      0.0152,     -0.0031,      0.0044,      0.0002,\n",
      "             0.0055,     -0.0106,     -0.0138,      0.0163,      0.0112,\n",
      "             0.0118,      0.0058,      0.0082,     -0.0068,     -0.0178,\n",
      "             0.0150,     -0.0176,      0.0003,      0.0112,      0.0027,\n",
      "             0.0066,      0.0067,     -0.0055,      0.0108,     -0.0113,\n",
      "             0.0050,     -0.0035,     -0.0054,      0.0076,     -0.0121,\n",
      "             0.0041,      0.0180,     -0.0085,      0.0072,      0.0102,\n",
      "             0.0167,     -0.0041,      0.0087,     -0.0064,      0.0003,\n",
      "             0.0045,     -0.0104,     -0.0014,      0.0153,      0.0145,\n",
      "            -0.0086,     -0.0073,      0.0102,     -0.0050,      0.0125,\n",
      "            -0.0133,      0.0129,      0.0171,     -0.0048,     -0.0061,\n",
      "            -0.0078,     -0.0174,     -0.0045,      0.0171,     -0.0102,\n",
      "            -0.0010,     -0.0126,     -0.0123,     -0.0018,      0.0149,\n",
      "            -0.0037,     -0.0095,      0.0101,     -0.0076,      0.0058,\n",
      "            -0.0179,     -0.0046,      0.0054,      0.0074,      0.0164,\n",
      "            -0.0057,     -0.0077,     -0.0084,      0.0037,      0.0045,\n",
      "            -0.0048,     -0.0178,     -0.0002,     -0.0170,     -0.0070,\n",
      "            -0.0145,      0.0022,     -0.0032,      0.0015,     -0.0074,\n",
      "             0.0053,      0.0039,     -0.0001,      0.0010,     -0.0084,\n",
      "            -0.0090,      0.0164,      0.0033,     -0.0085,     -0.0040,\n",
      "             0.0071,     -0.0087,      0.0147,     -0.0107,     -0.0099,\n",
      "             0.0016,     -0.0031,      0.0086,     -0.0160,      0.0042,\n",
      "             0.0179,      0.0102,     -0.0115,     -0.0144,     -0.0149,\n",
      "            -0.0161,     -0.0030,     -0.0142,     -0.0119,      0.0014,\n",
      "            -0.0043,      0.0017,      0.0151,      0.0066,     -0.0131,\n",
      "            -0.0126,      0.0073,      0.0061,     -0.0007,     -0.0164,\n",
      "            -0.0070,      0.0142,      0.0007,     -0.0117,     -0.0047,\n",
      "            -0.0079,      0.0046,      0.0120,     -0.0138,     -0.0154,\n",
      "             0.0176,     -0.0139,     -0.0161,     -0.0118,      0.0088,\n",
      "             0.0018,      0.0017,      0.0150,     -0.0065,      0.0084,\n",
      "            -0.0117,     -0.0126,     -0.0135,      0.0178,     -0.0087,\n",
      "             0.0004,     -0.0028,     -0.0087,      0.0158,      0.0081,\n",
      "            -0.0115,      0.0061,     -0.0128,      0.0156,     -0.0055,\n",
      "             0.0019,      0.0164,     -0.0116,      0.0022,      0.0131,\n",
      "            -0.0011,      0.0056,     -0.0046,      0.0164,     -0.0157,\n",
      "            -0.0178,     -0.0088,      0.0024,     -0.0138,     -0.0161,\n",
      "            -0.0038,     -0.0109,      0.0001,     -0.0080,      0.0068,\n",
      "            -0.0076,     -0.0167,     -0.0107,     -0.0067,      0.0057,\n",
      "             0.0151,     -0.0078,     -0.0040,     -0.0078,     -0.0045,\n",
      "            -0.0102,     -0.0171,     -0.0041,      0.0150,      0.0097,\n",
      "             0.0105,     -0.0130,     -0.0018,     -0.0098,      0.0155,\n",
      "             0.0118,     -0.0050,     -0.0005,     -0.0048,      0.0143,\n",
      "            -0.0087,     -0.0038,      0.0116,     -0.0074,      0.0146,\n",
      "             0.0030,     -0.0040,      0.0077,     -0.0070,     -0.0180,\n",
      "             0.0179,     -0.0016,      0.0030,     -0.0156,     -0.0126,\n",
      "            -0.0141,      0.0153,     -0.0066,     -0.0143,      0.0005,\n",
      "             0.0064,     -0.0053,     -0.0086,      0.0078,      0.0069,\n",
      "            -0.0127,     -0.0068,     -0.0104,     -0.0180,     -0.0072,\n",
      "            -0.0042,      0.0061,     -0.0122,      0.0084,     -0.0006,\n",
      "            -0.0118,     -0.0172,     -0.0137,     -0.0139,      0.0146,\n",
      "            -0.0048,     -0.0009,      0.0139,     -0.0147,     -0.0174,\n",
      "             0.0141,     -0.0164,     -0.0088,     -0.0126,      0.0151,\n",
      "            -0.0160,      0.0115,     -0.0169,     -0.0016,      0.0167,\n",
      "            -0.0042,     -0.0132,     -0.0075,     -0.0037,     -0.0040,\n",
      "             0.0046,     -0.0038,      0.0104,     -0.0029,     -0.0104,\n",
      "            -0.0114,      0.0104,     -0.0114,      0.0178,      0.0173,\n",
      "             0.0139,     -0.0059,     -0.0103,     -0.0057,      0.0076,\n",
      "             0.0117,     -0.0092,     -0.0052,      0.0006,      0.0172,\n",
      "            -0.0024,     -0.0011,      0.0145,     -0.0133,      0.0068,\n",
      "             0.0080,     -0.0176,     -0.0036,      0.0129,     -0.0093,\n",
      "             0.0115,     -0.0137,      0.0175,     -0.0073,     -0.0115,\n",
      "             0.0023,      0.0078,     -0.0139,      0.0117,     -0.0139,\n",
      "            -0.0092,      0.0138,      0.0066,     -0.0017,     -0.0113,\n",
      "             0.0119,      0.0040,     -0.0139,     -0.0070,     -0.0068,\n",
      "             0.0032,      0.0029,      0.0022,      0.0019,     -0.0112,\n",
      "             0.0148,     -0.0057,      0.0081,     -0.0046,      0.0130,\n",
      "             0.0078,      0.0089,      0.0114,     -0.0019,     -0.0171,\n",
      "             0.0028,     -0.0002,      0.0129,      0.0038,     -0.0014,\n",
      "            -0.0030,     -0.0172,     -0.0012,      0.0035,     -0.0137,\n",
      "             0.0064,      0.0119,     -0.0134,     -0.0105,      0.0068,\n",
      "            -0.0014,      0.0039,      0.0018,      0.0158,     -0.0108,\n",
      "            -0.0024,     -0.0160,     -0.0108,     -0.0134,     -0.0165,\n",
      "             0.0174,     -0.0152,      0.0151], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0005,  0.0110, -0.0223,  ..., -0.0198, -0.0105,  0.0005],\n",
      "        [-0.0169,  0.0028,  0.0249,  ..., -0.0261, -0.0329,  0.0261],\n",
      "        [ 0.0178, -0.0356, -0.0327,  ..., -0.0360,  0.0244, -0.0283],\n",
      "        ...,\n",
      "        [-0.0152,  0.0213, -0.0182,  ..., -0.0054, -0.0316, -0.0127],\n",
      "        [ 0.0053,  0.0327, -0.0272,  ...,  0.0161, -0.0217,  0.0102],\n",
      "        [ 0.0258,  0.0355,  0.0243,  ..., -0.0216, -0.0002,  0.0138]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0334,  0.0053,  0.0175,  ..., -0.0358,  0.0010,  0.0068],\n",
      "        [-0.0107,  0.0270, -0.0217,  ...,  0.0223, -0.0012, -0.0164],\n",
      "        [-0.0006,  0.0299,  0.0271,  ..., -0.0305,  0.0250, -0.0199],\n",
      "        ...,\n",
      "        [ 0.0059, -0.0063, -0.0081,  ...,  0.0292, -0.0292,  0.0086],\n",
      "        [ 0.0336,  0.0309, -0.0335,  ...,  0.0207,  0.0331,  0.0328],\n",
      "        [-0.0265,  0.0153, -0.0168,  ...,  0.0131,  0.0068, -0.0010]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0088, -0.0208, -0.0203,  ...,  0.0114,  0.0106, -0.0249],\n",
      "        [ 0.0049,  0.0218,  0.0298,  ..., -0.0294, -0.0107,  0.0165],\n",
      "        [-0.0187, -0.0107, -0.0320,  ...,  0.0230, -0.0292, -0.0100],\n",
      "        ...,\n",
      "        [-0.0075,  0.0205, -0.0034,  ...,  0.0191,  0.0282,  0.0337],\n",
      "        [ 0.0318, -0.0294,  0.0014,  ...,  0.0009,  0.0092,  0.0343],\n",
      "        [ 0.0191, -0.0251,  0.0043,  ..., -0.0189, -0.0301,  0.0008]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0195, -0.0354,  0.0070,  ..., -0.0155,  0.0049, -0.0356],\n",
      "        [ 0.0146,  0.0056, -0.0146,  ..., -0.0339,  0.0179,  0.0208],\n",
      "        [-0.0264, -0.0234,  0.0350,  ...,  0.0214,  0.0269,  0.0190],\n",
      "        ...,\n",
      "        [ 0.0261,  0.0112, -0.0296,  ..., -0.0138,  0.0052, -0.0241],\n",
      "        [-0.0304,  0.0264,  0.0323,  ..., -0.0348, -0.0092, -0.0075],\n",
      "        [-0.0267, -0.0094,  0.0010,  ...,  0.0185,  0.0089, -0.0103]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([     0.0074,      0.0267,      0.0206,      0.0173,      0.0084,\n",
      "             0.0216,     -0.0082,      0.0061,     -0.0049,     -0.0276,\n",
      "            -0.0125,      0.0291,     -0.0340,      0.0120,      0.0349,\n",
      "            -0.0123,      0.0079,     -0.0279,     -0.0050,      0.0198,\n",
      "            -0.0143,     -0.0281,     -0.0163,     -0.0335,      0.0103,\n",
      "            -0.0121,      0.0295,      0.0042,      0.0060,     -0.0113,\n",
      "             0.0183,     -0.0227,     -0.0128,      0.0033,      0.0068,\n",
      "            -0.0305,      0.0321,     -0.0057,      0.0020,     -0.0145,\n",
      "            -0.0057,      0.0065,     -0.0099,      0.0048,     -0.0025,\n",
      "             0.0192,     -0.0072,     -0.0281,     -0.0076,      0.0098,\n",
      "             0.0215,     -0.0065,     -0.0295,     -0.0267,      0.0102,\n",
      "             0.0021,     -0.0205,      0.0198,      0.0330,     -0.0180,\n",
      "            -0.0077,      0.0143,     -0.0267,      0.0329,     -0.0302,\n",
      "             0.0330,      0.0049,      0.0246,      0.0299,      0.0112,\n",
      "            -0.0068,      0.0280,      0.0242,     -0.0211,      0.0091,\n",
      "             0.0321,      0.0001,      0.0022,     -0.0087,     -0.0180,\n",
      "             0.0327,      0.0066,      0.0291,     -0.0094,     -0.0277,\n",
      "            -0.0133,      0.0177,      0.0319,      0.0321,      0.0163,\n",
      "             0.0260,     -0.0292,     -0.0339,      0.0104,      0.0115,\n",
      "            -0.0168,     -0.0318,     -0.0210,      0.0285,      0.0298,\n",
      "             0.0225,     -0.0343,     -0.0337,      0.0315,      0.0102,\n",
      "             0.0251,     -0.0117,      0.0045,     -0.0285,      0.0156,\n",
      "            -0.0200,     -0.0135,      0.0249,      0.0161,     -0.0035,\n",
      "            -0.0240,     -0.0248,      0.0246,      0.0067,      0.0057,\n",
      "             0.0320,      0.0344,      0.0280,      0.0158,      0.0256,\n",
      "             0.0261,      0.0222,     -0.0244,      0.0303,     -0.0201,\n",
      "            -0.0104,      0.0176,     -0.0256,      0.0184,     -0.0107,\n",
      "             0.0280,      0.0347,      0.0302,      0.0194,     -0.0047,\n",
      "             0.0053,      0.0348,      0.0014,      0.0243,      0.0237,\n",
      "             0.0214,      0.0231,      0.0234,     -0.0260,      0.0354,\n",
      "            -0.0271,      0.0036,     -0.0214,     -0.0212,     -0.0063,\n",
      "             0.0327,     -0.0320,      0.0265,     -0.0139,      0.0285,\n",
      "             0.0021,     -0.0030,     -0.0262,     -0.0246,     -0.0016,\n",
      "            -0.0232,     -0.0066,      0.0318,      0.0049,     -0.0302,\n",
      "            -0.0222,      0.0264,     -0.0199,     -0.0230,      0.0095,\n",
      "            -0.0326,      0.0000,      0.0337,     -0.0222,      0.0045,\n",
      "            -0.0327,     -0.0234,      0.0193,     -0.0290,      0.0026,\n",
      "            -0.0084,     -0.0241,     -0.0114,     -0.0004,     -0.0321,\n",
      "            -0.0173,     -0.0252,     -0.0035,      0.0190,      0.0110,\n",
      "             0.0091,      0.0062,      0.0319,     -0.0027,     -0.0057,\n",
      "             0.0249,     -0.0339,      0.0238,     -0.0272,      0.0099,\n",
      "             0.0260,      0.0085,     -0.0257,     -0.0091,      0.0017,\n",
      "             0.0035,      0.0191,     -0.0238,      0.0116,     -0.0057,\n",
      "             0.0292,     -0.0217,      0.0215,      0.0199,     -0.0217,\n",
      "            -0.0305,      0.0313,      0.0273,     -0.0269,      0.0162,\n",
      "            -0.0136,      0.0343,     -0.0327,      0.0039,     -0.0232,\n",
      "            -0.0273,     -0.0094,     -0.0263,     -0.0170,     -0.0352,\n",
      "             0.0032,     -0.0059,      0.0240,      0.0039,      0.0265,\n",
      "            -0.0043,      0.0037,     -0.0048,     -0.0309,      0.0028,\n",
      "            -0.0326,     -0.0204,     -0.0129,      0.0199,      0.0039,\n",
      "             0.0131,      0.0178,      0.0268,     -0.0329,     -0.0016,\n",
      "             0.0178,     -0.0059,      0.0279,      0.0338,      0.0264,\n",
      "             0.0190,     -0.0004,      0.0171,     -0.0218,     -0.0220,\n",
      "             0.0011,     -0.0257,      0.0009,      0.0173,      0.0256,\n",
      "            -0.0329,     -0.0250,      0.0320,     -0.0236,      0.0157,\n",
      "             0.0299,     -0.0024,      0.0305,     -0.0262,      0.0042,\n",
      "            -0.0324,     -0.0007,      0.0086,     -0.0319,      0.0101,\n",
      "             0.0128,      0.0314,     -0.0152,      0.0047,     -0.0090,\n",
      "            -0.0261,     -0.0058,     -0.0195,     -0.0282,     -0.0146,\n",
      "             0.0170,      0.0076,     -0.0218,      0.0189,     -0.0356,\n",
      "             0.0099,      0.0316,     -0.0354,     -0.0213,     -0.0016,\n",
      "            -0.0280,      0.0248,     -0.0228,     -0.0161,     -0.0068,\n",
      "             0.0050,     -0.0116,      0.0145,     -0.0357,     -0.0282,\n",
      "             0.0146,      0.0154,     -0.0330,      0.0232,      0.0309,\n",
      "             0.0210,      0.0296,     -0.0079,     -0.0276,     -0.0329,\n",
      "            -0.0314,      0.0304,     -0.0035,      0.0146,      0.0164,\n",
      "            -0.0256,     -0.0046,      0.0234,     -0.0251,      0.0294,\n",
      "             0.0128,      0.0025,     -0.0022,     -0.0230,      0.0107,\n",
      "            -0.0350,      0.0305,     -0.0071,      0.0285,      0.0299,\n",
      "             0.0166,      0.0029,     -0.0281,      0.0041,      0.0322,\n",
      "             0.0297,      0.0258,     -0.0064,      0.0314,      0.0018,\n",
      "            -0.0018,      0.0295,      0.0046,     -0.0044,     -0.0191,\n",
      "            -0.0084,     -0.0009,     -0.0310,      0.0201,     -0.0001,\n",
      "            -0.0009,     -0.0031,     -0.0202,     -0.0359,      0.0155,\n",
      "             0.0321,     -0.0357,      0.0313,      0.0031,      0.0097,\n",
      "            -0.0116,      0.0111,      0.0052,     -0.0060,     -0.0004,\n",
      "            -0.0129,     -0.0188,      0.0326,     -0.0208,     -0.0000,\n",
      "             0.0045,     -0.0102,      0.0202,      0.0030,     -0.0053,\n",
      "            -0.0284,     -0.0355,      0.0277,      0.0208,      0.0199,\n",
      "            -0.0110,     -0.0254,     -0.0321,      0.0033,      0.0024,\n",
      "             0.0033,      0.0286,      0.0329,      0.0225,     -0.0190,\n",
      "             0.0266,      0.0357,      0.0276,     -0.0027,      0.0341,\n",
      "            -0.0189,     -0.0031,      0.0337,     -0.0087,     -0.0081,\n",
      "             0.0131,     -0.0229,      0.0029,      0.0050,     -0.0049,\n",
      "            -0.0076,      0.0251,      0.0088,     -0.0088,     -0.0181,\n",
      "            -0.0014,      0.0210,     -0.0359,      0.0119,     -0.0212,\n",
      "             0.0157,     -0.0061,     -0.0289,     -0.0259,     -0.0225,\n",
      "            -0.0339,     -0.0120,     -0.0078,     -0.0222,     -0.0357,\n",
      "            -0.0291,      0.0212,     -0.0119,     -0.0212,     -0.0153,\n",
      "             0.0060,      0.0272,      0.0023,     -0.0350,     -0.0029,\n",
      "            -0.0111,     -0.0043,      0.0201,     -0.0025,     -0.0040,\n",
      "            -0.0178,     -0.0105,     -0.0342,      0.0168,      0.0177,\n",
      "            -0.0170,      0.0353,      0.0339,     -0.0162,     -0.0252,\n",
      "            -0.0089,      0.0200,      0.0342,     -0.0254,     -0.0216,\n",
      "            -0.0201,     -0.0161,      0.0149,      0.0030,     -0.0134,\n",
      "             0.0136,     -0.0226,      0.0238,      0.0207,     -0.0134,\n",
      "             0.0286,     -0.0311,     -0.0230,     -0.0010,      0.0257,\n",
      "            -0.0125,      0.0206,     -0.0027,      0.0066,      0.0308,\n",
      "            -0.0084,      0.0308,     -0.0147,      0.0333,     -0.0321,\n",
      "             0.0340,      0.0090,     -0.0175,      0.0080,     -0.0361,\n",
      "             0.0356,      0.0192,      0.0072,      0.0040,      0.0001,\n",
      "             0.0086,      0.0342,      0.0353,      0.0308,     -0.0141,\n",
      "            -0.0105,      0.0258,      0.0154,     -0.0227,      0.0091,\n",
      "             0.0292,      0.0313,     -0.0207,     -0.0224,     -0.0125,\n",
      "             0.0260,     -0.0031,     -0.0011,      0.0169,      0.0155,\n",
      "             0.0319,     -0.0267,     -0.0323,      0.0006,     -0.0255,\n",
      "            -0.0077,      0.0266,     -0.0027,     -0.0095,      0.0005,\n",
      "            -0.0012,     -0.0297,      0.0314,     -0.0246,     -0.0216,\n",
      "            -0.0129,      0.0196,      0.0265,     -0.0126,      0.0009,\n",
      "            -0.0169,     -0.0165,     -0.0230,      0.0003,      0.0057,\n",
      "            -0.0135,      0.0066,      0.0060,     -0.0168,      0.0204,\n",
      "            -0.0275,     -0.0015,      0.0258,     -0.0170,      0.0049,\n",
      "             0.0268,      0.0275,      0.0197,     -0.0055,     -0.0026,\n",
      "            -0.0234,     -0.0036,      0.0017,     -0.0306,     -0.0078,\n",
      "             0.0116,      0.0218,      0.0043,     -0.0063,      0.0348,\n",
      "             0.0304,      0.0190,     -0.0196,      0.0281,      0.0206,\n",
      "             0.0191,     -0.0138,      0.0196,     -0.0332,     -0.0275,\n",
      "             0.0209,      0.0338,     -0.0333,      0.0227,      0.0083,\n",
      "            -0.0016,      0.0340,     -0.0352,     -0.0157,      0.0183,\n",
      "             0.0200,     -0.0026,     -0.0281,     -0.0225,      0.0320,\n",
      "            -0.0055,      0.0170,     -0.0167,     -0.0361,      0.0297,\n",
      "            -0.0299,     -0.0212,     -0.0338,      0.0239,     -0.0202,\n",
      "            -0.0045,     -0.0149,     -0.0328,     -0.0144,     -0.0011,\n",
      "             0.0169,      0.0129,      0.0111,     -0.0269,     -0.0080,\n",
      "            -0.0156,      0.0149,     -0.0162,      0.0226,     -0.0266,\n",
      "            -0.0126,     -0.0164,      0.0092,      0.0087,     -0.0297,\n",
      "            -0.0029,     -0.0094,      0.0329,     -0.0336,      0.0241,\n",
      "             0.0194,      0.0331,     -0.0232,      0.0100,      0.0279,\n",
      "             0.0234,      0.0107,     -0.0173,     -0.0336,     -0.0163,\n",
      "             0.0054,     -0.0049,      0.0278,     -0.0341,     -0.0186,\n",
      "             0.0285,     -0.0121,      0.0263,     -0.0301,     -0.0317,\n",
      "            -0.0028,      0.0203,      0.0307,      0.0203,     -0.0135,\n",
      "            -0.0148,      0.0311,     -0.0087,     -0.0048,      0.0192,\n",
      "             0.0120,      0.0292,     -0.0170,      0.0234,     -0.0169,\n",
      "             0.0088,     -0.0317,     -0.0208,      0.0264,      0.0021,\n",
      "             0.0155,      0.0284,     -0.0343,      0.0243,     -0.0264,\n",
      "             0.0204,      0.0011,      0.0249,     -0.0103,     -0.0264,\n",
      "            -0.0317,      0.0235,     -0.0355,     -0.0312,      0.0287,\n",
      "            -0.0214,      0.0008,     -0.0211,     -0.0099,      0.0082,\n",
      "             0.0053,      0.0025,     -0.0137,      0.0276,      0.0327,\n",
      "             0.0018,      0.0257,     -0.0318,      0.0138,      0.0097,\n",
      "            -0.0015,     -0.0289,      0.0102,     -0.0262,      0.0273,\n",
      "            -0.0303,      0.0206,     -0.0248,      0.0047,      0.0139,\n",
      "            -0.0173,     -0.0041,      0.0224,     -0.0124,      0.0044,\n",
      "            -0.0191,     -0.0155,     -0.0232,     -0.0220,      0.0068,\n",
      "            -0.0041,     -0.0117,     -0.0215,     -0.0002,     -0.0271,\n",
      "            -0.0110,      0.0324,      0.0260,      0.0013,      0.0126,\n",
      "            -0.0048,      0.0173,      0.0033,      0.0038,      0.0166,\n",
      "            -0.0007,     -0.0136,      0.0221,     -0.0288,     -0.0252,\n",
      "             0.0003,     -0.0259,     -0.0344,     -0.0094,      0.0353,\n",
      "             0.0264,      0.0139,      0.0179,     -0.0182,      0.0331,\n",
      "            -0.0186,      0.0079,     -0.0219,     -0.0310,      0.0108,\n",
      "             0.0335,     -0.0316,      0.0155,      0.0022,     -0.0251,\n",
      "            -0.0120,     -0.0178,      0.0338], requires_grad=True), Parameter containing:\n",
      "tensor([[    -0.0166,     -0.0103,     -0.0099,  ...,     -0.0117,\n",
      "              0.0286,     -0.0296],\n",
      "        [    -0.0300,     -0.0000,      0.0279,  ...,      0.0105,\n",
      "              0.0114,      0.0147],\n",
      "        [    -0.0242,      0.0222,     -0.0090,  ...,      0.0359,\n",
      "              0.0026,     -0.0191],\n",
      "        ...,\n",
      "        [     0.0124,     -0.0181,      0.0049,  ...,      0.0288,\n",
      "             -0.0249,      0.0327],\n",
      "        [     0.0224,     -0.0024,      0.0117,  ...,     -0.0268,\n",
      "             -0.0197,     -0.0061],\n",
      "        [     0.0095,     -0.0337,     -0.0095,  ...,     -0.0178,\n",
      "              0.0243,      0.0123]], requires_grad=True), Parameter containing:\n",
      "tensor([    -0.0148,     -0.0032,     -0.0056,  ...,     -0.0032,\n",
      "             0.0066,      0.0001], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0051, -0.0157, -0.0006,  ...,  0.0094,  0.0113, -0.0089],\n",
      "        [-0.0002, -0.0148,  0.0022,  ...,  0.0138, -0.0150, -0.0168],\n",
      "        [ 0.0046,  0.0109,  0.0160,  ...,  0.0178, -0.0173, -0.0095],\n",
      "        ...,\n",
      "        [ 0.0121,  0.0018,  0.0064,  ..., -0.0026, -0.0172,  0.0092],\n",
      "        [-0.0050,  0.0024,  0.0054,  ...,  0.0096,  0.0055, -0.0064],\n",
      "        [-0.0072, -0.0124,  0.0050,  ...,  0.0055,  0.0081,  0.0156]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([     0.0043,     -0.0137,     -0.0089,      0.0107,      0.0027,\n",
      "             0.0157,      0.0016,     -0.0117,      0.0000,      0.0169,\n",
      "            -0.0088,     -0.0007,     -0.0007,      0.0064,      0.0148,\n",
      "             0.0132,     -0.0016,     -0.0148,     -0.0155,      0.0019,\n",
      "            -0.0163,      0.0077,      0.0108,     -0.0142,     -0.0072,\n",
      "            -0.0046,      0.0108,     -0.0153,      0.0035,      0.0065,\n",
      "             0.0161,     -0.0033,      0.0136,      0.0157,     -0.0042,\n",
      "             0.0088,     -0.0069,     -0.0029,      0.0017,     -0.0041,\n",
      "            -0.0170,      0.0162,     -0.0058,      0.0029,      0.0015,\n",
      "            -0.0060,      0.0012,     -0.0055,     -0.0104,     -0.0064,\n",
      "            -0.0163,      0.0104,      0.0011,      0.0053,     -0.0072,\n",
      "             0.0125,      0.0116,     -0.0005,      0.0070,     -0.0020,\n",
      "            -0.0043,     -0.0179,      0.0093,      0.0151,     -0.0126,\n",
      "             0.0039,      0.0176,     -0.0079,      0.0024,      0.0147,\n",
      "            -0.0160,     -0.0043,      0.0008,     -0.0025,     -0.0071,\n",
      "            -0.0116,      0.0038,     -0.0166,      0.0179,     -0.0017,\n",
      "             0.0120,      0.0011,      0.0154,     -0.0146,      0.0163,\n",
      "            -0.0048,      0.0032,      0.0079,      0.0140,     -0.0087,\n",
      "             0.0060,      0.0175,      0.0085,      0.0131,     -0.0002,\n",
      "             0.0127,     -0.0165,     -0.0072,      0.0017,      0.0061,\n",
      "             0.0118,      0.0076,      0.0128,      0.0022,     -0.0132,\n",
      "             0.0018,     -0.0082,     -0.0024,      0.0121,     -0.0054,\n",
      "            -0.0078,     -0.0172,      0.0151,     -0.0067,      0.0026,\n",
      "             0.0134,      0.0043,      0.0180,      0.0016,     -0.0028,\n",
      "            -0.0165,     -0.0156,      0.0105,     -0.0057,     -0.0072,\n",
      "             0.0093,     -0.0001,     -0.0174,      0.0107,     -0.0104,\n",
      "            -0.0015,     -0.0123,      0.0014,     -0.0144,     -0.0082,\n",
      "            -0.0078,     -0.0166,      0.0060,      0.0082,      0.0021,\n",
      "             0.0124,      0.0037,     -0.0105,     -0.0138,      0.0162,\n",
      "             0.0102,      0.0059,      0.0150,      0.0170,      0.0096,\n",
      "             0.0025,      0.0142,      0.0086,      0.0141,      0.0017,\n",
      "            -0.0050,      0.0063,     -0.0151,     -0.0023,     -0.0023,\n",
      "            -0.0158,      0.0137,      0.0173,      0.0084,      0.0105,\n",
      "            -0.0175,     -0.0105,     -0.0038,     -0.0093,     -0.0144,\n",
      "             0.0061,     -0.0151,      0.0095,     -0.0137,      0.0164,\n",
      "            -0.0066,      0.0004,      0.0165,     -0.0043,      0.0091,\n",
      "            -0.0098,      0.0019,     -0.0120,     -0.0085,     -0.0134,\n",
      "            -0.0062,     -0.0152,     -0.0098,     -0.0035,      0.0160,\n",
      "             0.0141,      0.0157,     -0.0033,      0.0002,     -0.0178,\n",
      "             0.0030,     -0.0161,      0.0098,      0.0057,     -0.0012,\n",
      "             0.0125,      0.0020,      0.0173,      0.0073,     -0.0172,\n",
      "            -0.0133,      0.0035,      0.0121,     -0.0054,     -0.0042,\n",
      "             0.0136,      0.0143,     -0.0079,      0.0049,      0.0075,\n",
      "            -0.0044,     -0.0104,     -0.0069,     -0.0033,     -0.0052,\n",
      "            -0.0025,     -0.0070,      0.0086,      0.0030,      0.0025,\n",
      "            -0.0076,     -0.0145,      0.0066,     -0.0085,     -0.0023,\n",
      "            -0.0092,     -0.0169,      0.0026,     -0.0103,     -0.0161,\n",
      "            -0.0119,      0.0008,     -0.0129,      0.0033,     -0.0170,\n",
      "            -0.0162,     -0.0138,     -0.0016,      0.0171,     -0.0104,\n",
      "             0.0137,     -0.0162,      0.0083,      0.0086,     -0.0053,\n",
      "            -0.0145,     -0.0052,      0.0008,     -0.0173,      0.0046,\n",
      "             0.0081,     -0.0150,      0.0082,      0.0028,      0.0078,\n",
      "             0.0162,     -0.0133,      0.0103,      0.0026,     -0.0162,\n",
      "             0.0064,      0.0097,     -0.0151,     -0.0049,      0.0041,\n",
      "            -0.0026,     -0.0006,     -0.0072,      0.0094,     -0.0135,\n",
      "             0.0103,      0.0148,      0.0084,     -0.0127,     -0.0115,\n",
      "            -0.0171,      0.0043,      0.0171,      0.0106,     -0.0125,\n",
      "             0.0150,     -0.0070,     -0.0167,      0.0081,      0.0153,\n",
      "             0.0120,     -0.0059,     -0.0016,     -0.0002,     -0.0167,\n",
      "            -0.0107,     -0.0118,      0.0136,     -0.0105,     -0.0124,\n",
      "             0.0165,     -0.0138,      0.0171,     -0.0163,     -0.0158,\n",
      "            -0.0131,     -0.0049,      0.0053,     -0.0163,      0.0030,\n",
      "             0.0069,     -0.0074,     -0.0137,      0.0009,     -0.0135,\n",
      "            -0.0089,     -0.0091,      0.0082,     -0.0088,      0.0101,\n",
      "             0.0147,      0.0029,      0.0179,     -0.0000,     -0.0058,\n",
      "            -0.0072,      0.0172,      0.0018,      0.0128,      0.0081,\n",
      "             0.0105,     -0.0140,      0.0044,      0.0074,      0.0026,\n",
      "            -0.0126,     -0.0045,     -0.0144,      0.0092,     -0.0118,\n",
      "            -0.0052,     -0.0038,     -0.0164,     -0.0079,     -0.0019,\n",
      "             0.0019,     -0.0066,     -0.0050,      0.0180,      0.0036,\n",
      "             0.0106,      0.0006,     -0.0066,     -0.0104,      0.0042,\n",
      "             0.0089,      0.0022,     -0.0090,      0.0139,     -0.0082,\n",
      "            -0.0008,      0.0042,     -0.0157,      0.0114,     -0.0110,\n",
      "            -0.0057,      0.0127,     -0.0084,      0.0019,      0.0147,\n",
      "             0.0020,     -0.0002,     -0.0023,     -0.0076,      0.0108,\n",
      "             0.0067,     -0.0035,     -0.0076,     -0.0002,     -0.0032,\n",
      "            -0.0039,     -0.0067,      0.0033,     -0.0119,     -0.0031,\n",
      "             0.0064,     -0.0026,     -0.0069,     -0.0108,     -0.0098,\n",
      "            -0.0089,      0.0168,      0.0042,      0.0062,     -0.0105,\n",
      "             0.0152,      0.0164,      0.0132,      0.0075,     -0.0164,\n",
      "            -0.0019,      0.0022,     -0.0157,      0.0012,      0.0154,\n",
      "            -0.0094,     -0.0011,      0.0107,      0.0135,      0.0089,\n",
      "             0.0103,     -0.0128,      0.0056,     -0.0048,     -0.0019,\n",
      "            -0.0018,     -0.0102,     -0.0169,     -0.0102,     -0.0108,\n",
      "            -0.0024,      0.0102,      0.0078,     -0.0030,      0.0017,\n",
      "            -0.0011,      0.0115,     -0.0102,      0.0173,      0.0036,\n",
      "             0.0170,      0.0046,     -0.0042,      0.0062,     -0.0134,\n",
      "            -0.0052,     -0.0120,     -0.0113,      0.0075,      0.0031,\n",
      "            -0.0143,     -0.0165,     -0.0053,     -0.0073,     -0.0020,\n",
      "            -0.0012,      0.0028,     -0.0031,     -0.0064,      0.0125,\n",
      "             0.0126,      0.0133,     -0.0176,     -0.0053,      0.0006,\n",
      "            -0.0152,      0.0153,     -0.0011,      0.0155,      0.0104,\n",
      "             0.0016,      0.0027,     -0.0122,      0.0005,      0.0015,\n",
      "            -0.0091,      0.0100,      0.0116,      0.0159,      0.0081,\n",
      "            -0.0026,     -0.0175,     -0.0115,     -0.0012,      0.0048,\n",
      "            -0.0142,     -0.0025,     -0.0125,      0.0057,      0.0117,\n",
      "             0.0170,     -0.0142,      0.0157,      0.0028,     -0.0042,\n",
      "             0.0117,      0.0100,      0.0099,      0.0157,     -0.0110,\n",
      "            -0.0044,     -0.0020,     -0.0142,     -0.0059,      0.0146,\n",
      "            -0.0176,      0.0133,      0.0022,      0.0020,     -0.0029,\n",
      "            -0.0105,      0.0132,      0.0123,     -0.0040,      0.0067,\n",
      "             0.0152,      0.0023,     -0.0014,     -0.0077,     -0.0035,\n",
      "            -0.0166,     -0.0022,      0.0161,      0.0078,      0.0096,\n",
      "            -0.0034,     -0.0014,      0.0125,      0.0154,      0.0001,\n",
      "             0.0037,     -0.0135,     -0.0086,     -0.0141,      0.0155,\n",
      "             0.0077,     -0.0085,      0.0062,      0.0180,     -0.0145,\n",
      "            -0.0017,     -0.0089,     -0.0167,     -0.0073,     -0.0122,\n",
      "            -0.0008,      0.0168,     -0.0170,      0.0070,     -0.0006,\n",
      "            -0.0158,     -0.0056,      0.0052,     -0.0169,     -0.0056,\n",
      "             0.0141,      0.0082,      0.0055,      0.0015,     -0.0080,\n",
      "            -0.0037,      0.0080,      0.0002,      0.0144,     -0.0091,\n",
      "            -0.0064,     -0.0056,     -0.0007,     -0.0134,      0.0083,\n",
      "            -0.0110,     -0.0022,     -0.0089,      0.0086,      0.0094,\n",
      "            -0.0124,      0.0172,     -0.0167,      0.0047,     -0.0106,\n",
      "            -0.0106,      0.0064,     -0.0146,      0.0032,     -0.0072,\n",
      "            -0.0014,      0.0054,      0.0159,      0.0054,      0.0145,\n",
      "             0.0047,     -0.0155,     -0.0027,     -0.0058,      0.0169,\n",
      "            -0.0059,     -0.0034,     -0.0010,     -0.0108,      0.0048,\n",
      "            -0.0026,      0.0042,     -0.0020,      0.0093,     -0.0040,\n",
      "             0.0105,     -0.0060,      0.0168,     -0.0028,     -0.0177,\n",
      "            -0.0124,     -0.0082,     -0.0006,     -0.0105,      0.0075,\n",
      "             0.0045,     -0.0039,      0.0088,     -0.0078,      0.0177,\n",
      "            -0.0027,     -0.0060,     -0.0146,     -0.0119,     -0.0170,\n",
      "             0.0122,      0.0018,      0.0065,      0.0082,      0.0022,\n",
      "            -0.0060,     -0.0014,      0.0131,      0.0049,      0.0172,\n",
      "            -0.0087,      0.0177,      0.0148,      0.0117,     -0.0151,\n",
      "            -0.0067,      0.0133,      0.0154,      0.0069,      0.0143,\n",
      "             0.0115,      0.0029,      0.0166,     -0.0172,     -0.0102,\n",
      "            -0.0089,     -0.0035,      0.0065,     -0.0126,     -0.0100,\n",
      "             0.0122,      0.0165,     -0.0084,      0.0014,      0.0143,\n",
      "             0.0105,      0.0152,      0.0045,      0.0101,      0.0174,\n",
      "            -0.0100,     -0.0137,     -0.0079,      0.0094,     -0.0026,\n",
      "             0.0025,      0.0078,      0.0173,     -0.0075,      0.0143,\n",
      "             0.0080,      0.0163,     -0.0037,     -0.0012,     -0.0006,\n",
      "             0.0092,      0.0170,     -0.0160,     -0.0175,      0.0106,\n",
      "             0.0081,     -0.0107,      0.0090,     -0.0173,     -0.0024,\n",
      "            -0.0036,     -0.0102,     -0.0172,      0.0093,     -0.0029,\n",
      "             0.0177,     -0.0144,     -0.0063,     -0.0128,     -0.0116,\n",
      "            -0.0081,     -0.0165,      0.0152,      0.0090,     -0.0156,\n",
      "            -0.0096,      0.0160,      0.0169,      0.0026,      0.0040,\n",
      "             0.0053,     -0.0086,      0.0095,     -0.0092,      0.0161,\n",
      "            -0.0072,     -0.0016,      0.0095,     -0.0001,     -0.0085,\n",
      "             0.0068,      0.0047,     -0.0032,      0.0168,      0.0011,\n",
      "             0.0140,      0.0030,     -0.0090,      0.0108,     -0.0146,\n",
      "            -0.0134,      0.0130,     -0.0081,      0.0047,      0.0022,\n",
      "            -0.0075,     -0.0026,      0.0015,     -0.0141,      0.0090,\n",
      "             0.0167,     -0.0036,      0.0147,     -0.0121,     -0.0082,\n",
      "            -0.0061,     -0.0129,     -0.0121,     -0.0063,      0.0023,\n",
      "             0.0097,      0.0083,     -0.0037,     -0.0120,     -0.0036,\n",
      "            -0.0176,      0.0048,     -0.0180,      0.0112,     -0.0099,\n",
      "            -0.0039,     -0.0000,     -0.0126,     -0.0030,      0.0111,\n",
      "            -0.0046,     -0.0066,      0.0142,     -0.0170,     -0.0137,\n",
      "             0.0015,      0.0077,     -0.0108,     -0.0043,     -0.0062,\n",
      "            -0.0091,     -0.0052,      0.0144], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0098,  0.0205, -0.0138,  ..., -0.0069,  0.0180, -0.0016],\n",
      "        [ 0.0290, -0.0335,  0.0059,  ..., -0.0022, -0.0075, -0.0345],\n",
      "        [ 0.0123, -0.0221, -0.0127,  ..., -0.0048,  0.0268, -0.0316],\n",
      "        ...,\n",
      "        [ 0.0121, -0.0260, -0.0354,  ..., -0.0313, -0.0211, -0.0181],\n",
      "        [ 0.0193, -0.0151, -0.0255,  ..., -0.0169,  0.0355, -0.0172],\n",
      "        [-0.0049, -0.0345, -0.0007,  ..., -0.0178,  0.0200, -0.0167]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0218,  0.0157, -0.0052,  ..., -0.0102, -0.0070,  0.0110],\n",
      "        [-0.0183,  0.0137, -0.0168,  ...,  0.0355, -0.0243,  0.0099],\n",
      "        [-0.0015,  0.0154, -0.0284,  ..., -0.0197,  0.0325,  0.0103],\n",
      "        ...,\n",
      "        [-0.0150,  0.0132, -0.0172,  ...,  0.0158,  0.0275, -0.0225],\n",
      "        [ 0.0229,  0.0195,  0.0049,  ..., -0.0276,  0.0347, -0.0327],\n",
      "        [ 0.0247, -0.0060, -0.0313,  ..., -0.0105, -0.0155, -0.0093]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0033, -0.0340,  0.0082,  ..., -0.0173,  0.0344,  0.0237],\n",
      "        [ 0.0181,  0.0151, -0.0202,  ..., -0.0068,  0.0197,  0.0260],\n",
      "        [ 0.0214,  0.0274, -0.0113,  ..., -0.0313, -0.0011, -0.0014],\n",
      "        ...,\n",
      "        [-0.0306, -0.0021,  0.0100,  ...,  0.0027,  0.0346,  0.0122],\n",
      "        [ 0.0038, -0.0057, -0.0311,  ...,  0.0237, -0.0116, -0.0252],\n",
      "        [-0.0309,  0.0040, -0.0204,  ...,  0.0053, -0.0109, -0.0350]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0159, -0.0228,  0.0114,  ...,  0.0277, -0.0017,  0.0192],\n",
      "        [-0.0252,  0.0179, -0.0030,  ..., -0.0236,  0.0088,  0.0267],\n",
      "        [-0.0359, -0.0337,  0.0062,  ..., -0.0358, -0.0073,  0.0054],\n",
      "        ...,\n",
      "        [ 0.0328,  0.0333,  0.0250,  ..., -0.0325, -0.0030,  0.0082],\n",
      "        [ 0.0045,  0.0086, -0.0351,  ...,  0.0306,  0.0137,  0.0110],\n",
      "        [-0.0301, -0.0192,  0.0042,  ...,  0.0277, -0.0067, -0.0361]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0074, -0.0011, -0.0329,  0.0089,  0.0216, -0.0320,  0.0005,  0.0272,\n",
      "        -0.0175,  0.0124, -0.0058,  0.0336, -0.0229, -0.0279, -0.0183,  0.0252,\n",
      "        -0.0212,  0.0140,  0.0329, -0.0157, -0.0018, -0.0312, -0.0098, -0.0074,\n",
      "         0.0331,  0.0068,  0.0056, -0.0105,  0.0075, -0.0068, -0.0345, -0.0221,\n",
      "         0.0232, -0.0071, -0.0078,  0.0307,  0.0312, -0.0207,  0.0346, -0.0196,\n",
      "         0.0121,  0.0312,  0.0264, -0.0340,  0.0093,  0.0334,  0.0061,  0.0079,\n",
      "        -0.0176,  0.0278,  0.0019, -0.0115,  0.0358, -0.0088, -0.0336, -0.0275,\n",
      "         0.0179, -0.0276,  0.0262,  0.0322, -0.0205,  0.0348, -0.0312,  0.0149,\n",
      "         0.0317,  0.0186, -0.0024, -0.0015,  0.0109, -0.0328, -0.0153, -0.0241,\n",
      "         0.0233,  0.0264,  0.0257, -0.0041,  0.0257,  0.0176, -0.0351, -0.0232,\n",
      "         0.0151,  0.0068,  0.0237, -0.0132,  0.0171, -0.0222, -0.0163, -0.0073,\n",
      "        -0.0308,  0.0132, -0.0295, -0.0023, -0.0261, -0.0005,  0.0010, -0.0255,\n",
      "        -0.0202,  0.0251, -0.0348, -0.0027, -0.0232, -0.0206,  0.0231,  0.0110,\n",
      "         0.0221,  0.0248, -0.0080,  0.0185,  0.0256, -0.0179,  0.0201, -0.0343,\n",
      "        -0.0259, -0.0145, -0.0321,  0.0047,  0.0353, -0.0289,  0.0255,  0.0093,\n",
      "        -0.0286,  0.0005, -0.0206,  0.0106,  0.0191, -0.0309,  0.0332,  0.0299,\n",
      "         0.0146, -0.0026, -0.0154, -0.0037, -0.0359, -0.0205, -0.0017, -0.0279,\n",
      "        -0.0026, -0.0265, -0.0051,  0.0237, -0.0091,  0.0294,  0.0307, -0.0090,\n",
      "         0.0345, -0.0303,  0.0227, -0.0230, -0.0176,  0.0044,  0.0142, -0.0103,\n",
      "         0.0298, -0.0340, -0.0197,  0.0300,  0.0309, -0.0357, -0.0202, -0.0311,\n",
      "         0.0344, -0.0175, -0.0341, -0.0092,  0.0192,  0.0224, -0.0173,  0.0323,\n",
      "         0.0069, -0.0268, -0.0111, -0.0044,  0.0039,  0.0260, -0.0063,  0.0257,\n",
      "         0.0102,  0.0095, -0.0002, -0.0323, -0.0182,  0.0070,  0.0234, -0.0063,\n",
      "         0.0185,  0.0235, -0.0263,  0.0268,  0.0116, -0.0223, -0.0039, -0.0350,\n",
      "         0.0193, -0.0161,  0.0104,  0.0157, -0.0109, -0.0325, -0.0255,  0.0086,\n",
      "         0.0033,  0.0278,  0.0178, -0.0227, -0.0142,  0.0312,  0.0275,  0.0202,\n",
      "        -0.0062, -0.0101,  0.0270,  0.0254, -0.0289,  0.0152, -0.0337,  0.0015,\n",
      "        -0.0208,  0.0288,  0.0234,  0.0203,  0.0161,  0.0261, -0.0139, -0.0056,\n",
      "         0.0246, -0.0010, -0.0161, -0.0061, -0.0102,  0.0091,  0.0068, -0.0171,\n",
      "        -0.0138,  0.0050,  0.0278,  0.0007, -0.0327, -0.0143, -0.0026, -0.0106,\n",
      "         0.0091, -0.0039, -0.0104,  0.0209,  0.0186,  0.0015,  0.0192, -0.0289,\n",
      "         0.0210, -0.0311,  0.0348, -0.0264, -0.0294, -0.0037, -0.0277, -0.0234,\n",
      "        -0.0013, -0.0257,  0.0319, -0.0061,  0.0138,  0.0296, -0.0004,  0.0021,\n",
      "         0.0096,  0.0354,  0.0015, -0.0121, -0.0067,  0.0005,  0.0271, -0.0085,\n",
      "        -0.0322,  0.0214, -0.0316,  0.0178,  0.0111,  0.0266,  0.0040,  0.0053,\n",
      "         0.0101, -0.0331, -0.0022, -0.0200,  0.0034,  0.0110, -0.0175, -0.0262,\n",
      "         0.0183, -0.0142, -0.0295, -0.0008, -0.0142,  0.0171, -0.0359, -0.0188,\n",
      "        -0.0297, -0.0327, -0.0351,  0.0279, -0.0358,  0.0122, -0.0059,  0.0212,\n",
      "         0.0117, -0.0227,  0.0167, -0.0104, -0.0264,  0.0081, -0.0160, -0.0354,\n",
      "         0.0283,  0.0126,  0.0029,  0.0282,  0.0067, -0.0194,  0.0243,  0.0219,\n",
      "        -0.0038,  0.0056, -0.0029, -0.0032, -0.0173, -0.0207, -0.0311, -0.0202,\n",
      "        -0.0040,  0.0347,  0.0321,  0.0351,  0.0007, -0.0118, -0.0244, -0.0192,\n",
      "         0.0097, -0.0142, -0.0143,  0.0228,  0.0267, -0.0226,  0.0112, -0.0315,\n",
      "         0.0305,  0.0018,  0.0140, -0.0121, -0.0032,  0.0310, -0.0275,  0.0057,\n",
      "         0.0192,  0.0190, -0.0258,  0.0245, -0.0322,  0.0062,  0.0357, -0.0161,\n",
      "        -0.0161,  0.0029,  0.0028,  0.0087,  0.0049, -0.0002, -0.0060, -0.0184,\n",
      "        -0.0205, -0.0199, -0.0022, -0.0176, -0.0050,  0.0044,  0.0070,  0.0329,\n",
      "        -0.0310,  0.0190,  0.0283, -0.0120, -0.0113,  0.0198, -0.0160,  0.0023,\n",
      "        -0.0249, -0.0249, -0.0293, -0.0001, -0.0137,  0.0228, -0.0301,  0.0232,\n",
      "        -0.0349, -0.0094, -0.0030, -0.0264,  0.0043,  0.0267,  0.0267, -0.0301,\n",
      "        -0.0358,  0.0103,  0.0304, -0.0078, -0.0143, -0.0266,  0.0213,  0.0026,\n",
      "        -0.0181,  0.0292, -0.0089,  0.0223, -0.0132, -0.0238,  0.0331, -0.0085,\n",
      "         0.0013, -0.0254, -0.0202, -0.0194, -0.0239, -0.0049,  0.0022, -0.0099,\n",
      "         0.0220,  0.0219,  0.0127,  0.0012,  0.0359, -0.0054, -0.0274, -0.0201,\n",
      "        -0.0004,  0.0154,  0.0243,  0.0168, -0.0294,  0.0303,  0.0041, -0.0210,\n",
      "         0.0217,  0.0236,  0.0026, -0.0273,  0.0193, -0.0131,  0.0059, -0.0298,\n",
      "        -0.0187,  0.0036,  0.0302, -0.0360,  0.0247,  0.0037,  0.0327,  0.0115,\n",
      "        -0.0147, -0.0220, -0.0036,  0.0055, -0.0255, -0.0066,  0.0125, -0.0112,\n",
      "         0.0013, -0.0096,  0.0181, -0.0004,  0.0006, -0.0280, -0.0191, -0.0145,\n",
      "        -0.0165,  0.0101, -0.0197, -0.0118,  0.0118, -0.0223,  0.0231, -0.0150,\n",
      "        -0.0296,  0.0135, -0.0094,  0.0098, -0.0233,  0.0312,  0.0223, -0.0129,\n",
      "        -0.0249, -0.0265, -0.0151,  0.0118, -0.0056,  0.0183,  0.0039,  0.0229,\n",
      "         0.0269, -0.0345, -0.0010,  0.0358,  0.0277,  0.0300,  0.0020, -0.0098,\n",
      "         0.0290,  0.0253,  0.0221, -0.0278, -0.0337, -0.0210,  0.0268, -0.0353,\n",
      "         0.0196,  0.0063, -0.0125,  0.0347,  0.0022, -0.0046,  0.0304,  0.0068,\n",
      "         0.0215, -0.0139, -0.0107, -0.0092,  0.0358, -0.0335,  0.0193,  0.0171,\n",
      "         0.0106, -0.0190, -0.0136, -0.0271, -0.0354, -0.0185,  0.0173, -0.0065,\n",
      "        -0.0332,  0.0273,  0.0055, -0.0004, -0.0124, -0.0228, -0.0312,  0.0184,\n",
      "         0.0295, -0.0270, -0.0218,  0.0253, -0.0281,  0.0025, -0.0046,  0.0247,\n",
      "        -0.0133, -0.0064,  0.0181, -0.0319, -0.0047,  0.0055,  0.0173,  0.0139,\n",
      "         0.0088, -0.0085, -0.0112,  0.0270, -0.0196,  0.0238, -0.0338,  0.0097,\n",
      "        -0.0222,  0.0269,  0.0140,  0.0208, -0.0326,  0.0122, -0.0177,  0.0065,\n",
      "         0.0331, -0.0287, -0.0328,  0.0184, -0.0181,  0.0058, -0.0012, -0.0212,\n",
      "         0.0292, -0.0319, -0.0352,  0.0074, -0.0110, -0.0250,  0.0168,  0.0256,\n",
      "        -0.0325, -0.0147, -0.0263, -0.0043,  0.0118,  0.0074, -0.0144, -0.0150,\n",
      "         0.0157,  0.0252,  0.0103,  0.0135,  0.0314,  0.0193,  0.0127, -0.0003,\n",
      "         0.0319,  0.0336,  0.0004,  0.0194, -0.0336, -0.0048,  0.0352, -0.0185,\n",
      "         0.0012,  0.0084,  0.0293, -0.0056, -0.0028,  0.0205,  0.0249,  0.0336,\n",
      "         0.0359, -0.0253, -0.0058,  0.0066, -0.0031, -0.0239, -0.0031,  0.0353,\n",
      "        -0.0257,  0.0212, -0.0104, -0.0273, -0.0133, -0.0265, -0.0104,  0.0076,\n",
      "        -0.0228,  0.0233, -0.0142,  0.0023, -0.0167,  0.0207, -0.0330, -0.0159,\n",
      "         0.0011, -0.0085, -0.0280,  0.0122, -0.0007, -0.0277, -0.0290,  0.0356,\n",
      "        -0.0128, -0.0173, -0.0072,  0.0309, -0.0313, -0.0357, -0.0032,  0.0129,\n",
      "         0.0093, -0.0272,  0.0358, -0.0327, -0.0298, -0.0157, -0.0072, -0.0041,\n",
      "         0.0084,  0.0010, -0.0145,  0.0094,  0.0101, -0.0320, -0.0358, -0.0303,\n",
      "         0.0115, -0.0057,  0.0117,  0.0127, -0.0155, -0.0146, -0.0079,  0.0203,\n",
      "        -0.0268, -0.0354, -0.0306,  0.0120,  0.0106,  0.0181,  0.0047, -0.0040,\n",
      "         0.0060, -0.0115, -0.0186, -0.0239,  0.0130, -0.0298, -0.0320, -0.0013,\n",
      "         0.0236, -0.0266,  0.0289,  0.0355, -0.0100, -0.0312, -0.0248,  0.0025,\n",
      "         0.0273, -0.0150,  0.0136,  0.0049, -0.0106, -0.0080,  0.0106,  0.0251,\n",
      "        -0.0161,  0.0240,  0.0210, -0.0283,  0.0113, -0.0236, -0.0307, -0.0027,\n",
      "        -0.0280,  0.0052,  0.0201, -0.0258,  0.0040,  0.0265,  0.0185,  0.0081,\n",
      "        -0.0233,  0.0155, -0.0056, -0.0237, -0.0116,  0.0018,  0.0341,  0.0296,\n",
      "         0.0068,  0.0067,  0.0200, -0.0035, -0.0333,  0.0190, -0.0217,  0.0311,\n",
      "         0.0017,  0.0076, -0.0168,  0.0350, -0.0286,  0.0278,  0.0226,  0.0228,\n",
      "        -0.0050, -0.0016,  0.0310, -0.0066,  0.0223, -0.0311, -0.0188, -0.0204],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0199, -0.0027, -0.0025,  ..., -0.0221, -0.0094, -0.0104],\n",
      "        [ 0.0068, -0.0313, -0.0132,  ..., -0.0304,  0.0314,  0.0091],\n",
      "        [-0.0090, -0.0323,  0.0330,  ...,  0.0258,  0.0164, -0.0025],\n",
      "        ...,\n",
      "        [-0.0333, -0.0195, -0.0058,  ...,  0.0114, -0.0063,  0.0201],\n",
      "        [ 0.0318, -0.0162,  0.0090,  ...,  0.0196, -0.0295,  0.0139],\n",
      "        [ 0.0043,  0.0344, -0.0260,  ...,  0.0154, -0.0252,  0.0187]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0199,  0.0227,  0.0176,  ...,  0.0049, -0.0205, -0.0119],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0176, -0.0101, -0.0100,  ..., -0.0102,  0.0113,  0.0178],\n",
      "        [ 0.0016, -0.0162,  0.0112,  ...,  0.0071, -0.0009, -0.0135],\n",
      "        [ 0.0102, -0.0115, -0.0160,  ..., -0.0037, -0.0108, -0.0023],\n",
      "        ...,\n",
      "        [ 0.0069, -0.0013,  0.0010,  ..., -0.0082, -0.0028, -0.0067],\n",
      "        [-0.0178, -0.0106, -0.0039,  ...,  0.0126, -0.0172,  0.0114],\n",
      "        [ 0.0095, -0.0141, -0.0047,  ...,  0.0160,  0.0043,  0.0007]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([    -0.0077,     -0.0104,     -0.0029,      0.0008,     -0.0094,\n",
      "            -0.0034,      0.0166,     -0.0102,     -0.0049,      0.0056,\n",
      "             0.0124,     -0.0022,      0.0144,      0.0019,      0.0104,\n",
      "             0.0099,     -0.0034,     -0.0005,     -0.0138,     -0.0058,\n",
      "             0.0063,      0.0024,     -0.0023,      0.0100,      0.0100,\n",
      "            -0.0053,      0.0082,     -0.0176,     -0.0068,      0.0130,\n",
      "             0.0160,      0.0039,      0.0177,      0.0127,      0.0140,\n",
      "            -0.0037,      0.0032,      0.0060,      0.0180,      0.0131,\n",
      "            -0.0081,     -0.0086,      0.0146,     -0.0060,      0.0051,\n",
      "             0.0147,      0.0179,     -0.0059,     -0.0063,      0.0131,\n",
      "            -0.0085,     -0.0101,      0.0029,     -0.0032,     -0.0079,\n",
      "             0.0022,     -0.0126,      0.0095,      0.0173,      0.0042,\n",
      "             0.0063,      0.0177,     -0.0128,      0.0163,     -0.0161,\n",
      "             0.0018,      0.0092,     -0.0154,      0.0143,     -0.0029,\n",
      "            -0.0087,     -0.0011,      0.0031,      0.0075,     -0.0169,\n",
      "            -0.0147,      0.0003,      0.0093,     -0.0133,      0.0013,\n",
      "             0.0089,      0.0168,     -0.0108,      0.0125,      0.0126,\n",
      "            -0.0003,      0.0064,     -0.0019,     -0.0029,     -0.0009,\n",
      "             0.0055,     -0.0135,      0.0062,      0.0075,     -0.0028,\n",
      "             0.0133,      0.0049,     -0.0118,     -0.0034,     -0.0097,\n",
      "            -0.0020,      0.0133,     -0.0168,     -0.0127,     -0.0059,\n",
      "             0.0015,     -0.0004,      0.0139,     -0.0114,     -0.0014,\n",
      "            -0.0139,     -0.0097,     -0.0148,      0.0013,      0.0144,\n",
      "            -0.0020,      0.0161,      0.0091,     -0.0005,      0.0075,\n",
      "             0.0052,      0.0048,      0.0090,      0.0110,     -0.0056,\n",
      "            -0.0049,     -0.0057,      0.0126,     -0.0053,     -0.0003,\n",
      "            -0.0164,     -0.0154,      0.0149,     -0.0062,     -0.0145,\n",
      "            -0.0076,      0.0007,     -0.0114,     -0.0113,      0.0025,\n",
      "            -0.0044,      0.0158,      0.0151,      0.0139,      0.0159,\n",
      "             0.0140,      0.0117,      0.0138,      0.0073,     -0.0119,\n",
      "            -0.0005,      0.0020,     -0.0159,      0.0124,     -0.0051,\n",
      "            -0.0180,     -0.0150,     -0.0045,     -0.0002,      0.0040,\n",
      "            -0.0038,     -0.0006,     -0.0168,      0.0111,      0.0007,\n",
      "             0.0057,      0.0040,      0.0065,     -0.0165,     -0.0037,\n",
      "             0.0159,      0.0101,      0.0076,     -0.0122,     -0.0145,\n",
      "             0.0147,      0.0150,     -0.0178,     -0.0165,      0.0106,\n",
      "             0.0143,      0.0096,      0.0075,      0.0141,     -0.0140,\n",
      "            -0.0114,     -0.0046,      0.0173,     -0.0054,     -0.0098,\n",
      "             0.0136,      0.0043,     -0.0036,      0.0153,     -0.0046,\n",
      "            -0.0163,      0.0086,     -0.0095,      0.0124,     -0.0061,\n",
      "             0.0036,     -0.0003,     -0.0150,      0.0150,      0.0091,\n",
      "             0.0123,     -0.0091,      0.0039,     -0.0014,      0.0087,\n",
      "            -0.0009,     -0.0054,      0.0088,     -0.0081,     -0.0039,\n",
      "             0.0091,     -0.0011,     -0.0043,     -0.0086,      0.0117,\n",
      "             0.0108,      0.0114,      0.0064,     -0.0146,      0.0019,\n",
      "            -0.0071,      0.0105,     -0.0047,     -0.0172,      0.0031,\n",
      "             0.0079,     -0.0093,      0.0178,      0.0177,      0.0052,\n",
      "             0.0166,      0.0027,     -0.0037,      0.0074,     -0.0033,\n",
      "            -0.0128,     -0.0174,     -0.0171,     -0.0110,     -0.0076,\n",
      "            -0.0137,     -0.0061,     -0.0157,      0.0012,      0.0130,\n",
      "             0.0004,     -0.0119,     -0.0031,      0.0035,     -0.0028,\n",
      "            -0.0148,      0.0176,     -0.0119,      0.0065,      0.0117,\n",
      "            -0.0060,     -0.0128,     -0.0000,     -0.0137,      0.0170,\n",
      "            -0.0104,      0.0041,      0.0046,      0.0110,     -0.0039,\n",
      "            -0.0127,      0.0061,      0.0158,     -0.0125,     -0.0144,\n",
      "            -0.0129,      0.0168,     -0.0150,      0.0084,     -0.0149,\n",
      "             0.0033,      0.0102,      0.0135,      0.0070,     -0.0079,\n",
      "            -0.0050,     -0.0149,      0.0141,     -0.0053,      0.0110,\n",
      "            -0.0107,     -0.0024,     -0.0021,     -0.0169,      0.0004,\n",
      "             0.0019,      0.0067,     -0.0177,     -0.0097,      0.0051,\n",
      "            -0.0127,      0.0144,     -0.0015,      0.0172,      0.0118,\n",
      "             0.0061,      0.0154,      0.0031,      0.0093,      0.0122,\n",
      "             0.0018,      0.0064,      0.0060,     -0.0155,     -0.0099,\n",
      "             0.0136,      0.0100,      0.0006,      0.0046,     -0.0059,\n",
      "            -0.0160,     -0.0121,     -0.0094,     -0.0083,     -0.0102,\n",
      "            -0.0068,     -0.0081,     -0.0025,      0.0152,     -0.0061,\n",
      "            -0.0080,      0.0034,      0.0035,      0.0011,      0.0097,\n",
      "             0.0043,      0.0107,      0.0105,      0.0110,     -0.0040,\n",
      "             0.0145,     -0.0143,      0.0159,     -0.0150,      0.0082,\n",
      "             0.0015,      0.0167,      0.0093,      0.0153,     -0.0038,\n",
      "            -0.0076,      0.0015,     -0.0102,     -0.0147,     -0.0177,\n",
      "            -0.0135,     -0.0082,      0.0159,     -0.0036,      0.0154,\n",
      "            -0.0045,     -0.0049,      0.0114,     -0.0157,     -0.0088,\n",
      "            -0.0056,      0.0168,     -0.0150,     -0.0161,     -0.0077,\n",
      "             0.0079,     -0.0037,     -0.0126,     -0.0051,      0.0034,\n",
      "             0.0105,     -0.0039,     -0.0113,      0.0086,      0.0018,\n",
      "            -0.0041,     -0.0020,      0.0099,      0.0043,     -0.0105,\n",
      "             0.0082,     -0.0080,      0.0159,      0.0037,     -0.0041,\n",
      "             0.0020,      0.0057,      0.0047,      0.0125,     -0.0094,\n",
      "            -0.0021,      0.0164,     -0.0142,      0.0092,      0.0083,\n",
      "            -0.0072,      0.0158,     -0.0140,     -0.0167,     -0.0126,\n",
      "             0.0180,     -0.0038,     -0.0159,     -0.0013,     -0.0069,\n",
      "             0.0150,      0.0070,      0.0036,      0.0144,      0.0089,\n",
      "            -0.0091,     -0.0088,      0.0017,      0.0005,      0.0105,\n",
      "            -0.0070,      0.0049,      0.0037,     -0.0130,      0.0099,\n",
      "             0.0005,     -0.0093,      0.0004,     -0.0083,      0.0119,\n",
      "            -0.0067,      0.0171,     -0.0049,     -0.0126,      0.0137,\n",
      "             0.0074,      0.0148,      0.0051,      0.0128,     -0.0054,\n",
      "             0.0033,      0.0042,      0.0043,      0.0121,     -0.0174,\n",
      "            -0.0005,     -0.0020,     -0.0026,     -0.0014,     -0.0168,\n",
      "            -0.0034,     -0.0126,      0.0031,     -0.0094,      0.0070,\n",
      "            -0.0024,     -0.0092,     -0.0170,     -0.0027,     -0.0077,\n",
      "            -0.0071,     -0.0064,     -0.0016,      0.0070,     -0.0107,\n",
      "            -0.0131,      0.0052,      0.0094,     -0.0133,      0.0042,\n",
      "            -0.0171,      0.0031,     -0.0110,      0.0047,     -0.0126,\n",
      "            -0.0072,     -0.0107,      0.0136,      0.0060,     -0.0087,\n",
      "             0.0068,     -0.0101,     -0.0146,     -0.0154,      0.0079,\n",
      "             0.0006,     -0.0030,      0.0068,     -0.0044,     -0.0063,\n",
      "             0.0072,      0.0105,      0.0084,      0.0142,     -0.0045,\n",
      "            -0.0024,      0.0009,      0.0172,     -0.0025,     -0.0053,\n",
      "            -0.0012,     -0.0046,      0.0118,      0.0000,     -0.0065,\n",
      "             0.0104,     -0.0068,     -0.0106,     -0.0109,      0.0110,\n",
      "            -0.0046,     -0.0158,      0.0071,     -0.0133,     -0.0171,\n",
      "            -0.0046,      0.0155,     -0.0051,      0.0063,      0.0008,\n",
      "             0.0176,      0.0135,      0.0003,     -0.0120,      0.0156,\n",
      "             0.0072,      0.0148,      0.0021,      0.0065,      0.0101,\n",
      "             0.0169,     -0.0020,      0.0089,     -0.0058,     -0.0100,\n",
      "             0.0143,     -0.0154,     -0.0128,      0.0154,     -0.0149,\n",
      "             0.0018,      0.0101,      0.0078,      0.0137,     -0.0068,\n",
      "             0.0172,      0.0136,     -0.0137,      0.0078,     -0.0024,\n",
      "             0.0086,     -0.0025,     -0.0164,     -0.0089,     -0.0047,\n",
      "             0.0076,      0.0107,      0.0154,      0.0025,      0.0119,\n",
      "             0.0126,     -0.0169,     -0.0053,     -0.0061,      0.0069,\n",
      "             0.0161,      0.0176,     -0.0020,      0.0007,     -0.0145,\n",
      "            -0.0134,      0.0179,      0.0115,     -0.0084,     -0.0135,\n",
      "            -0.0019,      0.0144,      0.0021,     -0.0075,     -0.0144,\n",
      "            -0.0068,      0.0026,      0.0039,     -0.0103,     -0.0136,\n",
      "             0.0034,      0.0022,     -0.0056,      0.0158,      0.0020,\n",
      "            -0.0059,      0.0017,     -0.0151,      0.0028,      0.0133,\n",
      "             0.0030,      0.0165,     -0.0121,      0.0171,      0.0152,\n",
      "             0.0152,     -0.0001,      0.0149,     -0.0085,      0.0091,\n",
      "            -0.0025,      0.0092,      0.0075,     -0.0033,     -0.0150,\n",
      "            -0.0026,     -0.0106,      0.0137,     -0.0126,     -0.0116,\n",
      "            -0.0150,      0.0054,      0.0038,     -0.0042,      0.0147,\n",
      "            -0.0139,     -0.0081,     -0.0055,      0.0126,     -0.0011,\n",
      "            -0.0012,     -0.0035,     -0.0015,      0.0017,      0.0103,\n",
      "            -0.0028,      0.0131,      0.0059,     -0.0110,     -0.0096,\n",
      "            -0.0177,      0.0175,      0.0176,     -0.0093,     -0.0173,\n",
      "            -0.0167,     -0.0116,     -0.0149,     -0.0008,     -0.0087,\n",
      "            -0.0177,     -0.0052,     -0.0146,     -0.0172,     -0.0115,\n",
      "            -0.0123,      0.0133,      0.0175,     -0.0163,     -0.0089,\n",
      "            -0.0107,     -0.0116,     -0.0108,     -0.0075,      0.0117,\n",
      "            -0.0109,     -0.0063,      0.0053,      0.0057,      0.0118,\n",
      "            -0.0158,     -0.0112,      0.0142,      0.0104,     -0.0112,\n",
      "             0.0089,     -0.0041,     -0.0178,      0.0010,      0.0179,\n",
      "            -0.0050,     -0.0079,     -0.0051,     -0.0111,     -0.0054,\n",
      "             0.0133,      0.0167,      0.0053,     -0.0085,     -0.0007,\n",
      "            -0.0109,      0.0081,     -0.0169,      0.0128,     -0.0104,\n",
      "             0.0177,      0.0034,      0.0066,     -0.0136,      0.0170,\n",
      "             0.0034,      0.0045,     -0.0117,      0.0034,      0.0166,\n",
      "             0.0147,     -0.0096,     -0.0125,      0.0122,     -0.0056,\n",
      "            -0.0107,     -0.0130,      0.0040,     -0.0103,     -0.0163,\n",
      "             0.0045,      0.0174,     -0.0079,      0.0154,     -0.0134,\n",
      "             0.0105,     -0.0055,     -0.0083,      0.0077,     -0.0091,\n",
      "             0.0024,      0.0017,     -0.0005,     -0.0036,      0.0012,\n",
      "             0.0172,      0.0176,     -0.0163,      0.0062,     -0.0061,\n",
      "            -0.0150,     -0.0061,     -0.0014,     -0.0145,     -0.0051,\n",
      "             0.0020,      0.0018,      0.0149,      0.0136,     -0.0084,\n",
      "            -0.0028,      0.0136,      0.0001,      0.0167,     -0.0006,\n",
      "             0.0180,     -0.0099,      0.0041,      0.0072,     -0.0066,\n",
      "             0.0048,     -0.0137,      0.0113,     -0.0061,      0.0008,\n",
      "             0.0089,     -0.0165,      0.0043,     -0.0180,     -0.0175,\n",
      "             0.0075,      0.0113,     -0.0021,      0.0092,      0.0077,\n",
      "            -0.0143,     -0.0166,     -0.0163], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0318, -0.0360,  0.0020,  ..., -0.0179, -0.0236, -0.0007],\n",
      "        [-0.0314,  0.0324,  0.0184,  ..., -0.0294,  0.0080,  0.0275],\n",
      "        [ 0.0159,  0.0108, -0.0222,  ..., -0.0333, -0.0229, -0.0081],\n",
      "        ...,\n",
      "        [ 0.0250, -0.0020,  0.0126,  ...,  0.0099, -0.0288,  0.0060],\n",
      "        [-0.0218, -0.0048, -0.0208,  ..., -0.0045,  0.0266,  0.0293],\n",
      "        [ 0.0008, -0.0229,  0.0094,  ..., -0.0355,  0.0149, -0.0192]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0346,  0.0253, -0.0056,  ...,  0.0084, -0.0346, -0.0319],\n",
      "        [ 0.0311,  0.0109,  0.0081,  ..., -0.0276, -0.0269,  0.0244],\n",
      "        [-0.0347,  0.0266,  0.0223,  ...,  0.0005,  0.0310, -0.0236],\n",
      "        ...,\n",
      "        [-0.0275,  0.0096,  0.0169,  ..., -0.0354,  0.0091, -0.0316],\n",
      "        [-0.0346,  0.0233, -0.0132,  ..., -0.0160, -0.0359,  0.0149],\n",
      "        [-0.0147,  0.0121, -0.0346,  ...,  0.0226, -0.0152, -0.0358]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0142,  0.0096, -0.0290,  ..., -0.0131, -0.0235,  0.0133],\n",
      "        [ 0.0135, -0.0167, -0.0347,  ...,  0.0005,  0.0301, -0.0335],\n",
      "        [ 0.0339,  0.0040, -0.0228,  ...,  0.0255, -0.0032, -0.0199],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0222, -0.0342,  ..., -0.0193, -0.0161,  0.0183],\n",
      "        [-0.0079, -0.0198, -0.0243,  ...,  0.0118,  0.0032, -0.0105],\n",
      "        [ 0.0285, -0.0048,  0.0303,  ..., -0.0187, -0.0326,  0.0280]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0095,  0.0250,  0.0091,  ..., -0.0101, -0.0047, -0.0075],\n",
      "        [ 0.0204,  0.0088,  0.0360,  ...,  0.0338, -0.0221, -0.0105],\n",
      "        [ 0.0350,  0.0162,  0.0077,  ..., -0.0237,  0.0133, -0.0238],\n",
      "        ...,\n",
      "        [-0.0194, -0.0019, -0.0125,  ...,  0.0318,  0.0120,  0.0308],\n",
      "        [ 0.0037, -0.0058, -0.0021,  ..., -0.0273,  0.0116,  0.0055],\n",
      "        [-0.0142, -0.0267, -0.0324,  ...,  0.0268,  0.0009,  0.0216]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([    -0.0061,     -0.0199,      0.0160,     -0.0322,     -0.0172,\n",
      "            -0.0127,     -0.0000,      0.0077,     -0.0273,      0.0088,\n",
      "             0.0250,     -0.0277,      0.0178,      0.0298,     -0.0019,\n",
      "             0.0102,      0.0148,     -0.0141,     -0.0160,     -0.0268,\n",
      "             0.0114,     -0.0141,      0.0009,     -0.0144,      0.0202,\n",
      "            -0.0284,      0.0224,     -0.0166,      0.0030,      0.0240,\n",
      "            -0.0170,      0.0296,      0.0103,     -0.0062,     -0.0277,\n",
      "            -0.0035,      0.0079,     -0.0151,     -0.0125,      0.0023,\n",
      "             0.0221,     -0.0201,     -0.0263,      0.0126,     -0.0056,\n",
      "             0.0264,     -0.0020,     -0.0310,     -0.0277,     -0.0258,\n",
      "             0.0163,      0.0355,     -0.0184,      0.0293,     -0.0019,\n",
      "            -0.0106,      0.0138,     -0.0344,     -0.0132,     -0.0106,\n",
      "            -0.0121,     -0.0048,      0.0354,     -0.0039,      0.0336,\n",
      "            -0.0073,      0.0349,     -0.0076,      0.0248,     -0.0030,\n",
      "            -0.0318,     -0.0249,      0.0081,      0.0157,     -0.0073,\n",
      "             0.0304,     -0.0147,      0.0045,      0.0319,      0.0358,\n",
      "            -0.0200,      0.0217,      0.0344,     -0.0242,      0.0346,\n",
      "             0.0040,     -0.0276,      0.0124,      0.0239,     -0.0186,\n",
      "             0.0223,     -0.0079,      0.0302,     -0.0009,      0.0020,\n",
      "            -0.0358,     -0.0248,      0.0115,     -0.0275,      0.0144,\n",
      "            -0.0023,      0.0061,     -0.0257,      0.0278,     -0.0271,\n",
      "            -0.0066,     -0.0331,     -0.0172,     -0.0064,     -0.0028,\n",
      "            -0.0288,     -0.0088,      0.0298,     -0.0344,      0.0073,\n",
      "            -0.0350,     -0.0163,      0.0206,      0.0176,     -0.0087,\n",
      "            -0.0281,     -0.0294,      0.0344,     -0.0071,     -0.0335,\n",
      "             0.0011,      0.0128,      0.0326,     -0.0311,      0.0301,\n",
      "             0.0125,      0.0262,      0.0345,     -0.0020,     -0.0152,\n",
      "             0.0124,      0.0149,     -0.0273,      0.0241,      0.0051,\n",
      "            -0.0103,     -0.0268,     -0.0254,      0.0234,     -0.0262,\n",
      "             0.0044,     -0.0301,      0.0197,     -0.0241,     -0.0167,\n",
      "            -0.0093,      0.0265,      0.0254,     -0.0269,      0.0049,\n",
      "            -0.0034,      0.0280,      0.0024,     -0.0077,      0.0224,\n",
      "            -0.0328,      0.0305,      0.0275,      0.0341,     -0.0293,\n",
      "            -0.0241,     -0.0118,     -0.0112,     -0.0283,     -0.0118,\n",
      "            -0.0065,     -0.0036,     -0.0051,     -0.0316,     -0.0028,\n",
      "             0.0152,      0.0203,      0.0236,     -0.0176,      0.0161,\n",
      "            -0.0159,     -0.0294,      0.0356,     -0.0038,     -0.0156,\n",
      "            -0.0340,      0.0161,      0.0029,     -0.0261,      0.0332,\n",
      "             0.0022,     -0.0193,      0.0137,     -0.0155,      0.0169,\n",
      "            -0.0030,     -0.0327,      0.0217,      0.0209,     -0.0331,\n",
      "            -0.0068,      0.0247,     -0.0009,      0.0330,      0.0148,\n",
      "             0.0287,      0.0042,      0.0241,      0.0233,     -0.0204,\n",
      "             0.0057,      0.0320,      0.0323,      0.0272,      0.0048,\n",
      "             0.0234,      0.0064,     -0.0052,     -0.0204,      0.0143,\n",
      "             0.0107,      0.0157,      0.0194,     -0.0002,      0.0297,\n",
      "            -0.0143,     -0.0261,     -0.0238,     -0.0199,     -0.0151,\n",
      "            -0.0082,      0.0050,      0.0241,      0.0003,     -0.0214,\n",
      "            -0.0142,      0.0281,     -0.0001,     -0.0120,     -0.0237,\n",
      "             0.0167,     -0.0005,     -0.0034,     -0.0019,     -0.0116,\n",
      "            -0.0290,      0.0297,     -0.0027,     -0.0084,      0.0022,\n",
      "            -0.0353,     -0.0049,      0.0285,     -0.0250,      0.0279,\n",
      "            -0.0097,     -0.0182,      0.0292,     -0.0148,     -0.0295,\n",
      "            -0.0005,      0.0068,     -0.0346,      0.0117,      0.0200,\n",
      "             0.0295,      0.0305,     -0.0076,      0.0258,      0.0225,\n",
      "             0.0077,      0.0136,     -0.0270,     -0.0295,      0.0358,\n",
      "            -0.0356,     -0.0326,      0.0022,     -0.0180,      0.0007,\n",
      "            -0.0190,     -0.0198,     -0.0051,     -0.0298,      0.0273,\n",
      "             0.0062,     -0.0105,      0.0173,      0.0336,     -0.0144,\n",
      "            -0.0059,      0.0281,      0.0214,      0.0230,      0.0208,\n",
      "             0.0016,      0.0262,      0.0229,      0.0220,     -0.0202,\n",
      "            -0.0076,      0.0065,      0.0077,      0.0209,     -0.0039,\n",
      "             0.0361,      0.0075,     -0.0062,      0.0309,     -0.0253,\n",
      "             0.0185,      0.0141,      0.0049,      0.0210,     -0.0354,\n",
      "             0.0238,     -0.0116,      0.0334,     -0.0065,     -0.0257,\n",
      "            -0.0182,      0.0105,      0.0154,     -0.0008,     -0.0233,\n",
      "            -0.0284,     -0.0269,      0.0208,      0.0004,     -0.0271,\n",
      "             0.0115,     -0.0035,     -0.0116,     -0.0232,      0.0132,\n",
      "             0.0267,     -0.0027,     -0.0240,      0.0044,      0.0234,\n",
      "            -0.0172,     -0.0027,     -0.0206,      0.0233,     -0.0353,\n",
      "            -0.0182,     -0.0338,      0.0242,     -0.0245,      0.0100,\n",
      "             0.0178,     -0.0060,      0.0038,      0.0288,     -0.0054,\n",
      "            -0.0191,      0.0020,      0.0290,     -0.0327,     -0.0072,\n",
      "            -0.0155,      0.0284,      0.0322,     -0.0065,      0.0282,\n",
      "            -0.0128,      0.0181,      0.0073,      0.0163,     -0.0218,\n",
      "             0.0100,     -0.0093,     -0.0149,      0.0252,      0.0087,\n",
      "             0.0085,     -0.0251,      0.0142,      0.0130,     -0.0295,\n",
      "             0.0308,      0.0113,      0.0233,      0.0330,     -0.0087,\n",
      "            -0.0277,     -0.0230,     -0.0255,      0.0334,     -0.0199,\n",
      "             0.0103,      0.0233,      0.0160,     -0.0357,     -0.0265,\n",
      "             0.0014,      0.0327,      0.0234,      0.0162,     -0.0101,\n",
      "             0.0009,     -0.0108,      0.0177,      0.0059,      0.0242,\n",
      "             0.0101,     -0.0185,      0.0050,      0.0249,     -0.0121,\n",
      "            -0.0240,     -0.0325,      0.0041,     -0.0181,      0.0123,\n",
      "            -0.0198,      0.0067,      0.0278,     -0.0356,      0.0184,\n",
      "            -0.0127,      0.0003,     -0.0284,     -0.0226,     -0.0300,\n",
      "             0.0036,     -0.0300,      0.0300,      0.0006,     -0.0258,\n",
      "             0.0195,     -0.0268,     -0.0336,     -0.0125,      0.0155,\n",
      "             0.0031,     -0.0001,      0.0022,     -0.0135,     -0.0123,\n",
      "             0.0174,     -0.0273,      0.0049,      0.0302,     -0.0355,\n",
      "            -0.0061,      0.0250,      0.0295,     -0.0334,     -0.0261,\n",
      "             0.0235,     -0.0088,     -0.0295,      0.0209,      0.0335,\n",
      "             0.0087,      0.0001,     -0.0173,     -0.0357,     -0.0314,\n",
      "             0.0306,     -0.0034,     -0.0248,     -0.0064,      0.0221,\n",
      "             0.0342,     -0.0186,     -0.0067,     -0.0258,      0.0339,\n",
      "            -0.0145,      0.0328,     -0.0141,      0.0022,     -0.0139,\n",
      "             0.0089,     -0.0284,      0.0284,     -0.0007,      0.0236,\n",
      "             0.0080,      0.0218,      0.0334,      0.0140,      0.0285,\n",
      "            -0.0195,      0.0064,      0.0355,      0.0357,      0.0240,\n",
      "            -0.0340,      0.0207,      0.0226,     -0.0204,     -0.0083,\n",
      "             0.0097,      0.0325,      0.0163,     -0.0281,     -0.0349,\n",
      "            -0.0171,      0.0252,     -0.0269,      0.0332,      0.0188,\n",
      "            -0.0279,     -0.0140,      0.0096,     -0.0161,      0.0169,\n",
      "            -0.0344,     -0.0313,      0.0293,     -0.0174,      0.0180,\n",
      "            -0.0267,     -0.0209,      0.0272,      0.0336,     -0.0279,\n",
      "             0.0321,      0.0311,      0.0087,     -0.0007,      0.0313,\n",
      "             0.0134,     -0.0119,      0.0249,      0.0226,      0.0349,\n",
      "            -0.0355,     -0.0112,      0.0208,     -0.0299,     -0.0308,\n",
      "             0.0150,     -0.0112,      0.0354,     -0.0097,      0.0012,\n",
      "            -0.0156,     -0.0002,     -0.0070,      0.0092,     -0.0155,\n",
      "            -0.0204,      0.0341,     -0.0074,     -0.0307,     -0.0002,\n",
      "             0.0135,     -0.0065,     -0.0149,     -0.0264,     -0.0248,\n",
      "            -0.0052,     -0.0195,     -0.0289,     -0.0233,     -0.0266,\n",
      "            -0.0110,      0.0287,     -0.0092,      0.0347,      0.0329,\n",
      "            -0.0089,      0.0166,     -0.0072,     -0.0066,      0.0151,\n",
      "             0.0199,     -0.0346,      0.0145,     -0.0038,      0.0001,\n",
      "             0.0326,      0.0102,      0.0260,     -0.0073,     -0.0234,\n",
      "            -0.0306,     -0.0251,     -0.0169,     -0.0015,      0.0152,\n",
      "             0.0246,      0.0115,      0.0352,      0.0149,      0.0269,\n",
      "            -0.0193,     -0.0067,      0.0216,      0.0013,      0.0221,\n",
      "            -0.0320,      0.0253,      0.0241,     -0.0113,      0.0331,\n",
      "            -0.0296,      0.0287,     -0.0215,      0.0358,     -0.0266,\n",
      "            -0.0303,     -0.0167,      0.0203,     -0.0220,     -0.0179,\n",
      "            -0.0181,     -0.0011,     -0.0021,      0.0148,      0.0133,\n",
      "            -0.0256,     -0.0151,     -0.0141,      0.0271,     -0.0114,\n",
      "            -0.0101,      0.0134,     -0.0277,     -0.0010,     -0.0111,\n",
      "             0.0050,     -0.0039,     -0.0070,     -0.0224,      0.0093,\n",
      "            -0.0143,     -0.0355,     -0.0100,      0.0275,     -0.0097,\n",
      "             0.0349,     -0.0009,      0.0004,     -0.0089,      0.0359,\n",
      "             0.0316,     -0.0337,     -0.0287,      0.0119,     -0.0188,\n",
      "            -0.0049,      0.0136,      0.0053,      0.0340,      0.0127,\n",
      "             0.0133,      0.0066,      0.0197,      0.0076,      0.0021,\n",
      "             0.0348,     -0.0343,     -0.0307,      0.0216,     -0.0110,\n",
      "            -0.0147,      0.0062,     -0.0042,      0.0263,     -0.0195,\n",
      "             0.0185,      0.0323,     -0.0158,     -0.0096,     -0.0341,\n",
      "            -0.0314,      0.0034,      0.0328,     -0.0184,      0.0088,\n",
      "            -0.0255,     -0.0272,      0.0206,      0.0142,      0.0148,\n",
      "            -0.0108,      0.0014,     -0.0242,     -0.0080,     -0.0241,\n",
      "             0.0317,      0.0075,      0.0243,      0.0167,     -0.0170,\n",
      "            -0.0190,     -0.0341,      0.0288,      0.0232,      0.0263,\n",
      "            -0.0242,     -0.0158,      0.0045,     -0.0210,      0.0109,\n",
      "             0.0132,      0.0039,      0.0043,      0.0026,     -0.0212,\n",
      "             0.0056,     -0.0208,      0.0058,      0.0346,     -0.0321,\n",
      "            -0.0286,      0.0289,      0.0237,      0.0269,      0.0168,\n",
      "            -0.0204,      0.0228,     -0.0145,     -0.0199,     -0.0021,\n",
      "             0.0228,     -0.0328,     -0.0290,      0.0248,     -0.0331,\n",
      "             0.0184,     -0.0328,      0.0178,     -0.0246,     -0.0344,\n",
      "             0.0231,      0.0204,      0.0027,     -0.0151,     -0.0314,\n",
      "             0.0346,     -0.0298,     -0.0153,      0.0158,     -0.0045,\n",
      "             0.0087,      0.0070,     -0.0312,      0.0066,      0.0338,\n",
      "             0.0001,     -0.0138,      0.0029,     -0.0199,      0.0295,\n",
      "            -0.0054,      0.0069,      0.0136,      0.0039,      0.0048,\n",
      "            -0.0141,      0.0244,     -0.0300,     -0.0116,     -0.0067,\n",
      "             0.0321,      0.0277,      0.0155,      0.0055,      0.0329,\n",
      "            -0.0286,     -0.0234,     -0.0203], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0001,  0.0220, -0.0243,  ..., -0.0200,  0.0341,  0.0035],\n",
      "        [-0.0248, -0.0206,  0.0106,  ..., -0.0289,  0.0077,  0.0238],\n",
      "        [-0.0283,  0.0302, -0.0076,  ...,  0.0275,  0.0087,  0.0319],\n",
      "        ...,\n",
      "        [ 0.0130, -0.0357,  0.0189,  ..., -0.0339, -0.0217, -0.0200],\n",
      "        [-0.0086, -0.0047, -0.0333,  ...,  0.0141, -0.0209, -0.0149],\n",
      "        [-0.0343, -0.0340, -0.0069,  ..., -0.0112, -0.0006,  0.0087]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0202, -0.0298, -0.0217,  ...,  0.0082,  0.0255, -0.0197],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0014, -0.0175, -0.0011,  ..., -0.0106,  0.0156, -0.0059],\n",
      "        [-0.0166, -0.0157,  0.0110,  ..., -0.0051,  0.0030, -0.0142],\n",
      "        [-0.0023,  0.0043,  0.0088,  ...,  0.0033, -0.0108, -0.0003],\n",
      "        ...,\n",
      "        [-0.0116,  0.0129, -0.0147,  ..., -0.0002, -0.0136,  0.0006],\n",
      "        [ 0.0093,  0.0174,  0.0133,  ...,  0.0017,  0.0013,  0.0078],\n",
      "        [ 0.0025, -0.0006,  0.0080,  ..., -0.0093, -0.0074,  0.0170]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([    -0.0156,      0.0118,     -0.0120,      0.0126,     -0.0029,\n",
      "             0.0093,      0.0093,      0.0121,      0.0180,      0.0005,\n",
      "            -0.0052,     -0.0133,     -0.0105,     -0.0153,     -0.0159,\n",
      "             0.0142,     -0.0085,      0.0111,     -0.0143,     -0.0062,\n",
      "            -0.0111,     -0.0081,     -0.0089,      0.0169,      0.0099,\n",
      "             0.0070,     -0.0121,      0.0051,      0.0029,      0.0124,\n",
      "             0.0144,     -0.0000,      0.0013,     -0.0055,      0.0136,\n",
      "            -0.0004,      0.0033,     -0.0054,      0.0086,     -0.0084,\n",
      "            -0.0055,      0.0111,      0.0015,     -0.0138,      0.0005,\n",
      "            -0.0115,     -0.0175,      0.0135,     -0.0076,     -0.0099,\n",
      "            -0.0101,      0.0151,      0.0093,      0.0028,      0.0045,\n",
      "            -0.0123,     -0.0009,     -0.0159,      0.0119,      0.0066,\n",
      "             0.0077,      0.0143,      0.0003,     -0.0036,      0.0096,\n",
      "            -0.0030,     -0.0002,     -0.0167,     -0.0032,      0.0005,\n",
      "            -0.0112,      0.0069,     -0.0051,      0.0055,     -0.0108,\n",
      "            -0.0026,      0.0154,      0.0069,     -0.0112,     -0.0142,\n",
      "             0.0099,      0.0063,      0.0066,      0.0172,      0.0168,\n",
      "            -0.0154,      0.0174,     -0.0113,      0.0049,      0.0168,\n",
      "            -0.0043,     -0.0147,      0.0135,     -0.0100,     -0.0074,\n",
      "            -0.0093,      0.0002,     -0.0032,     -0.0125,     -0.0153,\n",
      "             0.0137,     -0.0089,     -0.0084,      0.0133,      0.0152,\n",
      "             0.0179,      0.0034,      0.0172,      0.0118,      0.0180,\n",
      "            -0.0106,      0.0053,      0.0027,     -0.0053,      0.0107,\n",
      "             0.0117,      0.0018,      0.0082,      0.0108,      0.0120,\n",
      "            -0.0168,     -0.0158,      0.0085,      0.0101,     -0.0037,\n",
      "             0.0144,      0.0093,     -0.0101,      0.0109,      0.0038,\n",
      "             0.0017,      0.0123,      0.0127,      0.0151,      0.0093,\n",
      "             0.0114,     -0.0109,      0.0095,     -0.0065,     -0.0002,\n",
      "            -0.0062,      0.0043,      0.0053,      0.0162,     -0.0169,\n",
      "            -0.0051,      0.0125,     -0.0156,     -0.0117,      0.0101,\n",
      "             0.0046,      0.0152,      0.0015,     -0.0121,     -0.0069,\n",
      "             0.0164,     -0.0018,     -0.0082,     -0.0152,      0.0008,\n",
      "            -0.0066,      0.0101,     -0.0020,     -0.0067,     -0.0075,\n",
      "            -0.0171,     -0.0083,     -0.0132,     -0.0162,     -0.0133,\n",
      "             0.0071,      0.0130,     -0.0097,      0.0155,     -0.0171,\n",
      "            -0.0095,      0.0036,     -0.0005,      0.0054,     -0.0069,\n",
      "            -0.0017,      0.0116,      0.0093,      0.0054,     -0.0070,\n",
      "             0.0004,     -0.0106,      0.0056,     -0.0106,      0.0160,\n",
      "             0.0151,      0.0116,     -0.0097,      0.0004,     -0.0145,\n",
      "             0.0018,     -0.0083,     -0.0063,      0.0167,      0.0072,\n",
      "             0.0129,      0.0016,     -0.0173,     -0.0076,     -0.0088,\n",
      "            -0.0071,      0.0002,     -0.0020,     -0.0135,      0.0130,\n",
      "             0.0045,     -0.0134,      0.0094,      0.0002,      0.0138,\n",
      "             0.0145,      0.0054,      0.0041,     -0.0083,      0.0151,\n",
      "            -0.0135,      0.0080,      0.0005,      0.0064,      0.0015,\n",
      "             0.0005,     -0.0129,     -0.0109,     -0.0146,      0.0048,\n",
      "            -0.0176,     -0.0019,      0.0115,     -0.0002,     -0.0103,\n",
      "            -0.0006,     -0.0151,     -0.0024,     -0.0045,     -0.0156,\n",
      "             0.0087,      0.0091,     -0.0174,     -0.0120,      0.0172,\n",
      "            -0.0093,     -0.0009,     -0.0070,     -0.0113,      0.0105,\n",
      "            -0.0072,     -0.0158,     -0.0133,     -0.0058,      0.0085,\n",
      "             0.0067,      0.0112,      0.0124,     -0.0126,     -0.0171,\n",
      "             0.0118,      0.0128,      0.0056,     -0.0066,     -0.0029,\n",
      "             0.0058,      0.0037,      0.0024,      0.0026,      0.0033,\n",
      "             0.0140,      0.0031,     -0.0044,      0.0122,      0.0064,\n",
      "            -0.0039,      0.0086,      0.0155,     -0.0005,      0.0061,\n",
      "             0.0068,      0.0134,      0.0160,     -0.0034,     -0.0010,\n",
      "            -0.0113,     -0.0124,     -0.0004,      0.0100,      0.0031,\n",
      "             0.0012,      0.0142,      0.0063,     -0.0130,      0.0177,\n",
      "            -0.0065,      0.0118,      0.0173,     -0.0164,     -0.0097,\n",
      "             0.0100,     -0.0002,      0.0016,      0.0002,      0.0165,\n",
      "             0.0178,     -0.0097,      0.0180,     -0.0162,     -0.0024,\n",
      "             0.0098,     -0.0080,     -0.0025,     -0.0037,     -0.0062,\n",
      "             0.0059,     -0.0034,     -0.0151,     -0.0082,     -0.0020,\n",
      "            -0.0033,      0.0053,     -0.0135,      0.0133,     -0.0022,\n",
      "            -0.0121,      0.0071,     -0.0088,     -0.0133,      0.0123,\n",
      "            -0.0136,      0.0145,     -0.0068,     -0.0100,      0.0116,\n",
      "             0.0017,     -0.0048,      0.0062,     -0.0067,     -0.0120,\n",
      "             0.0038,      0.0064,     -0.0106,     -0.0178,      0.0002,\n",
      "             0.0002,      0.0032,     -0.0134,     -0.0063,      0.0118,\n",
      "             0.0056,     -0.0031,      0.0086,      0.0019,     -0.0017,\n",
      "            -0.0028,      0.0165,     -0.0067,     -0.0096,      0.0036,\n",
      "             0.0058,      0.0016,      0.0118,     -0.0000,      0.0027,\n",
      "             0.0027,     -0.0025,      0.0132,     -0.0133,     -0.0120,\n",
      "            -0.0092,     -0.0171,     -0.0048,     -0.0110,     -0.0088,\n",
      "            -0.0102,      0.0112,     -0.0093,     -0.0041,      0.0078,\n",
      "            -0.0177,     -0.0121,     -0.0046,     -0.0014,      0.0119,\n",
      "             0.0156,      0.0048,      0.0086,     -0.0023,      0.0012,\n",
      "             0.0101,      0.0073,      0.0099,      0.0100,      0.0044,\n",
      "            -0.0076,      0.0015,      0.0122,      0.0161,     -0.0045,\n",
      "             0.0062,     -0.0084,     -0.0118,      0.0016,     -0.0096,\n",
      "            -0.0063,      0.0014,     -0.0092,     -0.0081,      0.0070,\n",
      "             0.0104,      0.0061,      0.0008,      0.0096,     -0.0055,\n",
      "             0.0010,      0.0080,     -0.0064,     -0.0056,     -0.0158,\n",
      "             0.0151,      0.0166,     -0.0084,     -0.0121,      0.0048,\n",
      "             0.0146,     -0.0079,      0.0021,      0.0061,      0.0142,\n",
      "            -0.0098,      0.0093,     -0.0003,     -0.0090,     -0.0146,\n",
      "            -0.0168,      0.0099,      0.0176,      0.0144,     -0.0106,\n",
      "             0.0151,      0.0071,     -0.0112,      0.0084,      0.0092,\n",
      "             0.0075,      0.0149,      0.0100,      0.0055,      0.0026,\n",
      "            -0.0164,     -0.0050,      0.0033,      0.0118,      0.0167,\n",
      "             0.0057,      0.0016,     -0.0035,      0.0112,      0.0018,\n",
      "             0.0180,     -0.0138,      0.0001,     -0.0025,     -0.0089,\n",
      "            -0.0014,      0.0175,     -0.0125,     -0.0102,     -0.0175,\n",
      "             0.0115,     -0.0143,     -0.0007,      0.0088,      0.0139,\n",
      "            -0.0158,     -0.0128,     -0.0171,     -0.0071,     -0.0173,\n",
      "            -0.0051,      0.0050,      0.0033,      0.0173,     -0.0141,\n",
      "             0.0043,      0.0072,     -0.0138,     -0.0180,     -0.0096,\n",
      "            -0.0040,     -0.0100,      0.0048,      0.0138,      0.0042,\n",
      "             0.0155,      0.0159,     -0.0164,     -0.0084,     -0.0002,\n",
      "             0.0025,     -0.0048,      0.0128,     -0.0122,     -0.0064,\n",
      "            -0.0123,     -0.0072,     -0.0153,      0.0160,     -0.0136,\n",
      "            -0.0170,     -0.0006,      0.0114,      0.0015,     -0.0056,\n",
      "            -0.0125,     -0.0061,     -0.0079,      0.0162,      0.0160,\n",
      "             0.0129,      0.0028,     -0.0160,     -0.0008,     -0.0112,\n",
      "            -0.0001,     -0.0123,     -0.0013,      0.0091,     -0.0161,\n",
      "            -0.0114,     -0.0048,      0.0136,     -0.0045,      0.0035,\n",
      "             0.0053,      0.0066,     -0.0062,     -0.0009,     -0.0120,\n",
      "            -0.0046,      0.0083,     -0.0175,     -0.0114,      0.0084,\n",
      "            -0.0044,      0.0118,      0.0046,     -0.0090,     -0.0099,\n",
      "            -0.0094,     -0.0075,     -0.0121,      0.0176,      0.0133,\n",
      "             0.0143,      0.0166,      0.0172,      0.0019,      0.0155,\n",
      "             0.0074,     -0.0112,     -0.0111,     -0.0141,     -0.0161,\n",
      "            -0.0017,     -0.0112,     -0.0013,     -0.0088,     -0.0114,\n",
      "            -0.0032,     -0.0123,     -0.0139,      0.0099,     -0.0095,\n",
      "            -0.0023,     -0.0086,      0.0166,     -0.0075,     -0.0097,\n",
      "            -0.0016,      0.0118,     -0.0094,      0.0143,     -0.0075,\n",
      "             0.0076,      0.0171,      0.0149,      0.0123,     -0.0044,\n",
      "             0.0004,     -0.0118,     -0.0012,      0.0168,      0.0175,\n",
      "            -0.0148,      0.0110,     -0.0056,     -0.0049,      0.0007,\n",
      "             0.0110,      0.0011,     -0.0067,      0.0116,      0.0098,\n",
      "            -0.0055,      0.0119,      0.0174,     -0.0133,     -0.0113,\n",
      "             0.0066,     -0.0062,     -0.0078,      0.0124,     -0.0027,\n",
      "            -0.0039,     -0.0073,      0.0010,     -0.0169,     -0.0025,\n",
      "             0.0087,      0.0091,      0.0059,     -0.0152,      0.0014,\n",
      "             0.0164,     -0.0091,      0.0101,      0.0023,     -0.0074,\n",
      "             0.0141,     -0.0017,      0.0137,     -0.0099,     -0.0059,\n",
      "            -0.0169,      0.0092,     -0.0141,      0.0036,      0.0077,\n",
      "             0.0034,      0.0029,     -0.0046,      0.0080,     -0.0023,\n",
      "            -0.0000,      0.0165,      0.0162,     -0.0162,     -0.0014,\n",
      "            -0.0103,      0.0086,      0.0002,     -0.0031,      0.0162,\n",
      "            -0.0017,     -0.0103,     -0.0073,      0.0133,      0.0150,\n",
      "            -0.0137,      0.0127,      0.0013,     -0.0145,      0.0155,\n",
      "             0.0132,     -0.0034,      0.0101,     -0.0090,      0.0114,\n",
      "             0.0140,      0.0109,     -0.0163,     -0.0096,     -0.0003,\n",
      "            -0.0158,      0.0086,      0.0176,     -0.0159,      0.0097,\n",
      "            -0.0091,     -0.0151,     -0.0012,      0.0114,     -0.0079,\n",
      "            -0.0094,      0.0119,     -0.0132,     -0.0160,     -0.0001,\n",
      "             0.0153,     -0.0085,     -0.0088,     -0.0140,      0.0157,\n",
      "            -0.0066,      0.0109,      0.0112,     -0.0017,     -0.0076,\n",
      "            -0.0108,     -0.0168,      0.0084,     -0.0037,     -0.0055,\n",
      "            -0.0137,      0.0119,     -0.0135,      0.0081,     -0.0018,\n",
      "             0.0121,     -0.0100,     -0.0067,     -0.0068,     -0.0068,\n",
      "             0.0141,      0.0051,     -0.0035,     -0.0167,      0.0016,\n",
      "             0.0149,     -0.0016,     -0.0122,     -0.0029,     -0.0108,\n",
      "            -0.0090,     -0.0115,     -0.0034,     -0.0099,     -0.0040,\n",
      "             0.0122,      0.0026,     -0.0006,      0.0157,      0.0136,\n",
      "            -0.0177,      0.0008,      0.0114,      0.0154,      0.0006,\n",
      "            -0.0025,      0.0179,     -0.0119,      0.0088,     -0.0128,\n",
      "             0.0115,     -0.0069,     -0.0003,      0.0064,      0.0050,\n",
      "             0.0019,      0.0126,      0.0066,      0.0088,     -0.0180,\n",
      "             0.0172,      0.0034,     -0.0147,     -0.0117,     -0.0167,\n",
      "             0.0120,      0.0058,     -0.0151,      0.0018,     -0.0020,\n",
      "            -0.0130,      0.0095,      0.0151], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0167,  0.0055, -0.0185,  ..., -0.0169, -0.0036,  0.0051],\n",
      "        [ 0.0332, -0.0052,  0.0015,  ...,  0.0047, -0.0167,  0.0309],\n",
      "        [-0.0125,  0.0251,  0.0331,  ...,  0.0202, -0.0120, -0.0075],\n",
      "        ...,\n",
      "        [ 0.0088,  0.0166, -0.0155,  ...,  0.0127,  0.0149, -0.0241],\n",
      "        [-0.0287,  0.0322,  0.0151,  ...,  0.0170,  0.0355,  0.0040],\n",
      "        [ 0.0119,  0.0333,  0.0323,  ..., -0.0085, -0.0184,  0.0209]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0005,  0.0216,  0.0075,  ...,  0.0268, -0.0348,  0.0038],\n",
      "        [ 0.0195,  0.0053,  0.0269,  ...,  0.0360, -0.0067,  0.0149],\n",
      "        [ 0.0078, -0.0303, -0.0238,  ...,  0.0358, -0.0340,  0.0246],\n",
      "        ...,\n",
      "        [-0.0157,  0.0265, -0.0050,  ...,  0.0005, -0.0051, -0.0268],\n",
      "        [ 0.0013, -0.0032,  0.0328,  ...,  0.0319, -0.0135,  0.0025],\n",
      "        [ 0.0315, -0.0147,  0.0215,  ..., -0.0336, -0.0222, -0.0205]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0156, -0.0104,  0.0039,  ...,  0.0034,  0.0014,  0.0310],\n",
      "        [-0.0258, -0.0180, -0.0124,  ...,  0.0060, -0.0349,  0.0343],\n",
      "        [ 0.0272,  0.0086,  0.0294,  ..., -0.0119,  0.0074, -0.0329],\n",
      "        ...,\n",
      "        [-0.0285,  0.0214, -0.0266,  ..., -0.0050, -0.0219, -0.0248],\n",
      "        [ 0.0194,  0.0277,  0.0077,  ...,  0.0122, -0.0205, -0.0139],\n",
      "        [ 0.0145, -0.0059,  0.0173,  ...,  0.0005,  0.0315, -0.0019]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0120,  0.0098, -0.0210,  ...,  0.0047, -0.0007, -0.0245],\n",
      "        [-0.0196,  0.0249,  0.0223,  ...,  0.0145, -0.0207,  0.0273],\n",
      "        [ 0.0197, -0.0047, -0.0307,  ..., -0.0191,  0.0345, -0.0310],\n",
      "        ...,\n",
      "        [-0.0151, -0.0249, -0.0328,  ..., -0.0287, -0.0315,  0.0243],\n",
      "        [-0.0243, -0.0063, -0.0314,  ..., -0.0330,  0.0112,  0.0318],\n",
      "        [-0.0342, -0.0139,  0.0005,  ...,  0.0040,  0.0008,  0.0138]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([     0.0141,     -0.0259,      0.0272,      0.0302,      0.0154,\n",
      "            -0.0165,     -0.0351,      0.0252,      0.0299,      0.0049,\n",
      "             0.0132,      0.0038,     -0.0219,      0.0276,     -0.0300,\n",
      "            -0.0111,      0.0229,      0.0325,     -0.0160,     -0.0319,\n",
      "            -0.0284,     -0.0123,      0.0154,      0.0230,      0.0240,\n",
      "            -0.0233,      0.0100,      0.0052,      0.0244,      0.0261,\n",
      "             0.0095,     -0.0177,     -0.0316,     -0.0322,      0.0235,\n",
      "             0.0216,      0.0302,      0.0129,     -0.0150,      0.0167,\n",
      "            -0.0107,      0.0048,      0.0297,     -0.0196,      0.0284,\n",
      "             0.0318,      0.0095,     -0.0035,      0.0161,     -0.0108,\n",
      "            -0.0143,      0.0260,     -0.0158,      0.0249,     -0.0347,\n",
      "             0.0336,      0.0229,      0.0204,     -0.0334,      0.0251,\n",
      "            -0.0159,     -0.0262,      0.0095,     -0.0051,     -0.0237,\n",
      "             0.0134,      0.0000,      0.0124,     -0.0348,     -0.0184,\n",
      "             0.0067,     -0.0218,     -0.0101,     -0.0028,     -0.0308,\n",
      "            -0.0151,      0.0278,     -0.0162,     -0.0158,     -0.0264,\n",
      "            -0.0178,     -0.0174,     -0.0046,      0.0083,      0.0256,\n",
      "            -0.0100,      0.0156,     -0.0185,      0.0098,      0.0239,\n",
      "            -0.0040,     -0.0292,      0.0085,      0.0014,     -0.0031,\n",
      "             0.0055,     -0.0266,     -0.0254,      0.0023,      0.0328,\n",
      "             0.0322,     -0.0141,      0.0350,      0.0336,      0.0244,\n",
      "             0.0329,     -0.0093,     -0.0133,     -0.0045,     -0.0109,\n",
      "             0.0103,     -0.0211,     -0.0054,      0.0257,      0.0237,\n",
      "            -0.0059,      0.0083,     -0.0048,      0.0135,     -0.0032,\n",
      "             0.0228,      0.0034,      0.0106,     -0.0164,      0.0247,\n",
      "            -0.0122,      0.0140,      0.0294,     -0.0161,     -0.0315,\n",
      "             0.0349,     -0.0046,     -0.0119,      0.0260,     -0.0209,\n",
      "            -0.0195,      0.0288,      0.0103,      0.0255,      0.0060,\n",
      "             0.0057,      0.0083,     -0.0061,      0.0305,     -0.0355,\n",
      "             0.0120,      0.0044,     -0.0234,      0.0192,     -0.0260,\n",
      "            -0.0290,      0.0201,      0.0249,     -0.0162,      0.0064,\n",
      "             0.0121,      0.0126,     -0.0075,      0.0304,     -0.0118,\n",
      "            -0.0246,      0.0186,     -0.0016,      0.0259,      0.0070,\n",
      "            -0.0211,     -0.0173,      0.0211,      0.0305,     -0.0350,\n",
      "            -0.0096,      0.0326,      0.0094,      0.0152,      0.0279,\n",
      "            -0.0100,     -0.0040,     -0.0208,     -0.0350,      0.0328,\n",
      "            -0.0132,     -0.0271,      0.0064,      0.0303,     -0.0060,\n",
      "             0.0038,      0.0171,     -0.0292,     -0.0024,      0.0320,\n",
      "             0.0057,      0.0089,     -0.0320,     -0.0280,     -0.0178,\n",
      "             0.0205,     -0.0123,     -0.0091,      0.0080,      0.0050,\n",
      "            -0.0185,     -0.0104,     -0.0334,     -0.0040,     -0.0109,\n",
      "            -0.0352,     -0.0273,      0.0349,     -0.0127,     -0.0347,\n",
      "             0.0102,      0.0263,     -0.0076,      0.0202,      0.0204,\n",
      "            -0.0164,      0.0037,      0.0104,      0.0352,      0.0111,\n",
      "            -0.0104,      0.0360,      0.0001,      0.0214,     -0.0179,\n",
      "             0.0315,      0.0262,      0.0048,     -0.0225,      0.0021,\n",
      "            -0.0289,     -0.0085,      0.0201,     -0.0305,      0.0138,\n",
      "            -0.0142,      0.0236,      0.0347,      0.0168,     -0.0350,\n",
      "             0.0110,      0.0256,     -0.0227,     -0.0184,     -0.0331,\n",
      "            -0.0045,      0.0161,     -0.0103,      0.0187,     -0.0321,\n",
      "            -0.0347,     -0.0055,      0.0309,     -0.0124,     -0.0305,\n",
      "             0.0197,     -0.0254,     -0.0302,      0.0116,     -0.0289,\n",
      "             0.0039,     -0.0191,     -0.0064,      0.0119,     -0.0092,\n",
      "            -0.0317,     -0.0024,      0.0270,     -0.0339,     -0.0163,\n",
      "            -0.0216,      0.0151,      0.0148,      0.0105,      0.0162,\n",
      "            -0.0348,      0.0039,      0.0190,     -0.0135,     -0.0028,\n",
      "            -0.0089,     -0.0281,      0.0060,     -0.0350,     -0.0179,\n",
      "            -0.0102,      0.0185,      0.0313,     -0.0216,     -0.0056,\n",
      "             0.0100,      0.0253,      0.0127,      0.0031,     -0.0234,\n",
      "            -0.0114,     -0.0040,      0.0023,      0.0006,      0.0341,\n",
      "            -0.0279,     -0.0190,     -0.0330,      0.0187,      0.0319,\n",
      "            -0.0272,      0.0038,     -0.0336,     -0.0251,      0.0360,\n",
      "             0.0088,     -0.0240,      0.0067,     -0.0177,      0.0057,\n",
      "             0.0205,      0.0099,      0.0214,     -0.0224,     -0.0043,\n",
      "            -0.0186,     -0.0145,      0.0060,     -0.0161,     -0.0063,\n",
      "             0.0152,     -0.0184,     -0.0027,     -0.0111,      0.0040,\n",
      "             0.0356,      0.0020,      0.0040,      0.0283,     -0.0122,\n",
      "             0.0126,     -0.0126,      0.0347,      0.0328,     -0.0018,\n",
      "             0.0080,     -0.0256,      0.0271,      0.0187,      0.0271,\n",
      "            -0.0250,     -0.0196,     -0.0172,     -0.0082,      0.0195,\n",
      "             0.0144,     -0.0196,      0.0347,      0.0017,      0.0315,\n",
      "            -0.0172,     -0.0305,      0.0133,     -0.0164,      0.0085,\n",
      "             0.0233,     -0.0106,     -0.0202,     -0.0069,     -0.0053,\n",
      "             0.0284,      0.0134,      0.0018,      0.0246,      0.0084,\n",
      "             0.0074,     -0.0132,     -0.0236,      0.0312,     -0.0193,\n",
      "             0.0140,      0.0322,     -0.0123,     -0.0180,     -0.0222,\n",
      "             0.0138,     -0.0007,     -0.0102,     -0.0294,     -0.0269,\n",
      "            -0.0220,      0.0040,     -0.0116,      0.0020,      0.0119,\n",
      "             0.0079,      0.0166,     -0.0238,     -0.0336,      0.0110,\n",
      "             0.0196,      0.0273,     -0.0284,      0.0140,      0.0317,\n",
      "            -0.0031,     -0.0209,      0.0114,      0.0074,      0.0176,\n",
      "            -0.0233,      0.0293,      0.0273,     -0.0136,     -0.0263,\n",
      "            -0.0243,     -0.0069,      0.0326,      0.0295,     -0.0231,\n",
      "             0.0092,      0.0128,      0.0314,     -0.0336,     -0.0186,\n",
      "             0.0257,     -0.0207,     -0.0209,     -0.0313,     -0.0354,\n",
      "            -0.0117,     -0.0298,      0.0082,      0.0143,      0.0261,\n",
      "            -0.0332,     -0.0299,      0.0252,     -0.0077,      0.0226,\n",
      "            -0.0103,      0.0006,      0.0148,      0.0170,     -0.0198,\n",
      "             0.0253,     -0.0352,     -0.0192,      0.0056,     -0.0134,\n",
      "            -0.0084,      0.0332,     -0.0176,     -0.0331,     -0.0078,\n",
      "             0.0004,     -0.0078,      0.0126,     -0.0311,      0.0198,\n",
      "            -0.0293,     -0.0013,     -0.0312,      0.0144,      0.0123,\n",
      "            -0.0078,     -0.0242,      0.0239,      0.0298,     -0.0110,\n",
      "             0.0047,      0.0356,      0.0051,      0.0113,     -0.0157,\n",
      "             0.0007,     -0.0071,      0.0016,      0.0244,      0.0058,\n",
      "             0.0166,     -0.0112,     -0.0337,     -0.0320,     -0.0275,\n",
      "             0.0294,      0.0277,      0.0179,     -0.0080,      0.0041,\n",
      "             0.0158,      0.0215,     -0.0090,     -0.0095,      0.0110,\n",
      "             0.0129,      0.0295,      0.0132,     -0.0182,     -0.0206,\n",
      "             0.0353,      0.0246,      0.0228,     -0.0023,      0.0108,\n",
      "             0.0296,      0.0125,      0.0244,      0.0250,      0.0241,\n",
      "            -0.0344,     -0.0023,     -0.0297,     -0.0350,      0.0333,\n",
      "             0.0162,      0.0059,     -0.0116,      0.0064,     -0.0237,\n",
      "            -0.0135,     -0.0295,     -0.0235,      0.0189,      0.0151,\n",
      "             0.0231,      0.0330,     -0.0211,      0.0166,     -0.0346,\n",
      "             0.0038,     -0.0080,     -0.0190,     -0.0080,      0.0085,\n",
      "            -0.0240,      0.0108,      0.0292,      0.0001,      0.0037,\n",
      "            -0.0208,      0.0128,      0.0348,      0.0228,      0.0181,\n",
      "             0.0156,      0.0327,     -0.0137,     -0.0302,      0.0353,\n",
      "             0.0070,     -0.0093,      0.0098,      0.0064,      0.0153,\n",
      "             0.0100,      0.0282,     -0.0177,      0.0359,     -0.0137,\n",
      "            -0.0107,      0.0009,      0.0264,     -0.0242,      0.0009,\n",
      "            -0.0031,     -0.0017,     -0.0225,      0.0293,      0.0140,\n",
      "            -0.0244,     -0.0176,      0.0282,     -0.0235,      0.0252,\n",
      "            -0.0185,     -0.0150,      0.0267,      0.0304,      0.0092,\n",
      "             0.0266,     -0.0302,     -0.0148,      0.0274,     -0.0250,\n",
      "            -0.0352,      0.0072,     -0.0198,      0.0330,      0.0357,\n",
      "            -0.0096,     -0.0040,     -0.0170,     -0.0136,     -0.0098,\n",
      "            -0.0101,      0.0187,     -0.0304,      0.0197,     -0.0166,\n",
      "             0.0079,     -0.0095,     -0.0225,      0.0294,     -0.0157,\n",
      "             0.0201,      0.0150,      0.0128,     -0.0333,     -0.0091,\n",
      "             0.0092,     -0.0165,     -0.0088,      0.0343,      0.0134,\n",
      "            -0.0041,     -0.0335,      0.0127,     -0.0222,     -0.0257,\n",
      "             0.0018,      0.0085,      0.0262,      0.0182,      0.0299,\n",
      "            -0.0147,      0.0054,     -0.0121,     -0.0093,      0.0013,\n",
      "             0.0277,     -0.0139,      0.0245,     -0.0060,      0.0053,\n",
      "            -0.0168,     -0.0048,     -0.0328,      0.0198,     -0.0133,\n",
      "             0.0352,      0.0114,      0.0071,      0.0017,      0.0050,\n",
      "            -0.0318,     -0.0083,     -0.0194,      0.0005,     -0.0092,\n",
      "             0.0137,      0.0181,     -0.0061,     -0.0250,      0.0288,\n",
      "            -0.0003,     -0.0077,      0.0093,     -0.0266,     -0.0162,\n",
      "            -0.0333,      0.0016,      0.0304,      0.0021,      0.0029,\n",
      "             0.0016,     -0.0165,     -0.0207,      0.0246,     -0.0195,\n",
      "             0.0031,      0.0222,     -0.0214,      0.0210,     -0.0345,\n",
      "             0.0287,      0.0306,      0.0324,      0.0051,     -0.0096,\n",
      "            -0.0024,     -0.0111,     -0.0100,     -0.0128,      0.0262,\n",
      "             0.0329,     -0.0177,     -0.0059,      0.0149,     -0.0322,\n",
      "            -0.0062,     -0.0063,      0.0248,     -0.0130,     -0.0064,\n",
      "            -0.0076,     -0.0341,     -0.0349,     -0.0292,     -0.0318,\n",
      "             0.0207,     -0.0211,      0.0358,      0.0036,     -0.0160,\n",
      "             0.0226,      0.0312,      0.0299,      0.0241,      0.0145,\n",
      "            -0.0255,      0.0360,      0.0068,     -0.0240,     -0.0002,\n",
      "            -0.0268,     -0.0071,      0.0247,     -0.0209,      0.0095,\n",
      "            -0.0313,     -0.0054,      0.0262,     -0.0235,      0.0289,\n",
      "            -0.0338,      0.0139,     -0.0231,     -0.0324,      0.0251,\n",
      "             0.0281,     -0.0021,     -0.0231,     -0.0222,      0.0302,\n",
      "            -0.0108,     -0.0241,     -0.0016,     -0.0266,      0.0112,\n",
      "             0.0344,      0.0178,      0.0146,     -0.0035,     -0.0170,\n",
      "             0.0117,      0.0263,      0.0353,     -0.0298,      0.0163,\n",
      "            -0.0068,      0.0237,      0.0260,     -0.0264,     -0.0047,\n",
      "            -0.0172,      0.0148,      0.0349,     -0.0170,      0.0085,\n",
      "            -0.0295,      0.0042,     -0.0290,     -0.0127,     -0.0038,\n",
      "            -0.0250,     -0.0073,      0.0338,     -0.0330,     -0.0280,\n",
      "             0.0322,     -0.0316,     -0.0020], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0144,  0.0064, -0.0274,  ..., -0.0283, -0.0316,  0.0205],\n",
      "        [ 0.0287, -0.0026, -0.0116,  ..., -0.0344, -0.0125, -0.0185],\n",
      "        [-0.0055, -0.0188,  0.0193,  ...,  0.0293, -0.0247, -0.0076],\n",
      "        ...,\n",
      "        [-0.0061, -0.0032,  0.0285,  ...,  0.0226,  0.0285, -0.0038],\n",
      "        [-0.0061, -0.0190, -0.0160,  ...,  0.0038, -0.0013, -0.0162],\n",
      "        [ 0.0258, -0.0065, -0.0199,  ..., -0.0222, -0.0116, -0.0134]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0360,  0.0234, -0.0037,  ..., -0.0260, -0.0077, -0.0192],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0096,  0.0128, -0.0105,  ..., -0.0125, -0.0156, -0.0055],\n",
      "        [-0.0039, -0.0064,  0.0071,  ...,  0.0152,  0.0091, -0.0038],\n",
      "        [ 0.0176,  0.0042, -0.0014,  ...,  0.0110,  0.0047, -0.0144],\n",
      "        ...,\n",
      "        [-0.0141, -0.0076, -0.0175,  ...,  0.0172, -0.0014, -0.0162],\n",
      "        [ 0.0139, -0.0080,  0.0012,  ..., -0.0145,  0.0119,  0.0093],\n",
      "        [-0.0079, -0.0028, -0.0119,  ...,  0.0118, -0.0123,  0.0131]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([     0.0009,      0.0084,     -0.0133,      0.0080,      0.0043,\n",
      "            -0.0107,      0.0010,      0.0006,      0.0089,      0.0068,\n",
      "             0.0046,     -0.0014,     -0.0132,     -0.0150,      0.0006,\n",
      "             0.0137,     -0.0079,      0.0042,     -0.0120,      0.0049,\n",
      "            -0.0073,     -0.0125,     -0.0115,     -0.0119,      0.0102,\n",
      "             0.0112,      0.0037,     -0.0112,      0.0174,      0.0001,\n",
      "             0.0138,      0.0037,      0.0004,     -0.0087,      0.0008,\n",
      "            -0.0066,      0.0115,     -0.0023,      0.0003,      0.0008,\n",
      "             0.0136,     -0.0062,     -0.0108,     -0.0145,     -0.0092,\n",
      "             0.0069,      0.0059,     -0.0159,      0.0072,     -0.0004,\n",
      "            -0.0067,      0.0046,     -0.0180,     -0.0009,     -0.0138,\n",
      "            -0.0020,     -0.0158,      0.0031,     -0.0119,     -0.0119,\n",
      "             0.0075,      0.0119,      0.0152,     -0.0093,     -0.0082,\n",
      "            -0.0087,     -0.0162,      0.0144,      0.0023,      0.0178,\n",
      "             0.0086,      0.0149,     -0.0084,     -0.0173,     -0.0169,\n",
      "             0.0100,      0.0011,      0.0168,     -0.0012,      0.0029,\n",
      "             0.0159,     -0.0075,     -0.0159,      0.0111,      0.0016,\n",
      "             0.0001,     -0.0134,      0.0165,     -0.0075,      0.0007,\n",
      "            -0.0150,      0.0058,     -0.0008,     -0.0083,      0.0082,\n",
      "             0.0093,     -0.0053,      0.0109,      0.0171,     -0.0169,\n",
      "            -0.0108,      0.0016,      0.0035,     -0.0142,     -0.0031,\n",
      "            -0.0111,     -0.0027,     -0.0082,     -0.0114,     -0.0152,\n",
      "            -0.0075,     -0.0082,     -0.0046,      0.0161,     -0.0017,\n",
      "             0.0083,     -0.0119,      0.0013,      0.0149,      0.0000,\n",
      "            -0.0024,      0.0025,      0.0147,      0.0065,      0.0088,\n",
      "            -0.0008,      0.0001,     -0.0015,     -0.0017,     -0.0036,\n",
      "            -0.0058,     -0.0065,     -0.0175,      0.0080,      0.0056,\n",
      "             0.0094,     -0.0054,      0.0122,     -0.0178,      0.0125,\n",
      "             0.0138,     -0.0179,      0.0099,     -0.0126,      0.0015,\n",
      "             0.0025,      0.0063,     -0.0049,      0.0175,      0.0064,\n",
      "            -0.0032,      0.0158,     -0.0109,      0.0044,      0.0040,\n",
      "             0.0034,      0.0158,      0.0177,      0.0018,      0.0012,\n",
      "            -0.0111,     -0.0094,      0.0118,     -0.0111,      0.0016,\n",
      "             0.0165,     -0.0036,     -0.0130,      0.0094,      0.0080,\n",
      "             0.0018,     -0.0166,      0.0070,      0.0079,      0.0158,\n",
      "             0.0025,      0.0016,     -0.0175,      0.0144,     -0.0180,\n",
      "             0.0092,      0.0051,      0.0034,     -0.0046,     -0.0114,\n",
      "             0.0162,     -0.0152,      0.0139,     -0.0018,     -0.0124,\n",
      "            -0.0037,      0.0102,      0.0136,     -0.0161,     -0.0126,\n",
      "            -0.0102,      0.0087,     -0.0064,     -0.0014,      0.0163,\n",
      "            -0.0140,      0.0013,     -0.0077,      0.0068,     -0.0114,\n",
      "            -0.0095,      0.0032,     -0.0023,     -0.0004,     -0.0048,\n",
      "            -0.0058,      0.0159,      0.0144,      0.0115,      0.0176,\n",
      "             0.0015,      0.0102,     -0.0028,     -0.0049,     -0.0131,\n",
      "            -0.0004,     -0.0078,     -0.0008,     -0.0090,      0.0066,\n",
      "             0.0058,     -0.0026,      0.0064,      0.0016,     -0.0049,\n",
      "             0.0175,      0.0102,      0.0112,     -0.0032,     -0.0092,\n",
      "             0.0031,     -0.0029,     -0.0002,      0.0143,      0.0087,\n",
      "            -0.0052,      0.0013,      0.0064,     -0.0051,      0.0043,\n",
      "            -0.0164,     -0.0175,     -0.0157,      0.0110,      0.0113,\n",
      "             0.0174,     -0.0057,      0.0131,     -0.0120,      0.0092,\n",
      "            -0.0082,      0.0060,      0.0018,      0.0164,      0.0099,\n",
      "             0.0015,     -0.0043,      0.0035,     -0.0174,      0.0035,\n",
      "             0.0022,      0.0145,      0.0096,      0.0030,     -0.0001,\n",
      "            -0.0023,      0.0151,     -0.0088,     -0.0062,     -0.0098,\n",
      "             0.0120,      0.0121,      0.0146,      0.0168,      0.0102,\n",
      "            -0.0057,      0.0117,     -0.0117,      0.0171,      0.0141,\n",
      "            -0.0128,      0.0082,      0.0047,      0.0091,     -0.0022,\n",
      "            -0.0173,     -0.0101,      0.0070,      0.0031,     -0.0133,\n",
      "            -0.0059,      0.0082,     -0.0063,      0.0127,     -0.0166,\n",
      "             0.0048,      0.0009,     -0.0117,      0.0113,     -0.0066,\n",
      "             0.0034,      0.0121,     -0.0009,     -0.0024,     -0.0175,\n",
      "             0.0008,     -0.0176,     -0.0141,     -0.0167,     -0.0053,\n",
      "             0.0064,      0.0170,      0.0168,     -0.0122,     -0.0153,\n",
      "            -0.0032,     -0.0165,      0.0146,      0.0057,      0.0176,\n",
      "            -0.0090,      0.0164,      0.0079,      0.0136,      0.0126,\n",
      "            -0.0084,      0.0090,      0.0016,      0.0100,     -0.0138,\n",
      "             0.0101,     -0.0049,      0.0044,      0.0062,     -0.0088,\n",
      "            -0.0176,      0.0071,     -0.0047,      0.0098,      0.0058,\n",
      "            -0.0135,      0.0065,     -0.0108,      0.0064,     -0.0171,\n",
      "             0.0145,      0.0094,     -0.0066,     -0.0139,     -0.0015,\n",
      "             0.0024,     -0.0141,      0.0073,     -0.0132,      0.0025,\n",
      "             0.0136,      0.0060,     -0.0081,     -0.0139,     -0.0083,\n",
      "            -0.0131,     -0.0148,      0.0029,     -0.0080,      0.0030,\n",
      "            -0.0096,      0.0160,     -0.0058,      0.0026,      0.0058,\n",
      "             0.0154,      0.0000,      0.0026,      0.0145,      0.0077,\n",
      "            -0.0017,     -0.0143,      0.0148,     -0.0065,      0.0066,\n",
      "            -0.0078,      0.0069,      0.0165,     -0.0057,      0.0130,\n",
      "            -0.0079,      0.0045,      0.0012,     -0.0111,      0.0069,\n",
      "             0.0136,      0.0111,      0.0023,      0.0174,     -0.0002,\n",
      "            -0.0048,     -0.0041,     -0.0076,      0.0093,      0.0019,\n",
      "             0.0176,      0.0138,      0.0030,      0.0071,     -0.0158,\n",
      "             0.0098,     -0.0112,     -0.0112,     -0.0042,     -0.0002,\n",
      "             0.0034,      0.0147,     -0.0070,      0.0099,      0.0029,\n",
      "            -0.0038,     -0.0121,      0.0105,      0.0082,      0.0007,\n",
      "            -0.0154,     -0.0002,      0.0018,     -0.0141,     -0.0035,\n",
      "            -0.0083,      0.0127,      0.0095,     -0.0172,     -0.0144,\n",
      "             0.0121,      0.0165,     -0.0124,      0.0113,      0.0144,\n",
      "            -0.0020,      0.0075,      0.0155,     -0.0061,      0.0016,\n",
      "             0.0107,     -0.0113,      0.0076,      0.0049,      0.0058,\n",
      "            -0.0087,     -0.0172,      0.0003,      0.0005,      0.0098,\n",
      "             0.0052,      0.0065,     -0.0102,     -0.0128,     -0.0134,\n",
      "            -0.0151,      0.0009,      0.0142,     -0.0002,     -0.0036,\n",
      "            -0.0059,     -0.0173,      0.0103,      0.0143,     -0.0145,\n",
      "            -0.0159,      0.0114,     -0.0101,     -0.0174,     -0.0009,\n",
      "            -0.0001,     -0.0138,     -0.0157,      0.0042,     -0.0180,\n",
      "            -0.0128,      0.0093,      0.0008,     -0.0055,     -0.0005,\n",
      "             0.0047,     -0.0006,     -0.0135,     -0.0115,     -0.0057,\n",
      "            -0.0123,     -0.0148,     -0.0153,     -0.0059,      0.0122,\n",
      "             0.0023,     -0.0090,     -0.0025,      0.0131,      0.0145,\n",
      "             0.0020,      0.0068,      0.0105,     -0.0103,     -0.0033,\n",
      "             0.0149,     -0.0053,      0.0014,     -0.0088,     -0.0134,\n",
      "            -0.0094,      0.0061,     -0.0043,      0.0011,      0.0174,\n",
      "            -0.0019,      0.0082,      0.0063,     -0.0126,     -0.0016,\n",
      "             0.0101,     -0.0145,      0.0105,      0.0161,     -0.0119,\n",
      "            -0.0000,     -0.0034,     -0.0084,     -0.0093,      0.0068,\n",
      "            -0.0145,      0.0087,     -0.0042,      0.0022,     -0.0104,\n",
      "            -0.0100,     -0.0138,     -0.0073,     -0.0046,      0.0169,\n",
      "            -0.0096,      0.0130,      0.0055,     -0.0037,     -0.0174,\n",
      "            -0.0083,     -0.0048,     -0.0179,      0.0005,      0.0043,\n",
      "             0.0118,     -0.0066,     -0.0164,      0.0059,     -0.0074,\n",
      "            -0.0149,     -0.0015,     -0.0089,      0.0164,      0.0104,\n",
      "             0.0147,     -0.0114,     -0.0018,      0.0177,      0.0122,\n",
      "            -0.0159,      0.0140,     -0.0038,      0.0105,     -0.0046,\n",
      "             0.0085,      0.0036,      0.0105,      0.0038,     -0.0151,\n",
      "             0.0003,      0.0111,      0.0093,     -0.0015,      0.0153,\n",
      "            -0.0176,      0.0161,      0.0059,     -0.0049,     -0.0024,\n",
      "            -0.0156,     -0.0128,      0.0144,     -0.0134,     -0.0045,\n",
      "            -0.0037,      0.0125,     -0.0004,      0.0066,      0.0024,\n",
      "            -0.0086,     -0.0124,     -0.0073,     -0.0056,     -0.0087,\n",
      "            -0.0033,     -0.0113,     -0.0146,     -0.0013,     -0.0044,\n",
      "             0.0084,     -0.0160,      0.0161,     -0.0167,      0.0179,\n",
      "             0.0039,      0.0088,      0.0005,     -0.0119,     -0.0120,\n",
      "            -0.0171,     -0.0163,      0.0025,     -0.0039,     -0.0076,\n",
      "             0.0118,      0.0014,      0.0124,      0.0004,     -0.0047,\n",
      "             0.0108,      0.0031,      0.0162,      0.0055,      0.0034,\n",
      "             0.0099,      0.0157,      0.0099,     -0.0171,     -0.0026,\n",
      "             0.0044,      0.0090,     -0.0159,     -0.0046,     -0.0024,\n",
      "            -0.0080,     -0.0072,     -0.0118,     -0.0043,      0.0083,\n",
      "             0.0169,     -0.0009,     -0.0098,     -0.0129,     -0.0052,\n",
      "            -0.0158,      0.0151,     -0.0019,     -0.0110,     -0.0111,\n",
      "             0.0120,      0.0122,     -0.0067,     -0.0115,      0.0107,\n",
      "            -0.0144,     -0.0039,      0.0012,      0.0120,     -0.0075,\n",
      "             0.0011,     -0.0017,      0.0169,      0.0107,     -0.0104,\n",
      "            -0.0063,      0.0010,      0.0046,     -0.0090,      0.0001,\n",
      "            -0.0178,      0.0053,     -0.0041,      0.0030,      0.0044,\n",
      "            -0.0172,     -0.0136,      0.0110,     -0.0029,      0.0042,\n",
      "            -0.0034,      0.0126,     -0.0082,     -0.0022,     -0.0107,\n",
      "            -0.0106,     -0.0145,     -0.0113,      0.0119,     -0.0002,\n",
      "            -0.0175,     -0.0031,     -0.0083,      0.0169,     -0.0142,\n",
      "            -0.0109,      0.0058,      0.0176,     -0.0006,     -0.0116,\n",
      "            -0.0151,      0.0095,      0.0169,     -0.0124,     -0.0076,\n",
      "             0.0045,      0.0119,      0.0153,     -0.0016,      0.0053,\n",
      "             0.0169,      0.0161,      0.0098,     -0.0143,      0.0039,\n",
      "            -0.0164,     -0.0028,     -0.0101,     -0.0105,      0.0034,\n",
      "            -0.0164,      0.0127,      0.0128,      0.0033,      0.0016,\n",
      "            -0.0074,     -0.0067,     -0.0137,     -0.0069,      0.0102,\n",
      "             0.0051,     -0.0176,      0.0012,     -0.0032,      0.0001,\n",
      "            -0.0059,     -0.0064,     -0.0153,      0.0163,      0.0092,\n",
      "             0.0159,     -0.0053,     -0.0131,     -0.0026,      0.0011,\n",
      "             0.0005,     -0.0074,     -0.0133,      0.0178,      0.0136,\n",
      "            -0.0064,      0.0061,      0.0135,     -0.0134,      0.0084,\n",
      "            -0.0052,      0.0059,     -0.0178,      0.0013,      0.0142,\n",
      "            -0.0117,     -0.0047,     -0.0100], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0116, -0.0157, -0.0095,  ..., -0.0280, -0.0025,  0.0183],\n",
      "        [ 0.0212,  0.0013,  0.0327,  ...,  0.0029,  0.0065, -0.0024],\n",
      "        [ 0.0320,  0.0174, -0.0340,  ..., -0.0357,  0.0311, -0.0068],\n",
      "        ...,\n",
      "        [-0.0063, -0.0040,  0.0024,  ..., -0.0034, -0.0159, -0.0242],\n",
      "        [ 0.0334, -0.0177, -0.0217,  ...,  0.0300,  0.0246, -0.0051],\n",
      "        [-0.0011, -0.0162, -0.0300,  ...,  0.0243,  0.0244, -0.0270]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[    -0.0288,     -0.0241,      0.0258,  ...,      0.0114,\n",
      "             -0.0263,     -0.0218],\n",
      "        [    -0.0182,      0.0022,      0.0244,  ...,     -0.0000,\n",
      "             -0.0225,     -0.0132],\n",
      "        [     0.0035,     -0.0003,     -0.0249,  ...,      0.0287,\n",
      "             -0.0292,      0.0133],\n",
      "        ...,\n",
      "        [    -0.0128,     -0.0115,     -0.0055,  ...,     -0.0282,\n",
      "              0.0340,     -0.0034],\n",
      "        [    -0.0105,      0.0206,     -0.0219,  ...,      0.0169,\n",
      "             -0.0128,      0.0079],\n",
      "        [    -0.0230,     -0.0152,     -0.0331,  ...,     -0.0163,\n",
      "              0.0337,      0.0178]], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0069,  0.0185, -0.0098,  ..., -0.0338, -0.0125,  0.0194],\n",
      "        [-0.0239,  0.0297,  0.0121,  ...,  0.0124, -0.0269,  0.0093],\n",
      "        [-0.0117, -0.0114, -0.0178,  ..., -0.0314, -0.0129, -0.0256],\n",
      "        ...,\n",
      "        [-0.0052, -0.0310,  0.0321,  ..., -0.0130,  0.0088, -0.0142],\n",
      "        [-0.0160, -0.0002,  0.0204,  ..., -0.0048,  0.0298, -0.0132],\n",
      "        [-0.0293,  0.0145,  0.0075,  ...,  0.0281, -0.0204, -0.0283]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0222, -0.0053,  0.0121,  ...,  0.0265, -0.0291,  0.0282],\n",
      "        [-0.0338,  0.0180,  0.0298,  ...,  0.0085, -0.0220,  0.0060],\n",
      "        [ 0.0103, -0.0150,  0.0290,  ...,  0.0069,  0.0183,  0.0274],\n",
      "        ...,\n",
      "        [-0.0084, -0.0072, -0.0220,  ..., -0.0008, -0.0077,  0.0300],\n",
      "        [ 0.0088, -0.0111, -0.0186,  ...,  0.0152,  0.0291,  0.0343],\n",
      "        [-0.0344, -0.0312,  0.0328,  ..., -0.0164, -0.0269, -0.0010]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([     0.0103,      0.0032,      0.0343,     -0.0252,      0.0047,\n",
      "             0.0328,      0.0155,      0.0113,     -0.0143,      0.0259,\n",
      "            -0.0259,     -0.0353,     -0.0168,      0.0190,     -0.0361,\n",
      "             0.0033,      0.0277,     -0.0183,      0.0301,     -0.0332,\n",
      "            -0.0205,     -0.0251,      0.0088,     -0.0169,     -0.0114,\n",
      "             0.0121,     -0.0073,      0.0344,     -0.0089,     -0.0291,\n",
      "            -0.0182,     -0.0106,      0.0283,      0.0032,     -0.0298,\n",
      "            -0.0237,      0.0202,     -0.0243,     -0.0169,     -0.0294,\n",
      "             0.0043,      0.0045,     -0.0228,     -0.0030,      0.0160,\n",
      "             0.0340,      0.0162,     -0.0186,      0.0251,     -0.0188,\n",
      "             0.0281,     -0.0106,     -0.0122,     -0.0314,      0.0011,\n",
      "             0.0298,      0.0331,      0.0251,     -0.0081,      0.0327,\n",
      "            -0.0288,     -0.0177,     -0.0243,     -0.0200,     -0.0053,\n",
      "             0.0286,      0.0294,      0.0351,     -0.0265,     -0.0161,\n",
      "             0.0073,     -0.0340,     -0.0107,      0.0217,      0.0074,\n",
      "             0.0084,      0.0333,      0.0319,     -0.0261,      0.0306,\n",
      "            -0.0023,      0.0356,      0.0324,      0.0039,     -0.0008,\n",
      "            -0.0084,     -0.0344,      0.0027,     -0.0218,      0.0304,\n",
      "            -0.0043,     -0.0254,     -0.0208,     -0.0224,     -0.0341,\n",
      "             0.0004,      0.0302,      0.0179,      0.0238,      0.0169,\n",
      "            -0.0096,      0.0128,      0.0182,     -0.0320,      0.0326,\n",
      "            -0.0162,      0.0050,     -0.0024,      0.0249,     -0.0328,\n",
      "             0.0119,      0.0333,      0.0180,     -0.0040,     -0.0265,\n",
      "             0.0246,     -0.0136,      0.0191,      0.0040,     -0.0316,\n",
      "            -0.0330,     -0.0084,      0.0119,      0.0010,      0.0354,\n",
      "             0.0074,     -0.0118,     -0.0286,      0.0011,      0.0100,\n",
      "            -0.0248,     -0.0223,      0.0261,      0.0360,     -0.0335,\n",
      "            -0.0303,     -0.0279,      0.0082,      0.0220,     -0.0163,\n",
      "             0.0238,      0.0212,      0.0103,     -0.0347,     -0.0015,\n",
      "            -0.0086,      0.0093,     -0.0289,     -0.0104,     -0.0334,\n",
      "             0.0106,     -0.0355,     -0.0227,     -0.0224,     -0.0242,\n",
      "            -0.0207,     -0.0216,     -0.0091,     -0.0007,      0.0052,\n",
      "            -0.0339,      0.0182,      0.0066,      0.0339,      0.0229,\n",
      "             0.0233,      0.0342,     -0.0282,     -0.0074,      0.0310,\n",
      "             0.0166,      0.0001,     -0.0233,     -0.0189,     -0.0323,\n",
      "            -0.0230,      0.0114,      0.0231,      0.0149,      0.0360,\n",
      "             0.0191,      0.0141,      0.0344,      0.0256,     -0.0277,\n",
      "            -0.0318,      0.0302,     -0.0041,     -0.0251,      0.0341,\n",
      "            -0.0255,     -0.0070,      0.0173,      0.0222,      0.0041,\n",
      "            -0.0165,      0.0135,      0.0272,     -0.0241,     -0.0320,\n",
      "             0.0242,      0.0137,     -0.0227,     -0.0140,      0.0171,\n",
      "             0.0215,     -0.0295,     -0.0086,      0.0063,     -0.0263,\n",
      "             0.0270,     -0.0059,     -0.0047,     -0.0331,      0.0277,\n",
      "            -0.0212,      0.0097,     -0.0311,      0.0115,      0.0226,\n",
      "             0.0087,     -0.0173,      0.0170,     -0.0219,      0.0264,\n",
      "             0.0339,     -0.0029,      0.0174,     -0.0132,      0.0265,\n",
      "             0.0334,      0.0117,      0.0161,      0.0248,     -0.0182,\n",
      "             0.0358,      0.0150,     -0.0064,     -0.0038,      0.0331,\n",
      "            -0.0078,      0.0249,     -0.0268,      0.0255,      0.0084,\n",
      "             0.0175,     -0.0029,      0.0141,      0.0317,      0.0025,\n",
      "            -0.0253,      0.0304,     -0.0129,      0.0189,      0.0202,\n",
      "             0.0090,     -0.0189,      0.0293,     -0.0130,     -0.0130,\n",
      "             0.0249,      0.0230,      0.0236,      0.0220,      0.0126,\n",
      "            -0.0011,      0.0098,     -0.0105,     -0.0017,      0.0355,\n",
      "             0.0181,     -0.0231,     -0.0101,      0.0289,      0.0310,\n",
      "             0.0286,     -0.0066,      0.0137,     -0.0301,      0.0265,\n",
      "             0.0066,     -0.0091,      0.0212,     -0.0354,     -0.0300,\n",
      "            -0.0167,      0.0340,      0.0177,      0.0102,     -0.0354,\n",
      "            -0.0308,      0.0337,      0.0346,     -0.0331,      0.0295,\n",
      "             0.0257,      0.0154,      0.0131,     -0.0110,      0.0163,\n",
      "            -0.0222,     -0.0040,      0.0146,      0.0302,      0.0068,\n",
      "            -0.0279,      0.0325,     -0.0243,     -0.0247,      0.0036,\n",
      "             0.0049,     -0.0213,     -0.0225,     -0.0048,     -0.0309,\n",
      "             0.0189,      0.0359,     -0.0223,      0.0006,      0.0206,\n",
      "             0.0292,     -0.0064,      0.0200,     -0.0093,     -0.0321,\n",
      "             0.0029,     -0.0294,     -0.0102,     -0.0010,     -0.0080,\n",
      "            -0.0207,      0.0253,     -0.0250,      0.0008,     -0.0131,\n",
      "             0.0021,      0.0124,      0.0251,     -0.0254,      0.0280,\n",
      "            -0.0120,     -0.0081,      0.0238,     -0.0223,      0.0353,\n",
      "            -0.0305,      0.0266,      0.0070,     -0.0041,      0.0155,\n",
      "             0.0072,     -0.0049,     -0.0133,     -0.0174,      0.0321,\n",
      "            -0.0094,      0.0337,     -0.0145,      0.0075,     -0.0181,\n",
      "             0.0306,     -0.0024,     -0.0099,     -0.0176,      0.0092,\n",
      "            -0.0214,      0.0223,     -0.0294,     -0.0278,      0.0268,\n",
      "             0.0240,     -0.0307,     -0.0054,     -0.0004,      0.0245,\n",
      "             0.0192,      0.0326,     -0.0121,     -0.0172,      0.0092,\n",
      "            -0.0292,     -0.0046,      0.0166,     -0.0315,      0.0126,\n",
      "            -0.0096,     -0.0033,     -0.0200,      0.0045,     -0.0143,\n",
      "             0.0255,      0.0013,      0.0195,      0.0195,      0.0029,\n",
      "            -0.0179,      0.0275,      0.0293,      0.0040,     -0.0167,\n",
      "            -0.0018,      0.0108,      0.0212,     -0.0240,      0.0196,\n",
      "             0.0200,     -0.0278,     -0.0321,      0.0281,     -0.0159,\n",
      "             0.0291,     -0.0178,     -0.0242,      0.0124,      0.0310,\n",
      "            -0.0157,      0.0115,      0.0319,     -0.0239,     -0.0255,\n",
      "            -0.0196,     -0.0313,      0.0323,      0.0129,     -0.0350,\n",
      "            -0.0173,     -0.0304,      0.0212,      0.0154,      0.0138,\n",
      "            -0.0122,      0.0119,     -0.0003,      0.0219,     -0.0037,\n",
      "            -0.0281,     -0.0290,      0.0192,      0.0311,      0.0356,\n",
      "            -0.0351,      0.0225,      0.0306,      0.0266,      0.0155,\n",
      "            -0.0355,      0.0034,     -0.0283,     -0.0219,      0.0360,\n",
      "            -0.0056,     -0.0140,     -0.0219,      0.0191,     -0.0272,\n",
      "            -0.0306,     -0.0046,     -0.0154,     -0.0149,     -0.0167,\n",
      "            -0.0003,     -0.0100,      0.0014,     -0.0079,     -0.0041,\n",
      "            -0.0037,      0.0100,      0.0291,     -0.0320,     -0.0161,\n",
      "             0.0328,     -0.0115,     -0.0260,      0.0162,     -0.0241,\n",
      "             0.0342,      0.0027,     -0.0285,     -0.0038,     -0.0123,\n",
      "            -0.0030,     -0.0153,     -0.0007,     -0.0076,      0.0245,\n",
      "             0.0159,      0.0259,      0.0057,      0.0215,      0.0219,\n",
      "             0.0310,     -0.0024,      0.0153,      0.0160,      0.0061,\n",
      "             0.0136,     -0.0044,     -0.0046,      0.0275,      0.0336,\n",
      "            -0.0020,      0.0062,     -0.0039,      0.0290,     -0.0187,\n",
      "            -0.0067,     -0.0347,     -0.0116,      0.0042,      0.0296,\n",
      "             0.0036,      0.0082,      0.0131,      0.0180,     -0.0274,\n",
      "            -0.0104,      0.0224,      0.0113,     -0.0006,     -0.0257,\n",
      "             0.0017,     -0.0162,      0.0245,     -0.0261,     -0.0007,\n",
      "             0.0010,     -0.0309,     -0.0316,      0.0164,     -0.0035,\n",
      "            -0.0080,      0.0356,     -0.0341,     -0.0064,     -0.0225,\n",
      "            -0.0073,      0.0336,     -0.0256,     -0.0171,      0.0044,\n",
      "             0.0281,      0.0056,      0.0025,      0.0103,      0.0308,\n",
      "            -0.0071,      0.0252,      0.0091,     -0.0256,     -0.0232,\n",
      "            -0.0346,      0.0020,     -0.0000,      0.0214,     -0.0142,\n",
      "             0.0090,      0.0050,     -0.0261,      0.0076,     -0.0240,\n",
      "             0.0056,     -0.0074,      0.0075,     -0.0151,      0.0118,\n",
      "             0.0158,     -0.0108,     -0.0148,     -0.0254,      0.0175,\n",
      "             0.0097,     -0.0179,      0.0325,      0.0346,      0.0160,\n",
      "            -0.0127,     -0.0334,      0.0058,      0.0225,     -0.0306,\n",
      "             0.0269,     -0.0315,     -0.0012,     -0.0176,      0.0294,\n",
      "             0.0179,     -0.0138,     -0.0308,     -0.0233,      0.0261,\n",
      "            -0.0055,      0.0274,      0.0251,     -0.0280,     -0.0013,\n",
      "            -0.0010,      0.0243,      0.0085,      0.0305,     -0.0160,\n",
      "            -0.0134,      0.0335,     -0.0158,     -0.0284,     -0.0155,\n",
      "             0.0199,      0.0218,      0.0347,      0.0179,     -0.0146,\n",
      "            -0.0321,     -0.0192,     -0.0111,      0.0161,     -0.0051,\n",
      "            -0.0021,     -0.0015,      0.0063,      0.0127,     -0.0200,\n",
      "             0.0158,      0.0176,      0.0118,      0.0093,      0.0116,\n",
      "             0.0148,      0.0209,     -0.0123,     -0.0134,     -0.0288,\n",
      "             0.0250,      0.0065,      0.0219,     -0.0254,      0.0074,\n",
      "             0.0244,      0.0015,      0.0092,      0.0174,      0.0150,\n",
      "             0.0028,     -0.0098,      0.0156,      0.0159,      0.0337,\n",
      "             0.0056,     -0.0049,      0.0014,      0.0001,     -0.0281,\n",
      "             0.0079,     -0.0135,      0.0276,     -0.0230,      0.0186,\n",
      "             0.0122,      0.0144,     -0.0280,      0.0238,     -0.0232,\n",
      "            -0.0194,      0.0352,     -0.0290,      0.0106,      0.0064,\n",
      "            -0.0327,     -0.0124,      0.0226,     -0.0245,      0.0062,\n",
      "             0.0253,     -0.0305,      0.0319,     -0.0203,      0.0023,\n",
      "            -0.0080,     -0.0029,      0.0173,     -0.0058,      0.0236,\n",
      "             0.0242,      0.0082,     -0.0099,     -0.0129,      0.0249,\n",
      "             0.0149,     -0.0178,      0.0298,      0.0129,      0.0132,\n",
      "            -0.0302,      0.0294,     -0.0340,      0.0078,      0.0080,\n",
      "             0.0015,      0.0116,     -0.0350,      0.0335,     -0.0222,\n",
      "             0.0137,     -0.0103,     -0.0098,     -0.0229,      0.0258,\n",
      "             0.0353,     -0.0277,      0.0079,     -0.0041,      0.0181,\n",
      "             0.0183,     -0.0166,      0.0285,      0.0197,      0.0180,\n",
      "             0.0171,     -0.0334,      0.0287,     -0.0071,      0.0258,\n",
      "             0.0120,     -0.0354,      0.0094,     -0.0021,     -0.0343,\n",
      "             0.0247,      0.0190,     -0.0271,     -0.0359,     -0.0181,\n",
      "            -0.0137,     -0.0041,     -0.0077,      0.0110,     -0.0102,\n",
      "            -0.0314,     -0.0239,     -0.0296,     -0.0323,      0.0028,\n",
      "            -0.0231,     -0.0004,      0.0022,     -0.0047,      0.0148,\n",
      "             0.0019,      0.0107,     -0.0115,      0.0108,     -0.0319,\n",
      "             0.0267,      0.0059,      0.0138,     -0.0291,      0.0203,\n",
      "            -0.0273,     -0.0318,      0.0233,     -0.0265,      0.0326,\n",
      "            -0.0031,      0.0159,     -0.0216,      0.0359,     -0.0022,\n",
      "             0.0277,      0.0145,      0.0356], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0263, -0.0085,  0.0156,  ..., -0.0102,  0.0098,  0.0053],\n",
      "        [-0.0331, -0.0311, -0.0302,  ...,  0.0282, -0.0352, -0.0304],\n",
      "        [-0.0309, -0.0252, -0.0187,  ..., -0.0050,  0.0203,  0.0302],\n",
      "        ...,\n",
      "        [-0.0118,  0.0278, -0.0050,  ...,  0.0131,  0.0238,  0.0254],\n",
      "        [-0.0358, -0.0178,  0.0227,  ...,  0.0122,  0.0353,  0.0335],\n",
      "        [-0.0094, -0.0200, -0.0057,  ...,  0.0249,  0.0136,  0.0250]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0134, -0.0050,  0.0184,  ...,  0.0262,  0.0082, -0.0232],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0159,  0.0147,  0.0165,  ..., -0.0133, -0.0051,  0.0016],\n",
      "        [ 0.0150, -0.0113,  0.0153,  ...,  0.0161,  0.0108,  0.0079],\n",
      "        [-0.0134, -0.0036,  0.0033,  ...,  0.0097,  0.0169, -0.0057],\n",
      "        ...,\n",
      "        [-0.0177,  0.0007, -0.0178,  ..., -0.0040,  0.0030, -0.0156],\n",
      "        [-0.0026, -0.0098,  0.0027,  ..., -0.0051, -0.0070, -0.0147],\n",
      "        [-0.0102, -0.0044,  0.0093,  ...,  0.0076,  0.0115,  0.0051]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([     0.0040,     -0.0018,      0.0062,      0.0004,      0.0039,\n",
      "             0.0179,     -0.0069,      0.0093,     -0.0133,      0.0080,\n",
      "             0.0088,      0.0147,      0.0007,      0.0116,      0.0112,\n",
      "            -0.0026,     -0.0072,      0.0005,      0.0107,     -0.0025,\n",
      "            -0.0061,     -0.0057,     -0.0139,      0.0147,      0.0026,\n",
      "             0.0170,     -0.0125,      0.0067,     -0.0092,     -0.0016,\n",
      "            -0.0092,     -0.0001,      0.0051,      0.0075,      0.0090,\n",
      "            -0.0083,      0.0068,     -0.0107,     -0.0039,      0.0137,\n",
      "            -0.0090,     -0.0079,      0.0050,      0.0076,     -0.0020,\n",
      "            -0.0073,      0.0084,     -0.0060,      0.0074,     -0.0024,\n",
      "            -0.0098,      0.0164,     -0.0000,      0.0124,     -0.0155,\n",
      "             0.0062,     -0.0169,      0.0118,     -0.0128,      0.0006,\n",
      "             0.0080,     -0.0147,     -0.0061,      0.0129,      0.0052,\n",
      "             0.0115,     -0.0124,     -0.0067,     -0.0098,     -0.0110,\n",
      "            -0.0150,      0.0161,      0.0102,      0.0177,      0.0044,\n",
      "            -0.0069,     -0.0161,      0.0125,      0.0077,      0.0013,\n",
      "            -0.0134,     -0.0083,      0.0167,      0.0005,     -0.0013,\n",
      "            -0.0068,      0.0081,      0.0122,      0.0129,      0.0003,\n",
      "            -0.0047,      0.0130,      0.0068,      0.0118,      0.0065,\n",
      "             0.0089,      0.0161,      0.0152,     -0.0163,      0.0049,\n",
      "             0.0179,      0.0171,     -0.0088,     -0.0081,      0.0041,\n",
      "            -0.0058,     -0.0010,     -0.0126,     -0.0133,     -0.0001,\n",
      "            -0.0131,      0.0060,      0.0131,     -0.0024,      0.0176,\n",
      "             0.0075,     -0.0108,     -0.0057,     -0.0146,      0.0064,\n",
      "             0.0089,     -0.0049,     -0.0158,      0.0012,      0.0105,\n",
      "            -0.0089,     -0.0101,     -0.0167,      0.0142,     -0.0145,\n",
      "            -0.0148,     -0.0016,      0.0112,      0.0133,     -0.0000,\n",
      "             0.0160,      0.0141,      0.0167,      0.0069,      0.0013,\n",
      "            -0.0064,     -0.0101,     -0.0049,     -0.0143,      0.0131,\n",
      "             0.0068,     -0.0119,     -0.0083,      0.0105,      0.0163,\n",
      "             0.0165,     -0.0098,      0.0011,      0.0038,     -0.0087,\n",
      "             0.0024,      0.0024,      0.0005,     -0.0038,     -0.0043,\n",
      "             0.0051,     -0.0164,     -0.0010,     -0.0179,      0.0087,\n",
      "             0.0158,     -0.0162,     -0.0091,     -0.0074,     -0.0112,\n",
      "            -0.0154,     -0.0154,     -0.0139,     -0.0093,      0.0034,\n",
      "             0.0121,     -0.0106,      0.0149,      0.0010,     -0.0067,\n",
      "            -0.0099,      0.0039,      0.0171,     -0.0120,     -0.0149,\n",
      "             0.0021,     -0.0101,      0.0039,      0.0003,      0.0150,\n",
      "            -0.0112,     -0.0112,      0.0101,      0.0035,      0.0002,\n",
      "             0.0085,      0.0104,      0.0116,      0.0097,     -0.0045,\n",
      "             0.0025,     -0.0084,      0.0143,      0.0125,     -0.0142,\n",
      "            -0.0176,      0.0129,     -0.0126,      0.0131,      0.0050,\n",
      "             0.0101,     -0.0017,      0.0074,     -0.0153,     -0.0087,\n",
      "             0.0047,      0.0163,      0.0109,     -0.0146,     -0.0112,\n",
      "             0.0054,     -0.0163,     -0.0073,     -0.0074,     -0.0092,\n",
      "            -0.0073,      0.0044,     -0.0118,     -0.0019,     -0.0120,\n",
      "             0.0145,      0.0034,      0.0037,      0.0175,      0.0080,\n",
      "            -0.0111,     -0.0166,      0.0033,     -0.0158,      0.0175,\n",
      "            -0.0051,     -0.0055,     -0.0174,      0.0058,     -0.0164,\n",
      "             0.0152,     -0.0144,     -0.0168,     -0.0138,     -0.0112,\n",
      "             0.0085,      0.0105,     -0.0036,     -0.0083,     -0.0172,\n",
      "             0.0164,      0.0016,      0.0119,     -0.0158,      0.0112,\n",
      "            -0.0170,     -0.0124,      0.0097,      0.0022,     -0.0097,\n",
      "            -0.0035,      0.0179,     -0.0113,      0.0075,     -0.0152,\n",
      "             0.0180,     -0.0130,      0.0072,      0.0130,     -0.0177,\n",
      "             0.0137,      0.0130,     -0.0176,      0.0086,      0.0080,\n",
      "             0.0172,     -0.0125,     -0.0013,      0.0128,     -0.0145,\n",
      "             0.0165,     -0.0115,     -0.0165,      0.0006,      0.0180,\n",
      "             0.0036,     -0.0080,     -0.0026,      0.0133,      0.0026,\n",
      "             0.0088,      0.0151,      0.0131,      0.0040,     -0.0100,\n",
      "            -0.0130,      0.0154,     -0.0152,      0.0100,      0.0122,\n",
      "             0.0079,      0.0134,      0.0141,      0.0116,      0.0134,\n",
      "            -0.0146,      0.0135,     -0.0143,     -0.0098,     -0.0177,\n",
      "             0.0171,     -0.0083,     -0.0099,      0.0178,     -0.0093,\n",
      "            -0.0105,      0.0019,     -0.0001,      0.0128,      0.0179,\n",
      "            -0.0105,     -0.0047,     -0.0175,     -0.0008,     -0.0085,\n",
      "            -0.0038,     -0.0027,      0.0076,      0.0028,      0.0138,\n",
      "             0.0063,     -0.0100,      0.0005,      0.0050,     -0.0179,\n",
      "            -0.0161,     -0.0165,     -0.0014,     -0.0029,      0.0078,\n",
      "            -0.0146,      0.0058,     -0.0039,     -0.0080,     -0.0130,\n",
      "             0.0093,     -0.0062,      0.0072,      0.0169,     -0.0077,\n",
      "             0.0127,     -0.0009,     -0.0166,      0.0056,      0.0018,\n",
      "            -0.0019,     -0.0032,     -0.0153,      0.0053,      0.0087,\n",
      "            -0.0013,      0.0057,      0.0155,     -0.0041,      0.0046,\n",
      "            -0.0100,      0.0017,     -0.0055,     -0.0146,     -0.0105,\n",
      "            -0.0067,      0.0026,     -0.0150,     -0.0088,     -0.0175,\n",
      "             0.0022,      0.0044,     -0.0147,      0.0074,     -0.0010,\n",
      "             0.0039,     -0.0090,      0.0137,      0.0028,     -0.0139,\n",
      "            -0.0149,      0.0180,     -0.0032,     -0.0078,     -0.0002,\n",
      "            -0.0098,      0.0055,      0.0057,     -0.0039,     -0.0055,\n",
      "            -0.0009,     -0.0157,     -0.0057,     -0.0001,     -0.0149,\n",
      "             0.0171,      0.0080,      0.0007,      0.0032,      0.0142,\n",
      "             0.0012,      0.0008,      0.0152,      0.0072,      0.0064,\n",
      "             0.0131,      0.0034,      0.0165,      0.0133,      0.0155,\n",
      "            -0.0079,      0.0084,     -0.0038,      0.0156,     -0.0114,\n",
      "             0.0160,     -0.0097,      0.0060,     -0.0094,     -0.0036,\n",
      "             0.0122,     -0.0173,     -0.0112,      0.0127,     -0.0061,\n",
      "            -0.0126,     -0.0024,     -0.0018,      0.0111,      0.0104,\n",
      "             0.0109,      0.0031,      0.0056,      0.0149,      0.0095,\n",
      "             0.0163,     -0.0036,     -0.0104,     -0.0007,      0.0075,\n",
      "             0.0180,     -0.0120,     -0.0101,      0.0161,      0.0045,\n",
      "             0.0035,     -0.0068,     -0.0161,      0.0079,      0.0091,\n",
      "            -0.0008,     -0.0138,     -0.0145,     -0.0029,     -0.0172,\n",
      "            -0.0137,     -0.0144,     -0.0003,      0.0105,     -0.0149,\n",
      "            -0.0179,     -0.0094,     -0.0101,      0.0099,     -0.0094,\n",
      "             0.0089,     -0.0162,      0.0037,     -0.0158,     -0.0024,\n",
      "             0.0067,      0.0153,      0.0180,      0.0091,      0.0062,\n",
      "            -0.0092,      0.0062,     -0.0174,     -0.0043,     -0.0004,\n",
      "             0.0175,      0.0120,     -0.0068,      0.0140,      0.0002,\n",
      "             0.0050,     -0.0071,     -0.0116,      0.0044,     -0.0029,\n",
      "             0.0112,     -0.0097,      0.0078,      0.0063,     -0.0151,\n",
      "            -0.0004,     -0.0100,      0.0093,     -0.0029,      0.0047,\n",
      "             0.0174,      0.0083,      0.0094,     -0.0167,     -0.0050,\n",
      "            -0.0084,     -0.0041,     -0.0004,     -0.0147,     -0.0066,\n",
      "            -0.0063,      0.0141,     -0.0053,      0.0170,     -0.0120,\n",
      "            -0.0056,     -0.0130,     -0.0044,     -0.0161,      0.0138,\n",
      "            -0.0070,      0.0040,      0.0040,      0.0099,      0.0069,\n",
      "             0.0136,      0.0050,     -0.0002,     -0.0119,     -0.0010,\n",
      "             0.0146,     -0.0051,     -0.0172,     -0.0009,     -0.0059,\n",
      "            -0.0032,     -0.0055,     -0.0060,     -0.0057,     -0.0027,\n",
      "             0.0149,     -0.0020,     -0.0009,      0.0055,      0.0047,\n",
      "             0.0024,      0.0041,     -0.0152,      0.0032,      0.0028,\n",
      "             0.0147,      0.0172,      0.0164,     -0.0166,      0.0144,\n",
      "             0.0163,     -0.0070,      0.0070,      0.0080,      0.0168,\n",
      "             0.0082,      0.0095,     -0.0133,     -0.0099,      0.0036,\n",
      "            -0.0170,      0.0047,      0.0127,      0.0153,      0.0017,\n",
      "             0.0033,     -0.0071,      0.0109,      0.0066,     -0.0151,\n",
      "             0.0053,      0.0180,      0.0075,      0.0174,     -0.0140,\n",
      "            -0.0136,      0.0161,      0.0001,     -0.0151,     -0.0010,\n",
      "            -0.0086,     -0.0109,      0.0056,     -0.0010,      0.0164,\n",
      "             0.0087,      0.0073,      0.0160,     -0.0123,     -0.0085,\n",
      "             0.0051,      0.0037,      0.0084,      0.0081,     -0.0037,\n",
      "            -0.0086,      0.0094,      0.0011,      0.0111,      0.0145,\n",
      "             0.0098,      0.0036,     -0.0129,     -0.0024,      0.0121,\n",
      "            -0.0028,     -0.0157,      0.0079,      0.0051,      0.0097,\n",
      "             0.0069,     -0.0013,     -0.0024,      0.0136,     -0.0046,\n",
      "             0.0019,      0.0074,      0.0158,     -0.0121,     -0.0080,\n",
      "             0.0083,      0.0080,      0.0035,     -0.0049,     -0.0100,\n",
      "            -0.0151,      0.0144,     -0.0111,      0.0000,     -0.0048,\n",
      "            -0.0108,     -0.0157,      0.0133,     -0.0087,      0.0055,\n",
      "             0.0092,      0.0162,     -0.0048,     -0.0143,      0.0000,\n",
      "            -0.0000,      0.0073,     -0.0061,      0.0095,     -0.0050,\n",
      "             0.0177,      0.0044,     -0.0007,      0.0160,      0.0006,\n",
      "            -0.0138,      0.0033,      0.0113,     -0.0078,     -0.0020,\n",
      "            -0.0000,      0.0046,     -0.0064,      0.0028,     -0.0137,\n",
      "            -0.0144,     -0.0155,      0.0131,     -0.0132,     -0.0102,\n",
      "             0.0069,      0.0172,      0.0036,     -0.0118,     -0.0155,\n",
      "            -0.0125,     -0.0106,      0.0056,      0.0085,     -0.0089,\n",
      "            -0.0058,      0.0029,     -0.0047,      0.0049,      0.0140,\n",
      "             0.0084,     -0.0064,      0.0040,     -0.0051,      0.0165,\n",
      "            -0.0079,     -0.0145,     -0.0152,      0.0082,     -0.0147,\n",
      "             0.0062,      0.0104,      0.0095,     -0.0024,     -0.0057,\n",
      "             0.0116,     -0.0016,     -0.0172,      0.0001,      0.0096,\n",
      "             0.0008,      0.0038,      0.0038,     -0.0118,      0.0158,\n",
      "            -0.0032,      0.0165,      0.0018,      0.0161,      0.0082,\n",
      "             0.0014,      0.0003,     -0.0072,     -0.0026,     -0.0113,\n",
      "             0.0150,     -0.0066,     -0.0011,     -0.0079,      0.0001,\n",
      "             0.0032,     -0.0045,      0.0074,     -0.0140,     -0.0113,\n",
      "            -0.0071,     -0.0132,     -0.0041,      0.0016,      0.0118,\n",
      "             0.0103,      0.0019,     -0.0024,     -0.0098,     -0.0168,\n",
      "             0.0136,     -0.0011,     -0.0009,      0.0134,      0.0009,\n",
      "             0.0052,     -0.0152,      0.0077,      0.0153,     -0.0084,\n",
      "             0.0151,     -0.0123,      0.0026,     -0.0114,     -0.0092,\n",
      "             0.0175,     -0.0024,     -0.0019], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0267, -0.0241, -0.0047,  ...,  0.0353,  0.0001, -0.0324],\n",
      "        [ 0.0244,  0.0179, -0.0080,  ...,  0.0357, -0.0134, -0.0182],\n",
      "        [-0.0348, -0.0255,  0.0295,  ...,  0.0307, -0.0291, -0.0337],\n",
      "        ...,\n",
      "        [-0.0060,  0.0057,  0.0321,  ...,  0.0144,  0.0184,  0.0345],\n",
      "        [-0.0305, -0.0261, -0.0274,  ...,  0.0226, -0.0161, -0.0217],\n",
      "        [ 0.0106,  0.0008,  0.0081,  ..., -0.0345, -0.0007,  0.0313]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0091, -0.0291, -0.0291,  ..., -0.0319,  0.0028, -0.0041],\n",
      "        [ 0.0341,  0.0066, -0.0184,  ...,  0.0033,  0.0324,  0.0202],\n",
      "        [-0.0153,  0.0086,  0.0200,  ..., -0.0089, -0.0207, -0.0193],\n",
      "        ...,\n",
      "        [ 0.0264, -0.0083,  0.0298,  ..., -0.0010, -0.0352,  0.0061],\n",
      "        [-0.0309,  0.0348, -0.0241,  ...,  0.0180,  0.0342, -0.0249],\n",
      "        [ 0.0211, -0.0018,  0.0169,  ..., -0.0175, -0.0210, -0.0135]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0135, -0.0099,  0.0116,  ...,  0.0176,  0.0195,  0.0209],\n",
      "        [-0.0123, -0.0190, -0.0011,  ..., -0.0018,  0.0128,  0.0140],\n",
      "        [-0.0054, -0.0165, -0.0340,  ..., -0.0048, -0.0305,  0.0310],\n",
      "        ...,\n",
      "        [-0.0265, -0.0210,  0.0150,  ..., -0.0166,  0.0277, -0.0233],\n",
      "        [-0.0118, -0.0217,  0.0245,  ...,  0.0225, -0.0325,  0.0343],\n",
      "        [-0.0253, -0.0156, -0.0124,  ...,  0.0104, -0.0250,  0.0313]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0057, -0.0111, -0.0034,  ...,  0.0313, -0.0079,  0.0130],\n",
      "        [ 0.0230, -0.0054,  0.0059,  ...,  0.0126, -0.0104,  0.0294],\n",
      "        [-0.0120,  0.0288,  0.0287,  ..., -0.0297, -0.0199,  0.0004],\n",
      "        ...,\n",
      "        [ 0.0209,  0.0216,  0.0117,  ..., -0.0160, -0.0330, -0.0244],\n",
      "        [-0.0142, -0.0260,  0.0244,  ..., -0.0011,  0.0302,  0.0045],\n",
      "        [ 0.0221, -0.0339, -0.0285,  ...,  0.0339,  0.0280,  0.0264]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([    -0.0334,      0.0206,     -0.0180,      0.0151,     -0.0049,\n",
      "             0.0112,     -0.0173,     -0.0258,     -0.0109,     -0.0241,\n",
      "            -0.0141,     -0.0177,      0.0084,      0.0184,     -0.0104,\n",
      "            -0.0132,     -0.0160,      0.0018,      0.0087,      0.0312,\n",
      "            -0.0285,     -0.0254,     -0.0291,     -0.0199,     -0.0228,\n",
      "             0.0260,     -0.0246,      0.0220,      0.0288,     -0.0092,\n",
      "            -0.0187,     -0.0254,      0.0271,     -0.0273,      0.0152,\n",
      "             0.0307,     -0.0226,      0.0037,     -0.0296,     -0.0195,\n",
      "            -0.0283,     -0.0337,      0.0292,     -0.0347,     -0.0076,\n",
      "            -0.0147,     -0.0299,      0.0167,     -0.0196,     -0.0256,\n",
      "            -0.0075,     -0.0040,      0.0069,     -0.0067,      0.0151,\n",
      "            -0.0261,      0.0239,      0.0039,      0.0301,     -0.0134,\n",
      "             0.0221,      0.0324,      0.0130,      0.0274,     -0.0335,\n",
      "            -0.0251,     -0.0267,     -0.0020,      0.0246,     -0.0149,\n",
      "             0.0135,      0.0242,      0.0066,      0.0248,     -0.0193,\n",
      "            -0.0063,      0.0163,      0.0090,      0.0206,     -0.0226,\n",
      "            -0.0027,      0.0124,     -0.0309,     -0.0290,     -0.0032,\n",
      "             0.0191,     -0.0284,      0.0214,      0.0163,      0.0251,\n",
      "            -0.0261,      0.0126,     -0.0146,      0.0220,     -0.0356,\n",
      "             0.0037,      0.0082,     -0.0331,      0.0070,      0.0358,\n",
      "            -0.0189,      0.0281,      0.0028,      0.0256,      0.0263,\n",
      "            -0.0127,     -0.0278,      0.0333,     -0.0070,     -0.0284,\n",
      "            -0.0024,     -0.0327,     -0.0209,      0.0353,     -0.0299,\n",
      "             0.0239,      0.0030,     -0.0155,     -0.0191,      0.0333,\n",
      "            -0.0080,     -0.0168,     -0.0102,      0.0154,     -0.0053,\n",
      "            -0.0090,      0.0307,      0.0352,     -0.0232,     -0.0063,\n",
      "             0.0296,      0.0174,     -0.0219,      0.0247,     -0.0283,\n",
      "            -0.0184,     -0.0249,     -0.0052,      0.0167,      0.0087,\n",
      "            -0.0002,     -0.0075,     -0.0157,     -0.0153,     -0.0106,\n",
      "            -0.0002,      0.0108,      0.0147,     -0.0101,      0.0066,\n",
      "            -0.0156,      0.0021,      0.0136,      0.0160,     -0.0020,\n",
      "            -0.0077,     -0.0056,     -0.0006,      0.0093,      0.0296,\n",
      "            -0.0154,      0.0143,      0.0196,     -0.0127,      0.0162,\n",
      "             0.0210,      0.0215,      0.0258,     -0.0342,      0.0155,\n",
      "            -0.0007,      0.0260,     -0.0068,      0.0079,      0.0077,\n",
      "            -0.0159,     -0.0250,     -0.0114,     -0.0260,      0.0271,\n",
      "             0.0173,     -0.0123,      0.0308,      0.0297,      0.0286,\n",
      "             0.0322,      0.0223,     -0.0296,      0.0036,      0.0275,\n",
      "            -0.0311,      0.0260,     -0.0205,     -0.0200,     -0.0142,\n",
      "             0.0314,     -0.0074,     -0.0018,     -0.0268,     -0.0129,\n",
      "            -0.0154,     -0.0151,     -0.0246,     -0.0010,     -0.0095,\n",
      "            -0.0056,      0.0133,      0.0058,     -0.0342,     -0.0155,\n",
      "            -0.0296,     -0.0072,      0.0310,     -0.0070,     -0.0196,\n",
      "            -0.0318,      0.0048,      0.0327,     -0.0306,      0.0293,\n",
      "            -0.0094,     -0.0100,     -0.0138,      0.0083,      0.0040,\n",
      "             0.0233,      0.0316,      0.0282,     -0.0352,      0.0276,\n",
      "            -0.0349,     -0.0128,     -0.0294,      0.0266,      0.0255,\n",
      "             0.0146,     -0.0020,     -0.0046,      0.0237,      0.0164,\n",
      "             0.0157,      0.0313,      0.0235,     -0.0171,      0.0329,\n",
      "            -0.0048,      0.0016,     -0.0177,     -0.0301,     -0.0077,\n",
      "             0.0310,      0.0223,     -0.0273,     -0.0313,     -0.0028,\n",
      "            -0.0088,      0.0126,      0.0100,     -0.0316,      0.0140,\n",
      "            -0.0249,      0.0008,      0.0221,      0.0299,     -0.0055,\n",
      "            -0.0270,     -0.0083,      0.0127,      0.0111,     -0.0139,\n",
      "            -0.0339,      0.0312,     -0.0112,      0.0169,      0.0090,\n",
      "            -0.0164,      0.0209,     -0.0247,     -0.0155,      0.0174,\n",
      "            -0.0323,      0.0030,     -0.0350,      0.0079,     -0.0084,\n",
      "            -0.0209,      0.0044,     -0.0280,     -0.0037,      0.0292,\n",
      "             0.0258,      0.0331,      0.0298,     -0.0066,     -0.0222,\n",
      "            -0.0351,      0.0286,      0.0108,     -0.0220,     -0.0224,\n",
      "             0.0274,      0.0190,      0.0054,      0.0192,      0.0172,\n",
      "            -0.0020,     -0.0350,     -0.0319,     -0.0299,     -0.0108,\n",
      "            -0.0247,     -0.0308,      0.0211,     -0.0336,     -0.0074,\n",
      "            -0.0238,     -0.0026,     -0.0306,      0.0046,     -0.0234,\n",
      "            -0.0249,     -0.0031,      0.0214,      0.0111,     -0.0115,\n",
      "            -0.0352,      0.0002,      0.0161,     -0.0321,      0.0129,\n",
      "            -0.0076,      0.0303,     -0.0149,     -0.0037,      0.0035,\n",
      "             0.0099,     -0.0057,      0.0273,      0.0035,     -0.0235,\n",
      "            -0.0358,     -0.0248,      0.0006,      0.0199,      0.0251,\n",
      "            -0.0151,     -0.0068,      0.0227,      0.0328,     -0.0310,\n",
      "            -0.0353,      0.0089,     -0.0124,      0.0319,      0.0218,\n",
      "            -0.0214,     -0.0096,      0.0044,     -0.0051,     -0.0190,\n",
      "             0.0212,      0.0068,     -0.0139,      0.0038,      0.0108,\n",
      "            -0.0062,     -0.0034,      0.0180,      0.0059,      0.0257,\n",
      "            -0.0326,      0.0161,      0.0120,     -0.0239,     -0.0285,\n",
      "            -0.0088,     -0.0135,      0.0307,      0.0029,     -0.0031,\n",
      "             0.0236,     -0.0183,      0.0094,      0.0188,     -0.0072,\n",
      "             0.0047,     -0.0309,     -0.0354,      0.0063,     -0.0039,\n",
      "            -0.0360,     -0.0243,     -0.0098,     -0.0142,      0.0250,\n",
      "            -0.0159,      0.0000,     -0.0054,     -0.0280,      0.0085,\n",
      "             0.0185,      0.0283,      0.0063,     -0.0248,      0.0258,\n",
      "             0.0165,      0.0134,     -0.0040,     -0.0171,      0.0259,\n",
      "             0.0170,      0.0276,      0.0021,     -0.0081,      0.0114,\n",
      "            -0.0167,      0.0089,      0.0297,     -0.0146,     -0.0209,\n",
      "            -0.0001,      0.0218,     -0.0051,     -0.0288,     -0.0090,\n",
      "             0.0160,     -0.0340,      0.0085,     -0.0231,     -0.0238,\n",
      "            -0.0276,      0.0337,      0.0126,      0.0089,     -0.0061,\n",
      "             0.0155,     -0.0037,     -0.0041,      0.0339,      0.0287,\n",
      "            -0.0306,      0.0012,      0.0253,      0.0304,      0.0301,\n",
      "            -0.0124,      0.0038,     -0.0244,     -0.0118,      0.0165,\n",
      "             0.0055,      0.0274,     -0.0273,     -0.0090,      0.0334,\n",
      "            -0.0326,     -0.0299,     -0.0014,      0.0209,     -0.0294,\n",
      "            -0.0222,      0.0092,     -0.0076,     -0.0175,      0.0306,\n",
      "             0.0106,      0.0041,      0.0107,      0.0264,      0.0078,\n",
      "             0.0215,      0.0300,     -0.0211,     -0.0347,     -0.0221,\n",
      "            -0.0324,      0.0217,     -0.0194,      0.0285,      0.0272,\n",
      "             0.0219,      0.0298,     -0.0348,     -0.0085,     -0.0279,\n",
      "             0.0071,     -0.0271,      0.0113,     -0.0162,     -0.0087,\n",
      "             0.0199,     -0.0316,     -0.0144,      0.0326,      0.0314,\n",
      "             0.0306,      0.0154,     -0.0204,      0.0322,     -0.0047,\n",
      "            -0.0309,     -0.0180,     -0.0155,     -0.0198,     -0.0164,\n",
      "            -0.0315,     -0.0273,     -0.0358,      0.0107,      0.0210,\n",
      "             0.0190,      0.0353,      0.0149,      0.0235,     -0.0039,\n",
      "            -0.0140,     -0.0086,     -0.0029,     -0.0182,     -0.0328,\n",
      "            -0.0346,     -0.0013,     -0.0344,      0.0086,     -0.0136,\n",
      "            -0.0233,     -0.0001,     -0.0140,      0.0195,      0.0125,\n",
      "            -0.0062,     -0.0308,     -0.0012,      0.0320,     -0.0235,\n",
      "            -0.0215,     -0.0210,      0.0262,      0.0096,     -0.0137,\n",
      "            -0.0170,      0.0316,      0.0107,     -0.0323,      0.0019,\n",
      "            -0.0212,      0.0180,      0.0208,      0.0338,      0.0345,\n",
      "             0.0343,     -0.0090,      0.0093,     -0.0257,     -0.0171,\n",
      "            -0.0210,      0.0075,     -0.0266,      0.0083,     -0.0029,\n",
      "            -0.0102,     -0.0186,     -0.0206,     -0.0302,     -0.0300,\n",
      "             0.0341,      0.0006,     -0.0178,      0.0076,     -0.0108,\n",
      "             0.0327,     -0.0118,     -0.0298,     -0.0223,      0.0219,\n",
      "            -0.0334,     -0.0356,      0.0270,      0.0197,      0.0166,\n",
      "             0.0334,      0.0153,     -0.0121,      0.0142,      0.0290,\n",
      "            -0.0097,     -0.0155,      0.0334,      0.0018,     -0.0214,\n",
      "             0.0234,      0.0085,     -0.0296,      0.0305,      0.0136,\n",
      "             0.0190,     -0.0011,     -0.0081,     -0.0038,     -0.0324,\n",
      "            -0.0271,     -0.0066,     -0.0227,     -0.0344,      0.0250,\n",
      "            -0.0324,     -0.0252,      0.0220,     -0.0319,     -0.0176,\n",
      "             0.0216,      0.0099,     -0.0245,      0.0148,      0.0203,\n",
      "            -0.0151,     -0.0038,      0.0060,     -0.0168,     -0.0165,\n",
      "            -0.0041,      0.0138,     -0.0252,     -0.0315,      0.0198,\n",
      "             0.0099,      0.0077,     -0.0289,     -0.0101,     -0.0314,\n",
      "            -0.0064,      0.0188,     -0.0033,     -0.0185,     -0.0241,\n",
      "            -0.0221,     -0.0223,      0.0216,      0.0134,      0.0224,\n",
      "            -0.0261,     -0.0141,     -0.0158,      0.0194,     -0.0210,\n",
      "            -0.0128,     -0.0344,     -0.0088,     -0.0061,      0.0011,\n",
      "            -0.0157,      0.0219,      0.0199,      0.0142,     -0.0046,\n",
      "            -0.0065,     -0.0272,     -0.0280,      0.0045,     -0.0098,\n",
      "             0.0198,     -0.0287,      0.0282,      0.0266,      0.0050,\n",
      "            -0.0067,     -0.0080,     -0.0280,     -0.0356,     -0.0088,\n",
      "            -0.0038,     -0.0201,     -0.0055,     -0.0285,      0.0106,\n",
      "             0.0021,     -0.0274,      0.0225,     -0.0340,      0.0065,\n",
      "             0.0087,     -0.0071,     -0.0160,      0.0032,      0.0141,\n",
      "            -0.0294,     -0.0128,      0.0066,      0.0296,      0.0049,\n",
      "            -0.0229,      0.0048,      0.0016,      0.0038,     -0.0136,\n",
      "            -0.0081,      0.0119,      0.0300,      0.0356,      0.0198,\n",
      "             0.0098,      0.0215,     -0.0238,      0.0089,      0.0212,\n",
      "             0.0109,      0.0217,     -0.0019,      0.0350,     -0.0118,\n",
      "             0.0260,      0.0134,      0.0068,      0.0114,      0.0154,\n",
      "            -0.0054,      0.0148,     -0.0240,     -0.0013,      0.0045,\n",
      "            -0.0306,     -0.0117,      0.0030,     -0.0149,     -0.0267,\n",
      "            -0.0016,      0.0057,     -0.0075,     -0.0018,     -0.0019,\n",
      "             0.0271,      0.0096,      0.0082,     -0.0006,     -0.0330,\n",
      "            -0.0218,      0.0200,     -0.0351,     -0.0091,      0.0315,\n",
      "            -0.0071,      0.0260,     -0.0157,     -0.0165,     -0.0177,\n",
      "            -0.0024,      0.0265,     -0.0199,      0.0122,     -0.0084,\n",
      "            -0.0277,     -0.0153,      0.0025,     -0.0060,      0.0000,\n",
      "            -0.0319,     -0.0083,      0.0011,      0.0155,     -0.0260,\n",
      "            -0.0114,      0.0310,      0.0071,      0.0334,     -0.0194,\n",
      "             0.0229,      0.0100,      0.0202], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0285, -0.0039,  0.0050,  ..., -0.0018,  0.0194,  0.0350],\n",
      "        [ 0.0298,  0.0020,  0.0075,  ...,  0.0126,  0.0287, -0.0051],\n",
      "        [-0.0247, -0.0033, -0.0356,  ..., -0.0017, -0.0261,  0.0342],\n",
      "        ...,\n",
      "        [ 0.0352, -0.0341, -0.0306,  ...,  0.0176,  0.0065, -0.0023],\n",
      "        [ 0.0171, -0.0291, -0.0094,  ...,  0.0072,  0.0271, -0.0135],\n",
      "        [-0.0224, -0.0081,  0.0150,  ...,  0.0009, -0.0121,  0.0258]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0211, -0.0315, -0.0354,  ...,  0.0121,  0.0119,  0.0035],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0120, -0.0017,  0.0146,  ..., -0.0113, -0.0042,  0.0144],\n",
      "        [-0.0180, -0.0088, -0.0120,  ...,  0.0041,  0.0089, -0.0136],\n",
      "        [ 0.0135,  0.0133, -0.0013,  ...,  0.0078,  0.0106,  0.0155],\n",
      "        ...,\n",
      "        [-0.0070, -0.0075, -0.0056,  ..., -0.0062,  0.0016, -0.0100],\n",
      "        [-0.0098,  0.0012, -0.0122,  ...,  0.0170, -0.0092,  0.0004],\n",
      "        [-0.0158,  0.0120,  0.0106,  ...,  0.0079, -0.0010, -0.0050]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([     0.0170,     -0.0034,      0.0103,      0.0023,     -0.0007,\n",
      "             0.0017,     -0.0065,     -0.0150,      0.0054,     -0.0123,\n",
      "             0.0173,     -0.0014,      0.0119,     -0.0160,      0.0126,\n",
      "            -0.0123,     -0.0179,      0.0081,      0.0179,     -0.0082,\n",
      "            -0.0068,     -0.0098,      0.0047,     -0.0157,      0.0025,\n",
      "            -0.0144,     -0.0016,     -0.0148,      0.0074,      0.0150,\n",
      "            -0.0091,     -0.0038,      0.0056,     -0.0021,      0.0102,\n",
      "             0.0066,     -0.0097,     -0.0076,      0.0165,     -0.0131,\n",
      "             0.0060,      0.0075,      0.0100,     -0.0172,     -0.0003,\n",
      "            -0.0069,     -0.0019,      0.0138,      0.0030,      0.0090,\n",
      "             0.0158,     -0.0102,     -0.0004,      0.0138,      0.0056,\n",
      "            -0.0053,     -0.0158,      0.0126,     -0.0135,      0.0175,\n",
      "            -0.0098,      0.0025,      0.0151,     -0.0005,      0.0021,\n",
      "             0.0117,      0.0179,      0.0079,     -0.0038,     -0.0125,\n",
      "             0.0119,      0.0035,      0.0047,     -0.0163,     -0.0152,\n",
      "             0.0103,     -0.0023,      0.0169,      0.0110,      0.0118,\n",
      "             0.0045,     -0.0018,     -0.0064,     -0.0100,      0.0028,\n",
      "             0.0164,      0.0147,     -0.0099,      0.0157,      0.0003,\n",
      "            -0.0161,      0.0113,     -0.0046,      0.0048,      0.0125,\n",
      "            -0.0062,     -0.0022,      0.0020,     -0.0132,      0.0121,\n",
      "            -0.0081,     -0.0152,      0.0045,     -0.0054,      0.0136,\n",
      "             0.0153,      0.0171,     -0.0126,     -0.0052,     -0.0082,\n",
      "             0.0046,     -0.0080,      0.0069,     -0.0058,      0.0005,\n",
      "            -0.0099,      0.0175,      0.0082,      0.0022,     -0.0114,\n",
      "             0.0079,     -0.0108,      0.0007,     -0.0162,      0.0017,\n",
      "            -0.0097,     -0.0064,     -0.0109,     -0.0166,     -0.0071,\n",
      "             0.0059,     -0.0051,     -0.0168,     -0.0162,     -0.0091,\n",
      "             0.0066,     -0.0094,      0.0041,      0.0171,     -0.0106,\n",
      "             0.0085,     -0.0029,      0.0041,     -0.0149,     -0.0056,\n",
      "            -0.0053,      0.0159,      0.0025,     -0.0090,     -0.0038,\n",
      "            -0.0120,     -0.0175,      0.0148,      0.0060,     -0.0129,\n",
      "             0.0123,      0.0140,     -0.0151,     -0.0022,     -0.0085,\n",
      "            -0.0074,      0.0099,      0.0101,     -0.0027,      0.0117,\n",
      "            -0.0065,     -0.0139,     -0.0063,     -0.0084,     -0.0149,\n",
      "             0.0043,      0.0173,      0.0090,      0.0142,     -0.0109,\n",
      "             0.0147,     -0.0066,     -0.0136,      0.0015,      0.0099,\n",
      "            -0.0018,     -0.0067,      0.0147,      0.0036,      0.0133,\n",
      "            -0.0079,     -0.0120,     -0.0104,      0.0087,      0.0022,\n",
      "             0.0103,      0.0170,     -0.0129,     -0.0026,      0.0150,\n",
      "            -0.0055,      0.0127,      0.0048,     -0.0051,      0.0023,\n",
      "            -0.0171,     -0.0007,      0.0155,     -0.0071,      0.0150,\n",
      "             0.0125,      0.0106,      0.0162,      0.0018,      0.0065,\n",
      "            -0.0148,     -0.0149,     -0.0152,      0.0073,     -0.0005,\n",
      "             0.0114,      0.0066,     -0.0096,     -0.0148,     -0.0010,\n",
      "             0.0108,      0.0122,     -0.0146,      0.0027,      0.0063,\n",
      "             0.0106,     -0.0132,      0.0056,      0.0132,      0.0086,\n",
      "             0.0102,     -0.0125,      0.0071,      0.0130,      0.0011,\n",
      "             0.0093,     -0.0041,      0.0154,     -0.0008,      0.0105,\n",
      "            -0.0057,     -0.0146,      0.0130,     -0.0090,     -0.0014,\n",
      "            -0.0153,      0.0124,      0.0087,      0.0024,      0.0036,\n",
      "             0.0016,     -0.0150,     -0.0047,     -0.0052,     -0.0136,\n",
      "            -0.0080,     -0.0082,     -0.0060,      0.0125,     -0.0051,\n",
      "            -0.0131,     -0.0016,      0.0066,     -0.0131,      0.0139,\n",
      "            -0.0050,      0.0171,     -0.0171,     -0.0041,      0.0107,\n",
      "             0.0030,      0.0165,      0.0027,      0.0030,      0.0067,\n",
      "            -0.0036,     -0.0116,      0.0168,     -0.0173,      0.0125,\n",
      "             0.0029,     -0.0069,      0.0136,      0.0108,      0.0052,\n",
      "             0.0010,      0.0115,     -0.0069,      0.0111,     -0.0129,\n",
      "            -0.0050,     -0.0052,     -0.0155,     -0.0127,      0.0153,\n",
      "             0.0173,     -0.0179,      0.0124,     -0.0147,     -0.0033,\n",
      "            -0.0017,      0.0109,      0.0005,     -0.0152,     -0.0030,\n",
      "             0.0030,      0.0141,      0.0007,     -0.0125,      0.0161,\n",
      "             0.0010,     -0.0078,     -0.0065,     -0.0075,      0.0126,\n",
      "             0.0093,     -0.0045,      0.0105,      0.0152,     -0.0079,\n",
      "            -0.0135,      0.0101,      0.0173,     -0.0169,      0.0165,\n",
      "             0.0130,     -0.0169,      0.0059,     -0.0094,     -0.0063,\n",
      "             0.0001,     -0.0089,     -0.0119,      0.0019,     -0.0126,\n",
      "            -0.0133,     -0.0059,     -0.0071,      0.0132,      0.0125,\n",
      "            -0.0096,     -0.0053,      0.0055,     -0.0168,     -0.0118,\n",
      "            -0.0062,      0.0092,      0.0104,      0.0166,      0.0022,\n",
      "            -0.0131,     -0.0014,      0.0104,     -0.0120,     -0.0153,\n",
      "             0.0169,      0.0054,     -0.0056,     -0.0012,      0.0054,\n",
      "             0.0040,      0.0094,      0.0017,      0.0016,      0.0024,\n",
      "             0.0122,     -0.0136,     -0.0152,     -0.0061,      0.0078,\n",
      "            -0.0112,     -0.0130,     -0.0016,     -0.0001,     -0.0026,\n",
      "            -0.0069,      0.0127,      0.0048,      0.0158,      0.0127,\n",
      "             0.0031,      0.0034,      0.0069,      0.0127,     -0.0175,\n",
      "            -0.0009,      0.0086,      0.0100,     -0.0119,      0.0037,\n",
      "            -0.0035,      0.0055,     -0.0039,     -0.0125,      0.0043,\n",
      "            -0.0084,     -0.0040,     -0.0022,      0.0177,      0.0123,\n",
      "             0.0062,     -0.0152,     -0.0064,     -0.0074,      0.0140,\n",
      "             0.0112,      0.0026,      0.0012,      0.0168,     -0.0173,\n",
      "            -0.0156,     -0.0024,      0.0170,     -0.0008,     -0.0035,\n",
      "             0.0051,     -0.0007,     -0.0088,     -0.0022,     -0.0177,\n",
      "            -0.0158,      0.0048,      0.0149,     -0.0008,      0.0053,\n",
      "             0.0060,      0.0118,      0.0016,     -0.0044,     -0.0046,\n",
      "             0.0165,      0.0034,      0.0069,     -0.0114,     -0.0148,\n",
      "            -0.0007,      0.0088,     -0.0010,     -0.0053,     -0.0158,\n",
      "             0.0027,     -0.0159,     -0.0001,     -0.0070,     -0.0065,\n",
      "            -0.0018,     -0.0002,     -0.0015,      0.0027,      0.0059,\n",
      "             0.0123,     -0.0112,     -0.0067,      0.0090,      0.0048,\n",
      "             0.0021,     -0.0019,     -0.0013,     -0.0172,     -0.0170,\n",
      "             0.0046,      0.0058,     -0.0042,      0.0135,      0.0053,\n",
      "            -0.0055,      0.0133,      0.0047,      0.0074,     -0.0157,\n",
      "             0.0047,      0.0094,      0.0169,      0.0086,      0.0019,\n",
      "             0.0101,     -0.0175,     -0.0066,      0.0036,     -0.0068,\n",
      "             0.0074,     -0.0118,     -0.0176,     -0.0145,      0.0094,\n",
      "            -0.0010,      0.0053,     -0.0113,      0.0165,     -0.0069,\n",
      "            -0.0030,      0.0034,      0.0027,      0.0061,      0.0160,\n",
      "             0.0180,     -0.0046,     -0.0079,      0.0014,      0.0100,\n",
      "            -0.0032,      0.0171,     -0.0004,     -0.0069,      0.0042,\n",
      "            -0.0141,      0.0062,     -0.0103,      0.0025,      0.0063,\n",
      "             0.0046,      0.0132,     -0.0110,      0.0072,      0.0069,\n",
      "             0.0017,     -0.0035,      0.0034,     -0.0124,     -0.0050,\n",
      "            -0.0048,      0.0126,     -0.0027,      0.0172,      0.0169,\n",
      "            -0.0173,      0.0035,     -0.0168,     -0.0065,      0.0117,\n",
      "            -0.0105,     -0.0014,      0.0002,     -0.0008,     -0.0048,\n",
      "             0.0177,     -0.0076,     -0.0111,     -0.0156,     -0.0096,\n",
      "             0.0112,      0.0030,      0.0035,      0.0174,      0.0089,\n",
      "            -0.0095,     -0.0115,      0.0114,     -0.0048,      0.0002,\n",
      "            -0.0083,      0.0119,      0.0148,      0.0085,      0.0009,\n",
      "            -0.0154,      0.0072,      0.0028,      0.0035,     -0.0012,\n",
      "             0.0169,      0.0023,     -0.0166,      0.0103,      0.0177,\n",
      "             0.0040,     -0.0139,     -0.0171,      0.0039,     -0.0115,\n",
      "            -0.0092,      0.0168,     -0.0043,      0.0047,      0.0120,\n",
      "            -0.0112,      0.0128,      0.0058,      0.0014,     -0.0153,\n",
      "            -0.0168,      0.0112,      0.0149,      0.0172,     -0.0174,\n",
      "             0.0059,      0.0144,      0.0171,      0.0053,      0.0151,\n",
      "            -0.0130,     -0.0115,      0.0164,     -0.0018,     -0.0015,\n",
      "            -0.0042,      0.0104,     -0.0151,      0.0127,     -0.0061,\n",
      "             0.0164,     -0.0017,     -0.0128,      0.0124,      0.0152,\n",
      "            -0.0162,      0.0098,     -0.0121,     -0.0040,      0.0127,\n",
      "            -0.0111,     -0.0030,     -0.0031,      0.0031,      0.0054,\n",
      "             0.0100,      0.0035,     -0.0047,     -0.0103,      0.0067,\n",
      "            -0.0076,     -0.0032,     -0.0060,     -0.0104,      0.0016,\n",
      "            -0.0168,     -0.0132,      0.0059,      0.0052,      0.0179,\n",
      "            -0.0161,     -0.0055,     -0.0167,      0.0097,     -0.0137,\n",
      "             0.0006,      0.0121,     -0.0109,     -0.0133,      0.0122,\n",
      "             0.0052,      0.0128,      0.0056,      0.0138,     -0.0147,\n",
      "             0.0033,      0.0144,     -0.0179,      0.0084,      0.0116,\n",
      "             0.0044,     -0.0029,     -0.0013,     -0.0112,     -0.0051,\n",
      "             0.0040,      0.0045,      0.0061,     -0.0033,     -0.0177,\n",
      "             0.0101,     -0.0131,      0.0139,      0.0123,      0.0179,\n",
      "             0.0117,      0.0144,     -0.0116,     -0.0020,     -0.0178,\n",
      "             0.0055,     -0.0141,      0.0098,     -0.0083,     -0.0091,\n",
      "             0.0025,     -0.0161,     -0.0018,      0.0173,      0.0066,\n",
      "            -0.0123,      0.0116,     -0.0123,     -0.0150,     -0.0022,\n",
      "            -0.0053,      0.0130,     -0.0125,     -0.0046,     -0.0174,\n",
      "             0.0107,     -0.0038,     -0.0075,     -0.0147,      0.0079,\n",
      "             0.0049,     -0.0055,     -0.0069,     -0.0158,     -0.0037,\n",
      "             0.0065,      0.0171,     -0.0097,      0.0061,      0.0060,\n",
      "            -0.0039,      0.0136,     -0.0051,      0.0028,     -0.0133,\n",
      "             0.0101,      0.0169,     -0.0169,      0.0087,      0.0021,\n",
      "            -0.0009,      0.0116,     -0.0130,      0.0046,      0.0098,\n",
      "             0.0083,     -0.0165,     -0.0136,     -0.0065,     -0.0047,\n",
      "             0.0022,      0.0093,     -0.0179,     -0.0083,      0.0005,\n",
      "            -0.0142,     -0.0143,     -0.0112,      0.0071,      0.0049,\n",
      "            -0.0077,      0.0124,     -0.0032,     -0.0079,     -0.0157,\n",
      "             0.0155,     -0.0141,     -0.0057,      0.0118,      0.0127,\n",
      "             0.0121,     -0.0086,      0.0137,      0.0109,      0.0175,\n",
      "             0.0028,     -0.0046,     -0.0129,      0.0133,     -0.0081,\n",
      "             0.0003,      0.0090,     -0.0005,     -0.0000,      0.0059,\n",
      "            -0.0090,      0.0050,     -0.0074,      0.0159,     -0.0144,\n",
      "             0.0106,      0.0011,      0.0043], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0285, -0.0213, -0.0034,  ..., -0.0159, -0.0043,  0.0227],\n",
      "        [-0.0090,  0.0048,  0.0121,  ..., -0.0220,  0.0038, -0.0318],\n",
      "        [-0.0103,  0.0039, -0.0092,  ..., -0.0114,  0.0248, -0.0098],\n",
      "        ...,\n",
      "        [ 0.0215,  0.0308,  0.0179,  ..., -0.0082,  0.0008,  0.0009],\n",
      "        [-0.0086, -0.0013, -0.0033,  ...,  0.0252, -0.0020, -0.0306],\n",
      "        [-0.0196, -0.0231, -0.0189,  ...,  0.0063, -0.0185,  0.0124]],\n",
      "       requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(type(model))  # Ensure it's a `torch.nn.Module`\n",
    "print(model)        # Display model structure\n",
    "print(list(model.parameters()))  # Ensure it returns a valid parameter list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "a66acb76-a6da-4179-b468-df9bf0e4e6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.3.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch._dynamo' has no attribute 'disable' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[313], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m GPTModel(GPT_CONFIG_124M)\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 15\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0004\u001b[39m)\n\u001b[1;32m     17\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     18\u001b[0m train_losses, val_losses, tokens_seen \u001b[38;5;241m=\u001b[39m train_model_simple(\n\u001b[1;32m     19\u001b[0m     model, train_loader, val_loader, optimizer, device,\n\u001b[1;32m     20\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs, eval_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, eval_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     21\u001b[0m     start_context\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvery effort moves you\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:45\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39mbetas, eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m     42\u001b[0m                 weight_decay\u001b[38;5;241m=\u001b[39mweight_decay, amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m     43\u001b[0m                 maximize\u001b[38;5;241m=\u001b[39mmaximize, foreach\u001b[38;5;241m=\u001b[39mforeach, capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m     44\u001b[0m                 differentiable\u001b[38;5;241m=\u001b[39mdifferentiable, fused\u001b[38;5;241m=\u001b[39mfused)\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(params, defaults)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:284\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    281\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_param_group(cast(\u001b[38;5;28mdict\u001b[39m, param_group))\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/_compile.py:22\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/_dynamo/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:40\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_python_dispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _disable_current_modes\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traceback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m format_traceback_short\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, exc, trace_rules\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompilerFn\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m remove_dead_code, remove_pointless_jumps\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/_dynamo/trace_rules.py:50\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _config_module\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getfile, hashable, NP_SUPPORTED_MODULES, unwrap_if_wrapper\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     51\u001b[0m     BuiltinVariable,\n\u001b[1;32m     52\u001b[0m     FunctorchHigherOrderVariable,\n\u001b[1;32m     53\u001b[0m     NestedUserFunctionVariable,\n\u001b[1;32m     54\u001b[0m     SkipFunctionVariable,\n\u001b[1;32m     55\u001b[0m     TorchInGraphFunctionVariable,\n\u001b[1;32m     56\u001b[0m     UserFunctionVariable,\n\u001b[1;32m     57\u001b[0m     UserMethodVariable,\n\u001b[1;32m     58\u001b[0m )\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03mMap of function objects to their tracing rules (Dynamo variables).\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m* TorchInGraphFunctionVariable: The functions should be put into the FX graph or can be constant folded. E.g.,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/_dynamo/variables/__init__.py:34\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackwardHookVariable\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     FunctoolsPartialVariable,\n\u001b[1;32m     29\u001b[0m     NestedUserFunctionVariable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     UserMethodVariable,\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhigher_order_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     35\u001b[0m     FunctorchHigherOrderVariable,\n\u001b[1;32m     36\u001b[0m     TorchHigherOrderOperatorVariable,\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m     CountIteratorVariable,\n\u001b[1;32m     40\u001b[0m     CycleIteratorVariable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     RepeatIteratorVariable,\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyVariableTracker\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/_dynamo/variables/higher_order_ops.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moperators\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy_to_fake_tensor, get_fake_value, get_real_value\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/onnx/__init__.py:46\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CheckerError  \u001b[38;5;66;03m# Backwards compatibility\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     35\u001b[0m     _optimize_graph,\n\u001b[1;32m     36\u001b[0m     _run_symbolic_function,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     unregister_custom_op_symbolic,\n\u001b[1;32m     44\u001b[0m )\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexporter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort:skip. needs to be last to avoid circular import\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     DiagnosticOptions,\n\u001b[1;32m     48\u001b[0m     ExportOptions,\n\u001b[1;32m     49\u001b[0m     ONNXProgram,\n\u001b[1;32m     50\u001b[0m     ONNXProgramSerializer,\n\u001b[1;32m     51\u001b[0m     ONNXRuntimeOptions,\n\u001b[1;32m     52\u001b[0m     InvalidExportOptionsError,\n\u001b[1;32m     53\u001b[0m     OnnxExporterError,\n\u001b[1;32m     54\u001b[0m     OnnxRegistry,\n\u001b[1;32m     55\u001b[0m     dynamo_export,\n\u001b[1;32m     56\u001b[0m     enable_fake_mode,\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnxruntime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     60\u001b[0m     is_onnxrt_backend_supported,\n\u001b[1;32m     61\u001b[0m     OrtBackend \u001b[38;5;28;01mas\u001b[39;00m _OrtBackend,\n\u001b[1;32m     62\u001b[0m     OrtBackendOptions \u001b[38;5;28;01mas\u001b[39;00m _OrtBackendOptions,\n\u001b[1;32m     63\u001b[0m     OrtExecutionProvider \u001b[38;5;28;01mas\u001b[39;00m _OrtExecutionProvider,\n\u001b[1;32m     64\u001b[0m )\n\u001b[1;32m     66\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# Modules\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbolic_helper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_onnxrt_backend_supported\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    115\u001b[0m ]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/onnx/_internal/exporter/__init__.py:13\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mONNXRegistry\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mONNXProgram\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverification\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m ]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _testing \u001b[38;5;28;01mas\u001b[39;00m testing, _verification \u001b[38;5;28;01mas\u001b[39;00m verification\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m analyze\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export_compat\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export, exported_program_to_ir\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/onnx/_internal/exporter/_analysis.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_export\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserde\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graph_signature\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexporter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _dispatching, _registration\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/_export/__init__.py:40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m log_export_usage\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tree_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reorder_kwargs\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_unlift\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _create_stateful_graph_module\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_shapes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     42\u001b[0m     _process_constraints,\n\u001b[1;32m     43\u001b[0m     _process_dynamic_shapes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     dynamic_dim,\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexported_program\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     49\u001b[0m     _disable_prexisiting_fake_mode,\n\u001b[1;32m     50\u001b[0m     ExportedProgram,\n\u001b[1;32m     51\u001b[0m     ModuleCallEntry,\n\u001b[1;32m     52\u001b[0m     ModuleCallSignature,\n\u001b[1;32m     53\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/export/_unlift.py:20\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_remove_effect_tokens_pass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _remove_effect_tokens\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexported_program\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     ExportedProgram,\n\u001b[1;32m     14\u001b[0m     ExportGraphSignature,\n\u001b[1;32m     15\u001b[0m     InputKind,\n\u001b[1;32m     16\u001b[0m     OutputKind,\n\u001b[1;32m     17\u001b[0m )\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_input_constraints_pre_hook\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     flat_args_with_path, received_spec \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_flatten_with_path(args)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m received_spec \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_spec:\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torch._dynamo' has no attribute 'disable' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Add debugging prints\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "# Make sure GPTModel is properly defined and not causing import issues\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0004)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebba008-fee8-4a24-94c2-3a1b7d7e1858",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(torch._dynamo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662d8431-7e4f-45a4-a934-872d50cd571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765165eb-46d2-4bb2-8c4d-f312a4c62e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TORCH_COMPILE\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0f66c-15e2-4cef-b545-8e5129f57470",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "ff723149-1b4c-4f8c-b562-00ce4f5db87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error initializing optimizer: partially initialized module 'torch._dynamo' has no attribute 'disable' (most likely due to a circular import)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TORCH_COMPILE\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Simple model\n",
    "model = nn.Linear(10, 10).to(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Optimizer\n",
    "try:\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "    print(\"Optimizer initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing optimizer: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc5c200-f1a4-4032-b1bf-1c270362dfdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
